{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q parlai","metadata":{"execution":{"iopub.status.busy":"2022-12-03T21:13:51.776308Z","iopub.execute_input":"2022-12-03T21:13:51.777651Z","iopub.status.idle":"2022-12-03T21:14:54.913220Z","shell.execute_reply.started":"2022-12-03T21:13:51.777540Z","shell.execute_reply":"2022-12-03T21:14:54.912030Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\ndask-cudf 21.10.1 requires cupy-cuda114, which is not installed.\nbeatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\nvirtualenv 20.16.5 requires importlib-metadata>=4.8.3; python_version < \"3.8\", but you have importlib-metadata 4.2.0 which is incompatible.\ntfx-bsl 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\ntensorflow 2.6.4 requires h5py~=3.1.0, but you have h5py 3.7.0 which is incompatible.\ntensorflow 2.6.4 requires numpy~=1.19.2, but you have numpy 1.21.0 which is incompatible.\ntensorflow 2.6.4 requires tensorboard<2.7,>=2.6.0, but you have tensorboard 2.10.1 which is incompatible.\ntensorflow 2.6.4 requires typing-extensions<3.11,>=3.7, but you have typing-extensions 4.1.1 which is incompatible.\ntensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\ntensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.6.4 which is incompatible.\npytoolconfig 1.2.2 requires tomli>=2.0; python_version < \"3.11\", but you have tomli 1.2.3 which is incompatible.\npdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.5.3 which is incompatible.\npandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\nnnabla 1.31.0 requires protobuf<=3.19.4; platform_system != \"Windows\", but you have protobuf 3.19.6 which is incompatible.\nmdit-py-plugins 0.3.0 requires markdown-it-py<3.0.0,>=1.0.0, but you have markdown-it-py 0.5.8 which is incompatible.\njupytext 1.13.8 requires markdown-it-py<3.0.0,>=1.0.0, but you have markdown-it-py 0.5.8 which is incompatible.\ngym 0.26.2 requires importlib-metadata>=4.8.0; python_version < \"3.10\", but you have importlib-metadata 4.2.0 which is incompatible.\ngrpcio-status 1.47.0 requires grpcio>=1.47.0, but you have grpcio 1.43.0 which is incompatible.\ngcsfs 2022.5.0 requires fsspec==2022.5.0, but you have fsspec 2022.8.2 which is incompatible.\ndask-cudf 21.10.1 requires dask==2021.09.1, but you have dask 2022.2.0 which is incompatible.\ndask-cudf 21.10.1 requires distributed==2021.09.1, but you have distributed 2022.2.0 which is incompatible.\napache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\nallennlp 2.10.1 requires numpy>=1.21.4, but you have numpy 1.21.0 which is incompatible.\naiobotocore 2.4.0 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.27.93 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Actual work prev1corr1type1","metadata":{}},{"cell_type":"markdown","source":"run 1","metadata":{}},{"cell_type":"code","source":"# run 1 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type1/run1/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model1","metadata":{"execution":{"iopub.status.busy":"2022-12-03T21:15:03.050208Z","iopub.execute_input":"2022-12-03T21:15:03.050649Z","iopub.status.idle":"2022-12-03T21:30:46.693229Z","shell.execute_reply.started":"2022-12-03T21:15:03.050610Z","shell.execute_reply":"2022-12-03T21:30:46.691373Z"},"scrolled":true,"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"21:15:24 | building data: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/pretrained_transformers.tgz\n21:15:24 | Downloading http://parl.ai/downloads/_models/pretrained_transformers/pretrained_transformers.tgz to /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/pretrained_transformers.tgz\nDownloading pretrained_transformers.tgz: 100%|â–ˆ| 4.22G/4.22G [01:18<00:00, 53.7M\n21:19:17 | building dictionary first...\n21:19:17 | No model with opt yet at: /tmp/model1(.opt)\n21:19:17 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type1/run1/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n21:19:17 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n21:19:17 | Using CUDA\n21:19:17 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n21:19:18 | num words = 54944\n21:19:24 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n21:19:43 | Total parameters: 128,042,498 (128,042,498 trainable)\n21:19:43 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n21:19:43 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n21:19:43 | Opt:\n21:19:43 |     activation: gelu\n21:19:43 |     adafactor_eps: '(1e-30, 0.001)'\n21:19:43 |     adam_eps: 1e-08\n21:19:43 |     add_p1_after_newln: False\n21:19:43 |     aggregate_micro: False\n21:19:43 |     allow_missing_init_opts: False\n21:19:43 |     attention_dropout: 0.1\n21:19:43 |     batchsize: 20\n21:19:43 |     betas: '(0.9, 0.999)'\n21:19:43 |     bpe_add_prefix_space: None\n21:19:43 |     bpe_debug: False\n21:19:43 |     bpe_dropout: None\n21:19:43 |     bpe_merge: None\n21:19:43 |     bpe_vocab: None\n21:19:43 |     candidates: inline\n21:19:43 |     cap_num_predictions: 100\n21:19:43 |     checkpoint_activations: False\n21:19:43 |     class_weights: None\n21:19:43 |     classes: \"['__notok__', '__ok__']\"\n21:19:43 |     classes_from_file: None\n21:19:43 |     data_parallel: True\n21:19:43 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n21:19:43 |     datatype: train\n21:19:43 |     delimiter: '\\n'\n21:19:43 |     dict_class: parlai.core.dict:DictionaryAgent\n21:19:43 |     dict_endtoken: __start__\n21:19:43 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n21:19:43 |     dict_include_test: False\n21:19:43 |     dict_include_valid: False\n21:19:43 |     dict_initpath: None\n21:19:43 |     dict_language: english\n21:19:43 |     dict_loaded: True\n21:19:43 |     dict_lower: True\n21:19:43 |     dict_max_ngram_size: -1\n21:19:43 |     dict_maxexs: -1\n21:19:43 |     dict_maxtokens: -1\n21:19:43 |     dict_minfreq: 0\n21:19:43 |     dict_nulltoken: __null__\n21:19:43 |     dict_starttoken: __start__\n21:19:43 |     dict_textfields: text,labels\n21:19:43 |     dict_tokenizer: bpe\n21:19:43 |     dict_unktoken: __unk__\n21:19:43 |     display_examples: False\n21:19:43 |     download_path: None\n21:19:43 |     dropout: 0.1\n21:19:43 |     dynamic_batching: None\n21:19:43 |     embedding_projection: random\n21:19:43 |     embedding_size: 768\n21:19:43 |     embedding_type: random\n21:19:43 |     embeddings_scale: False\n21:19:43 |     encode_candidate_vecs: True\n21:19:43 |     encode_candidate_vecs_batchsize: 256\n21:19:43 |     eval_batchsize: None\n21:19:43 |     eval_candidates: inline\n21:19:43 |     eval_dynamic_batching: None\n21:19:43 |     evaltask: None\n21:19:43 |     ffn_size: 3072\n21:19:43 |     final_extra_opt: \n21:19:43 |     fixed_candidate_vecs: reuse\n21:19:43 |     fixed_candidates_path: None\n21:19:43 |     force_fp16_tokens: False\n21:19:43 |     fp16: True\n21:19:43 |     fp16_impl: safe\n21:19:43 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type1/run1/data\n21:19:43 |     fromfile_datatype_extension: True\n21:19:43 |     gpu: -1\n21:19:43 |     gradient_clip: 0.1\n21:19:43 |     hide_labels: False\n21:19:43 |     history_add_global_end_token: None\n21:19:43 |     history_reversed: False\n21:19:43 |     history_size: 20\n21:19:43 |     ignore_bad_candidates: False\n21:19:43 |     ignore_labels: None\n21:19:43 |     image_cropsize: 224\n21:19:43 |     image_mode: raw\n21:19:43 |     image_size: 256\n21:19:43 |     inference: max\n21:19:43 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n21:19:43 |     init_opt: None\n21:19:43 |     interactive_candidates: fixed\n21:19:43 |     interactive_mode: False\n21:19:43 |     invsqrt_lr_decay_gamma: -1\n21:19:43 |     is_debug: False\n21:19:43 |     label_truncate: 72\n21:19:43 |     learn_embeddings: True\n21:19:43 |     learn_positional_embeddings: True\n21:19:43 |     learningrate: 5e-05\n21:19:43 |     load_from_checkpoint: False\n21:19:43 |     load_from_pretrained_ranker: True\n21:19:43 |     log_every_n_secs: 10.0\n21:19:43 |     log_every_n_steps: 50\n21:19:43 |     log_keep_fields: all\n21:19:43 |     loglevel: info\n21:19:43 |     lr_scheduler: reduceonplateau\n21:19:43 |     lr_scheduler_decay: 0.5\n21:19:43 |     lr_scheduler_patience: 3\n21:19:43 |     max_train_steps: -1\n21:19:43 |     max_train_time: 7200.0\n21:19:43 |     memory_attention: sqrt\n21:19:43 |     metrics: default\n21:19:43 |     model: transformer/classifier\n21:19:43 |     model_file: /tmp/model1\n21:19:43 |     model_parallel: False\n21:19:43 |     momentum: 0\n21:19:43 |     multitask_weights: [1]\n21:19:43 |     mutators: None\n21:19:43 |     n_decoder_layers: -1\n21:19:43 |     n_encoder_layers: -1\n21:19:43 |     n_heads: 12\n21:19:43 |     n_layers: 12\n21:19:43 |     n_positions: 1024\n21:19:43 |     n_segments: 2\n21:19:43 |     nesterov: True\n21:19:43 |     no_cuda: False\n21:19:43 |     normalize_sent_emb: False\n21:19:43 |     num_epochs: -1\n21:19:43 |     num_workers: 0\n21:19:43 |     nus: (0.7,)\n21:19:43 |     optimizer: adamax\n21:19:43 |     output_scaling: 0.06\n21:19:43 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type1/run1/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model1'}\"\n21:19:43 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n21:19:43 |     person_tokens: False\n21:19:43 |     print_scores: False\n21:19:43 |     rank_candidates: False\n21:19:43 |     rank_top_k: -1\n21:19:43 |     reduction_type: mean\n21:19:43 |     ref_class: None\n21:19:43 |     relu_dropout: 0.0\n21:19:43 |     repeat_blocking_heuristic: True\n21:19:43 |     return_cand_scores: False\n21:19:43 |     save_after_valid: True\n21:19:43 |     save_every_n_secs: -1\n21:19:43 |     save_format: conversations\n21:19:43 |     share_encoders: False\n21:19:43 |     share_word_embeddings: False\n21:19:43 |     short_final_eval: False\n21:19:43 |     special_tok_lst: None\n21:19:43 |     split_lines: False\n21:19:43 |     starttime: Dec03_21-19\n21:19:43 |     task: fromfile:parlaiformat\n21:19:43 |     tensorboard_log: False\n21:19:43 |     tensorboard_logdir: None\n21:19:43 |     text_truncate: 360\n21:19:43 |     threshold: 0.5\n21:19:43 |     topk: 5\n21:19:43 |     train_predict: False\n21:19:43 |     truncate: 1024\n21:19:43 |     update_classifier_head_only: False\n21:19:43 |     update_freq: 1\n21:19:43 |     use_memories: False\n21:19:43 |     use_reply: none\n21:19:43 |     validation_cutoff: 1.0\n21:19:43 |     validation_every_n_epochs: -1\n21:19:43 |     validation_every_n_secs: 20.0\n21:19:43 |     validation_every_n_steps: -1\n21:19:43 |     validation_max_exs: -1\n21:19:43 |     validation_metric: accuracy\n21:19:43 |     validation_metric_mode: max\n21:19:43 |     validation_patience: 30\n21:19:43 |     validation_share_agent: False\n21:19:43 |     variant: xlm\n21:19:43 |     verbose: False\n21:19:43 |     wandb_entity: None\n21:19:43 |     wandb_log: False\n21:19:43 |     wandb_name: None\n21:19:43 |     wandb_project: None\n21:19:43 |     warmup_rate: 0.0001\n21:19:43 |     warmup_updates: 1000\n21:19:43 |     weight_decay: None\n21:19:43 |     world_logs: \n21:19:43 |     wrap_memory_encoder: False\n21:19:44 | creating task(s): fromfile:parlaiformat\n21:19:44 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run1/data_train.txt\n21:19:44 | training...\n21:19:55 | time:10s total_exs:260 total_steps:13 epochs:1.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5654 5.654e-10               .5534                 .5469   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5600            .5768              .5833   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .5704 11.34     1 266.8 348.3       0          0 26.02  260   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5654             32768  2.549    .1189 5.962 .6865 6.549e-07 119.2 155.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   13 386.1  504 1.308        .5655\n\n21:20:04 | time:20s total_exs:1000 total_steps:50 epochs:5.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6581 6.581e-10               .6576                 .6463   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6694            .6586              .6703   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6472 10.98     1 259.5  1056       0          0  81.4  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6581             32768  2.743    .1189 5.981 .6615 2.505e-06 119.6 486.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                   50 379.1 1543 4.08        .6581\n\n21:20:04 | creating task(s): fromfile:parlaiformat\n21:20:04 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run1/data_valid.txt\n21:20:04 | running eval: valid\n21:20:04 | eval completed in 0.19s\n21:20:04 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1913       0          0 142.1   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6246 2.505e-06    72 852.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     50 233.5 2766        .8748\n\u001b[0m\n21:20:04 | \u001b[1;32mnew best accuracy: 0.875\u001b[0m\n21:20:04 | saving best valid model: /tmp/model1\n21:20:04 | Saving dictionary to /tmp/model1.dict\n21:20:09 | saving model checkpoint: /tmp/model1.checkpoint\n21:20:09 | Saving dictionary to /tmp/model1.checkpoint.dict\n21:20:27 | time:43s total_exs:1700 total_steps:85 epochs:8.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8357 8.357e-10               .8387                 .8592   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8192            .8326              .8125   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8537 10.71     1 254.3 877.2       0          0 68.99  700   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8357             32768  2.911    .1189 6.043 .6064 4.255e-06 120.9 416.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   85 375.1 1294 3.458        .8358\n\n21:20:29 | time:45s total_exs:1880 total_steps:94 epochs:9.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9111 9.111e-10               .9208                 .9588   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8857            .8987              .8554   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9467 10.78     1 255.6 989.3       0          0 77.43  180   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9111             32768  3.311    .1189 6.167 .5437 4.705e-06 123.3 477.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   94 378.9 1467 3.909        .9116\n\n21:20:29 | running eval: valid\n21:20:29 | eval completed in 0.18s\n21:20:29 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  2025       0          0 150.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5544 4.705e-06    72 902.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     94 233.5 2927        .8748\n\u001b[0m\n21:20:29 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 1\u001b[0m\n21:20:29 | saving model checkpoint: /tmp/model1.checkpoint\n21:20:49 | time:65s total_exs:2660 total_steps:133 epochs:13.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9154 9.154e-10               .9229                 .8957   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9518            .9062              .9410   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8740  11.3     1   266  1032       0          0 77.62  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9154             32768  4.238    .1189 6.064 .4369 6.654e-06 121.3 470.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  133 387.3 1503 3.89        .9151\n\n21:20:49 | time:65s total_exs:2680 total_steps:134 epochs:13.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9500 9.5e-10               .9474                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9000            .9524              .9091   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.3     1   266  1139       0          0 85.58   20   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9500             32768  7.216    .1189     6 .3418 6.704e-06   120 513.6   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  134  386 1652 4.734        .9499\n\n21:20:49 | running eval: valid\n21:20:50 | eval completed in 0.19s\n21:20:50 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1918       0          0 142.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .4377 6.704e-06    72 855.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    134 233.5 2773        .8748\n\u001b[0m\n21:20:50 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 2\u001b[0m\n21:20:50 | saving model checkpoint: /tmp/model1.checkpoint\n21:21:05 | time:81s total_exs:3460 total_steps:173 epochs:17.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9654 9.654e-10               .9679                 .9760   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9599            .9624              .9532   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9719 10.77     1 255.3 980.4       0          0 76.79  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9654             32768  4.757    .1189 6.087 .2072 8.654e-06 121.7 467.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  173 377.1 1448 3.849        .9654\n\n21:21:10 | time:86s total_exs:3860 total_steps:193 epochs:19.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9800 9.8e-10               .9804                 .9950   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9662            .9796              .9648   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9948 11.03     1 260.6  1068       0          0 81.97  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9800             32768  4.099    .1190 6.035 .09279 9.654e-06 120.7 494.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  193 381.2 1563 4.115        .9800\n\n21:21:10 | running eval: valid\n21:21:10 | eval completed in 0.19s\n21:21:10 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1913       0          0 142.1   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .4025 9.654e-06    72   853       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    193 233.5 2767        .8748\n\u001b[0m\n21:21:10 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 3\u001b[0m\n21:21:10 | saving model checkpoint: /tmp/model1.checkpoint\n21:21:25 | time:101s total_exs:4640 total_steps:232 epochs:23.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9897 9.897e-10               .9896                 .9896   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9896            .9899              .9899   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9899 11.19 .9744 263.7  1014       0          0 76.91  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9897             32768  3.541    .1190 5.985 .04456 1.16e-05 119.7 460.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  232 383.4 1474 3.854        .9897\n\n21:21:30 | time:106s total_exs:5080 total_steps:254 epochs:25.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9977 9.977e-10               .9979                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9959            .9975              .9950   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.17 .3182 263.4  1071       0          0 81.35  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9977             32768  .3222    .1190   6.1 .01639 1.27e-05   122 496.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  254 385.4 1567 4.084        .9977\n\n21:21:30 | running eval: valid\n21:21:30 | eval completed in 0.18s\n21:21:30 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1989       0          0 147.8   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .7547 1.27e-05    72 886.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    254 233.5 2876        .8748\n\u001b[0m\n21:21:30 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 4\u001b[0m\n21:21:30 | saving model checkpoint: /tmp/model1.checkpoint\n21:21:45 | time:121s total_exs:5880 total_steps:294 epochs:29.40\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9950 9.95e-10               .9953                 .9976   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9930            .9947              .9920   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9973 10.99 .2000 259.8  1039       0          0 79.96  800   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9950             32768  8.077    .1190 6.067 .02212 1.47e-05 121.3 485.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  294 381.1 1524 4.001        .9950\n\n21:21:50 | time:126s total_exs:6320 total_steps:316 epochs:31.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.37 .09091 267.5  1069       0          0 79.96   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  \\\n    440   1             32768 .04931    .1190 6.095 .001578 1.58e-05 121.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   487.4       0          0                  316 389.4 1557 4.015            1\n\n21:21:50 | running eval: valid\n21:21:51 | eval completed in 0.18s\n21:21:51 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8000                 .7692   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7826              .8182   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.46 161.5  2000       0          0 148.6   24 .7917   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 1.159 1.58e-05    72 891.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    316 233.5 2892        .7913\n\u001b[0m\n21:21:51 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 5\u001b[0m\n21:21:51 | saving model checkpoint: /tmp/model1.checkpoint\n21:22:05 | time:141s total_exs:7120 total_steps:356 epochs:35.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.1 .0250 261.9  1029       0          0 78.59  800   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .02647    .1190 6.055 .001275 1.78e-05 121.1 475.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  356 383.1 1505 3.939            1\n\n21:22:11 | time:147s total_exs:7540 total_steps:377 epochs:37.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.95     0 259.1  1033       0          0 79.77  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01328    .1190 5.895 .001111 1.885e-05 117.9 470.3   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  377  377 1504 4.006            1\n\n21:22:11 | running eval: valid\n21:22:11 | eval completed in 0.18s\n21:22:11 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  2006       0          0   149   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 .9192 1.885e-05    72 894.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    377 233.5 2901        .8748\n\u001b[0m\n21:22:11 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 6\u001b[0m\n21:22:11 | saving model checkpoint: /tmp/model1.checkpoint\n21:22:26 | time:162s total_exs:8320 total_steps:416 epochs:41.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.28     0 265.6  1017       0          0 76.59  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .01202    .1190 6.028 .001007 2.08e-05 120.6 461.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  416 386.2 1479 3.838            1\n\n21:22:31 | time:167s total_exs:8720 total_steps:436 epochs:43.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.05     0 260.9 993.8       0          0 76.17  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .01104    .1190  6.05 .0009365 2.18e-05   121 460.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  436 381.9 1455 3.825            1\n\n21:22:31 | running eval: valid\n21:22:31 | eval completed in 0.19s\n21:22:31 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1945       0          0 144.4   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08095     6 .9187 2.18e-05    72   867       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    436 233.5 2812        .8748\n\u001b[0m\n21:22:31 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 7\u001b[0m\n21:22:31 | saving model checkpoint: /tmp/model1.checkpoint\n21:22:46 | time:182s total_exs:9500 total_steps:475 epochs:47.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.27     0 265.5  1021       0          0 76.89  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01024    .1190 6.008 .0008767 2.375e-05 120.2 461.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  475 385.6 1483 3.853            1\n\n21:22:51 | time:187s total_exs:9960 total_steps:498 epochs:49.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.21     0 264.2  1070       0          0 81.01  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .009631    .1190 6.026 .0008214 2.49e-05 120.5 488.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  498 384.7 1558 4.067            1\n\n21:22:51 | running eval: valid\n21:22:52 | eval completed in 0.20s\n21:22:52 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1881       0          0 139.5   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 .9346 2.49e-05    72 838.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    498 233.5 2720        .8748\n\u001b[0m\n21:22:52 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 8\u001b[0m\n21:22:52 | saving model checkpoint: /tmp/model1.checkpoint\n21:23:06 | time:202s total_exs:10740 total_steps:537 epochs:53.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.98     0 259.6  1012       0          0 77.97  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .009043    .1190 6.026 .0007734 2.685e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   469.8       0          0                  537 380.1 1482 3.907            1\n\n21:23:12 | time:208s total_exs:11200 total_steps:560 epochs:56.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.32     0 266.3  1096       0          0 82.29  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss      lr  ltpb  ltps  \\\n     1             32768 .008685    .1190 6.083 .0007261 2.8e-05 121.7 500.6   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  560  388 1597 4.131            1\n\n21:23:12 | running eval: valid\n21:23:12 | eval completed in 0.18s\n21:23:12 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  2028       0          0 150.6   24 .8333   \n    gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 1.015 2.8e-05    72 903.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    560 233.5 2932        .8322\n\u001b[0m\n21:23:12 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 9\u001b[0m\n21:23:12 | saving model checkpoint: /tmp/model1.checkpoint\n21:23:27 | time:223s total_exs:12000 total_steps:600 epochs:60.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.15     0 263.1  1053       0          0 80.06  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss    lr  ltpb  ltps  \\\n     1             32768 .008045    .1190 5.955 .0006875 3e-05 119.1 476.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  600 382.2 1530 4.012            1\n\n21:23:32 | time:228s total_exs:12440 total_steps:622 epochs:62.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.08     0 261.5  1038       0          0 79.38  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .007823    .1190 6.041 .000644 3.11e-05 120.8 479.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  622 382.4 1518 3.985            1\n\n21:23:32 | running eval: valid\n21:23:32 | eval completed in 0.18s\n21:23:32 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1990       0          0 147.8   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 .9916 3.11e-05    72   887       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    622 233.5 2877        .8748\n\u001b[0m\n21:23:32 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 10\u001b[0m\n21:23:32 | saving model checkpoint: /tmp/model1.checkpoint\n21:23:48 | time:244s total_exs:13220 total_steps:661 epochs:66.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.04     0 260.8   994       0          0 76.22  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .007183    .1190 6.031 .0006088 3.305e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   459.7       0          0                  661 381.4 1454 3.82            1\n\n21:23:52 | time:248s total_exs:13600 total_steps:680 epochs:68.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.63     0 252.6  1046       0          0  82.8  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss      lr  ltpb  ltps  \\\n     1             32768 .006761    .1190 6.016 .0005759 3.4e-05 120.3 498.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  680 372.9 1544 4.161            1\n\n21:23:52 | running eval: valid\n21:23:53 | eval completed in 0.18s\n21:23:53 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1988       0          0 147.7   24 .8750   \n    gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 .9939 3.4e-05    72 886.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    680 233.5 2875        .8748\n\u001b[0m\n21:23:53 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 11\u001b[0m\n21:23:53 | saving model checkpoint: /tmp/model1.checkpoint\n21:24:08 | time:264s total_exs:14380 total_steps:719 epochs:71.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.14     0 262.9  1008       0          0 76.69  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006388    .1190 6.005 .0005443 3.595e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   460.6       0          0                  719  383 1469 3.843            1\n\n21:24:13 | time:269s total_exs:14760 total_steps:738 epochs:73.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.03     0 260.5  1062       0          0 81.55  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .006138    .1191 5.937 .0005165 3.69e-05 118.7 484.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  738 379.3 1546 4.097            1\n\n21:24:13 | running eval: valid\n21:24:13 | eval completed in 0.18s\n21:24:13 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  2002       0          0 148.7   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 1.054 3.69e-05    72 892.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    738 233.5 2895        .8322\n\u001b[0m\n21:24:13 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 12\u001b[0m\n21:24:13 | saving model checkpoint: /tmp/model1.checkpoint\n21:24:28 | time:284s total_exs:15540 total_steps:777 epochs:77.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.86     0 257.2 995.2       0          0 77.38  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .005671    .1191 6.064 .0004835 3.885e-05 121.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   469.2       0          0                  777 378.5 1464 3.878            1\n\n21:24:33 | time:289s total_exs:15980 total_steps:799 epochs:79.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.93     0 258.6  1047       0          0 80.93  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .005378    .1191 6.014 .0004568 3.995e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   486.7       0          0                  799 378.9 1533 4.063            1\n\n21:24:33 | running eval: valid\n21:24:33 | eval completed in 0.17s\n21:24:33 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  2068       0          0 153.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 1.155 3.995e-05    72   922       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    799 233.5 2991        .8333\n\u001b[0m\n21:24:33 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 13\u001b[0m\n21:24:33 | saving model checkpoint: /tmp/model1.checkpoint\n21:24:48 | time:304s total_exs:16760 total_steps:838 epochs:83.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.85     0   257 992.1       0          0 77.22  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .005034    .1191 6.044 .000429 4.19e-05 120.9 466.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  838 377.8 1459 3.87            1\n\n21:24:53 | time:309s total_exs:17200 total_steps:860 epochs:86.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.25     0   265  1065       0          0 80.35  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss      lr  ltpb  ltps  \\\n     1             32768 .004741    .1191 6.009 .000404 4.3e-05 120.2 482.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  860 385.1 1547 4.034            1\n\n21:24:53 | running eval: valid\n21:24:54 | eval completed in 0.18s\n21:24:54 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1969       0          0 146.3   24 .8333   \n    gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 1.169 4.3e-05    72 877.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    860 233.5 2847        .8333\n\u001b[0m\n21:24:54 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 14\u001b[0m\n21:24:54 | saving model checkpoint: /tmp/model1.checkpoint\n21:25:08 | time:324s total_exs:18000 total_steps:900 epochs:90.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.21     0 264.2  1036       0          0 78.42  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss      lr  ltpb  ltps  \\\n     1             32768 .004463    .1191 6.022 .0003793 4.5e-05 120.5 472.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  900 384.6 1508 3.93            1\n\n21:25:14 | time:330s total_exs:18460 total_steps:923 epochs:92.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.17     0 263.5  1068       0          0 81.06  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004208    .1191 5.939 .0003577 4.615e-05 118.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   481.4       0          0                  923 382.3 1549 4.07            1\n\n21:25:14 | running eval: valid\n21:25:14 | eval completed in 0.21s\n21:25:14 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1766       0          0 131.1   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 1.142 4.615e-05    72 787.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    923 233.5 2553        .8333\n\u001b[0m\n21:25:14 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 15\u001b[0m\n21:25:14 | saving model checkpoint: /tmp/model1.checkpoint\n21:25:29 | time:345s total_exs:19280 total_steps:964 epochs:96.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.3     0 265.9  1067       0          0 80.27  820   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .003935    .1191 6.024 .0003344 4.82e-05 120.5 483.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  964 386.4 1551 4.023            1\n\n21:25:34 | time:350s total_exs:19740 total_steps:987 epochs:98.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.89     0 257.9  1063       0          0 82.48  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003699    .1191 5.987 .0003143 4.935e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   493.8       0          0                  987 377.6 1557 4.141            1\n\n21:25:34 | running eval: valid\n21:25:35 | eval completed in 0.18s\n21:25:35 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  2040       0          0 151.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 1.326 4.935e-05    72 909.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    987 233.5 2949        .8333\n\u001b[0m\n21:25:35 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 16\u001b[0m\n21:25:35 | saving model checkpoint: /tmp/model1.checkpoint\n21:25:54 | time:370s total_exs:20520 total_steps:1026 epochs:102.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.05     0 260.9  1010       0          0 77.42  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .003463    .1191 6.051 .000294 4.995e-05   121 468.5   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1026  382 1479 3.879            1\n\n21:25:55 | time:371s total_exs:20540 total_steps:1027 epochs:102.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1   9.5     0   230 977.2       0          0 84.96   20   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003399    .1191   5.8 .0002878 4.995e-05   116   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   492.8       0          0                 1027  346 1470 4.703            1\n\n21:25:55 | running eval: valid\n21:25:55 | eval completed in 0.18s\n21:25:55 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1986       0          0 147.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6 1.313 4.995e-05    72   885       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1027 233.5 2871        .8333\n\u001b[0m\n21:25:55 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 17\u001b[0m\n21:25:55 | saving model checkpoint: /tmp/model1.checkpoint\n21:26:10 | time:385s total_exs:21320 total_steps:1066 epochs:106.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.19     0 263.8  1008       0          0 76.45  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003205    .1191 6.031 .0002721 4.995e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     461       0          0                 1066 384.4 1469 3.824            1\n\n21:26:15 | time:391s total_exs:21740 total_steps:1087 epochs:108.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.65     0   273  1085       0          0 79.53  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003023    .1191 6.052 .0002566 4.995e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   481.3       0          0                 1087  394 1567 3.994            1\n\n21:26:15 | running eval: valid\n21:26:15 | eval completed in 0.18s\n21:26:15 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1968       0          0 146.2   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 1.359 4.995e-05    72 877.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1087 233.5 2846        .8333\n\u001b[0m\n21:26:15 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 18\u001b[0m\n21:26:15 | saving model checkpoint: /tmp/model1.checkpoint\n21:26:29 | time:405s total_exs:22540 total_steps:1127 epochs:112.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9988 9.987e-10               .9988                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9976            .9987              .9974   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.85 .0250   257  1027       0          0 79.92  800   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9988             32768  7.157    .1191 6.045 .001126 4.995e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   483.1       0          0                 1127 377.9 1510 4.005        .9988\n\n21:26:35 | time:411s total_exs:23000 total_steps:1150 epochs:115.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9957 9.957e-10               .9956                 .9956   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9956            .9957              .9957   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9957 11.11 .1304 262.1  1054       0          0 80.44  460   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9957             32768  7.404    .1191 5.991 .03286 4.995e-05 119.8   482   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1150  382 1536 4.038        .9957\n\n21:26:35 | running eval: valid\n21:26:35 | eval completed in 0.18s\n21:26:35 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  2019       0          0   150   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 1.417 4.995e-05    72 900.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1150 233.5 2920        .8333\n\u001b[0m\n21:26:35 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 19\u001b[0m\n21:26:35 | saving model checkpoint: /tmp/model1.checkpoint\n21:26:50 | time:426s total_exs:23800 total_steps:1190 epochs:119.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9962 9.962e-10               .9961                 .9949   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9974            .9963              .9976   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9951 11.17 .1000 263.4  1033       0          0 78.43  800   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9962             32768  11.72    .1191 5.973 .02589 4.995e-05 119.5 468.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1190 382.8 1501 3.93        .9963\n\n21:26:55 | time:431s total_exs:24240 total_steps:1212 epochs:121.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.07     0 261.4  1046       0          0 80.05  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002643    .1191 5.968 .0002149 4.995e-05 119.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   477.8       0          0                 1212 380.8 1524 4.019            1\n\n21:26:55 | running eval: valid\n21:26:56 | eval completed in 0.18s\n21:26:56 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  2025       0          0 150.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 1.062 4.995e-05    72 902.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1212 233.5 2928        .8748\n\u001b[0m\n21:26:56 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 20\u001b[0m\n21:26:56 | saving model checkpoint: /tmp/model1.checkpoint\n21:27:10 | time:446s total_exs:25020 total_steps:1251 epochs:125.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.07     0 261.3  1007       0          0 77.05  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00239    .1191 6.049 .0002025 4.995e-05   121 466.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1251 382.3 1473 3.861            1\n\n21:27:16 | time:452s total_exs:25440 total_steps:1272 epochs:127.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.08 .04762 261.7  1018       0          0 77.83   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n    420   1             32768 .01521    .1191 5.995 .0001961 4.995e-05 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   466.6       0          0                 1272 381.6 1485 3.908            1\n\n21:27:16 | running eval: valid\n21:27:16 | eval completed in 0.18s\n21:27:16 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  2014       0          0 149.6   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 .9052 4.995e-05    72   898       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1272 233.5 2912        .8748\n\u001b[0m\n21:27:16 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 21\u001b[0m\n21:27:16 | saving model checkpoint: /tmp/model1.checkpoint\n21:27:30 | time:466s total_exs:26220 total_steps:1311 epochs:131.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9974 9.974e-10               .9976                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9952            .9973              .9945   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.02 .1026 260.4  1007       0          0 77.35  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9974             32768  12.81    .1192 6.067 .01534 4.995e-05 121.3 469.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1311 381.8 1477 3.877        .9974\n\n21:27:36 | time:472s total_exs:26680 total_steps:1334 epochs:133.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9978 9.978e-10               .9981                 .9962   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9975                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                  .9950  10.6 .04348 251.9  1038       0          0 82.45   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  \\\n    460 .9978             32768  .2261    .1192  6.13 .01883 4.995e-05 122.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   505.4       0          0                 1334 374.5 1544 4.139        .9978\n\n21:27:36 | running eval: valid\n21:27:36 | eval completed in 0.18s\n21:27:36 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  2022       0          0 150.2   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 1.467 4.995e-05    72 901.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1334 233.5 2924        .8322\n\u001b[0m\n21:27:36 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 22\u001b[0m\n21:27:36 | saving model checkpoint: /tmp/model1.checkpoint\n21:27:51 | time:487s total_exs:27460 total_steps:1373 epochs:137.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.95     0 259.1  1004       0          0  77.5  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002059    .1192 5.982 .0001708 4.995e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.6       0          0                 1373 378.7 1467 3.884            1\n\n21:27:56 | time:492s total_exs:27900 total_steps:1395 epochs:139.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.85     0 256.9  1063       0          0 82.72  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001919    .1192 6.082 .0001618 4.995e-05 121.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   503.1       0          0                 1395 378.5 1566 4.154            1\n\n21:27:56 | running eval: valid\n21:27:56 | eval completed in 0.18s\n21:27:56 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  2023       0          0 150.2   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 1.493 4.995e-05    72 901.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1395 233.5 2924        .8322\n\u001b[0m\n21:27:56 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 23\u001b[0m\n21:27:56 | saving model checkpoint: /tmp/model1.checkpoint\n21:28:11 | time:507s total_exs:28720 total_steps:1436 epochs:143.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.17     0 263.3  1063       0          0 80.76  820   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001819    .1192 6.076 .0001539 4.995e-05 121.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   490.7       0          0                 1436 384.8 1554 4.047            1\n\n21:28:17 | time:512s total_exs:29140 total_steps:1457 epochs:145.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.29     0 265.8  1082       0          0 81.38  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001756    .1192 6.076 .0001469 4.995e-05 121.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   494.5       0          0                 1457 387.3 1576 4.087            1\n\n21:28:17 | running eval: valid\n21:28:17 | eval completed in 0.21s\n21:28:17 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1816       0          0 134.9   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6 1.502 4.995e-05    72 809.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1457 233.5 2626        .8322\n\u001b[0m\n21:28:17 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 24\u001b[0m\n21:28:17 | saving model checkpoint: /tmp/model1.checkpoint\n21:28:32 | time:528s total_exs:29920 total_steps:1496 epochs:149.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.05     0   261  1014       0          0 77.68  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001668    .1192 6.031 .0001407 4.995e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   468.5       0          0                 1496 381.6 1482 3.893            1\n\n21:28:37 | time:533s total_exs:30320 total_steps:1516 epochs:151.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.36     0 267.2  1101       0          0 82.38  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001592    .1192 6.015 .0001346 4.995e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   495.5       0          0                 1516 387.5 1596 4.139            1\n\n21:28:37 | running eval: valid\n21:28:37 | eval completed in 0.18s\n21:28:37 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1993       0          0 148.1   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6 1.512 4.995e-05    72 888.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1516 233.5 2882        .8322\n\u001b[0m\nEpoch 00009: reducing learning rate of group 0 to 2.4975e-05.\n21:28:37 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 25\u001b[0m\n21:28:37 | saving model checkpoint: /tmp/model1.checkpoint\n21:28:52 | time:548s total_exs:31080 total_steps:1554 epochs:155.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.01     0 260.2 982.7       0          0 75.54  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001545    .1192 6.092 .0001305 2.498e-05 121.8   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   460.2       0          0                 1554  382 1443 3.785            1\n\n21:28:57 | time:553s total_exs:31540 total_steps:1577 epochs:157.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.53     0 270.7  1102       0          0  81.4  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001562    .1192 6.017 .0001284 2.498e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   489.8       0          0                 1577  391 1592 4.087            1\n\n21:28:57 | running eval: valid\n21:28:58 | eval completed in 0.18s\n21:28:58 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  2035       0          0 151.2   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 1.511 2.498e-05    72 907.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1577 233.5 2942        .8322\n\u001b[0m\n21:28:58 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 26\u001b[0m\n21:28:58 | saving model checkpoint: /tmp/model1.checkpoint\n21:29:13 | time:569s total_exs:32320 total_steps:1616 epochs:161.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.86     0 257.3 986.3       0          0 76.67  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001521    .1192 6.018 .0001254 2.498e-05 120.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.4       0          0                 1616 377.6 1448 3.842            1\n\n21:29:18 | time:574s total_exs:32700 total_steps:1635 epochs:163.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.05     0 261.1  1022       0          0 78.26  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001447    .1192 6.047 .0001224 2.498e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   473.3       0          0                 1635  382 1495 3.932            1\n\n21:29:18 | running eval: valid\n21:29:18 | eval completed in 0.18s\n21:29:18 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1987       0          0 147.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 1.495 2.498e-05    72 885.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1635 233.5 2874        .8322\n\u001b[0m\n21:29:18 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 27\u001b[0m\n21:29:18 | saving model checkpoint: /tmp/model1.checkpoint\n21:29:38 | time:594s total_exs:33500 total_steps:1675 epochs:167.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.36     0 267.1  1041       0          0 77.92  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001419    .1192 5.997 .0001199 2.498e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   467.3       0          0                 1675 387.1 1508 3.905            1\n\n21:29:38 | running eval: valid\n21:29:38 | eval completed in 0.21s\n21:29:38 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1716       0          0 127.4   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6   1.5 2.498e-05    72 764.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1675 233.5 2480        .8322\n\u001b[0m\n21:29:38 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 28\u001b[0m\n21:29:38 | saving model checkpoint: /tmp/model1.checkpoint\n21:29:53 | time:609s total_exs:34300 total_steps:1715 epochs:171.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.1     0 261.9  1031       0          0  78.7  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001394    .1192 6.032 .0001163 2.498e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   474.7       0          0                 1715 382.6 1505 3.944            1\n\n21:29:58 | time:614s total_exs:34760 total_steps:1738 epochs:173.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.08     0 261.5  1074       0          0 82.11  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001339    .1192 6.087 .0001131 2.498e-05 121.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   499.8       0          0                 1738 383.3 1574 4.122            1\n\n21:29:58 | running eval: valid\n21:29:59 | eval completed in 0.18s\n21:29:59 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1963       0          0 145.8   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 1.527 2.498e-05    72 875.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1738 233.5 2839        .8322\n\u001b[0m\nEpoch 00013: reducing learning rate of group 0 to 1.2488e-05.\n21:29:59 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 29\u001b[0m\n21:29:59 | saving model checkpoint: /tmp/model1.checkpoint\n21:30:13 | time:629s total_exs:35560 total_steps:1778 epochs:177.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.13     0 262.5  1045       0          0  79.6  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001319    .1192 6.058 .0001115 1.249e-05 121.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   482.2       0          0                 1778 383.7 1527 3.989            1\n\n21:30:19 | time:635s total_exs:36000 total_steps:1800 epochs:180.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.2     0   264  1086       0          0 82.24  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n     1             32768 .001302    .1192 6.064 .00011 1.249e-05 121.3 498.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1800 385.3 1584 4.13            1\n\n21:30:19 | running eval: valid\n21:30:19 | eval completed in 0.18s\n21:30:19 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1947       0          0 144.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6  1.53 1.249e-05    72 868.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1800 233.5 2815        .8322\n\u001b[0m\n21:30:19 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 30\u001b[0m\n21:30:19 | saving model checkpoint: /tmp/model1.checkpoint\n21:30:24 | ran out of patience! stopping training.\n21:30:24 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n21:30:24 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n21:30:24 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type1/run1/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n21:30:24 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n21:30:24 | Using CUDA\n21:30:24 | loading dictionary from /tmp/model1.dict\n21:30:24 | num words = 54944\n21:30:29 | Loading existing model parameters from /tmp/model1\n21:30:34 | Total parameters: 128,042,498 (128,042,498 trainable)\n21:30:36 | creating task(s): fromfile:parlaiformat\n21:30:36 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run1/data_valid.txt\n21:30:36 | running eval: valid\n21:30:36 | eval completed in 0.47s\n21:30:36 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5 849.5       0          0 63.06   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297     6 .6246 2.505e-06    72 378.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     50 233.5 1228        .8748\n\u001b[0m\n21:30:36 | creating task(s): fromfile:parlaiformat\n21:30:36 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run1/data_test.txt\n21:30:36 | running eval: test\n21:30:41 | eval completed in 4.46s\n21:30:41 | \u001b[1mtest:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .4048                 .2656   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8500            .8418              .9779   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7389 12.07 281.4  3172       0          0 225.4 1000 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297   5.2 .6500 2.505e-06   104  1172       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     50 385.4 4345        .7981\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type1/run1/data_test.txt -m transformer/classifier -mf /tmp/model1 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-03T21:31:24.651629Z","iopub.execute_input":"2022-12-03T21:31:24.653999Z","iopub.status.idle":"2022-12-03T21:32:13.362173Z","shell.execute_reply.started":"2022-12-03T21:31:24.653947Z","shell.execute_reply":"2022-12-03T21:32:13.360963Z"},"scrolled":true,"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"21:31:48 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr1type1/run1/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr1type1/run1/data)\u001b[0m\n21:31:48 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n21:31:48 | Using CUDA\n21:31:48 | loading dictionary from /tmp/model1.dict\n21:31:48 | num words = 54944\n21:31:52 | Loading existing model parameters from /tmp/model1\n21:32:01 | Total parameters: 128,042,498 (128,042,498 trainable)\n21:32:02 | Opt:\n21:32:02 |     activation: gelu\n21:32:02 |     adafactor_eps: '[1e-30, 0.001]'\n21:32:02 |     adam_eps: 1e-08\n21:32:02 |     add_p1_after_newln: False\n21:32:02 |     aggregate_micro: False\n21:32:02 |     allow_missing_init_opts: False\n21:32:02 |     area_under_curve_class: None\n21:32:02 |     area_under_curve_digits: -1\n21:32:02 |     attention_dropout: 0.1\n21:32:02 |     batchsize: 40\n21:32:02 |     betas: '[0.9, 0.999]'\n21:32:02 |     bpe_add_prefix_space: None\n21:32:02 |     bpe_debug: False\n21:32:02 |     bpe_dropout: None\n21:32:02 |     bpe_merge: None\n21:32:02 |     bpe_vocab: None\n21:32:02 |     candidates: inline\n21:32:02 |     cap_num_predictions: 100\n21:32:02 |     checkpoint_activations: False\n21:32:02 |     class_weights: None\n21:32:02 |     classes: \"['__notok__', '__ok__']\"\n21:32:02 |     classes_from_file: None\n21:32:02 |     data_parallel: True\n21:32:02 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n21:32:02 |     datatype: train\n21:32:02 |     delimiter: '\\n'\n21:32:02 |     dict_class: parlai.core.dict:DictionaryAgent\n21:32:02 |     dict_endtoken: __start__\n21:32:02 |     dict_file: /tmp/model1.dict\n21:32:02 |     dict_include_test: False\n21:32:02 |     dict_include_valid: False\n21:32:02 |     dict_initpath: None\n21:32:02 |     dict_language: english\n21:32:02 |     dict_loaded: True\n21:32:02 |     dict_lower: True\n21:32:02 |     dict_max_ngram_size: -1\n21:32:02 |     dict_maxexs: -1\n21:32:02 |     dict_maxtokens: -1\n21:32:02 |     dict_minfreq: 0\n21:32:02 |     dict_nulltoken: __null__\n21:32:02 |     dict_starttoken: __start__\n21:32:02 |     dict_textfields: text,labels\n21:32:02 |     dict_tokenizer: bpe\n21:32:02 |     dict_unktoken: __unk__\n21:32:02 |     display_examples: False\n21:32:02 |     download_path: None\n21:32:02 |     dropout: 0.1\n21:32:02 |     dynamic_batching: None\n21:32:02 |     embedding_projection: random\n21:32:02 |     embedding_size: 768\n21:32:02 |     embedding_type: random\n21:32:02 |     embeddings_scale: False\n21:32:02 |     encode_candidate_vecs: True\n21:32:02 |     encode_candidate_vecs_batchsize: 256\n21:32:02 |     eval_batchsize: None\n21:32:02 |     eval_candidates: inline\n21:32:02 |     eval_dynamic_batching: None\n21:32:02 |     evaltask: None\n21:32:02 |     ffn_size: 3072\n21:32:02 |     final_extra_opt: \n21:32:02 |     fixed_candidate_vecs: reuse\n21:32:02 |     fixed_candidates_path: None\n21:32:02 |     force_fp16_tokens: True\n21:32:02 |     fp16: True\n21:32:02 |     fp16_impl: safe\n21:32:02 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type1/run1/data_test.txt\n21:32:02 |     fromfile_datatype_extension: True\n21:32:02 |     gpu: -1\n21:32:02 |     gradient_clip: 0.1\n21:32:02 |     hide_labels: False\n21:32:02 |     history_add_global_end_token: None\n21:32:02 |     history_reversed: False\n21:32:02 |     history_size: 20\n21:32:02 |     ignore_bad_candidates: False\n21:32:02 |     ignore_labels: None\n21:32:02 |     image_cropsize: 224\n21:32:02 |     image_mode: raw\n21:32:02 |     image_size: 256\n21:32:02 |     inference: max\n21:32:02 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n21:32:02 |     init_opt: None\n21:32:02 |     interactive_candidates: fixed\n21:32:02 |     interactive_mode: False\n21:32:02 |     invsqrt_lr_decay_gamma: -1\n21:32:02 |     is_debug: False\n21:32:02 |     label_truncate: 72\n21:32:02 |     learn_embeddings: True\n21:32:02 |     learn_positional_embeddings: True\n21:32:02 |     learningrate: 5e-05\n21:32:02 |     load_from_pretrained_ranker: True\n21:32:02 |     log_every_n_secs: 10.0\n21:32:02 |     log_every_n_steps: 50\n21:32:02 |     log_keep_fields: all\n21:32:02 |     loglevel: info\n21:32:02 |     lr_scheduler: reduceonplateau\n21:32:02 |     lr_scheduler_decay: 0.5\n21:32:02 |     lr_scheduler_patience: 3\n21:32:02 |     max_train_steps: -1\n21:32:02 |     max_train_time: 7200.0\n21:32:02 |     memory_attention: sqrt\n21:32:02 |     metrics: default\n21:32:02 |     model: transformer/classifier\n21:32:02 |     model_file: /tmp/model1\n21:32:02 |     model_parallel: False\n21:32:02 |     momentum: 0\n21:32:02 |     multitask_weights: [1]\n21:32:02 |     mutators: None\n21:32:02 |     n_decoder_layers: -1\n21:32:02 |     n_encoder_layers: -1\n21:32:02 |     n_heads: 12\n21:32:02 |     n_layers: 12\n21:32:02 |     n_positions: 1024\n21:32:02 |     n_segments: 2\n21:32:02 |     nesterov: True\n21:32:02 |     no_cuda: False\n21:32:02 |     normalize_sent_emb: False\n21:32:02 |     num_epochs: -1\n21:32:02 |     num_examples: -1\n21:32:02 |     num_workers: 0\n21:32:02 |     nus: [0.7]\n21:32:02 |     optimizer: adamax\n21:32:02 |     output_scaling: 0.06\n21:32:02 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type1/run1/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model1', 'batchsize': 40}\"\n21:32:02 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n21:32:02 |     person_tokens: False\n21:32:02 |     print_scores: False\n21:32:02 |     rank_candidates: False\n21:32:02 |     rank_top_k: -1\n21:32:02 |     reduction_type: mean\n21:32:02 |     ref_class: None\n21:32:02 |     relu_dropout: 0.0\n21:32:02 |     repeat_blocking_heuristic: True\n21:32:02 |     report_filename: \n21:32:02 |     return_cand_scores: False\n21:32:02 |     save_after_valid: True\n21:32:02 |     save_every_n_secs: -1\n21:32:02 |     save_format: conversations\n21:32:02 |     share_encoders: False\n21:32:02 |     share_word_embeddings: False\n21:32:02 |     short_final_eval: False\n21:32:02 |     special_tok_lst: None\n21:32:02 |     split_lines: False\n21:32:02 |     starttime: Dec03_21-19\n21:32:02 |     task: fromfile:parlaiformat\n21:32:02 |     tensorboard_log: False\n21:32:02 |     tensorboard_logdir: None\n21:32:02 |     text_truncate: 360\n21:32:02 |     threshold: 0.5\n21:32:02 |     topk: 5\n21:32:02 |     train_predict: False\n21:32:02 |     truncate: 1024\n21:32:02 |     update_classifier_head_only: False\n21:32:02 |     update_freq: 1\n21:32:02 |     use_memories: False\n21:32:02 |     use_reply: none\n21:32:02 |     validation_cutoff: 1.0\n21:32:02 |     validation_every_n_epochs: -1\n21:32:02 |     validation_every_n_secs: 20.0\n21:32:02 |     validation_every_n_steps: -1\n21:32:02 |     validation_max_exs: -1\n21:32:02 |     validation_metric: accuracy\n21:32:02 |     validation_metric_mode: max\n21:32:02 |     validation_patience: 30\n21:32:02 |     validation_share_agent: False\n21:32:02 |     variant: xlm\n21:32:02 |     verbose: False\n21:32:02 |     wandb_entity: None\n21:32:02 |     wandb_log: False\n21:32:02 |     wandb_name: None\n21:32:02 |     wandb_project: None\n21:32:02 |     warmup_rate: 0.0001\n21:32:02 |     warmup_updates: 1000\n21:32:02 |     weight_decay: None\n21:32:02 |     world_logs: \n21:32:02 |     wrap_memory_encoder: False\n21:32:02 | Evaluating task fromfile:parlaiformat using datatype valid.\n21:32:02 | creating task(s): fromfile:parlaiformat\n21:32:02 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n21:32:02 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run1/data_test.txt\n21:32:11 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .4048                 .2656   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8500            .8418              .9779   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7389 12.07 562.9  1802       0          0   128 1000 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .6500 2.505e-06   208 665.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     50 770.9 2467        .7981\u001b[0m\n21:32:11 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .4048                 .2656   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8500            .8418              .9779   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7389 12.07 562.9  1802       0          0   128 1000 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .6500 2.505e-06   208 665.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     50 770.9 2467        .7981\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model1*","metadata":{"execution":{"iopub.status.busy":"2022-12-03T21:35:44.644550Z","iopub.execute_input":"2022-12-03T21:35:44.645040Z","iopub.status.idle":"2022-12-03T21:35:45.629447Z","shell.execute_reply.started":"2022-12-03T21:35:44.644999Z","shell.execute_reply":"2022-12-03T21:35:45.628201Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"rm: cannot remove '/tmp/model1*': No such file or directory\n","output_type":"stream"}]},{"cell_type":"markdown","source":"run 2","metadata":{}},{"cell_type":"code","source":"# run 2 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type1/run2/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model2","metadata":{"execution":{"iopub.status.busy":"2022-12-03T21:35:58.743006Z","iopub.execute_input":"2022-12-03T21:35:58.744001Z","iopub.status.idle":"2022-12-03T21:47:53.703153Z","shell.execute_reply.started":"2022-12-03T21:35:58.743953Z","shell.execute_reply":"2022-12-03T21:47:53.701900Z"},"scrolled":true,"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"21:36:06 | building dictionary first...\n21:36:06 | No model with opt yet at: /tmp/model2(.opt)\n21:36:06 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type1/run2/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n21:36:06 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n21:36:06 | Using CUDA\n21:36:06 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n21:36:06 | num words = 54944\n21:36:11 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n21:36:21 | Total parameters: 128,042,498 (128,042,498 trainable)\n21:36:21 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n21:36:21 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n21:36:21 | Opt:\n21:36:21 |     activation: gelu\n21:36:21 |     adafactor_eps: '(1e-30, 0.001)'\n21:36:21 |     adam_eps: 1e-08\n21:36:21 |     add_p1_after_newln: False\n21:36:21 |     aggregate_micro: False\n21:36:21 |     allow_missing_init_opts: False\n21:36:21 |     attention_dropout: 0.1\n21:36:21 |     batchsize: 20\n21:36:21 |     betas: '(0.9, 0.999)'\n21:36:21 |     bpe_add_prefix_space: None\n21:36:21 |     bpe_debug: False\n21:36:21 |     bpe_dropout: None\n21:36:21 |     bpe_merge: None\n21:36:21 |     bpe_vocab: None\n21:36:21 |     candidates: inline\n21:36:21 |     cap_num_predictions: 100\n21:36:21 |     checkpoint_activations: False\n21:36:21 |     class_weights: None\n21:36:21 |     classes: \"['__notok__', '__ok__']\"\n21:36:21 |     classes_from_file: None\n21:36:21 |     data_parallel: True\n21:36:21 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n21:36:21 |     datatype: train\n21:36:21 |     delimiter: '\\n'\n21:36:21 |     dict_class: parlai.core.dict:DictionaryAgent\n21:36:21 |     dict_endtoken: __start__\n21:36:21 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n21:36:21 |     dict_include_test: False\n21:36:21 |     dict_include_valid: False\n21:36:21 |     dict_initpath: None\n21:36:21 |     dict_language: english\n21:36:21 |     dict_loaded: True\n21:36:21 |     dict_lower: True\n21:36:21 |     dict_max_ngram_size: -1\n21:36:21 |     dict_maxexs: -1\n21:36:21 |     dict_maxtokens: -1\n21:36:21 |     dict_minfreq: 0\n21:36:21 |     dict_nulltoken: __null__\n21:36:21 |     dict_starttoken: __start__\n21:36:21 |     dict_textfields: text,labels\n21:36:21 |     dict_tokenizer: bpe\n21:36:21 |     dict_unktoken: __unk__\n21:36:21 |     display_examples: False\n21:36:21 |     download_path: None\n21:36:21 |     dropout: 0.1\n21:36:21 |     dynamic_batching: None\n21:36:21 |     embedding_projection: random\n21:36:21 |     embedding_size: 768\n21:36:21 |     embedding_type: random\n21:36:21 |     embeddings_scale: False\n21:36:21 |     encode_candidate_vecs: True\n21:36:21 |     encode_candidate_vecs_batchsize: 256\n21:36:21 |     eval_batchsize: None\n21:36:21 |     eval_candidates: inline\n21:36:21 |     eval_dynamic_batching: None\n21:36:21 |     evaltask: None\n21:36:21 |     ffn_size: 3072\n21:36:21 |     final_extra_opt: \n21:36:21 |     fixed_candidate_vecs: reuse\n21:36:21 |     fixed_candidates_path: None\n21:36:21 |     force_fp16_tokens: False\n21:36:21 |     fp16: True\n21:36:21 |     fp16_impl: safe\n21:36:21 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type1/run2/data\n21:36:21 |     fromfile_datatype_extension: True\n21:36:21 |     gpu: -1\n21:36:21 |     gradient_clip: 0.1\n21:36:21 |     hide_labels: False\n21:36:21 |     history_add_global_end_token: None\n21:36:21 |     history_reversed: False\n21:36:21 |     history_size: 20\n21:36:21 |     ignore_bad_candidates: False\n21:36:21 |     ignore_labels: None\n21:36:21 |     image_cropsize: 224\n21:36:21 |     image_mode: raw\n21:36:21 |     image_size: 256\n21:36:21 |     inference: max\n21:36:21 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n21:36:21 |     init_opt: None\n21:36:21 |     interactive_candidates: fixed\n21:36:21 |     interactive_mode: False\n21:36:21 |     invsqrt_lr_decay_gamma: -1\n21:36:21 |     is_debug: False\n21:36:21 |     label_truncate: 72\n21:36:21 |     learn_embeddings: True\n21:36:21 |     learn_positional_embeddings: True\n21:36:21 |     learningrate: 5e-05\n21:36:21 |     load_from_checkpoint: False\n21:36:21 |     load_from_pretrained_ranker: True\n21:36:21 |     log_every_n_secs: 10.0\n21:36:21 |     log_every_n_steps: 50\n21:36:21 |     log_keep_fields: all\n21:36:21 |     loglevel: info\n21:36:21 |     lr_scheduler: reduceonplateau\n21:36:21 |     lr_scheduler_decay: 0.5\n21:36:21 |     lr_scheduler_patience: 3\n21:36:21 |     max_train_steps: -1\n21:36:21 |     max_train_time: 7200.0\n21:36:21 |     memory_attention: sqrt\n21:36:21 |     metrics: default\n21:36:21 |     model: transformer/classifier\n21:36:21 |     model_file: /tmp/model2\n21:36:21 |     model_parallel: False\n21:36:21 |     momentum: 0\n21:36:21 |     multitask_weights: [1]\n21:36:21 |     mutators: None\n21:36:21 |     n_decoder_layers: -1\n21:36:21 |     n_encoder_layers: -1\n21:36:21 |     n_heads: 12\n21:36:21 |     n_layers: 12\n21:36:21 |     n_positions: 1024\n21:36:21 |     n_segments: 2\n21:36:21 |     nesterov: True\n21:36:21 |     no_cuda: False\n21:36:21 |     normalize_sent_emb: False\n21:36:21 |     num_epochs: -1\n21:36:21 |     num_workers: 0\n21:36:21 |     nus: (0.7,)\n21:36:21 |     optimizer: adamax\n21:36:21 |     output_scaling: 0.06\n21:36:21 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type1/run2/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model2'}\"\n21:36:21 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n21:36:21 |     person_tokens: False\n21:36:21 |     print_scores: False\n21:36:21 |     rank_candidates: False\n21:36:21 |     rank_top_k: -1\n21:36:21 |     reduction_type: mean\n21:36:21 |     ref_class: None\n21:36:21 |     relu_dropout: 0.0\n21:36:21 |     repeat_blocking_heuristic: True\n21:36:21 |     return_cand_scores: False\n21:36:21 |     save_after_valid: True\n21:36:21 |     save_every_n_secs: -1\n21:36:21 |     save_format: conversations\n21:36:21 |     share_encoders: False\n21:36:21 |     share_word_embeddings: False\n21:36:21 |     short_final_eval: False\n21:36:21 |     special_tok_lst: None\n21:36:21 |     split_lines: False\n21:36:21 |     starttime: Dec03_21-36\n21:36:21 |     task: fromfile:parlaiformat\n21:36:21 |     tensorboard_log: False\n21:36:21 |     tensorboard_logdir: None\n21:36:21 |     text_truncate: 360\n21:36:21 |     threshold: 0.5\n21:36:21 |     topk: 5\n21:36:21 |     train_predict: False\n21:36:21 |     truncate: 1024\n21:36:21 |     update_classifier_head_only: False\n21:36:21 |     update_freq: 1\n21:36:21 |     use_memories: False\n21:36:21 |     use_reply: none\n21:36:21 |     validation_cutoff: 1.0\n21:36:21 |     validation_every_n_epochs: -1\n21:36:21 |     validation_every_n_secs: 20.0\n21:36:21 |     validation_every_n_steps: -1\n21:36:21 |     validation_max_exs: -1\n21:36:21 |     validation_metric: accuracy\n21:36:21 |     validation_metric_mode: max\n21:36:21 |     validation_patience: 30\n21:36:21 |     validation_share_agent: False\n21:36:21 |     variant: xlm\n21:36:21 |     verbose: False\n21:36:21 |     wandb_entity: None\n21:36:21 |     wandb_log: False\n21:36:21 |     wandb_name: None\n21:36:21 |     wandb_project: None\n21:36:21 |     warmup_rate: 0.0001\n21:36:21 |     warmup_updates: 1000\n21:36:21 |     weight_decay: None\n21:36:21 |     world_logs: \n21:36:21 |     wrap_memory_encoder: False\n21:36:21 | creating task(s): fromfile:parlaiformat\n21:36:21 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run2/data_train.txt\n21:36:21 | training...\n21:36:32 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5425 5.425e-10               .4404                 .5714   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .3582            .6131              .5292   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7286 11.78     1 275.6 547.9       0          0 39.77  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5425             32768  2.233    .1206 6.005 .6871 1.005e-06 120.1 238.8   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 395.6 786.7 1.993        .5263\n\n21:36:41 | time:20s total_exs:1140 total_steps:57 epochs:5.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6878 6.878e-10               .6796                 .6921   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6676            .6957              .6839   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7078 12.02     1 280.4  1060       0          0 75.65  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6878             32768  2.264    .1207 5.992 .6694 2.855e-06 119.8 453.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   57 400.2 1514 3.791        .6877\n\n21:36:41 | creating task(s): fromfile:parlaiformat\n21:36:41 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run2/data_valid.txt\n21:36:42 | running eval: valid\n21:36:42 | eval completed in 0.20s\n21:36:42 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6667 6.667e-10               .6364                 .7000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5833            .6923              .6429   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1774       0          0 136.4   24 .6667   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6677 2.855e-06    72 818.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                     57  228 2593        .6643\n\u001b[0m\n21:36:42 | \u001b[1;32mnew best accuracy: 0.6667\u001b[0m\n21:36:42 | saving best valid model: /tmp/model2\n21:36:42 | Saving dictionary to /tmp/model2.dict\n21:36:46 | saving model checkpoint: /tmp/model2.checkpoint\n21:36:46 | Saving dictionary to /tmp/model2.checkpoint.dict\n21:37:03 | time:42s total_exs:1880 total_steps:94 epochs:9.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8135 8.135e-10               .8292                 .7901   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8724            .7946              .8449   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7500 11.96     1 279.1  1012       0          0 72.51  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8135             32768  2.482    .1207 6.038 .6233 4.705e-06 120.8 437.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   94 399.9 1450 3.634        .8126\n\n21:37:06 | time:45s total_exs:2100 total_steps:105 epochs:10.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8864 8.864e-10               .9035                 .8357   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9832            .8619              .9750   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7723 11.09     1 261.8  1032       0          0 78.83  220   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8864             32768  2.423    .1207 6.082 .5655 5.254e-06 121.6 479.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  105 383.5 1511 3.973        .8844\n\n21:37:06 | running eval: valid\n21:37:06 | eval completed in 0.19s\n21:37:06 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1798       0          0 138.3   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5860 5.254e-06    72 829.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    105  228 2628        .9167\n\u001b[0m\n21:37:06 | \u001b[1;32mnew best accuracy: 0.9167 (previous best was 0.6667)\u001b[0m\n21:37:06 | saving best valid model: /tmp/model2\n21:37:16 | saving model checkpoint: /tmp/model2.checkpoint\n21:37:36 | time:74s total_exs:2880 total_steps:144 epochs:14.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8872 8.872e-10               .8903                 .8561   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9273            .8839              .9229   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8481 11.68     1 273.5  1060       0          0  77.5  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8872             32768  3.199    .1207 5.987 .4747 7.204e-06 119.7   464   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  144 393.3 1524 3.884        .8870\n\n21:37:37 | time:75s total_exs:2940 total_steps:147 epochs:14.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9333 9.333e-10               .9286                 .8966   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9630            .9375              .9677   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9091 11.18     1 263.7  1042       0          0 79.06   60   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9333             32768   3.44    .1189   5.9 .3496 7.354e-06   118 466.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  147 381.7 1509 4.074        .9335\n\n21:37:37 | running eval: valid\n21:37:37 | eval completed in 0.19s\n21:37:37 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1804       0          0 138.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .3815 7.354e-06    72 832.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    147  228 2636        .9167\n\u001b[0m\n21:37:37 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 1\u001b[0m\n21:37:37 | saving model checkpoint: /tmp/model2.checkpoint\n21:37:57 | time:95s total_exs:3700 total_steps:185 epochs:18.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9487 9.487e-10               .9525                 .9444   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9607            .9442              .9538   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9348 11.78     1 275.6  1047       0          0 76.01  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9487             32768  4.517    .1207 6.071 .2381 9.254e-06 121.4 461.5   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  185  397 1509 3.809        .9486\n\n21:37:57 | time:96s total_exs:3720 total_steps:186 epochs:18.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .8500 8.5e-10               .8571                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9000            .8421              .8889   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8000  12.4     1   288  1139       0          0 79.08   20   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8500             32768  5.174    .1190     6 .3350 9.304e-06   120 474.6   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  186  408 1614 4.344        .8496\n\n21:37:57 | running eval: valid\n21:37:57 | eval completed in 0.20s\n21:37:57 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1754       0          0 134.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .2422 9.304e-06    72 809.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    186  228 2564        .9167\n\u001b[0m\n21:37:57 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 2\u001b[0m\n21:37:57 | saving model checkpoint: /tmp/model2.checkpoint\n21:38:12 | time:111s total_exs:4500 total_steps:225 epochs:22.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9577 9.577e-10               .9583                 .9428   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9743            .9571              .9735   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9412 11.33     1 266.7  1021       0          0  76.6  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9577             32768  4.935    .1207 5.997 .1260 1.125e-05 119.9 459.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  225 386.6 1481 3.838        .9577\n\n21:38:17 | time:116s total_exs:4900 total_steps:245 epochs:24.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9775 9.775e-10               .9788                 .9858   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9720            .9760              .9683   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9839 11.59     1 271.7  1009       0          0 74.29  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9775             32768  2.689    .1207  6.07 .07543 1.225e-05 121.4   451   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  245 393.1 1460 3.73        .9775\n\n21:38:17 | running eval: valid\n21:38:18 | eval completed in 0.19s\n21:38:18 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1788       0          0 137.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .3432 1.225e-05    72 825.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    245  228 2614        .8748\n\u001b[0m\n21:38:18 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 3\u001b[0m\n21:38:18 | saving model checkpoint: /tmp/model2.checkpoint\n21:38:32 | time:131s total_exs:5680 total_steps:284 epochs:28.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9923 9.923e-10               .9925                 .9876   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9975            .9921              .9974   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9869 11.92 .6923 278.4  1072       0          0 77.03  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9923             32768  2.083    .1207 6.021 .0268 1.42e-05 120.4 463.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  284 398.8 1536 3.86        .9923\n\n21:38:38 | time:136s total_exs:6100 total_steps:305 epochs:30.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9976 9.976e-10               .9978                 .9956   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9974                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9949  11.9 .1429 277.9  1075       0          0 77.33  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9976             32768   1.05    .1207 6.067 .007235 1.525e-05 121.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   469.1       0          0                  305 399.2 1544 3.883        .9976\n\n21:38:38 | running eval: valid\n21:38:38 | eval completed in 0.20s\n21:38:38 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1762       0          0 135.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .7476 1.525e-05    72   813       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    305  228 2575        .8748\n\u001b[0m\n21:38:38 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 4\u001b[0m\n21:38:38 | saving model checkpoint: /tmp/model2.checkpoint\n21:38:53 | time:151s total_exs:6860 total_steps:343 epochs:34.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1    12 .05263   280  1047       0          0 74.81   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    760   1             32768  .1029    .1207 6.021 .002083 1.715e-05 120.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   450.4       0          0                  343 400.4 1498 3.749            1\n\n21:38:58 | time:157s total_exs:7280 total_steps:364 epochs:36.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.59     0 271.8  1068       0          0 78.61  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .02183    .1207 5.971 .001651 1.82e-05 119.4 469.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  364 391.2 1538 3.948            1\n\n21:38:58 | running eval: valid\n21:38:58 | eval completed in 0.19s\n21:38:58 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1816       0          0 139.7   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 .8300 1.82e-05    72 838.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    364  228 2654        .8748\n\u001b[0m\n21:38:58 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 5\u001b[0m\n21:38:58 | saving model checkpoint: /tmp/model2.checkpoint\n21:39:13 | time:172s total_exs:8060 total_steps:403 epochs:40.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.75 .02564   275  1058       0          0 76.94   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    780   1             32768 .02273    .1207 5.974 .001461 2.015e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.6       0          0                  403 394.5 1518 3.855            1\n\n21:39:18 | time:177s total_exs:8460 total_steps:423 epochs:42.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8 .0500   276  1046       0          0  75.8  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n     1             32768 .07145    .1207  5.92 .00135 2.115e-05 118.4 448.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  423 394.4 1495 3.807            1\n\n21:39:18 | running eval: valid\n21:39:19 | eval completed in 0.19s\n21:39:19 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1793       0          0 137.9   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 .9617 2.115e-05    72 827.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    423  228 2621        .8333\n\u001b[0m\n21:39:19 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 6\u001b[0m\n21:39:19 | saving model checkpoint: /tmp/model2.checkpoint\n21:39:34 | time:192s total_exs:9240 total_steps:462 epochs:46.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.69 .02564 273.7  1044       0          0 76.27   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  \\\n    780   1             32768  .0302    .1207 6.015 .001239 2.31e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   458.8       0          0                  462  394 1503 3.822            1\n\n21:39:39 | time:197s total_exs:9620 total_steps:481 epochs:48.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0 276.1  1090       0          0 78.95  380   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01581    .1207 6.068 .001155 2.405e-05 121.4 479.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  481 397.4 1569 3.966            1\n\n21:39:39 | running eval: valid\n21:39:39 | eval completed in 0.19s\n21:39:39 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1787       0          0 137.4   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 1.131 2.405e-05    72 824.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    481  228 2612        .8333\n\u001b[0m\n21:39:39 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 7\u001b[0m\n21:39:39 | saving model checkpoint: /tmp/model2.checkpoint\n21:39:54 | time:212s total_exs:10380 total_steps:519 epochs:51.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.78     0 275.6  1043       0          0 75.68  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01269    .1207 6.026 .001073 2.595e-05 120.5 456.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  519 396.2 1499 3.786            1\n\n21:39:59 | time:218s total_exs:10780 total_steps:539 epochs:53.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.95     0   279  1078       0          0 77.24  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01176    .1207  5.99 .001002 2.695e-05 119.8 462.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  539 398.8 1540 3.879            1\n\n21:39:59 | running eval: valid\n21:39:59 | eval completed in 0.19s\n21:39:59 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1791       0          0 137.8   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 1.156 2.695e-05    72 826.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    539  228 2618        .8333\n\u001b[0m\n21:39:59 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 8\u001b[0m\n21:39:59 | saving model checkpoint: /tmp/model2.checkpoint\n21:40:14 | time:233s total_exs:11560 total_steps:578 epochs:57.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.46     0 269.2  1027       0          0 76.32  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .01106    .1208 6.023 .0009415 2.89e-05 120.5 459.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  578 389.6 1487 3.825            1\n\n21:40:19 | time:238s total_exs:11960 total_steps:598 epochs:59.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.66     0 273.3  1057       0          0 77.38  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .01039    .1208  6.13 .000884 2.99e-05 122.6 474.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  598 395.9 1532 3.887            1\n\n21:40:19 | running eval: valid\n21:40:19 | eval completed in 0.21s\n21:40:19 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1613       0          0   124   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 1.075 2.99e-05    72 744.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    598  228 2358        .8333\n\u001b[0m\n21:40:19 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 9\u001b[0m\n21:40:19 | saving model checkpoint: /tmp/model2.checkpoint\n21:40:39 | time:258s total_exs:12740 total_steps:637 epochs:63.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.82     0 276.5  1070       0          0 77.44  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .009654    .1208 6.044 .0008249 3.185e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     468       0          0                  637 397.3 1538 3.881            1\n\n21:40:40 | time:258s total_exs:12760 total_steps:638 epochs:63.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.95     0   299  1222       0          0 81.69   20   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .00934    .1208   6.3 .0007982 3.19e-05   126 514.7   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  638  425 1736 4.501            1\n\n21:40:40 | running eval: valid\n21:40:40 | eval completed in 0.22s\n21:40:40 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1659       0          0 127.5   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 1.189 3.19e-05    72 765.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    638  228 2425        .8333\n\u001b[0m\n21:40:40 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 10\u001b[0m\n21:40:40 | saving model checkpoint: /tmp/model2.checkpoint\n21:40:55 | time:273s total_exs:13520 total_steps:676 epochs:67.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.73     0 274.6  1037       0          0 75.55  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .008889    .1208 6.029 .0007566 3.38e-05 120.6 455.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  676 395.2 1493 3.786            1\n\n21:41:00 | time:279s total_exs:13940 total_steps:697 epochs:69.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.56     0 271.2  1054       0          0 77.73  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .008363    .1208 6.148 .0007133 3.485e-05   123   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   477.9       0          0                  697 394.2 1532 3.903            1\n\n21:41:00 | running eval: valid\n21:41:00 | eval completed in 0.23s\n21:41:00 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1522       0          0   117   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 1.171 3.485e-05    72 702.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    697  228 2224        .8333\n\u001b[0m\n21:41:00 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 11\u001b[0m\n21:41:00 | saving model checkpoint: /tmp/model2.checkpoint\n21:41:15 | time:294s total_exs:14720 total_steps:736 epochs:73.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9987                 .9974   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9987                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                  .9975 11.54 .02564 270.8  1033       0          0 76.27   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  \\\n    780 .9987             32768   5.33    .1208 5.992 .007176 3.68e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     457       0          0                  736 390.6 1490 3.822        .9987\n\n21:41:21 | time:299s total_exs:15140 total_steps:757 epochs:75.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.36 .04762 267.2  1055       0          0 78.96   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n    420   1             32768 .01245    .1208 6.062 .0006301 3.785e-05 121.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   478.7       0          0                  757 388.4 1534 3.965            1\n\n21:41:21 | running eval: valid\n21:41:21 | eval completed in 0.20s\n21:41:21 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7857                 .6875   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .7000              .8750   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .5833    11   156  1743       0          0   134   24 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 1.638 3.785e-05    72 804.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    757  228 2547        .7429\n\u001b[0m\n21:41:21 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 12\u001b[0m\n21:41:21 | saving model checkpoint: /tmp/model2.checkpoint\n21:41:36 | time:314s total_exs:15920 total_steps:796 epochs:79.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.84     0 276.8  1062       0          0 76.76  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .007917    .1208 5.995 .0005867 3.98e-05 119.9 460.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  796 396.7 1523 3.846            1\n\n21:41:41 | time:319s total_exs:16320 total_steps:816 epochs:81.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.78     0 275.5  1082       0          0 78.57  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .006411    .1208 5.975 .0005457 4.08e-05 119.5 469.4   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  816  395 1552 3.946            1\n\n21:41:41 | running eval: valid\n21:41:41 | eval completed in 0.20s\n21:41:41 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1768       0          0 135.9   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 .9724 4.08e-05    72 815.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    816  228 2584        .8748\n\u001b[0m\n21:41:41 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 13\u001b[0m\n21:41:41 | saving model checkpoint: /tmp/model2.checkpoint\n21:41:56 | time:335s total_exs:17100 total_steps:855 epochs:85.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.72     0 274.4  1060       0          0 77.28  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .006027    .1208 6.046 .000513 4.275e-05 120.9 467.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  855 395.3 1527 3.865            1\n\n21:42:01 | time:340s total_exs:17480 total_steps:874 epochs:87.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.67     0 273.3  1035       0          0 75.71  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .005646    .1208 6.011 .0004802 4.37e-05 120.2   455   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  874 393.5 1490 3.803            1\n\n21:42:01 | running eval: valid\n21:42:01 | eval completed in 0.20s\n21:42:01 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1760       0          0 135.3   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 .9880 4.37e-05    72 812.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    874  228 2572        .8748\n\u001b[0m\n21:42:01 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 14\u001b[0m\n21:42:01 | saving model checkpoint: /tmp/model2.checkpoint\n21:42:16 | time:355s total_exs:18260 total_steps:913 epochs:91.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.77     0 275.3  1069       0          0 77.67  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .005309    .1208 6.018 .0004514 4.565e-05 120.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   467.4       0          0                  913 395.7 1537 3.892            1\n\n21:42:21 | time:360s total_exs:18680 total_steps:934 epochs:93.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.76     0 275.2  1058       0          0  76.9  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .004962    .1208 5.933 .0004216 4.67e-05 118.7 456.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  934 393.9 1514 3.861            1\n\n21:42:21 | running eval: valid\n21:42:22 | eval completed in 0.19s\n21:42:22 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1793       0          0 137.9   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 1.005 4.67e-05    72 827.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    934  228 2620        .8748\n\u001b[0m\n21:42:22 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 15\u001b[0m\n21:42:22 | saving model checkpoint: /tmp/model2.checkpoint\n21:42:36 | time:375s total_exs:19420 total_steps:971 epochs:97.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.88     0 277.6  1026       0          0 73.91  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .004673    .1208 6.003 .000397 4.855e-05 120.1 443.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  971 397.6 1470 3.704            1\n\n21:42:42 | time:380s total_exs:19860 total_steps:993 epochs:99.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.13     0 282.7  1086       0          0 76.82  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .004397    .1208 6.091 .000373 4.965e-05 121.8 467.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  993 404.5 1554 3.856            1\n\n21:42:42 | running eval: valid\n21:42:42 | eval completed in 0.19s\n21:42:42 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1806       0          0 138.9   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 1.022 4.965e-05    72 833.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    993  228 2639        .8748\n\u001b[0m\n21:42:42 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 16\u001b[0m\n21:42:42 | saving model checkpoint: /tmp/model2.checkpoint\n21:42:56 | time:395s total_exs:20640 total_steps:1032 epochs:103.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  12.1     0   282  1086       0          0 77.02  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004119    .1208 6.041 .0003492 4.995e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   465.3       0          0                 1032 402.8 1551 3.86            1\n\n21:43:02 | time:401s total_exs:21060 total_steps:1053 epochs:105.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.54     0 270.7  1003       0          0  74.1  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003854    .1208 5.967 .0003271 4.995e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps  ups  weighted_f1  \n   442.1       0          0                 1053  390 1445 3.72            1\n\n21:43:02 | running eval: valid\n21:43:02 | eval completed in 0.19s\n21:43:02 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1815       0          0 139.6   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 1.039 4.995e-05    72 837.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1053  228 2653        .8748\n\u001b[0m\n21:43:02 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 17\u001b[0m\n21:43:02 | saving model checkpoint: /tmp/model2.checkpoint\n21:43:17 | time:415s total_exs:21840 total_steps:1092 epochs:109.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.3  1052       0          0 76.71  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003636    .1209 6.008 .0003084 4.995e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.8       0          0                 1092 394.4 1513 3.844            1\n\n21:43:22 | time:421s total_exs:22260 total_steps:1113 epochs:111.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.87     0 277.4  1093       0          0 78.78  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003448    .1209 5.976 .0002906 4.995e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   470.8       0          0                 1113 396.9 1563 3.956            1\n\n21:43:22 | running eval: valid\n21:43:22 | eval completed in 0.20s\n21:43:22 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1775       0          0 136.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6  1.06 4.995e-05    72   819       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1113  228 2594        .8748\n\u001b[0m\n21:43:22 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 18\u001b[0m\n21:43:22 | saving model checkpoint: /tmp/model2.checkpoint\n21:43:37 | time:436s total_exs:23020 total_steps:1151 epochs:115.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.95     0 278.9  1052       0          0 75.42  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .003246    .1209 6.034 .000275 4.995e-05 120.7 455.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1151 399.6 1507 3.779            1\n\n21:43:43 | time:441s total_exs:23440 total_steps:1172 epochs:117.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.67     0 273.5  1074       0          0 78.52  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003079    .1209 6.095 .0002609 4.995e-05 121.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   478.6       0          0                 1172 395.4 1552 3.943            1\n\n21:43:43 | running eval: valid\n21:43:43 | eval completed in 0.20s\n21:43:43 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1707       0          0 131.3   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6 1.068 4.995e-05    72 787.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1172  228 2495        .8748\n\u001b[0m\n21:43:43 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 19\u001b[0m\n21:43:43 | saving model checkpoint: /tmp/model2.checkpoint\n21:43:58 | time:457s total_exs:24220 total_steps:1211 epochs:121.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.76     0 275.2  1054       0          0 76.58  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002909    .1209 6.005 .0002464 4.995e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.9       0          0                 1211 395.3 1514 3.838            1\n\n21:44:03 | time:462s total_exs:24620 total_steps:1231 epochs:123.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.87     0 277.4  1075       0          0 77.49  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002755    .1209 5.935 .0002334 4.995e-05 118.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.9       0          0                 1231 396.1 1534 3.892            1\n\n21:44:03 | running eval: valid\n21:44:03 | eval completed in 0.22s\n21:44:03 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1616       0          0 124.2   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 1.082 4.995e-05    72 745.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1231  228 2362        .8748\n\u001b[0m\n21:44:03 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 20\u001b[0m\n21:44:03 | saving model checkpoint: /tmp/model2.checkpoint\n21:44:18 | time:477s total_exs:25400 total_steps:1270 epochs:127.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.67     0 273.5  1058       0          0 77.36  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002626    .1209  5.99 .0002222 4.995e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.4       0          0                 1270 393.3 1521 3.877            1\n\n21:44:23 | time:482s total_exs:25820 total_steps:1291 epochs:129.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.85     0 276.9  1079       0          0 77.93  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002495    .1209 6.024 .0002113 4.995e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   469.4       0          0                 1291 397.4 1548 3.913            1\n\n21:44:23 | running eval: valid\n21:44:24 | eval completed in 0.19s\n21:44:24 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1814       0          0 139.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 1.095 4.995e-05    72 836.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1291  228 2651        .8748\n\u001b[0m\nEpoch 00005: reducing learning rate of group 0 to 2.4975e-05.\n21:44:24 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 21\u001b[0m\n21:44:24 | saving model checkpoint: /tmp/model2.checkpoint\n21:44:38 | time:497s total_exs:26580 total_steps:1329 epochs:132.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.91     0 278.2  1052       0          0 75.61  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002417    .1209 6.089 .0002045 2.498e-05 121.8   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   460.4       0          0                 1329  400 1512 3.789            1\n\n21:44:44 | time:502s total_exs:27000 total_steps:1350 epochs:135.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.72     0 274.4  1055       0          0 76.92  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002355    .1209 6.043 .0001994 2.498e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   464.8       0          0                 1350 395.3 1520 3.862            1\n\n21:44:44 | running eval: valid\n21:44:44 | eval completed in 0.19s\n21:44:44 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1811       0          0 139.2   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 1.101 2.498e-05    72 835.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1350  228 2647        .8748\n\u001b[0m\n21:44:44 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 22\u001b[0m\n21:44:44 | saving model checkpoint: /tmp/model2.checkpoint\n21:44:58 | time:517s total_exs:27780 total_steps:1389 epochs:138.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.64     0 272.8  1058       0          0 77.54  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002298    .1209 5.995 .0001943 2.498e-05 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   464.9       0          0                 1389 392.7 1523 3.886            1\n\n21:45:04 | time:523s total_exs:28220 total_steps:1411 epochs:141.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.63     0 272.5  1049       0          0 76.96  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002239    .1209 6.027 .0001895 2.498e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.9       0          0                 1411 393.1 1513 3.863            1\n\n21:45:04 | running eval: valid\n21:45:04 | eval completed in 0.19s\n21:45:04 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1803       0          0 138.6   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6 1.107 2.498e-05    72   832       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1411  228 2635        .8748\n\u001b[0m\n21:45:04 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 23\u001b[0m\n21:45:04 | saving model checkpoint: /tmp/model2.checkpoint\n21:45:19 | time:538s total_exs:29000 total_steps:1450 epochs:145.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.75     0   275  1051       0          0 76.41  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002179    .1209 5.964 .0001844 2.498e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   455.7       0          0                 1450 394.3 1506 3.829            1\n\n21:45:24 | time:543s total_exs:29380 total_steps:1469 epochs:146.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.99     0 279.9  1083       0          0 77.39  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002126    .1209 5.958 .0001798 2.498e-05 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.1       0          0                 1469 399.1 1544 3.886            1\n\n21:45:24 | running eval: valid\n21:45:25 | eval completed in 0.20s\n21:45:25 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1759       0          0 135.2   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 1.114 2.498e-05    72 811.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1469  228 2571        .8748\n\u001b[0m\n21:45:25 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 24\u001b[0m\n21:45:25 | saving model checkpoint: /tmp/model2.checkpoint\n21:45:39 | time:558s total_exs:30160 total_steps:1508 epochs:150.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.78     0 275.6  1056       0          0 76.61  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00208    .1209 6.026 .0001758 2.498e-05 120.5 461.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1508 396.1 1517 3.838            1\n\n21:45:45 | time:563s total_exs:30600 total_steps:1530 epochs:153.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.95     0   279  1063       0          0  76.2  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002025    .1209 6.041 .0001712 2.498e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.3       0          0                 1530 399.9 1524 3.825            1\n\n21:45:45 | running eval: valid\n21:45:45 | eval completed in 0.21s\n21:45:45 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1594       0          0 122.6   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6  1.12 2.498e-05    72 735.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1530  228 2330        .8748\n\u001b[0m\nEpoch 00009: reducing learning rate of group 0 to 1.2488e-05.\n21:45:45 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 25\u001b[0m\n21:45:45 | saving model checkpoint: /tmp/model2.checkpoint\n21:46:00 | time:578s total_exs:31380 total_steps:1569 epochs:156.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.86     0 277.2  1069       0          0 77.14  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001987    .1209 6.015 .000168 1.249e-05 120.3   464   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1569 397.5 1533 3.866            1\n\n21:46:05 | time:584s total_exs:31820 total_steps:1591 epochs:159.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.66     0 273.2  1058       0          0 77.49  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004826    .1209 6.009 .0001669 1.249e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   465.7       0          0                 1591 393.4 1524 3.89            1\n\n21:46:05 | running eval: valid\n21:46:06 | eval completed in 0.19s\n21:46:06 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1815       0          0 139.6   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 1.123 1.249e-05    72 837.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1591  228 2653        .8748\n\u001b[0m\n21:46:06 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 26\u001b[0m\n21:46:06 | saving model checkpoint: /tmp/model2.checkpoint\n21:46:20 | time:598s total_exs:32580 total_steps:1629 epochs:162.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.75     0   275  1042       0          0 75.79  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002422    .1210 6.045 .0001646 1.249e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.1       0          0                 1629 395.9 1500 3.798            1\n\n21:46:26 | time:604s total_exs:33040 total_steps:1652 epochs:165.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.67     0 273.3  1080       0          0 79.05  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001918    .1210  6.03 .0001615 1.249e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   476.7       0          0                 1652 393.9 1557 3.968            1\n\n21:46:26 | running eval: valid\n21:46:26 | eval completed in 0.19s\n21:46:26 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1802       0          0 138.6   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 1.128 1.249e-05    72 831.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1652  228 2634        .8748\n\u001b[0m\n21:46:26 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 27\u001b[0m\n21:46:26 | saving model checkpoint: /tmp/model2.checkpoint\n21:46:41 | time:619s total_exs:33840 total_steps:1692 epochs:169.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.04     0 280.7  1101       0          0 78.46  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001959    .1210 6.045 .000159 1.249e-05 120.9 474.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1692 401.6 1575 3.932            1\n\n21:46:46 | time:625s total_exs:34260 total_steps:1713 epochs:171.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.61     0 272.2  1017       0          0  74.7  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001866    .1210 6.171 .0001576 1.249e-05 123.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     461       0          0                 1713 395.6 1478 3.749            1\n\n21:46:46 | running eval: valid\n21:46:46 | eval completed in 0.19s\n21:46:46 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1787       0          0 137.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 1.132 1.249e-05    72 824.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1713  228 2611        .8748\n\u001b[0m\n21:46:46 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 28\u001b[0m\n21:46:46 | saving model checkpoint: /tmp/model2.checkpoint\n21:47:01 | time:640s total_exs:35060 total_steps:1753 epochs:175.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.58     0 271.6  1060       0          0 78.02  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001826    .1210 5.987 .0001543 1.249e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   467.1       0          0                 1753 391.4 1527 3.91            1\n\n21:47:07 | time:645s total_exs:35500 total_steps:1775 epochs:177.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.37     0 267.5  1041       0          0 77.85  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001801    .1210 6.036 .0001523 1.249e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   469.9       0          0                 1775 388.2 1511 3.908            1\n\n21:47:07 | running eval: valid\n21:47:07 | eval completed in 0.19s\n21:47:07 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1785       0          0 137.3   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08122     6 1.135 1.249e-05    72 823.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1775  228 2609        .8748\n\u001b[0m\nEpoch 00013: reducing learning rate of group 0 to 6.2438e-06.\n21:47:07 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 29\u001b[0m\n21:47:07 | saving model checkpoint: /tmp/model2.checkpoint\n21:47:21 | time:660s total_exs:36240 total_steps:1812 epochs:181.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.75     0   275  1017       0          0 73.95  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001783    .1210 6.057 .0001507 6.244e-06 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   447.9       0          0                 1812 396.1 1465 3.706            1\n\n21:47:27 | time:666s total_exs:36700 total_steps:1835 epochs:183.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.67     0 273.3  1056       0          0 77.29  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001767    .1210 5.961 .0001494 6.244e-06 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   460.7       0          0                 1835 392.6 1517 3.88            1\n\n21:47:27 | running eval: valid\n21:47:27 | eval completed in 0.20s\n21:47:27 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1770       0          0 136.1   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08123     6 1.137 6.244e-06    72   817       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1835  228 2588        .8748\n\u001b[0m\n21:47:27 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 30\u001b[0m\n21:47:27 | saving model checkpoint: /tmp/model2.checkpoint\n21:47:32 | ran out of patience! stopping training.\n21:47:32 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n21:47:32 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n21:47:32 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type1/run2/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n21:47:32 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n21:47:32 | Using CUDA\n21:47:32 | loading dictionary from /tmp/model2.dict\n21:47:32 | num words = 54944\n21:47:36 | Loading existing model parameters from /tmp/model2\n21:47:44 | Total parameters: 128,042,498 (128,042,498 trainable)\n21:47:46 | creating task(s): fromfile:parlaiformat\n21:47:46 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run2/data_valid.txt\n21:47:46 | running eval: valid\n21:47:46 | eval completed in 0.41s\n21:47:46 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156   839       0          0 64.51   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298     6 .5860 5.254e-06    72 387.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    105  228 1226        .9167\n\u001b[0m\n21:47:46 | creating task(s): fromfile:parlaiformat\n21:47:46 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run2/data_test.txt\n21:47:46 | running eval: test\n21:47:51 | eval completed in 5.01s\n21:47:51 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .7540 7.54e-10               .4434                 .2865   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9800            .8421              .9970   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7289 12.07 281.4  2827       0          0 200.9 1000 .7540   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298   5.2 .6124 5.254e-06   104  1045       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    105 385.4 3872        .8022\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type1/run2/data_test.txt -m transformer/classifier -mf /tmp/model2 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-03T21:48:15.612217Z","iopub.execute_input":"2022-12-03T21:48:15.612638Z","iopub.status.idle":"2022-12-03T21:48:47.833707Z","shell.execute_reply.started":"2022-12-03T21:48:15.612599Z","shell.execute_reply":"2022-12-03T21:48:47.832416Z"},"scrolled":true,"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"21:48:26 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr1type1/run2/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr1type1/run2/data)\u001b[0m\n21:48:26 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n21:48:26 | Using CUDA\n21:48:26 | loading dictionary from /tmp/model2.dict\n21:48:26 | num words = 54944\n21:48:30 | Loading existing model parameters from /tmp/model2\n21:48:36 | Total parameters: 128,042,498 (128,042,498 trainable)\n21:48:37 | Opt:\n21:48:37 |     activation: gelu\n21:48:37 |     adafactor_eps: '[1e-30, 0.001]'\n21:48:37 |     adam_eps: 1e-08\n21:48:37 |     add_p1_after_newln: False\n21:48:37 |     aggregate_micro: False\n21:48:37 |     allow_missing_init_opts: False\n21:48:37 |     area_under_curve_class: None\n21:48:37 |     area_under_curve_digits: -1\n21:48:37 |     attention_dropout: 0.1\n21:48:37 |     batchsize: 40\n21:48:37 |     betas: '[0.9, 0.999]'\n21:48:37 |     bpe_add_prefix_space: None\n21:48:37 |     bpe_debug: False\n21:48:37 |     bpe_dropout: None\n21:48:37 |     bpe_merge: None\n21:48:37 |     bpe_vocab: None\n21:48:37 |     candidates: inline\n21:48:37 |     cap_num_predictions: 100\n21:48:37 |     checkpoint_activations: False\n21:48:37 |     class_weights: None\n21:48:37 |     classes: \"['__notok__', '__ok__']\"\n21:48:37 |     classes_from_file: None\n21:48:37 |     data_parallel: True\n21:48:37 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n21:48:37 |     datatype: train\n21:48:37 |     delimiter: '\\n'\n21:48:37 |     dict_class: parlai.core.dict:DictionaryAgent\n21:48:37 |     dict_endtoken: __start__\n21:48:37 |     dict_file: /tmp/model2.dict\n21:48:37 |     dict_include_test: False\n21:48:37 |     dict_include_valid: False\n21:48:37 |     dict_initpath: None\n21:48:37 |     dict_language: english\n21:48:37 |     dict_loaded: True\n21:48:37 |     dict_lower: True\n21:48:37 |     dict_max_ngram_size: -1\n21:48:37 |     dict_maxexs: -1\n21:48:37 |     dict_maxtokens: -1\n21:48:37 |     dict_minfreq: 0\n21:48:37 |     dict_nulltoken: __null__\n21:48:37 |     dict_starttoken: __start__\n21:48:37 |     dict_textfields: text,labels\n21:48:37 |     dict_tokenizer: bpe\n21:48:37 |     dict_unktoken: __unk__\n21:48:37 |     display_examples: False\n21:48:37 |     download_path: None\n21:48:37 |     dropout: 0.1\n21:48:37 |     dynamic_batching: None\n21:48:37 |     embedding_projection: random\n21:48:37 |     embedding_size: 768\n21:48:37 |     embedding_type: random\n21:48:37 |     embeddings_scale: False\n21:48:37 |     encode_candidate_vecs: True\n21:48:37 |     encode_candidate_vecs_batchsize: 256\n21:48:37 |     eval_batchsize: None\n21:48:37 |     eval_candidates: inline\n21:48:37 |     eval_dynamic_batching: None\n21:48:37 |     evaltask: None\n21:48:37 |     ffn_size: 3072\n21:48:37 |     final_extra_opt: \n21:48:37 |     fixed_candidate_vecs: reuse\n21:48:37 |     fixed_candidates_path: None\n21:48:37 |     force_fp16_tokens: True\n21:48:37 |     fp16: True\n21:48:37 |     fp16_impl: safe\n21:48:37 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type1/run2/data_test.txt\n21:48:37 |     fromfile_datatype_extension: True\n21:48:37 |     gpu: -1\n21:48:37 |     gradient_clip: 0.1\n21:48:37 |     hide_labels: False\n21:48:37 |     history_add_global_end_token: None\n21:48:37 |     history_reversed: False\n21:48:37 |     history_size: 20\n21:48:37 |     ignore_bad_candidates: False\n21:48:37 |     ignore_labels: None\n21:48:37 |     image_cropsize: 224\n21:48:37 |     image_mode: raw\n21:48:37 |     image_size: 256\n21:48:37 |     inference: max\n21:48:37 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n21:48:37 |     init_opt: None\n21:48:37 |     interactive_candidates: fixed\n21:48:37 |     interactive_mode: False\n21:48:37 |     invsqrt_lr_decay_gamma: -1\n21:48:37 |     is_debug: False\n21:48:37 |     label_truncate: 72\n21:48:37 |     learn_embeddings: True\n21:48:37 |     learn_positional_embeddings: True\n21:48:37 |     learningrate: 5e-05\n21:48:37 |     load_from_pretrained_ranker: True\n21:48:37 |     log_every_n_secs: 10.0\n21:48:37 |     log_every_n_steps: 50\n21:48:37 |     log_keep_fields: all\n21:48:37 |     loglevel: info\n21:48:37 |     lr_scheduler: reduceonplateau\n21:48:37 |     lr_scheduler_decay: 0.5\n21:48:37 |     lr_scheduler_patience: 3\n21:48:37 |     max_train_steps: -1\n21:48:37 |     max_train_time: 7200.0\n21:48:37 |     memory_attention: sqrt\n21:48:37 |     metrics: default\n21:48:37 |     model: transformer/classifier\n21:48:37 |     model_file: /tmp/model2\n21:48:37 |     model_parallel: False\n21:48:37 |     momentum: 0\n21:48:37 |     multitask_weights: [1]\n21:48:37 |     mutators: None\n21:48:37 |     n_decoder_layers: -1\n21:48:37 |     n_encoder_layers: -1\n21:48:37 |     n_heads: 12\n21:48:37 |     n_layers: 12\n21:48:37 |     n_positions: 1024\n21:48:37 |     n_segments: 2\n21:48:37 |     nesterov: True\n21:48:37 |     no_cuda: False\n21:48:37 |     normalize_sent_emb: False\n21:48:37 |     num_epochs: -1\n21:48:37 |     num_examples: -1\n21:48:37 |     num_workers: 0\n21:48:37 |     nus: [0.7]\n21:48:37 |     optimizer: adamax\n21:48:37 |     output_scaling: 0.06\n21:48:37 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type1/run2/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model2', 'batchsize': 40}\"\n21:48:37 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n21:48:37 |     person_tokens: False\n21:48:37 |     print_scores: False\n21:48:37 |     rank_candidates: False\n21:48:37 |     rank_top_k: -1\n21:48:37 |     reduction_type: mean\n21:48:37 |     ref_class: None\n21:48:37 |     relu_dropout: 0.0\n21:48:37 |     repeat_blocking_heuristic: True\n21:48:37 |     report_filename: \n21:48:37 |     return_cand_scores: False\n21:48:37 |     save_after_valid: True\n21:48:37 |     save_every_n_secs: -1\n21:48:37 |     save_format: conversations\n21:48:37 |     share_encoders: False\n21:48:37 |     share_word_embeddings: False\n21:48:37 |     short_final_eval: False\n21:48:37 |     special_tok_lst: None\n21:48:37 |     split_lines: False\n21:48:37 |     starttime: Dec03_21-36\n21:48:37 |     task: fromfile:parlaiformat\n21:48:37 |     tensorboard_log: False\n21:48:37 |     tensorboard_logdir: None\n21:48:37 |     text_truncate: 360\n21:48:37 |     threshold: 0.5\n21:48:37 |     topk: 5\n21:48:37 |     train_predict: False\n21:48:37 |     truncate: 1024\n21:48:37 |     update_classifier_head_only: False\n21:48:37 |     update_freq: 1\n21:48:37 |     use_memories: False\n21:48:37 |     use_reply: none\n21:48:37 |     validation_cutoff: 1.0\n21:48:37 |     validation_every_n_epochs: -1\n21:48:37 |     validation_every_n_secs: 20.0\n21:48:37 |     validation_every_n_steps: -1\n21:48:37 |     validation_max_exs: -1\n21:48:37 |     validation_metric: accuracy\n21:48:37 |     validation_metric_mode: max\n21:48:37 |     validation_patience: 30\n21:48:37 |     validation_share_agent: False\n21:48:37 |     variant: xlm\n21:48:37 |     verbose: False\n21:48:37 |     wandb_entity: None\n21:48:37 |     wandb_log: False\n21:48:37 |     wandb_name: None\n21:48:37 |     wandb_project: None\n21:48:37 |     warmup_rate: 0.0001\n21:48:37 |     warmup_updates: 1000\n21:48:37 |     weight_decay: None\n21:48:37 |     world_logs: \n21:48:37 |     wrap_memory_encoder: False\n21:48:38 | Evaluating task fromfile:parlaiformat using datatype valid.\n21:48:38 | creating task(s): fromfile:parlaiformat\n21:48:38 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n21:48:38 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run2/data_test.txt\n21:48:46 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .7540 7.54e-10               .4434                 .2865   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9800            .8421              .9970   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7289 12.07 562.9  1840       0          0 130.7 1000 .7540   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .6124 5.254e-06   208 679.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    105 770.9 2520        .8022\u001b[0m\n21:48:46 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .7540 7.54e-10               .4434                 .2865   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9800            .8421              .9970   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7289 12.07 562.9  1840       0          0 130.7 1000 .7540   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .6124 5.254e-06   208 679.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    105 770.9 2520        .8022\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model2*","metadata":{"execution":{"iopub.status.busy":"2022-12-03T21:49:31.144774Z","iopub.execute_input":"2022-12-03T21:49:31.145863Z","iopub.status.idle":"2022-12-03T21:49:32.329089Z","shell.execute_reply.started":"2022-12-03T21:49:31.145806Z","shell.execute_reply":"2022-12-03T21:49:32.327747Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"run 3","metadata":{}},{"cell_type":"code","source":"# run 3 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type1/run3/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model3","metadata":{"execution":{"iopub.status.busy":"2022-12-03T21:49:42.182393Z","iopub.execute_input":"2022-12-03T21:49:42.182782Z","iopub.status.idle":"2022-12-03T21:51:34.973622Z","shell.execute_reply.started":"2022-12-03T21:49:42.182745Z","shell.execute_reply":"2022-12-03T21:51:34.972315Z"},"scrolled":true,"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"21:49:49 | building dictionary first...\n21:49:49 | No model with opt yet at: /tmp/model3(.opt)\n21:49:49 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type1/run3/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n21:49:49 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n21:49:49 | Using CUDA\n21:49:49 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n21:49:49 | num words = 54944\n21:49:54 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n21:50:04 | Total parameters: 128,042,498 (128,042,498 trainable)\n21:50:04 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n21:50:04 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n21:50:04 | Opt:\n21:50:04 |     activation: gelu\n21:50:04 |     adafactor_eps: '(1e-30, 0.001)'\n21:50:04 |     adam_eps: 1e-08\n21:50:04 |     add_p1_after_newln: False\n21:50:04 |     aggregate_micro: False\n21:50:04 |     allow_missing_init_opts: False\n21:50:04 |     attention_dropout: 0.1\n21:50:04 |     batchsize: 20\n21:50:04 |     betas: '(0.9, 0.999)'\n21:50:04 |     bpe_add_prefix_space: None\n21:50:04 |     bpe_debug: False\n21:50:04 |     bpe_dropout: None\n21:50:04 |     bpe_merge: None\n21:50:04 |     bpe_vocab: None\n21:50:04 |     candidates: inline\n21:50:04 |     cap_num_predictions: 100\n21:50:04 |     checkpoint_activations: False\n21:50:04 |     class_weights: None\n21:50:04 |     classes: \"['__notok__', '__ok__']\"\n21:50:04 |     classes_from_file: None\n21:50:04 |     data_parallel: True\n21:50:04 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n21:50:04 |     datatype: train\n21:50:04 |     delimiter: '\\n'\n21:50:04 |     dict_class: parlai.core.dict:DictionaryAgent\n21:50:04 |     dict_endtoken: __start__\n21:50:04 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n21:50:04 |     dict_include_test: False\n21:50:04 |     dict_include_valid: False\n21:50:04 |     dict_initpath: None\n21:50:04 |     dict_language: english\n21:50:04 |     dict_loaded: True\n21:50:04 |     dict_lower: True\n21:50:04 |     dict_max_ngram_size: -1\n21:50:04 |     dict_maxexs: -1\n21:50:04 |     dict_maxtokens: -1\n21:50:04 |     dict_minfreq: 0\n21:50:04 |     dict_nulltoken: __null__\n21:50:04 |     dict_starttoken: __start__\n21:50:04 |     dict_textfields: text,labels\n21:50:04 |     dict_tokenizer: bpe\n21:50:04 |     dict_unktoken: __unk__\n21:50:04 |     display_examples: False\n21:50:04 |     download_path: None\n21:50:04 |     dropout: 0.1\n21:50:04 |     dynamic_batching: None\n21:50:04 |     embedding_projection: random\n21:50:04 |     embedding_size: 768\n21:50:04 |     embedding_type: random\n21:50:04 |     embeddings_scale: False\n21:50:04 |     encode_candidate_vecs: True\n21:50:04 |     encode_candidate_vecs_batchsize: 256\n21:50:04 |     eval_batchsize: None\n21:50:04 |     eval_candidates: inline\n21:50:04 |     eval_dynamic_batching: None\n21:50:04 |     evaltask: None\n21:50:04 |     ffn_size: 3072\n21:50:04 |     final_extra_opt: \n21:50:04 |     fixed_candidate_vecs: reuse\n21:50:04 |     fixed_candidates_path: None\n21:50:04 |     force_fp16_tokens: False\n21:50:04 |     fp16: True\n21:50:04 |     fp16_impl: safe\n21:50:04 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type1/run3/data\n21:50:04 |     fromfile_datatype_extension: True\n21:50:04 |     gpu: -1\n21:50:04 |     gradient_clip: 0.1\n21:50:04 |     hide_labels: False\n21:50:04 |     history_add_global_end_token: None\n21:50:04 |     history_reversed: False\n21:50:04 |     history_size: 20\n21:50:04 |     ignore_bad_candidates: False\n21:50:04 |     ignore_labels: None\n21:50:04 |     image_cropsize: 224\n21:50:04 |     image_mode: raw\n21:50:04 |     image_size: 256\n21:50:04 |     inference: max\n21:50:04 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n21:50:04 |     init_opt: None\n21:50:04 |     interactive_candidates: fixed\n21:50:04 |     interactive_mode: False\n21:50:04 |     invsqrt_lr_decay_gamma: -1\n21:50:04 |     is_debug: False\n21:50:04 |     label_truncate: 72\n21:50:04 |     learn_embeddings: True\n21:50:04 |     learn_positional_embeddings: True\n21:50:04 |     learningrate: 5e-05\n21:50:04 |     load_from_checkpoint: False\n21:50:04 |     load_from_pretrained_ranker: True\n21:50:04 |     log_every_n_secs: 10.0\n21:50:04 |     log_every_n_steps: 50\n21:50:04 |     log_keep_fields: all\n21:50:04 |     loglevel: info\n21:50:04 |     lr_scheduler: reduceonplateau\n21:50:04 |     lr_scheduler_decay: 0.5\n21:50:04 |     lr_scheduler_patience: 3\n21:50:04 |     max_train_steps: -1\n21:50:04 |     max_train_time: 7200.0\n21:50:04 |     memory_attention: sqrt\n21:50:04 |     metrics: default\n21:50:04 |     model: transformer/classifier\n21:50:04 |     model_file: /tmp/model3\n21:50:04 |     model_parallel: False\n21:50:04 |     momentum: 0\n21:50:04 |     multitask_weights: [1]\n21:50:04 |     mutators: None\n21:50:04 |     n_decoder_layers: -1\n21:50:04 |     n_encoder_layers: -1\n21:50:04 |     n_heads: 12\n21:50:04 |     n_layers: 12\n21:50:04 |     n_positions: 1024\n21:50:04 |     n_segments: 2\n21:50:04 |     nesterov: True\n21:50:04 |     no_cuda: False\n21:50:04 |     normalize_sent_emb: False\n21:50:04 |     num_epochs: -1\n21:50:04 |     num_workers: 0\n21:50:04 |     nus: (0.7,)\n21:50:04 |     optimizer: adamax\n21:50:04 |     output_scaling: 0.06\n21:50:04 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type1/run3/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model3'}\"\n21:50:04 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n21:50:04 |     person_tokens: False\n21:50:04 |     print_scores: False\n21:50:04 |     rank_candidates: False\n21:50:04 |     rank_top_k: -1\n21:50:04 |     reduction_type: mean\n21:50:04 |     ref_class: None\n21:50:04 |     relu_dropout: 0.0\n21:50:04 |     repeat_blocking_heuristic: True\n21:50:04 |     return_cand_scores: False\n21:50:04 |     save_after_valid: True\n21:50:04 |     save_every_n_secs: -1\n21:50:04 |     save_format: conversations\n21:50:04 |     share_encoders: False\n21:50:04 |     share_word_embeddings: False\n21:50:04 |     short_final_eval: False\n21:50:04 |     special_tok_lst: None\n21:50:04 |     split_lines: False\n21:50:04 |     starttime: Dec03_21-49\n21:50:04 |     task: fromfile:parlaiformat\n21:50:04 |     tensorboard_log: False\n21:50:04 |     tensorboard_logdir: None\n21:50:04 |     text_truncate: 360\n21:50:04 |     threshold: 0.5\n21:50:04 |     topk: 5\n21:50:04 |     train_predict: False\n21:50:04 |     truncate: 1024\n21:50:04 |     update_classifier_head_only: False\n21:50:04 |     update_freq: 1\n21:50:04 |     use_memories: False\n21:50:04 |     use_reply: none\n21:50:04 |     validation_cutoff: 1.0\n21:50:04 |     validation_every_n_epochs: -1\n21:50:04 |     validation_every_n_secs: 20.0\n21:50:04 |     validation_every_n_steps: -1\n21:50:04 |     validation_max_exs: -1\n21:50:04 |     validation_metric: accuracy\n21:50:04 |     validation_metric_mode: max\n21:50:04 |     validation_patience: 30\n21:50:04 |     validation_share_agent: False\n21:50:04 |     variant: xlm\n21:50:04 |     verbose: False\n21:50:04 |     wandb_entity: None\n21:50:04 |     wandb_log: False\n21:50:04 |     wandb_name: None\n21:50:04 |     wandb_project: None\n21:50:04 |     warmup_rate: 0.0001\n21:50:04 |     warmup_updates: 1000\n21:50:04 |     weight_decay: None\n21:50:04 |     world_logs: \n21:50:04 |     wrap_memory_encoder: False\n21:50:04 | creating task(s): fromfile:parlaiformat\n21:50:04 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run3/data_train.txt\n21:50:05 | training...\n21:50:15 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .4750 4.75e-10               .3713                 .4429   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .3196            .5494              .4923   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6214 11.52     1 270.4 539.9       0          0 39.93  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .4750             32768  3.329    .1206  5.97 .7077 1.005e-06 119.4 238.4   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 389.8 778.3 2.001        .4630\n\n21:50:25 | time:20s total_exs:1140 total_steps:57 epochs:5.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6054 6.054e-10               .6022                 .6122   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5925            .6086              .5989   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6185 11.26     1 265.2   998       0          0 75.25  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6054             32768  2.635    .1207 6.008 .6801 2.855e-06 120.2 452.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   57 385.4 1450 3.771        .6054\n\n21:50:25 | creating task(s): fromfile:parlaiformat\n21:50:25 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run3/data_valid.txt\n21:50:25 | running eval: valid\n21:50:25 | eval completed in 0.21s\n21:50:25 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .6957                 .7273   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .7200              .6923   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.71 164.5  1787       0          0 130.3   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6623 2.855e-06    72   782       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     57 236.5 2569        .7078\n\u001b[0m\n21:50:25 | \u001b[1;32mnew best accuracy: 0.7083\u001b[0m\n21:50:25 | saving best valid model: /tmp/model3\n21:50:25 | Saving dictionary to /tmp/model3.dict\n21:50:28 | saving model checkpoint: /tmp/model3.checkpoint\n21:50:28 | Saving dictionary to /tmp/model3.checkpoint.dict\n21:50:45 | time:40s total_exs:1860 total_steps:93 epochs:9.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8361 8.361e-10               .8234                 .8730   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7790            .8472              .8074   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8910 11.28     1 265.6 949.9       0          0 71.53  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8361             32768  2.883    .1207 5.981 .6222 4.655e-06 119.6 427.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   93 385.2 1378 3.585        .8355\n\n21:50:49 | time:44s total_exs:2140 total_steps:107 epochs:10.70\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8679                 .9200   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8214            .8814              .8387   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9286 11.41     1 268.3  1049       0          0 78.18  280   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8750             32768  3.783    .1207     6 .5500 5.354e-06   120 469.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  107 388.3 1518 3.934        .8746\n\n21:50:49 | running eval: valid\n21:50:49 | eval completed in 0.19s\n21:50:49 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 11.71 164.5  1892       0          0   138   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5314 5.354e-06    72   828       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    107 236.5 2720        .9583\n\u001b[0m\n21:50:49 | \u001b[1;32mnew best accuracy: 0.9583 (previous best was 0.7083)\u001b[0m\n21:50:49 | saving best valid model: /tmp/model3\n21:50:54 | saving model checkpoint: /tmp/model3.checkpoint\n21:51:12 | time:67s total_exs:2920 total_steps:146 epochs:14.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9436 9.436e-10               .9424                 .9474   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9375            .9447              .9400   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9495 11.24     1 264.8  1021       0          0 77.14  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9436             32768  4.154    .1207 5.985 .4304 7.304e-06 119.7 461.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  146 384.5 1483 3.866        .9436\n\n21:51:14 | time:69s total_exs:3080 total_steps:154 epochs:15.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9062 9.062e-10               .9057                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9114            .9068              .9125   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9012  11.2     1   264  1039       0          0  78.7  160   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9062             32768  4.842    .1207 5.987 .3216 7.704e-06 119.8 471.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  154 383.8 1510 3.979        .9063\n\n21:51:14 | running eval: valid\n21:51:14 | eval completed in 0.20s\n21:51:14 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 11.71 164.5  1830       0          0 133.4   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .2374 7.704e-06    72 800.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    154 236.5 2631            1\n\u001b[0m\n21:51:14 | \u001b[1;32mnew best accuracy: 1 (previous best was 0.9583)\u001b[0m\n21:51:14 | saving best valid model: /tmp/model3\n21:51:19 | task solved! stopping.\n21:51:19 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n21:51:19 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n21:51:19 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type1/run3/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n21:51:19 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n21:51:19 | Using CUDA\n21:51:19 | loading dictionary from /tmp/model3.dict\n21:51:19 | num words = 54944\n21:51:24 | Loading existing model parameters from /tmp/model3\n21:51:25 | Total parameters: 128,042,498 (128,042,498 trainable)\n21:51:27 | creating task(s): fromfile:parlaiformat\n21:51:27 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run3/data_valid.txt\n21:51:27 | running eval: valid\n21:51:28 | eval completed in 0.31s\n21:51:28 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 11.71 164.5  1312       0          0  95.7   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294     6 .2374 7.704e-06    72 574.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    154 236.5 1886            1\n\u001b[0m\n21:51:28 | creating task(s): fromfile:parlaiformat\n21:51:28 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run3/data_test.txt\n21:51:28 | running eval: test\n21:51:33 | eval completed in 4.97s\n21:51:33 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9360 9.36e-10               .7500                 .6154   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9600            .9633              .9953   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9333 12.07 281.4  2851       0          0 202.6 1000 .9360   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294   5.2 .2829 7.704e-06   104  1053       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    154 385.4 3904        .9420\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type1/run3/data_test.txt -m transformer/classifier -mf /tmp/model3 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-03T21:53:34.014021Z","iopub.execute_input":"2022-12-03T21:53:34.014461Z","iopub.status.idle":"2022-12-03T21:54:04.988328Z","shell.execute_reply.started":"2022-12-03T21:53:34.014425Z","shell.execute_reply":"2022-12-03T21:54:04.987078Z"},"scrolled":true,"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"21:53:42 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr1type1/run3/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr1type1/run3/data)\u001b[0m\n21:53:42 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n21:53:42 | Using CUDA\n21:53:42 | loading dictionary from /tmp/model3.dict\n21:53:43 | num words = 54944\n21:53:47 | Loading existing model parameters from /tmp/model3\n21:53:53 | Total parameters: 128,042,498 (128,042,498 trainable)\n21:53:54 | Opt:\n21:53:54 |     activation: gelu\n21:53:54 |     adafactor_eps: '[1e-30, 0.001]'\n21:53:54 |     adam_eps: 1e-08\n21:53:54 |     add_p1_after_newln: False\n21:53:54 |     aggregate_micro: False\n21:53:54 |     allow_missing_init_opts: False\n21:53:54 |     area_under_curve_class: None\n21:53:54 |     area_under_curve_digits: -1\n21:53:54 |     attention_dropout: 0.1\n21:53:54 |     batchsize: 40\n21:53:54 |     betas: '[0.9, 0.999]'\n21:53:54 |     bpe_add_prefix_space: None\n21:53:54 |     bpe_debug: False\n21:53:54 |     bpe_dropout: None\n21:53:54 |     bpe_merge: None\n21:53:54 |     bpe_vocab: None\n21:53:54 |     candidates: inline\n21:53:54 |     cap_num_predictions: 100\n21:53:54 |     checkpoint_activations: False\n21:53:54 |     class_weights: None\n21:53:54 |     classes: \"['__notok__', '__ok__']\"\n21:53:54 |     classes_from_file: None\n21:53:54 |     data_parallel: True\n21:53:54 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n21:53:54 |     datatype: train\n21:53:54 |     delimiter: '\\n'\n21:53:54 |     dict_class: parlai.core.dict:DictionaryAgent\n21:53:54 |     dict_endtoken: __start__\n21:53:54 |     dict_file: /tmp/model3.dict\n21:53:54 |     dict_include_test: False\n21:53:54 |     dict_include_valid: False\n21:53:54 |     dict_initpath: None\n21:53:54 |     dict_language: english\n21:53:54 |     dict_loaded: True\n21:53:54 |     dict_lower: True\n21:53:54 |     dict_max_ngram_size: -1\n21:53:54 |     dict_maxexs: -1\n21:53:54 |     dict_maxtokens: -1\n21:53:54 |     dict_minfreq: 0\n21:53:54 |     dict_nulltoken: __null__\n21:53:54 |     dict_starttoken: __start__\n21:53:54 |     dict_textfields: text,labels\n21:53:54 |     dict_tokenizer: bpe\n21:53:54 |     dict_unktoken: __unk__\n21:53:54 |     display_examples: False\n21:53:54 |     download_path: None\n21:53:54 |     dropout: 0.1\n21:53:54 |     dynamic_batching: None\n21:53:54 |     embedding_projection: random\n21:53:54 |     embedding_size: 768\n21:53:54 |     embedding_type: random\n21:53:54 |     embeddings_scale: False\n21:53:54 |     encode_candidate_vecs: True\n21:53:54 |     encode_candidate_vecs_batchsize: 256\n21:53:54 |     eval_batchsize: None\n21:53:54 |     eval_candidates: inline\n21:53:54 |     eval_dynamic_batching: None\n21:53:54 |     evaltask: None\n21:53:54 |     ffn_size: 3072\n21:53:54 |     final_extra_opt: \n21:53:54 |     fixed_candidate_vecs: reuse\n21:53:54 |     fixed_candidates_path: None\n21:53:54 |     force_fp16_tokens: True\n21:53:54 |     fp16: True\n21:53:54 |     fp16_impl: safe\n21:53:54 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type1/run3/data_test.txt\n21:53:54 |     fromfile_datatype_extension: True\n21:53:54 |     gpu: -1\n21:53:54 |     gradient_clip: 0.1\n21:53:54 |     hide_labels: False\n21:53:54 |     history_add_global_end_token: None\n21:53:54 |     history_reversed: False\n21:53:54 |     history_size: 20\n21:53:54 |     ignore_bad_candidates: False\n21:53:54 |     ignore_labels: None\n21:53:54 |     image_cropsize: 224\n21:53:54 |     image_mode: raw\n21:53:54 |     image_size: 256\n21:53:54 |     inference: max\n21:53:54 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n21:53:54 |     init_opt: None\n21:53:54 |     interactive_candidates: fixed\n21:53:54 |     interactive_mode: False\n21:53:54 |     invsqrt_lr_decay_gamma: -1\n21:53:54 |     is_debug: False\n21:53:54 |     label_truncate: 72\n21:53:54 |     learn_embeddings: True\n21:53:54 |     learn_positional_embeddings: True\n21:53:54 |     learningrate: 5e-05\n21:53:54 |     load_from_pretrained_ranker: True\n21:53:54 |     log_every_n_secs: 10.0\n21:53:54 |     log_every_n_steps: 50\n21:53:54 |     log_keep_fields: all\n21:53:54 |     loglevel: info\n21:53:54 |     lr_scheduler: reduceonplateau\n21:53:54 |     lr_scheduler_decay: 0.5\n21:53:54 |     lr_scheduler_patience: 3\n21:53:54 |     max_train_steps: -1\n21:53:54 |     max_train_time: 7200.0\n21:53:54 |     memory_attention: sqrt\n21:53:54 |     metrics: default\n21:53:54 |     model: transformer/classifier\n21:53:54 |     model_file: /tmp/model3\n21:53:54 |     model_parallel: False\n21:53:54 |     momentum: 0\n21:53:54 |     multitask_weights: [1]\n21:53:54 |     mutators: None\n21:53:54 |     n_decoder_layers: -1\n21:53:54 |     n_encoder_layers: -1\n21:53:54 |     n_heads: 12\n21:53:54 |     n_layers: 12\n21:53:54 |     n_positions: 1024\n21:53:54 |     n_segments: 2\n21:53:54 |     nesterov: True\n21:53:54 |     no_cuda: False\n21:53:54 |     normalize_sent_emb: False\n21:53:54 |     num_epochs: -1\n21:53:54 |     num_examples: -1\n21:53:54 |     num_workers: 0\n21:53:54 |     nus: [0.7]\n21:53:54 |     optimizer: adamax\n21:53:54 |     output_scaling: 0.06\n21:53:54 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type1/run3/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model3', 'batchsize': 40}\"\n21:53:54 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n21:53:54 |     person_tokens: False\n21:53:54 |     print_scores: False\n21:53:54 |     rank_candidates: False\n21:53:54 |     rank_top_k: -1\n21:53:54 |     reduction_type: mean\n21:53:54 |     ref_class: None\n21:53:54 |     relu_dropout: 0.0\n21:53:54 |     repeat_blocking_heuristic: True\n21:53:54 |     report_filename: \n21:53:54 |     return_cand_scores: False\n21:53:54 |     save_after_valid: True\n21:53:54 |     save_every_n_secs: -1\n21:53:54 |     save_format: conversations\n21:53:54 |     share_encoders: False\n21:53:54 |     share_word_embeddings: False\n21:53:54 |     short_final_eval: False\n21:53:54 |     special_tok_lst: None\n21:53:54 |     split_lines: False\n21:53:54 |     starttime: Dec03_21-49\n21:53:54 |     task: fromfile:parlaiformat\n21:53:54 |     tensorboard_log: False\n21:53:54 |     tensorboard_logdir: None\n21:53:54 |     text_truncate: 360\n21:53:54 |     threshold: 0.5\n21:53:54 |     topk: 5\n21:53:54 |     train_predict: False\n21:53:54 |     truncate: 1024\n21:53:54 |     update_classifier_head_only: False\n21:53:54 |     update_freq: 1\n21:53:54 |     use_memories: False\n21:53:54 |     use_reply: none\n21:53:54 |     validation_cutoff: 1.0\n21:53:54 |     validation_every_n_epochs: -1\n21:53:54 |     validation_every_n_secs: 20.0\n21:53:54 |     validation_every_n_steps: -1\n21:53:54 |     validation_max_exs: -1\n21:53:54 |     validation_metric: accuracy\n21:53:54 |     validation_metric_mode: max\n21:53:54 |     validation_patience: 30\n21:53:54 |     validation_share_agent: False\n21:53:54 |     variant: xlm\n21:53:54 |     verbose: False\n21:53:54 |     wandb_entity: None\n21:53:54 |     wandb_log: False\n21:53:54 |     wandb_name: None\n21:53:54 |     wandb_project: None\n21:53:54 |     warmup_rate: 0.0001\n21:53:54 |     warmup_updates: 1000\n21:53:54 |     weight_decay: None\n21:53:54 |     world_logs: \n21:53:54 |     wrap_memory_encoder: False\n21:53:55 | Evaluating task fromfile:parlaiformat using datatype valid.\n21:53:55 | creating task(s): fromfile:parlaiformat\n21:53:55 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n21:53:55 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run3/data_test.txt\n21:54:03 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9360 9.36e-10               .7500                 .6154   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9600            .9633              .9953   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9333 12.07 562.9  1812       0          0 128.7 1000 .9360   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2829 7.704e-06   208 669.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    154 770.9 2481        .9420\u001b[0m\n21:54:03 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9360 9.36e-10               .7500                 .6154   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9600            .9633              .9953   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9333 12.07 562.9  1812       0          0 128.7 1000 .9360   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2829 7.704e-06   208 669.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    154 770.9 2481        .9420\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model3*","metadata":{"execution":{"iopub.status.busy":"2022-12-03T21:55:15.278340Z","iopub.execute_input":"2022-12-03T21:55:15.278777Z","iopub.status.idle":"2022-12-03T21:55:16.516763Z","shell.execute_reply.started":"2022-12-03T21:55:15.278734Z","shell.execute_reply":"2022-12-03T21:55:16.515473Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"run 4","metadata":{}},{"cell_type":"code","source":"# run 4 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type1/run4/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model4","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-12-03T21:59:24.614041Z","iopub.execute_input":"2022-12-03T21:59:24.614481Z","iopub.status.idle":"2022-12-03T21:59:33.936549Z","shell.execute_reply.started":"2022-12-03T21:59:24.614441Z","shell.execute_reply":"2022-12-03T21:59:33.935299Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"21:59:33 | building dictionary first...\n21:59:33 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n21:59:33 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n21:59:33 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type1/run4/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n21:59:33 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n21:59:33 | Using CUDA\n21:59:33 | loading dictionary from /tmp/model4.dict\n^C\nTraceback (most recent call last):\n  File \"/opt/conda/bin/parlai\", line 8, in <module>\n    sys.exit(main())\n  File \"/opt/conda/lib/python3.7/site-packages/parlai/__main__.py\", line 14, in main\n    superscript_main()\n  File \"/opt/conda/lib/python3.7/site-packages/parlai/core/script.py\", line 325, in superscript_main\n    return SCRIPT_REGISTRY[cmd].klass._run_from_parser_and_opt(opt, parser)\n  File \"/opt/conda/lib/python3.7/site-packages/parlai/core/script.py\", line 108, in _run_from_parser_and_opt\n    return script.run()\n  File \"/opt/conda/lib/python3.7/site-packages/parlai/scripts/train_model.py\", line 1047, in run\n    self.train_loop = TrainLoop(self.opt)\n  File \"/opt/conda/lib/python3.7/site-packages/parlai/scripts/train_model.py\", line 371, in __init__\n    self.agent = create_agent(opt)\n  File \"/opt/conda/lib/python3.7/site-packages/parlai/core/agents.py\", line 468, in create_agent\n    model = create_agent_from_opt_file(opt)\n  File \"/opt/conda/lib/python3.7/site-packages/parlai/core/agents.py\", line 421, in create_agent_from_opt_file\n    return model_class(opt_from_file)\n  File \"/opt/conda/lib/python3.7/site-packages/parlai/core/torch_classifier_agent.py\", line 458, in __init__\n    super().__init__(opt, shared)\n  File \"/opt/conda/lib/python3.7/site-packages/parlai/core/torch_agent.py\", line 783, in __init__\n    self.dict = self.build_dictionary()\n  File \"/opt/conda/lib/python3.7/site-packages/parlai/core/torch_agent.py\", line 862, in build_dictionary\n    d = self.dictionary_class()(self.opt)\n  File \"/opt/conda/lib/python3.7/site-packages/parlai/core/dict.py\", line 292, in __init__\n    self.load(opt['dict_file'])\n  File \"/opt/conda/lib/python3.7/site-packages/parlai/core/dict.py\", line 633, in load\n    if lower_special and token in SPECIAL_TOKENS:\nKeyboardInterrupt\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type1/run4/data_test.txt -m transformer/classifier -mf /tmp/model4 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-03T21:59:33.939365Z","iopub.execute_input":"2022-12-03T21:59:33.939972Z","iopub.status.idle":"2022-12-03T22:00:03.252432Z","shell.execute_reply.started":"2022-12-03T21:59:33.939922Z","shell.execute_reply":"2022-12-03T22:00:03.250909Z"},"scrolled":true,"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"21:59:41 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr1type1/run4/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr1type1/run4/data)\u001b[0m\n21:59:41 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n21:59:41 | Using CUDA\n21:59:41 | loading dictionary from /tmp/model4.dict\n21:59:41 | num words = 54944\n21:59:45 | Loading existing model parameters from /tmp/model4\n21:59:51 | Total parameters: 128,042,498 (128,042,498 trainable)\n21:59:53 | Opt:\n21:59:53 |     activation: gelu\n21:59:53 |     adafactor_eps: '[1e-30, 0.001]'\n21:59:53 |     adam_eps: 1e-08\n21:59:53 |     add_p1_after_newln: False\n21:59:53 |     aggregate_micro: False\n21:59:53 |     allow_missing_init_opts: False\n21:59:53 |     area_under_curve_class: None\n21:59:53 |     area_under_curve_digits: -1\n21:59:53 |     attention_dropout: 0.1\n21:59:53 |     batchsize: 40\n21:59:53 |     betas: '[0.9, 0.999]'\n21:59:53 |     bpe_add_prefix_space: None\n21:59:53 |     bpe_debug: False\n21:59:53 |     bpe_dropout: None\n21:59:53 |     bpe_merge: None\n21:59:53 |     bpe_vocab: None\n21:59:53 |     candidates: inline\n21:59:53 |     cap_num_predictions: 100\n21:59:53 |     checkpoint_activations: False\n21:59:53 |     class_weights: None\n21:59:53 |     classes: \"['__notok__', '__ok__']\"\n21:59:53 |     classes_from_file: None\n21:59:53 |     data_parallel: True\n21:59:53 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n21:59:53 |     datatype: train\n21:59:53 |     delimiter: '\\n'\n21:59:53 |     dict_class: parlai.core.dict:DictionaryAgent\n21:59:53 |     dict_endtoken: __start__\n21:59:53 |     dict_file: /tmp/model4.dict\n21:59:53 |     dict_include_test: False\n21:59:53 |     dict_include_valid: False\n21:59:53 |     dict_initpath: None\n21:59:53 |     dict_language: english\n21:59:53 |     dict_loaded: True\n21:59:53 |     dict_lower: True\n21:59:53 |     dict_max_ngram_size: -1\n21:59:53 |     dict_maxexs: -1\n21:59:53 |     dict_maxtokens: -1\n21:59:53 |     dict_minfreq: 0\n21:59:53 |     dict_nulltoken: __null__\n21:59:53 |     dict_starttoken: __start__\n21:59:53 |     dict_textfields: text,labels\n21:59:53 |     dict_tokenizer: bpe\n21:59:53 |     dict_unktoken: __unk__\n21:59:53 |     display_examples: False\n21:59:53 |     download_path: None\n21:59:53 |     dropout: 0.1\n21:59:53 |     dynamic_batching: None\n21:59:53 |     embedding_projection: random\n21:59:53 |     embedding_size: 768\n21:59:53 |     embedding_type: random\n21:59:53 |     embeddings_scale: False\n21:59:53 |     encode_candidate_vecs: True\n21:59:53 |     encode_candidate_vecs_batchsize: 256\n21:59:53 |     eval_batchsize: None\n21:59:53 |     eval_candidates: inline\n21:59:53 |     eval_dynamic_batching: None\n21:59:53 |     evaltask: None\n21:59:53 |     ffn_size: 3072\n21:59:53 |     final_extra_opt: \n21:59:53 |     fixed_candidate_vecs: reuse\n21:59:53 |     fixed_candidates_path: None\n21:59:53 |     force_fp16_tokens: True\n21:59:53 |     fp16: True\n21:59:53 |     fp16_impl: safe\n21:59:53 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type1/run4/data_test.txt\n21:59:53 |     fromfile_datatype_extension: True\n21:59:53 |     gpu: -1\n21:59:53 |     gradient_clip: 0.1\n21:59:53 |     hide_labels: False\n21:59:53 |     history_add_global_end_token: None\n21:59:53 |     history_reversed: False\n21:59:53 |     history_size: 20\n21:59:53 |     ignore_bad_candidates: False\n21:59:53 |     ignore_labels: None\n21:59:53 |     image_cropsize: 224\n21:59:53 |     image_mode: raw\n21:59:53 |     image_size: 256\n21:59:53 |     inference: max\n21:59:53 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n21:59:53 |     init_opt: None\n21:59:53 |     interactive_candidates: fixed\n21:59:53 |     interactive_mode: False\n21:59:53 |     invsqrt_lr_decay_gamma: -1\n21:59:53 |     is_debug: False\n21:59:53 |     label_truncate: 72\n21:59:53 |     learn_embeddings: True\n21:59:53 |     learn_positional_embeddings: True\n21:59:53 |     learningrate: 5e-05\n21:59:53 |     load_from_pretrained_ranker: True\n21:59:53 |     log_every_n_secs: 10.0\n21:59:53 |     log_every_n_steps: 50\n21:59:53 |     log_keep_fields: all\n21:59:53 |     loglevel: info\n21:59:53 |     lr_scheduler: reduceonplateau\n21:59:53 |     lr_scheduler_decay: 0.5\n21:59:53 |     lr_scheduler_patience: 3\n21:59:53 |     max_train_steps: -1\n21:59:53 |     max_train_time: 7200.0\n21:59:53 |     memory_attention: sqrt\n21:59:53 |     metrics: default\n21:59:53 |     model: transformer/classifier\n21:59:53 |     model_file: /tmp/model4\n21:59:53 |     model_parallel: False\n21:59:53 |     momentum: 0\n21:59:53 |     multitask_weights: [1]\n21:59:53 |     mutators: None\n21:59:53 |     n_decoder_layers: -1\n21:59:53 |     n_encoder_layers: -1\n21:59:53 |     n_heads: 12\n21:59:53 |     n_layers: 12\n21:59:53 |     n_positions: 1024\n21:59:53 |     n_segments: 2\n21:59:53 |     nesterov: True\n21:59:53 |     no_cuda: False\n21:59:53 |     normalize_sent_emb: False\n21:59:53 |     num_epochs: -1\n21:59:53 |     num_examples: -1\n21:59:53 |     num_workers: 0\n21:59:53 |     nus: [0.7]\n21:59:53 |     optimizer: adamax\n21:59:53 |     output_scaling: 0.06\n21:59:53 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type1/run4/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model4', 'batchsize': 40}\"\n21:59:53 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n21:59:53 |     person_tokens: False\n21:59:53 |     print_scores: False\n21:59:53 |     rank_candidates: False\n21:59:53 |     rank_top_k: -1\n21:59:53 |     reduction_type: mean\n21:59:53 |     ref_class: None\n21:59:53 |     relu_dropout: 0.0\n21:59:53 |     repeat_blocking_heuristic: True\n21:59:53 |     report_filename: \n21:59:53 |     return_cand_scores: False\n21:59:53 |     save_after_valid: True\n21:59:53 |     save_every_n_secs: -1\n21:59:53 |     save_format: conversations\n21:59:53 |     share_encoders: False\n21:59:53 |     share_word_embeddings: False\n21:59:53 |     short_final_eval: False\n21:59:53 |     special_tok_lst: None\n21:59:53 |     split_lines: False\n21:59:53 |     starttime: Dec03_21-56\n21:59:53 |     task: fromfile:parlaiformat\n21:59:53 |     tensorboard_log: False\n21:59:53 |     tensorboard_logdir: None\n21:59:53 |     text_truncate: 360\n21:59:53 |     threshold: 0.5\n21:59:53 |     topk: 5\n21:59:53 |     train_predict: False\n21:59:53 |     truncate: 1024\n21:59:53 |     update_classifier_head_only: False\n21:59:53 |     update_freq: 1\n21:59:53 |     use_memories: False\n21:59:53 |     use_reply: none\n21:59:53 |     validation_cutoff: 1.0\n21:59:53 |     validation_every_n_epochs: -1\n21:59:53 |     validation_every_n_secs: 20.0\n21:59:53 |     validation_every_n_steps: -1\n21:59:53 |     validation_max_exs: -1\n21:59:53 |     validation_metric: accuracy\n21:59:53 |     validation_metric_mode: max\n21:59:53 |     validation_patience: 30\n21:59:53 |     validation_share_agent: False\n21:59:53 |     variant: xlm\n21:59:53 |     verbose: False\n21:59:53 |     wandb_entity: None\n21:59:53 |     wandb_log: False\n21:59:53 |     wandb_name: None\n21:59:53 |     wandb_project: None\n21:59:53 |     warmup_rate: 0.0001\n21:59:53 |     warmup_updates: 1000\n21:59:53 |     weight_decay: None\n21:59:53 |     world_logs: \n21:59:53 |     wrap_memory_encoder: False\n21:59:53 | Evaluating task fromfile:parlaiformat using datatype valid.\n21:59:53 | creating task(s): fromfile:parlaiformat\n21:59:53 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n21:59:53 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run4/data_test.txt\n22:00:01 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9470 9.47e-10               .7819                 .6643   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9698              .9942   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9467 12.07 562.9  1888       0          0 134.2 1000 .9470   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2866 7.204e-06   208 697.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    144 770.9 2586        .9510\u001b[0m\n22:00:01 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9470 9.47e-10               .7819                 .6643   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9698              .9942   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9467 12.07 562.9  1888       0          0 134.2 1000 .9470   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2866 7.204e-06   208 697.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    144 770.9 2586        .9510\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model4*","metadata":{"execution":{"iopub.status.busy":"2022-12-03T22:00:03.255047Z","iopub.execute_input":"2022-12-03T22:00:03.256074Z","iopub.status.idle":"2022-12-03T22:00:04.581365Z","shell.execute_reply.started":"2022-12-03T22:00:03.256026Z","shell.execute_reply":"2022-12-03T22:00:04.579961Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"run 5","metadata":{}},{"cell_type":"code","source":"# run 5 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type1/run5/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model5","metadata":{"execution":{"iopub.status.busy":"2022-12-03T22:00:04.587493Z","iopub.execute_input":"2022-12-03T22:00:04.589918Z","iopub.status.idle":"2022-12-03T22:11:58.829680Z","shell.execute_reply.started":"2022-12-03T22:00:04.589861Z","shell.execute_reply":"2022-12-03T22:11:58.828399Z"},"scrolled":true,"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"22:00:11 | building dictionary first...\n22:00:11 | No model with opt yet at: /tmp/model5(.opt)\n22:00:11 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type1/run5/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n22:00:11 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n22:00:11 | Using CUDA\n22:00:11 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n22:00:11 | num words = 54944\n22:00:16 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n22:00:26 | Total parameters: 128,042,498 (128,042,498 trainable)\n22:00:26 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n22:00:26 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n22:00:26 | Opt:\n22:00:26 |     activation: gelu\n22:00:26 |     adafactor_eps: '(1e-30, 0.001)'\n22:00:26 |     adam_eps: 1e-08\n22:00:26 |     add_p1_after_newln: False\n22:00:26 |     aggregate_micro: False\n22:00:26 |     allow_missing_init_opts: False\n22:00:26 |     attention_dropout: 0.1\n22:00:26 |     batchsize: 20\n22:00:26 |     betas: '(0.9, 0.999)'\n22:00:26 |     bpe_add_prefix_space: None\n22:00:26 |     bpe_debug: False\n22:00:26 |     bpe_dropout: None\n22:00:26 |     bpe_merge: None\n22:00:26 |     bpe_vocab: None\n22:00:26 |     candidates: inline\n22:00:26 |     cap_num_predictions: 100\n22:00:26 |     checkpoint_activations: False\n22:00:26 |     class_weights: None\n22:00:26 |     classes: \"['__notok__', '__ok__']\"\n22:00:26 |     classes_from_file: None\n22:00:26 |     data_parallel: True\n22:00:26 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n22:00:26 |     datatype: train\n22:00:26 |     delimiter: '\\n'\n22:00:26 |     dict_class: parlai.core.dict:DictionaryAgent\n22:00:26 |     dict_endtoken: __start__\n22:00:26 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n22:00:26 |     dict_include_test: False\n22:00:26 |     dict_include_valid: False\n22:00:26 |     dict_initpath: None\n22:00:26 |     dict_language: english\n22:00:26 |     dict_loaded: True\n22:00:26 |     dict_lower: True\n22:00:26 |     dict_max_ngram_size: -1\n22:00:26 |     dict_maxexs: -1\n22:00:26 |     dict_maxtokens: -1\n22:00:26 |     dict_minfreq: 0\n22:00:26 |     dict_nulltoken: __null__\n22:00:26 |     dict_starttoken: __start__\n22:00:26 |     dict_textfields: text,labels\n22:00:26 |     dict_tokenizer: bpe\n22:00:26 |     dict_unktoken: __unk__\n22:00:26 |     display_examples: False\n22:00:26 |     download_path: None\n22:00:26 |     dropout: 0.1\n22:00:26 |     dynamic_batching: None\n22:00:26 |     embedding_projection: random\n22:00:26 |     embedding_size: 768\n22:00:26 |     embedding_type: random\n22:00:26 |     embeddings_scale: False\n22:00:26 |     encode_candidate_vecs: True\n22:00:26 |     encode_candidate_vecs_batchsize: 256\n22:00:26 |     eval_batchsize: None\n22:00:26 |     eval_candidates: inline\n22:00:26 |     eval_dynamic_batching: None\n22:00:26 |     evaltask: None\n22:00:26 |     ffn_size: 3072\n22:00:26 |     final_extra_opt: \n22:00:26 |     fixed_candidate_vecs: reuse\n22:00:26 |     fixed_candidates_path: None\n22:00:26 |     force_fp16_tokens: False\n22:00:26 |     fp16: True\n22:00:26 |     fp16_impl: safe\n22:00:26 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type1/run5/data\n22:00:26 |     fromfile_datatype_extension: True\n22:00:26 |     gpu: -1\n22:00:26 |     gradient_clip: 0.1\n22:00:26 |     hide_labels: False\n22:00:26 |     history_add_global_end_token: None\n22:00:26 |     history_reversed: False\n22:00:26 |     history_size: 20\n22:00:26 |     ignore_bad_candidates: False\n22:00:26 |     ignore_labels: None\n22:00:26 |     image_cropsize: 224\n22:00:26 |     image_mode: raw\n22:00:26 |     image_size: 256\n22:00:26 |     inference: max\n22:00:26 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n22:00:26 |     init_opt: None\n22:00:26 |     interactive_candidates: fixed\n22:00:26 |     interactive_mode: False\n22:00:26 |     invsqrt_lr_decay_gamma: -1\n22:00:26 |     is_debug: False\n22:00:26 |     label_truncate: 72\n22:00:26 |     learn_embeddings: True\n22:00:26 |     learn_positional_embeddings: True\n22:00:26 |     learningrate: 5e-05\n22:00:26 |     load_from_checkpoint: False\n22:00:26 |     load_from_pretrained_ranker: True\n22:00:26 |     log_every_n_secs: 10.0\n22:00:26 |     log_every_n_steps: 50\n22:00:26 |     log_keep_fields: all\n22:00:26 |     loglevel: info\n22:00:26 |     lr_scheduler: reduceonplateau\n22:00:26 |     lr_scheduler_decay: 0.5\n22:00:26 |     lr_scheduler_patience: 3\n22:00:26 |     max_train_steps: -1\n22:00:26 |     max_train_time: 7200.0\n22:00:26 |     memory_attention: sqrt\n22:00:26 |     metrics: default\n22:00:26 |     model: transformer/classifier\n22:00:26 |     model_file: /tmp/model5\n22:00:26 |     model_parallel: False\n22:00:26 |     momentum: 0\n22:00:26 |     multitask_weights: [1]\n22:00:26 |     mutators: None\n22:00:26 |     n_decoder_layers: -1\n22:00:26 |     n_encoder_layers: -1\n22:00:26 |     n_heads: 12\n22:00:26 |     n_layers: 12\n22:00:26 |     n_positions: 1024\n22:00:26 |     n_segments: 2\n22:00:26 |     nesterov: True\n22:00:26 |     no_cuda: False\n22:00:26 |     normalize_sent_emb: False\n22:00:26 |     num_epochs: -1\n22:00:26 |     num_workers: 0\n22:00:26 |     nus: (0.7,)\n22:00:26 |     optimizer: adamax\n22:00:26 |     output_scaling: 0.06\n22:00:26 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type1/run5/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model5'}\"\n22:00:26 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n22:00:26 |     person_tokens: False\n22:00:26 |     print_scores: False\n22:00:26 |     rank_candidates: False\n22:00:26 |     rank_top_k: -1\n22:00:26 |     reduction_type: mean\n22:00:26 |     ref_class: None\n22:00:26 |     relu_dropout: 0.0\n22:00:26 |     repeat_blocking_heuristic: True\n22:00:26 |     return_cand_scores: False\n22:00:26 |     save_after_valid: True\n22:00:26 |     save_every_n_secs: -1\n22:00:26 |     save_format: conversations\n22:00:26 |     share_encoders: False\n22:00:26 |     share_word_embeddings: False\n22:00:26 |     short_final_eval: False\n22:00:26 |     special_tok_lst: None\n22:00:26 |     split_lines: False\n22:00:26 |     starttime: Dec03_22-00\n22:00:26 |     task: fromfile:parlaiformat\n22:00:26 |     tensorboard_log: False\n22:00:26 |     tensorboard_logdir: None\n22:00:26 |     text_truncate: 360\n22:00:26 |     threshold: 0.5\n22:00:26 |     topk: 5\n22:00:26 |     train_predict: False\n22:00:26 |     truncate: 1024\n22:00:26 |     update_classifier_head_only: False\n22:00:26 |     update_freq: 1\n22:00:26 |     use_memories: False\n22:00:26 |     use_reply: none\n22:00:26 |     validation_cutoff: 1.0\n22:00:26 |     validation_every_n_epochs: -1\n22:00:26 |     validation_every_n_secs: 20.0\n22:00:26 |     validation_every_n_steps: -1\n22:00:26 |     validation_max_exs: -1\n22:00:26 |     validation_metric: accuracy\n22:00:26 |     validation_metric_mode: max\n22:00:26 |     validation_patience: 30\n22:00:26 |     validation_share_agent: False\n22:00:26 |     variant: xlm\n22:00:26 |     verbose: False\n22:00:26 |     wandb_entity: None\n22:00:26 |     wandb_log: False\n22:00:26 |     wandb_name: None\n22:00:26 |     wandb_project: None\n22:00:26 |     warmup_rate: 0.0001\n22:00:26 |     warmup_updates: 1000\n22:00:26 |     weight_decay: None\n22:00:26 |     world_logs: \n22:00:26 |     wrap_memory_encoder: False\n22:00:27 | creating task(s): fromfile:parlaiformat\n22:00:27 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run5/data_train.txt\n22:00:27 | training...\n22:00:37 | time:10s total_exs:420 total_steps:21 epochs:2.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5595 5.595e-10               .2857                 .6379   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .1841            .6816              .5470   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9041 11.72     1 274.5 574.6       0          0 41.87  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5595             32768  2.539    .1206 5.957 .6812 1.055e-06 119.1 249.4   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   21 393.6 824.1 2.098        .4921\n\n22:00:47 | time:20s total_exs:1180 total_steps:59 epochs:5.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6566 6.566e-10               .5381                 .8261   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .3990            .7267              .6024   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9156 11.86     1 277.1  1083       0          0 78.15  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6566             32768   2.54    .1206 6.003 .6571 2.955e-06 120.1 469.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   59 397.2 1552 3.917        .6321\n\n22:00:47 | creating task(s): fromfile:parlaiformat\n22:00:47 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run5/data_valid.txt\n22:00:47 | running eval: valid\n22:00:47 | eval completed in 0.19s\n22:00:47 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .6667                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5000            .8000              .6667   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1789       0          0 141.1   24 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6415 2.955e-06    72 847.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                     59  224 2636        .7333\n\u001b[0m\n22:00:47 | \u001b[1;32mnew best accuracy: 0.75\u001b[0m\n22:00:47 | saving best valid model: /tmp/model5\n22:00:47 | Saving dictionary to /tmp/model5.dict\n22:00:51 | saving model checkpoint: /tmp/model5.checkpoint\n22:00:51 | Saving dictionary to /tmp/model5.checkpoint.dict\n22:01:09 | time:42s total_exs:1880 total_steps:94 epochs:9.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8586 8.586e-10               .8576                 .8791   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8371            .8596              .8393   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8808 12.11     1 282.3 968.3       0          0 68.61  700   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8586             32768  2.922    .1207 6.017 .5998 4.705e-06 120.3 412.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   94 402.6 1381 3.438        .8585\n\n22:01:12 | time:45s total_exs:2080 total_steps:104 epochs:10.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9100 9.1e-10               .9091                 .9375   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8824            .9109              .8846   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9388 11.77     1 275.4  1041       0          0 75.63  200   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9100             32768  3.236    .1189  6.02 .5313 5.204e-06 120.4 455.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  104 395.8 1497 3.814        .9100\n\n22:01:12 | running eval: valid\n22:01:12 | eval completed in 0.19s\n22:01:12 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1747       0          0 137.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5188 5.204e-06    72 827.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    104  224 2574        .9161\n\u001b[0m\n22:01:12 | \u001b[1;32mnew best accuracy: 0.9167 (previous best was 0.75)\u001b[0m\n22:01:12 | saving best valid model: /tmp/model5\n22:01:21 | saving model checkpoint: /tmp/model5.checkpoint\n22:01:37 | time:70s total_exs:2860 total_steps:143 epochs:14.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9154 9.154e-10               .9111                 .9260   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8966            .9193              .9060   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9330 11.68     1 273.5  1055       0          0 77.15  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9154             32768  3.998    .1207 5.967 .4283 7.154e-06 119.3 460.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  143 392.8 1515 3.866        .9153\n\n22:01:42 | time:75s total_exs:3220 total_steps:161 epochs:16.10\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9250 9.25e-10               .9217                 .9353   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9086            .9280              .9158   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9405 11.45     1   269  1058       0          0 78.66  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9250             32768  6.046    .1207 5.972 .2889 8.054e-06 119.4 469.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  161 388.4 1528 3.952        .9250\n\n22:01:42 | running eval: valid\n22:01:42 | eval completed in 0.20s\n22:01:42 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1707       0          0 134.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .3063 8.054e-06    72 808.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    161  224 2515        .9167\n\u001b[0m\n22:01:42 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 1\u001b[0m\n22:01:42 | saving model checkpoint: /tmp/model5.checkpoint\n22:02:02 | time:95s total_exs:3980 total_steps:199 epochs:19.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9513 9.513e-10               .9515                 .9356   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9680            .9511              .9677   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9351 11.77     1 275.4  1028       0          0 74.65  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9513             32768  6.837    .1207 5.987 .1922 9.954e-06 119.7 446.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  199 395.2 1475 3.741        .9513\n\n22:02:02 | time:95s total_exs:4000 total_steps:200 epochs:20.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.55     1   291  1220       0          0  83.8   20   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss    lr  ltpb  ltps  \\\n     1             32768  7.027    .1207   5.7 .06183 1e-05   114 477.7   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps  ups  weighted_f1  \n         0          0                  200  405 1697 4.63            1\n\n22:02:02 | running eval: valid\n22:02:02 | eval completed in 0.19s\n22:02:02 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1764       0          0 139.2   24 .8333   \n    gpu_mem  llen  loss    lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .3854 1e-05    72 835.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    200  224 2600        .8322\n\u001b[0m\n22:02:02 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 2\u001b[0m\n22:02:02 | saving model checkpoint: /tmp/model5.checkpoint\n22:02:17 | time:111s total_exs:4780 total_steps:239 epochs:23.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9731 9.731e-10               .9711                 .9566   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9860            .9748              .9878   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9621    12     1 280.1  1076       0          0 76.82  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9731             32768  3.551    .1207 5.918 .1116 1.195e-05 118.4 454.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  239 398.4 1530 3.85        .9731\n\n22:02:22 | time:116s total_exs:5160 total_steps:258 epochs:25.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9868 9.868e-10               .9875                 .9752   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9861                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9727 11.83     1 276.5  1093       0          0 79.02  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9868             32768   2.36    .1207 6.037 .05117 1.29e-05 120.7   477   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  258 397.3 1570 3.969        .9868\n\n22:02:22 | running eval: valid\n22:02:22 | eval completed in 0.18s\n22:02:22 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1827       0          0 144.2   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .6527 1.29e-05    72 865.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    258  224 2692        .8322\n\u001b[0m\n22:02:22 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 3\u001b[0m\n22:02:22 | saving model checkpoint: /tmp/model5.checkpoint\n22:02:37 | time:130s total_exs:5920 total_steps:296 epochs:29.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9921 9.921e-10               .9923                 .9873   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9974            .9918              .9973   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9865 11.89 .3684 277.9  1039       0          0 74.76  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9921             32768  3.522    .1207 6.026 .02677 1.48e-05 120.5 450.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  296 398.4 1489 3.746        .9921\n\n22:02:43 | time:136s total_exs:6340 total_steps:317 epochs:31.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9929 9.929e-10               .9931                 .9863   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9926                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9853 12.17 .1429 283.5  1096       0          0  77.3  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9929             32768  .7650    .1207 6.029 .02464 1.585e-05 120.6   466   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  317  404 1562 3.881        .9929\n\n22:02:43 | running eval: valid\n22:02:43 | eval completed in 0.19s\n22:02:43 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1788       0          0 141.1   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 1.149 1.585e-05    72 846.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    317  224 2635        .7884\n\u001b[0m\n22:02:43 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 4\u001b[0m\n22:02:43 | saving model checkpoint: /tmp/model5.checkpoint\n22:02:57 | time:150s total_exs:7120 total_steps:356 epochs:35.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9987                 .9974   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9987                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9974 11.83 .1026 276.6  1069       0          0 77.28  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n   .9987             32768  .6649    .1207     6 .004983 1.78e-05   120 463.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  356 396.6 1532 3.873        .9987\n\n22:03:03 | time:156s total_exs:7540 total_steps:377 epochs:37.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1  11.8 .04762 276.1  1029       0          0 74.56   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  \\\n    420   1             32768  4.975    .1207 6.076 .00255 1.885e-05 121.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     453       0          0                  377 397.6 1482 3.743            1\n\n22:03:03 | running eval: valid\n22:03:03 | eval completed in 0.19s\n22:03:03 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1761       0          0   139   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 1.072 1.885e-05    72 834.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    377  224 2595        .8322\n\u001b[0m\n22:03:03 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 5\u001b[0m\n22:03:03 | saving model checkpoint: /tmp/model5.checkpoint\n22:03:17 | time:171s total_exs:8320 total_steps:416 epochs:41.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.61 .05128 272.2  1042       0          0 76.56   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  \\\n    780   1             32768  .9409    .1207 5.964 .001483 2.08e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.6       0          0                  416 391.5 1499 3.836            1\n\n22:03:23 | time:176s total_exs:8760 total_steps:438 epochs:43.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.41     0 268.1  1038       0          0 77.45  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .01453    .1207 6.068 .001175 2.19e-05 121.4   470   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  438 389.5 1508 3.888            1\n\n22:03:23 | running eval: valid\n22:03:23 | eval completed in 0.20s\n22:03:23 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8000                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8571              .7500   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1734       0          0 136.8   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 1.142 2.19e-05    72 821.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    438  224 2556        .8286\n\u001b[0m\n22:03:23 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 6\u001b[0m\n22:03:23 | saving model checkpoint: /tmp/model5.checkpoint\n22:03:38 | time:191s total_exs:9520 total_steps:476 epochs:47.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.73 .02632 274.7  1032       0          0 75.14   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  \\\n    760   1             32768 .02312    .1207 5.966 .001073 2.38e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   448.3       0          0                  476  394 1480 3.766            1\n\n22:03:44 | time:197s total_exs:9940 total_steps:497 epochs:49.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.7     0 274.1  1081       0          0 78.87  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01214    .1190 5.995 .0009962 2.485e-05 119.9 472.9   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps  ups  weighted_f1  \n         0          0                  497  394 1554 3.96            1\n\n22:03:44 | running eval: valid\n22:03:44 | eval completed in 0.21s\n22:03:44 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1685       0          0   133   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6  1.11 2.485e-05    72 797.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    497  224 2483        .8322\n\u001b[0m\n22:03:44 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 7\u001b[0m\n22:03:44 | saving model checkpoint: /tmp/model5.checkpoint\n22:03:59 | time:212s total_exs:10700 total_steps:535 epochs:53.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.76     0 275.2  1042       0          0 75.71  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01127    .1207 5.929 .0009223 2.675e-05 118.6 448.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  535 393.8 1491 3.794            1\n\n22:04:04 | time:217s total_exs:11080 total_steps:554 epochs:55.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.28     0 265.7 996.3       0          0 74.99  380   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .01065    .1190     6 .0008725 2.77e-05   120   450   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  554 385.7 1446 3.766            1\n\n22:04:04 | running eval: valid\n22:04:04 | eval completed in 0.19s\n22:04:04 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1749       0          0   138   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 1.197 2.77e-05    72 828.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    554  224 2577        .8322\n\u001b[0m\n22:04:04 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 8\u001b[0m\n22:04:04 | saving model checkpoint: /tmp/model5.checkpoint\n22:04:19 | time:232s total_exs:11860 total_steps:593 epochs:59.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.92     0 278.4  1074       0          0 77.18  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .009557    .1208 6.044 .0008175 2.965e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   466.5       0          0                  593 399.3 1541 3.868            1\n\n22:04:24 | time:237s total_exs:12260 total_steps:613 epochs:61.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.55     0   271  1072       0          0 79.08  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .008931    .1208  5.94 .0007608 3.065e-05 118.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   469.7       0          0                  613 389.8 1541 3.972            1\n\n22:04:24 | running eval: valid\n22:04:24 | eval completed in 0.19s\n22:04:24 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1747       0          0 137.8   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 1.233 3.065e-05    72 827.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    613  224 2575        .8322\n\u001b[0m\n22:04:24 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 9\u001b[0m\n22:04:24 | saving model checkpoint: /tmp/model5.checkpoint\n22:04:39 | time:253s total_exs:13040 total_steps:652 epochs:65.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.83     0 276.6  1051       0          0 75.95  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .008552    .1208 6.008 .0007173 3.26e-05 120.2 456.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  652 396.8 1507 3.806            1\n\n22:04:44 | time:257s total_exs:13420 total_steps:671 epochs:67.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.87     0 277.3  1082       0          0 78.04  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .008969    .1208 6.047 .0006762 3.355e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n     472       0          0                  671 398.3 1554 3.92            1\n\n22:04:44 | running eval: valid\n22:04:44 | eval completed in 0.19s\n22:04:44 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1775       0          0   140   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 1.195 3.355e-05    72 840.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    671  224 2615        .8322\n\u001b[0m\n22:04:44 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 10\u001b[0m\n22:04:44 | saving model checkpoint: /tmp/model5.checkpoint\n22:04:59 | time:272s total_exs:14180 total_steps:709 epochs:70.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.75     0   275  1045       0          0 76.01  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .007482    .1208 6.034 .0006348 3.545e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.7       0          0                  709 395.7 1504 3.809            1\n\n22:05:05 | time:278s total_exs:14600 total_steps:730 epochs:73.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.49     0 269.7  1038       0          0 76.96  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .006966    .1208 6.052 .0005949 3.65e-05   121 465.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  730 390.8 1504 3.864            1\n\n22:05:05 | running eval: valid\n22:05:05 | eval completed in 0.19s\n22:05:05 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1802       0          0 142.2   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 1.251 3.65e-05    72 853.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    730  224 2655        .8322\n\u001b[0m\n22:05:05 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 11\u001b[0m\n22:05:05 | saving model checkpoint: /tmp/model5.checkpoint\n22:05:20 | time:293s total_exs:15380 total_steps:769 epochs:76.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.32     0 266.3  1036       0          0 77.83  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006446    .1208 5.918 .0005517 3.845e-05 118.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.6       0          0                  769 384.7 1497 3.901            1\n\n22:05:25 | time:298s total_exs:15780 total_steps:789 epochs:78.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.05     0   281  1096       0          0 78.03  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006103    .1208 6.005 .0005209 3.945e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   468.6       0          0                  789 401.1 1565 3.919            1\n\n22:05:25 | running eval: valid\n22:05:25 | eval completed in 0.19s\n22:05:25 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1733       0          0 136.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 1.267 3.945e-05    72 820.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    789  224 2553        .8322\n\u001b[0m\n22:05:25 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 12\u001b[0m\n22:05:25 | saving model checkpoint: /tmp/model5.checkpoint\n22:05:40 | time:313s total_exs:16540 total_steps:827 epochs:82.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0 275.9  1035       0          0 75.02  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00574    .1208 6.026 .0004902 4.135e-05 120.5 452.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  827 396.4 1487 3.759            1\n\n22:05:45 | time:318s total_exs:16940 total_steps:847 epochs:84.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.99     0 279.8  1076       0          0 76.91  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .005365    .1208  5.97 .0004585 4.235e-05 119.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.2       0          0                  847 399.2 1535 3.863            1\n\n22:05:45 | running eval: valid\n22:05:45 | eval completed in 0.22s\n22:05:45 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1508       0          0   119   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 1.312 4.235e-05    72 714.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    847  224 2222        .7884\n\u001b[0m\n22:05:45 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 13\u001b[0m\n22:05:45 | saving model checkpoint: /tmp/model5.checkpoint\n22:06:00 | time:333s total_exs:17720 total_steps:886 epochs:88.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.83     0 276.6  1068       0          0 77.18  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .005054    .1208 6.013 .0004316 4.43e-05 120.3 464.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  886 396.9 1532 3.868            1\n\n22:06:06 | time:339s total_exs:18140 total_steps:907 epochs:90.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.63     0 272.5  1083       0          0 79.49  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004769    .1208  6.01 .0004047 4.535e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   477.7       0          0                  907 392.7 1561 3.992            1\n\n22:06:06 | running eval: valid\n22:06:06 | eval completed in 0.19s\n22:06:06 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1761       0          0 138.9   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 1.266 4.535e-05    72 833.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    907  224 2595        .8322\n\u001b[0m\n22:06:06 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 14\u001b[0m\n22:06:06 | saving model checkpoint: /tmp/model5.checkpoint\n22:06:26 | time:359s total_exs:18860 total_steps:943 epochs:94.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.62     0 272.3  1060       0          0 77.82  720   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004455    .1208 5.978 .0003797 4.715e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   465.2       0          0                  943 391.9 1525  3.9            1\n\n22:06:26 | running eval: valid\n22:06:26 | eval completed in 0.19s\n22:06:26 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1755       0          0 138.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 1.283 4.715e-05    72 831.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    943  224 2587        .8322\n\u001b[0m\n22:06:26 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 15\u001b[0m\n22:06:26 | saving model checkpoint: /tmp/model5.checkpoint\n22:06:41 | time:374s total_exs:19640 total_steps:982 epochs:98.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.75     0 275.1  1049       0          0 76.27  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .004143    .1208 6.072 .0003525 4.91e-05 121.4 463.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  982 396.5 1512 3.823            1\n\n22:06:46 | time:379s total_exs:20020 total_steps:1001 epochs:100.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.99     0 279.7  1068       0          0 76.36  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .003886    .1208 6.079 .000331 4.995e-05 121.6 464.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1001 401.3 1532 3.836            1\n\n22:06:46 | running eval: valid\n22:06:46 | eval completed in 0.19s\n22:06:46 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1760       0          0 138.9   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6 1.311 4.995e-05    72 833.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1001  224 2594        .7884\n\u001b[0m\n22:06:46 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 16\u001b[0m\n22:06:46 | saving model checkpoint: /tmp/model5.checkpoint\n22:07:02 | time:395s total_exs:20800 total_steps:1040 epochs:104.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.96     0 279.2  1079       0          0 77.28  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003647    .1208 6.023 .0003107 4.995e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   465.5       0          0                 1040 399.7 1544 3.873            1\n\n22:07:07 | time:400s total_exs:21180 total_steps:1059 epochs:105.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.01     0 280.3  1086       0          0 77.47  380   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00344    .1191 6.016 .0002924 4.995e-05 120.3   466   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1059 400.6 1552 3.891            1\n\n22:07:07 | running eval: valid\n22:07:07 | eval completed in 0.19s\n22:07:07 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1771       0          0 139.8   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 1.548 4.995e-05    72 838.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1059  224 2610        .7884\n\u001b[0m\n22:07:07 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 17\u001b[0m\n22:07:07 | saving model checkpoint: /tmp/model5.checkpoint\n22:07:22 | time:415s total_exs:21940 total_steps:1097 epochs:109.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.84     0 276.8  1031       0          0  74.5  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003259    .1208  6.05 .0002771 4.995e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   450.7       0          0                 1097 397.8 1482 3.733            1\n\n22:07:27 | time:420s total_exs:22340 total_steps:1117 epochs:111.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.89     0 277.9  1077       0          0 77.52  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00306    .1208     6 .0002605 4.995e-05   120 465.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1117 397.9 1542 3.893            1\n\n22:07:27 | running eval: valid\n22:07:27 | eval completed in 0.19s\n22:07:27 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1778       0          0 140.3   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6  1.59 4.995e-05    72 842.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1117  224 2620        .7884\n\u001b[0m\n22:07:27 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 18\u001b[0m\n22:07:27 | saving model checkpoint: /tmp/model5.checkpoint\n22:07:42 | time:435s total_exs:23120 total_steps:1156 epochs:115.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.65     0 273.1  1052       0          0 77.02  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002904    .1209 5.977 .0002466 4.995e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   460.3       0          0                 1156 392.6 1512 3.86            1\n\n22:07:47 | time:441s total_exs:23500 total_steps:1175 epochs:117.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.78     0 275.5   986       0          0 71.57  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002742    .1209 5.942 .0002332 4.995e-05 118.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   425.3       0          0                 1175 394.4 1411 3.594            1\n\n22:07:47 | running eval: valid\n22:07:48 | eval completed in 0.20s\n22:07:48 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1714       0          0 135.3   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 1.588 4.995e-05    72   812       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1175  224 2527        .7884\n\u001b[0m\n22:07:48 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 19\u001b[0m\n22:07:48 | saving model checkpoint: /tmp/model5.checkpoint\n22:08:02 | time:456s total_exs:24260 total_steps:1213 epochs:121.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.7     0 274.1  1040       0          0 75.92  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002709    .1209 5.968 .0002218 4.995e-05 119.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   453.1       0          0                 1213 393.4 1494 3.805            1\n\n22:08:08 | time:461s total_exs:24680 total_steps:1234 epochs:123.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.57     0 271.4  1067       0          0 78.64  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002497    .1209 6.076 .0002123 4.995e-05 121.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   477.8       0          0                 1234 392.9 1545 3.948            1\n\n22:08:08 | running eval: valid\n22:08:08 | eval completed in 0.25s\n22:08:08 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1398       0          0 110.4   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6 1.181 4.995e-05    72 662.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1234  224 2060        .8322\n\u001b[0m\n22:08:08 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 20\u001b[0m\n22:08:08 | saving model checkpoint: /tmp/model5.checkpoint\n22:08:23 | time:476s total_exs:25440 total_steps:1272 epochs:127.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.85     0   277  1043       0          0  75.3  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002361    .1209 5.976 .0002006 4.995e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     450       0          0                 1272 396.6 1493 3.774            1\n\n22:08:28 | time:481s total_exs:25840 total_steps:1292 epochs:129.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.94     0 278.7  1088       0          0  78.1  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002254    .1209  6.05 .0001916 4.995e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   472.5       0          0                 1292 399.7 1561 3.922            1\n\n22:08:28 | running eval: valid\n22:08:28 | eval completed in 0.19s\n22:08:28 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1761       0          0   139   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 1.524 4.995e-05    72   834       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1292  224 2595        .7884\n\u001b[0m\n22:08:28 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 21\u001b[0m\n22:08:28 | saving model checkpoint: /tmp/model5.checkpoint\n22:08:43 | time:497s total_exs:26620 total_steps:1331 epochs:133.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0 275.9  1064       0          0 77.16  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002148    .1209 6.013 .0001822 4.995e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.9       0          0                 1331 396.2 1528 3.866            1\n\n22:08:49 | time:502s total_exs:27020 total_steps:1351 epochs:135.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.75     0 275.1  1055       0          0 76.69  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00205    .1209  6.05 .0001742 4.995e-05   121   464   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1351 396.1 1519 3.851            1\n\n22:08:49 | running eval: valid\n22:08:49 | eval completed in 0.21s\n22:08:49 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1612       0          0 127.2   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 1.201 4.995e-05    72 763.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1351  224 2376        .8322\n\u001b[0m\n22:08:49 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 22\u001b[0m\n22:08:49 | saving model checkpoint: /tmp/model5.checkpoint\n22:09:03 | time:517s total_exs:27800 total_steps:1390 epochs:139.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.61     0 272.2  1052       0          0 77.31  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001947    .1192 5.974 .0001653 4.995e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.9       0          0                 1390 391.7 1514 3.875            1\n\n22:09:09 | time:522s total_exs:28240 total_steps:1412 epochs:141.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.59     0 271.8  1080       0          0  79.5  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001866    .1209  6.05 .0001585 4.995e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     481       0          0                 1412 392.8 1561 3.991            1\n\n22:09:09 | running eval: valid\n22:09:09 | eval completed in 0.19s\n22:09:09 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1787       0          0   141   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6 1.564 4.995e-05    72 846.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1412  224 2633        .7884\n\u001b[0m\n22:09:09 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 23\u001b[0m\n22:09:09 | saving model checkpoint: /tmp/model5.checkpoint\n22:09:24 | time:537s total_exs:29000 total_steps:1450 epochs:145.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.68     0 273.6  1022       0          0 74.69  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001779    .1209 6.037 .000151 4.995e-05 120.7 450.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1450 394.3 1472 3.743            1\n\n22:09:29 | time:542s total_exs:29420 total_steps:1471 epochs:147.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0   276  1078       0          0 78.15  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768  .0017    .1209 6.029 .0001443 4.995e-05 120.6 471.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1471 396.6 1550 3.924            1\n\n22:09:29 | running eval: valid\n22:09:29 | eval completed in 0.19s\n22:09:29 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1817       0          0 143.4   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6 1.607 4.995e-05    72 860.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1471  224 2678        .7884\n\u001b[0m\nEpoch 00009: reducing learning rate of group 0 to 2.4975e-05.\n22:09:29 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 24\u001b[0m\n22:09:29 | saving model checkpoint: /tmp/model5.checkpoint\n22:09:44 | time:557s total_exs:30200 total_steps:1510 epochs:151.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.01     0 280.2  1078       0          0 76.96  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001645    .1209 5.985 .0001394 2.498e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.6       0          0                 1510 399.9 1539 3.856            1\n\n22:09:49 | time:563s total_exs:30600 total_steps:1530 epochs:153.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.69     0 273.7  1048       0          0 76.58  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001606    .1209 5.965 .0001363 2.498e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   456.8       0          0                 1530  393 1505 3.846            1\n\n22:09:49 | running eval: valid\n22:09:50 | eval completed in 0.19s\n22:09:50 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1779       0          0 140.4   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 1.656 2.498e-05    72 842.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1530  224 2622        .7884\n\u001b[0m\n22:09:50 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 25\u001b[0m\n22:09:50 | saving model checkpoint: /tmp/model5.checkpoint\n22:10:04 | time:578s total_exs:31380 total_steps:1569 epochs:156.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.69     0 273.9  1049       0          0 76.64  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001573    .1209 6.005 .0001335 2.498e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   460.2       0          0                 1569  394 1510 3.841            1\n\n22:10:10 | time:583s total_exs:31780 total_steps:1589 epochs:158.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.91     0 278.1  1077       0          0 77.43  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001545    .1209 6.025 .0001308 2.498e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   466.5       0          0                 1589 398.6 1543 3.889            1\n\n22:10:10 | running eval: valid\n22:10:10 | eval completed in 0.20s\n22:10:10 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1663       0          0 131.3   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 1.673 2.498e-05    72 787.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1589  224 2451        .7884\n\u001b[0m\n22:10:10 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 26\u001b[0m\n22:10:10 | saving model checkpoint: /tmp/model5.checkpoint\n22:10:24 | time:597s total_exs:32540 total_steps:1627 epochs:162.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.64     0 272.8  1030       0          0 75.52  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001503    .1209 5.963 .0001274 2.498e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   450.4       0          0                 1627  392 1480 3.785            1\n\n22:10:30 | time:603s total_exs:33000 total_steps:1650 epochs:165.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.02     0 280.4  1094       0          0 78.02  460   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00147    .1209 6.009 .0001247 2.498e-05 120.2 468.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1650 400.6 1563 3.916            1\n\n22:10:30 | running eval: valid\n22:10:30 | eval completed in 0.19s\n22:10:30 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1792       0          0 141.4   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 1.669 2.498e-05    72 848.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1650  224 2641        .7884\n\u001b[0m\n22:10:30 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 27\u001b[0m\n22:10:30 | saving model checkpoint: /tmp/model5.checkpoint\n22:10:45 | time:618s total_exs:33780 total_steps:1689 epochs:168.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.73     0 274.7  1071       0          0 78.01  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001437    .1210 6.008 .0001218 2.498e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   468.7       0          0                 1689 394.8 1540 3.909            1\n\n22:10:50 | time:624s total_exs:34200 total_steps:1710 epochs:171.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.9     0   278  1095       0          0 78.78  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001399    .1210 5.967 .0001186 2.498e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   470.1       0          0                 1710 397.3 1565 3.956            1\n\n22:10:50 | running eval: valid\n22:10:51 | eval completed in 0.19s\n22:10:51 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1761       0          0   139   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 1.642 2.498e-05    72 834.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1710  224 2596        .7884\n\u001b[0m\nEpoch 00013: reducing learning rate of group 0 to 1.2488e-05.\n22:10:51 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 28\u001b[0m\n22:10:51 | saving model checkpoint: /tmp/model5.checkpoint\n22:11:06 | time:639s total_exs:34980 total_steps:1749 epochs:174.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.74     0 274.7  1053       0          0 76.67  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001374    .1210 5.944 .0001165 1.249e-05 118.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   455.7       0          0                 1749 393.6 1509 3.842            1\n\n22:11:11 | time:644s total_exs:35380 total_steps:1769 epochs:176.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.58     0 271.6  1082       0          0 79.66  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001362    .1210  5.97 .0001154 1.249e-05 119.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   475.6       0          0                 1769 390.9 1557 4.001            1\n\n22:11:11 | running eval: valid\n22:11:11 | eval completed in 0.19s\n22:11:11 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1794       0          0 141.6   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 1.652 1.249e-05    72 849.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1769  224 2644        .7884\n\u001b[0m\n22:11:11 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 29\u001b[0m\n22:11:11 | saving model checkpoint: /tmp/model5.checkpoint\n22:11:26 | time:659s total_exs:36180 total_steps:1809 epochs:180.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.1  1075       0          0 78.44  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001349    .1210  5.99 .0001142 1.249e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   469.9       0          0                 1809 393.9 1545 3.931            1\n\n22:11:31 | time:665s total_exs:36580 total_steps:1829 epochs:182.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.79     0 275.7  1013       0          0 73.45  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001341    .1210 6.105 .0001137 1.249e-05 122.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   448.4       0          0                 1829 397.8 1461 3.689            1\n\n22:11:31 | running eval: valid\n22:11:31 | eval completed in 0.19s\n22:11:31 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1769       0          0 139.6   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 1.704 1.249e-05    72 837.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1829  224 2607        .7884\n\u001b[0m\n22:11:31 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 30\u001b[0m\n22:11:31 | saving model checkpoint: /tmp/model5.checkpoint\n22:11:36 | ran out of patience! stopping training.\n22:11:36 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n22:11:36 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n22:11:36 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type1/run5/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n22:11:36 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n22:11:36 | Using CUDA\n22:11:36 | loading dictionary from /tmp/model5.dict\n22:11:36 | num words = 54944\n22:11:41 | Loading existing model parameters from /tmp/model5\n22:11:50 | Total parameters: 128,042,498 (128,042,498 trainable)\n22:11:51 | creating task(s): fromfile:parlaiformat\n22:11:51 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run5/data_valid.txt\n22:11:51 | running eval: valid\n22:11:52 | eval completed in 0.29s\n22:11:52 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1203       0          0 94.91   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297     6 .5188 5.204e-06    72 569.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    104  224 1773        .9161\n\u001b[0m\n22:11:52 | creating task(s): fromfile:parlaiformat\n22:11:52 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run5/data_test.txt\n22:11:52 | running eval: test\n22:11:57 | eval completed in 4.78s\n22:11:57 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9130 9.13e-10               .6813                 .5376   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9300            .9496              .9915   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9111 12.07 281.4  2962       0          0 210.5 1000 .9130   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297   5.2 .5170 5.204e-06   104  1095       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    104 385.4 4057        .9228\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type1/run5/data_test.txt -m transformer/classifier -mf /tmp/model5 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-03T22:11:58.843312Z","iopub.execute_input":"2022-12-03T22:11:58.845609Z","iopub.status.idle":"2022-12-03T22:12:29.871749Z","shell.execute_reply.started":"2022-12-03T22:11:58.845565Z","shell.execute_reply":"2022-12-03T22:12:29.870481Z"},"scrolled":true,"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"22:12:08 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr1type1/run5/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr1type1/run5/data)\u001b[0m\n22:12:08 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n22:12:08 | Using CUDA\n22:12:08 | loading dictionary from /tmp/model5.dict\n22:12:08 | num words = 54944\n22:12:12 | Loading existing model parameters from /tmp/model5\n22:12:18 | Total parameters: 128,042,498 (128,042,498 trainable)\n22:12:19 | Opt:\n22:12:19 |     activation: gelu\n22:12:19 |     adafactor_eps: '[1e-30, 0.001]'\n22:12:19 |     adam_eps: 1e-08\n22:12:19 |     add_p1_after_newln: False\n22:12:19 |     aggregate_micro: False\n22:12:19 |     allow_missing_init_opts: False\n22:12:19 |     area_under_curve_class: None\n22:12:19 |     area_under_curve_digits: -1\n22:12:19 |     attention_dropout: 0.1\n22:12:19 |     batchsize: 40\n22:12:19 |     betas: '[0.9, 0.999]'\n22:12:19 |     bpe_add_prefix_space: None\n22:12:19 |     bpe_debug: False\n22:12:19 |     bpe_dropout: None\n22:12:19 |     bpe_merge: None\n22:12:19 |     bpe_vocab: None\n22:12:19 |     candidates: inline\n22:12:19 |     cap_num_predictions: 100\n22:12:19 |     checkpoint_activations: False\n22:12:19 |     class_weights: None\n22:12:19 |     classes: \"['__notok__', '__ok__']\"\n22:12:19 |     classes_from_file: None\n22:12:19 |     data_parallel: True\n22:12:19 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n22:12:19 |     datatype: train\n22:12:19 |     delimiter: '\\n'\n22:12:19 |     dict_class: parlai.core.dict:DictionaryAgent\n22:12:19 |     dict_endtoken: __start__\n22:12:19 |     dict_file: /tmp/model5.dict\n22:12:19 |     dict_include_test: False\n22:12:19 |     dict_include_valid: False\n22:12:19 |     dict_initpath: None\n22:12:19 |     dict_language: english\n22:12:19 |     dict_loaded: True\n22:12:19 |     dict_lower: True\n22:12:19 |     dict_max_ngram_size: -1\n22:12:19 |     dict_maxexs: -1\n22:12:19 |     dict_maxtokens: -1\n22:12:19 |     dict_minfreq: 0\n22:12:19 |     dict_nulltoken: __null__\n22:12:19 |     dict_starttoken: __start__\n22:12:19 |     dict_textfields: text,labels\n22:12:19 |     dict_tokenizer: bpe\n22:12:19 |     dict_unktoken: __unk__\n22:12:19 |     display_examples: False\n22:12:19 |     download_path: None\n22:12:19 |     dropout: 0.1\n22:12:19 |     dynamic_batching: None\n22:12:19 |     embedding_projection: random\n22:12:19 |     embedding_size: 768\n22:12:19 |     embedding_type: random\n22:12:19 |     embeddings_scale: False\n22:12:19 |     encode_candidate_vecs: True\n22:12:19 |     encode_candidate_vecs_batchsize: 256\n22:12:19 |     eval_batchsize: None\n22:12:19 |     eval_candidates: inline\n22:12:19 |     eval_dynamic_batching: None\n22:12:19 |     evaltask: None\n22:12:19 |     ffn_size: 3072\n22:12:19 |     final_extra_opt: \n22:12:19 |     fixed_candidate_vecs: reuse\n22:12:19 |     fixed_candidates_path: None\n22:12:19 |     force_fp16_tokens: True\n22:12:19 |     fp16: True\n22:12:19 |     fp16_impl: safe\n22:12:19 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type1/run5/data_test.txt\n22:12:19 |     fromfile_datatype_extension: True\n22:12:19 |     gpu: -1\n22:12:19 |     gradient_clip: 0.1\n22:12:19 |     hide_labels: False\n22:12:19 |     history_add_global_end_token: None\n22:12:19 |     history_reversed: False\n22:12:19 |     history_size: 20\n22:12:19 |     ignore_bad_candidates: False\n22:12:19 |     ignore_labels: None\n22:12:19 |     image_cropsize: 224\n22:12:19 |     image_mode: raw\n22:12:19 |     image_size: 256\n22:12:19 |     inference: max\n22:12:19 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n22:12:19 |     init_opt: None\n22:12:19 |     interactive_candidates: fixed\n22:12:19 |     interactive_mode: False\n22:12:19 |     invsqrt_lr_decay_gamma: -1\n22:12:19 |     is_debug: False\n22:12:19 |     label_truncate: 72\n22:12:19 |     learn_embeddings: True\n22:12:19 |     learn_positional_embeddings: True\n22:12:19 |     learningrate: 5e-05\n22:12:19 |     load_from_pretrained_ranker: True\n22:12:19 |     log_every_n_secs: 10.0\n22:12:19 |     log_every_n_steps: 50\n22:12:19 |     log_keep_fields: all\n22:12:19 |     loglevel: info\n22:12:19 |     lr_scheduler: reduceonplateau\n22:12:19 |     lr_scheduler_decay: 0.5\n22:12:19 |     lr_scheduler_patience: 3\n22:12:19 |     max_train_steps: -1\n22:12:19 |     max_train_time: 7200.0\n22:12:19 |     memory_attention: sqrt\n22:12:19 |     metrics: default\n22:12:19 |     model: transformer/classifier\n22:12:19 |     model_file: /tmp/model5\n22:12:19 |     model_parallel: False\n22:12:19 |     momentum: 0\n22:12:19 |     multitask_weights: [1]\n22:12:19 |     mutators: None\n22:12:19 |     n_decoder_layers: -1\n22:12:19 |     n_encoder_layers: -1\n22:12:19 |     n_heads: 12\n22:12:19 |     n_layers: 12\n22:12:19 |     n_positions: 1024\n22:12:19 |     n_segments: 2\n22:12:19 |     nesterov: True\n22:12:19 |     no_cuda: False\n22:12:19 |     normalize_sent_emb: False\n22:12:19 |     num_epochs: -1\n22:12:19 |     num_examples: -1\n22:12:19 |     num_workers: 0\n22:12:19 |     nus: [0.7]\n22:12:19 |     optimizer: adamax\n22:12:19 |     output_scaling: 0.06\n22:12:19 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type1/run5/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model5', 'batchsize': 40}\"\n22:12:19 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n22:12:19 |     person_tokens: False\n22:12:19 |     print_scores: False\n22:12:19 |     rank_candidates: False\n22:12:19 |     rank_top_k: -1\n22:12:19 |     reduction_type: mean\n22:12:19 |     ref_class: None\n22:12:19 |     relu_dropout: 0.0\n22:12:19 |     repeat_blocking_heuristic: True\n22:12:19 |     report_filename: \n22:12:19 |     return_cand_scores: False\n22:12:19 |     save_after_valid: True\n22:12:19 |     save_every_n_secs: -1\n22:12:19 |     save_format: conversations\n22:12:19 |     share_encoders: False\n22:12:19 |     share_word_embeddings: False\n22:12:19 |     short_final_eval: False\n22:12:19 |     special_tok_lst: None\n22:12:19 |     split_lines: False\n22:12:19 |     starttime: Dec03_22-00\n22:12:19 |     task: fromfile:parlaiformat\n22:12:19 |     tensorboard_log: False\n22:12:19 |     tensorboard_logdir: None\n22:12:19 |     text_truncate: 360\n22:12:19 |     threshold: 0.5\n22:12:19 |     topk: 5\n22:12:19 |     train_predict: False\n22:12:19 |     truncate: 1024\n22:12:19 |     update_classifier_head_only: False\n22:12:19 |     update_freq: 1\n22:12:19 |     use_memories: False\n22:12:19 |     use_reply: none\n22:12:19 |     validation_cutoff: 1.0\n22:12:19 |     validation_every_n_epochs: -1\n22:12:19 |     validation_every_n_secs: 20.0\n22:12:19 |     validation_every_n_steps: -1\n22:12:19 |     validation_max_exs: -1\n22:12:19 |     validation_metric: accuracy\n22:12:19 |     validation_metric_mode: max\n22:12:19 |     validation_patience: 30\n22:12:19 |     validation_share_agent: False\n22:12:19 |     variant: xlm\n22:12:19 |     verbose: False\n22:12:19 |     wandb_entity: None\n22:12:19 |     wandb_log: False\n22:12:19 |     wandb_name: None\n22:12:19 |     wandb_project: None\n22:12:19 |     warmup_rate: 0.0001\n22:12:19 |     warmup_updates: 1000\n22:12:19 |     weight_decay: None\n22:12:19 |     world_logs: \n22:12:19 |     wrap_memory_encoder: False\n22:12:20 | Evaluating task fromfile:parlaiformat using datatype valid.\n22:12:20 | creating task(s): fromfile:parlaiformat\n22:12:20 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n22:12:20 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type1/run5/data_test.txt\n22:12:28 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9130 9.13e-10               .6813                 .5376   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9300            .9496              .9915   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9111 12.07 562.9  1878       0          0 133.4 1000 .9130   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5170 5.204e-06   208 693.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    104 770.9 2572        .9228\u001b[0m\n22:12:28 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9130 9.13e-10               .6813                 .5376   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9300            .9496              .9915   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9111 12.07 562.9  1878       0          0 133.4 1000 .9130   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5170 5.204e-06   208 693.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    104 770.9 2572        .9228\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model5*","metadata":{"execution":{"iopub.status.busy":"2022-12-03T22:12:29.873419Z","iopub.execute_input":"2022-12-03T22:12:29.873811Z","iopub.status.idle":"2022-12-03T22:12:31.299202Z","shell.execute_reply.started":"2022-12-03T22:12:29.873777Z","shell.execute_reply":"2022-12-03T22:12:31.297661Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Actual work prev1corr1type2","metadata":{}},{"cell_type":"markdown","source":"run 1","metadata":{}},{"cell_type":"code","source":"# run 1 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type2/run1/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model1","metadata":{"execution":{"iopub.status.busy":"2022-12-03T22:12:31.304645Z","iopub.execute_input":"2022-12-03T22:12:31.306557Z","iopub.status.idle":"2022-12-03T22:24:47.169563Z","shell.execute_reply.started":"2022-12-03T22:12:31.306514Z","shell.execute_reply":"2022-12-03T22:24:47.168386Z"},"scrolled":true,"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"22:12:38 | building dictionary first...\n22:12:38 | No model with opt yet at: /tmp/model1(.opt)\n22:12:38 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run1/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n22:12:38 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n22:12:38 | Using CUDA\n22:12:38 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n22:12:38 | num words = 54944\n22:12:43 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n22:12:53 | Total parameters: 128,042,498 (128,042,498 trainable)\n22:12:53 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n22:12:53 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n22:12:53 | Opt:\n22:12:53 |     activation: gelu\n22:12:53 |     adafactor_eps: '(1e-30, 0.001)'\n22:12:53 |     adam_eps: 1e-08\n22:12:53 |     add_p1_after_newln: False\n22:12:53 |     aggregate_micro: False\n22:12:53 |     allow_missing_init_opts: False\n22:12:53 |     attention_dropout: 0.1\n22:12:53 |     batchsize: 20\n22:12:53 |     betas: '(0.9, 0.999)'\n22:12:53 |     bpe_add_prefix_space: None\n22:12:53 |     bpe_debug: False\n22:12:53 |     bpe_dropout: None\n22:12:53 |     bpe_merge: None\n22:12:53 |     bpe_vocab: None\n22:12:53 |     candidates: inline\n22:12:53 |     cap_num_predictions: 100\n22:12:53 |     checkpoint_activations: False\n22:12:53 |     class_weights: None\n22:12:53 |     classes: \"['__notok__', '__ok__']\"\n22:12:53 |     classes_from_file: None\n22:12:53 |     data_parallel: True\n22:12:53 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n22:12:53 |     datatype: train\n22:12:53 |     delimiter: '\\n'\n22:12:53 |     dict_class: parlai.core.dict:DictionaryAgent\n22:12:53 |     dict_endtoken: __start__\n22:12:53 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n22:12:53 |     dict_include_test: False\n22:12:53 |     dict_include_valid: False\n22:12:53 |     dict_initpath: None\n22:12:53 |     dict_language: english\n22:12:53 |     dict_loaded: True\n22:12:53 |     dict_lower: True\n22:12:53 |     dict_max_ngram_size: -1\n22:12:53 |     dict_maxexs: -1\n22:12:53 |     dict_maxtokens: -1\n22:12:53 |     dict_minfreq: 0\n22:12:53 |     dict_nulltoken: __null__\n22:12:53 |     dict_starttoken: __start__\n22:12:53 |     dict_textfields: text,labels\n22:12:53 |     dict_tokenizer: bpe\n22:12:53 |     dict_unktoken: __unk__\n22:12:53 |     display_examples: False\n22:12:53 |     download_path: None\n22:12:53 |     dropout: 0.1\n22:12:53 |     dynamic_batching: None\n22:12:53 |     embedding_projection: random\n22:12:53 |     embedding_size: 768\n22:12:53 |     embedding_type: random\n22:12:53 |     embeddings_scale: False\n22:12:53 |     encode_candidate_vecs: True\n22:12:53 |     encode_candidate_vecs_batchsize: 256\n22:12:53 |     eval_batchsize: None\n22:12:53 |     eval_candidates: inline\n22:12:53 |     eval_dynamic_batching: None\n22:12:53 |     evaltask: None\n22:12:53 |     ffn_size: 3072\n22:12:53 |     final_extra_opt: \n22:12:53 |     fixed_candidate_vecs: reuse\n22:12:53 |     fixed_candidates_path: None\n22:12:53 |     force_fp16_tokens: False\n22:12:53 |     fp16: True\n22:12:53 |     fp16_impl: safe\n22:12:53 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run1/data\n22:12:53 |     fromfile_datatype_extension: True\n22:12:53 |     gpu: -1\n22:12:53 |     gradient_clip: 0.1\n22:12:53 |     hide_labels: False\n22:12:53 |     history_add_global_end_token: None\n22:12:53 |     history_reversed: False\n22:12:53 |     history_size: 20\n22:12:53 |     ignore_bad_candidates: False\n22:12:53 |     ignore_labels: None\n22:12:53 |     image_cropsize: 224\n22:12:53 |     image_mode: raw\n22:12:53 |     image_size: 256\n22:12:53 |     inference: max\n22:12:53 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n22:12:53 |     init_opt: None\n22:12:53 |     interactive_candidates: fixed\n22:12:53 |     interactive_mode: False\n22:12:53 |     invsqrt_lr_decay_gamma: -1\n22:12:53 |     is_debug: False\n22:12:53 |     label_truncate: 72\n22:12:53 |     learn_embeddings: True\n22:12:53 |     learn_positional_embeddings: True\n22:12:53 |     learningrate: 5e-05\n22:12:53 |     load_from_checkpoint: False\n22:12:53 |     load_from_pretrained_ranker: True\n22:12:53 |     log_every_n_secs: 10.0\n22:12:53 |     log_every_n_steps: 50\n22:12:53 |     log_keep_fields: all\n22:12:53 |     loglevel: info\n22:12:53 |     lr_scheduler: reduceonplateau\n22:12:53 |     lr_scheduler_decay: 0.5\n22:12:53 |     lr_scheduler_patience: 3\n22:12:53 |     max_train_steps: -1\n22:12:53 |     max_train_time: 7200.0\n22:12:53 |     memory_attention: sqrt\n22:12:53 |     metrics: default\n22:12:53 |     model: transformer/classifier\n22:12:53 |     model_file: /tmp/model1\n22:12:53 |     model_parallel: False\n22:12:53 |     momentum: 0\n22:12:53 |     multitask_weights: [1]\n22:12:53 |     mutators: None\n22:12:53 |     n_decoder_layers: -1\n22:12:53 |     n_encoder_layers: -1\n22:12:53 |     n_heads: 12\n22:12:53 |     n_layers: 12\n22:12:53 |     n_positions: 1024\n22:12:53 |     n_segments: 2\n22:12:53 |     nesterov: True\n22:12:53 |     no_cuda: False\n22:12:53 |     normalize_sent_emb: False\n22:12:53 |     num_epochs: -1\n22:12:53 |     num_workers: 0\n22:12:53 |     nus: (0.7,)\n22:12:53 |     optimizer: adamax\n22:12:53 |     output_scaling: 0.06\n22:12:53 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type2/run1/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model1'}\"\n22:12:53 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n22:12:53 |     person_tokens: False\n22:12:53 |     print_scores: False\n22:12:53 |     rank_candidates: False\n22:12:53 |     rank_top_k: -1\n22:12:53 |     reduction_type: mean\n22:12:53 |     ref_class: None\n22:12:53 |     relu_dropout: 0.0\n22:12:53 |     repeat_blocking_heuristic: True\n22:12:53 |     return_cand_scores: False\n22:12:53 |     save_after_valid: True\n22:12:53 |     save_every_n_secs: -1\n22:12:53 |     save_format: conversations\n22:12:53 |     share_encoders: False\n22:12:53 |     share_word_embeddings: False\n22:12:53 |     short_final_eval: False\n22:12:53 |     special_tok_lst: None\n22:12:53 |     split_lines: False\n22:12:53 |     starttime: Dec03_22-12\n22:12:53 |     task: fromfile:parlaiformat\n22:12:53 |     tensorboard_log: False\n22:12:53 |     tensorboard_logdir: None\n22:12:53 |     text_truncate: 360\n22:12:53 |     threshold: 0.5\n22:12:53 |     topk: 5\n22:12:53 |     train_predict: False\n22:12:53 |     truncate: 1024\n22:12:53 |     update_classifier_head_only: False\n22:12:53 |     update_freq: 1\n22:12:53 |     use_memories: False\n22:12:53 |     use_reply: none\n22:12:53 |     validation_cutoff: 1.0\n22:12:53 |     validation_every_n_epochs: -1\n22:12:53 |     validation_every_n_secs: 20.0\n22:12:53 |     validation_every_n_steps: -1\n22:12:53 |     validation_max_exs: -1\n22:12:53 |     validation_metric: accuracy\n22:12:53 |     validation_metric_mode: max\n22:12:53 |     validation_patience: 30\n22:12:53 |     validation_share_agent: False\n22:12:53 |     variant: xlm\n22:12:53 |     verbose: False\n22:12:53 |     wandb_entity: None\n22:12:53 |     wandb_log: False\n22:12:53 |     wandb_name: None\n22:12:53 |     wandb_project: None\n22:12:53 |     warmup_rate: 0.0001\n22:12:53 |     warmup_updates: 1000\n22:12:53 |     weight_decay: None\n22:12:53 |     world_logs: \n22:12:53 |     wrap_memory_encoder: False\n22:12:53 | creating task(s): fromfile:parlaiformat\n22:12:53 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run1/data_train.txt\n22:12:53 | training...\n22:13:04 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .4400 4.4e-10               .4400                 .4055   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .4809            .4400              .4809   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .4055 11.05     1 261.1 510.9       0          0 39.13  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .4400             32768  2.624    .1189 5.915 .7063 1.005e-06 118.3 231.5   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 379.4 742.3 1.961        .4400\n\n22:13:13 | time:20s total_exs:1160 total_steps:58 epochs:5.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5816 5.816e-10               .5310                 .5660   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5000            .6223              .5928   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6550 11.32     1 266.4  1031       0          0 77.37  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5816             32768  2.521    .1189 5.947 .6796 2.905e-06 118.9 460.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   58 385.4 1491 3.877        .5791\n\n22:13:13 | creating task(s): fromfile:parlaiformat\n22:13:13 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run1/data_valid.txt\n22:13:14 | running eval: valid\n22:13:14 | eval completed in 0.21s\n22:13:14 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5417 5.417e-10               .4211                 .5714   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .3333            .6207              .5294   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.46 161.5  1763       0          0   131   24 .5417   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6685 2.905e-06    72 786.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     58 233.5 2550        .5209\n\u001b[0m\n22:13:14 | \u001b[1;32mnew best accuracy: 0.5417\u001b[0m\n22:13:14 | saving best valid model: /tmp/model1\n22:13:14 | Saving dictionary to /tmp/model1.dict\n22:13:18 | saving model checkpoint: /tmp/model1.checkpoint\n22:13:18 | Saving dictionary to /tmp/model1.checkpoint.dict\n22:13:34 | time:41s total_exs:1880 total_steps:94 epochs:9.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7639 7.639e-10               .6931                 .8312   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5944            .8081              .7321   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9018 10.99     1 259.8 914.2       0          0 70.39  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7639             32768  2.515    .1189 5.897 .6303 4.705e-06 117.9 415.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   94 377.7 1329 3.527        .7565\n\n22:13:38 | time:45s total_exs:2160 total_steps:108 epochs:10.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8179 8.179e-10               .8223                 .8676   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7815            .8132              .7708   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8605 10.94     1 258.9 967.4       0          0 74.74  280   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8179             32768  2.706    .1189 6.079 .5957 5.404e-06 121.6 454.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  108 380.4 1422 3.763        .8181\n\n22:13:38 | running eval: valid\n22:13:38 | eval completed in 0.24s\n22:13:38 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8148                 .7333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .7619              .8889   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .6667 11.46 161.5  1568       0          0 116.5   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6003 5.404e-06    72 699.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    108 233.5 2268        .7884\n\u001b[0m\n22:13:38 | \u001b[1;32mnew best accuracy: 0.7917 (previous best was 0.5417)\u001b[0m\n22:13:38 | saving best valid model: /tmp/model1\n22:13:48 | saving model checkpoint: /tmp/model1.checkpoint\n22:14:03 | time:70s total_exs:2940 total_steps:147 epochs:14.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8769 8.769e-10               .8750                 .8727   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8773            .8788              .8810   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8766 11.24     1 264.8  1009       0          0  76.2  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8769             32768  3.714    .1189 5.982 .4871 7.354e-06 119.6 455.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  147 384.5 1465 3.819        .8769\n\n22:14:08 | time:75s total_exs:3280 total_steps:164 epochs:16.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9176 9.176e-10               .9172                 .8960   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9394            .9181              .9401   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8971  11.1     1   262 981.4       0          0 74.92  340   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9176             32768  4.804    .1189 5.971 .3325 8.204e-06 119.4 447.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  164 381.4 1429 3.765        .9177\n\n22:14:08 | running eval: valid\n22:14:08 | eval completed in 0.19s\n22:14:08 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1869       0          0 138.8   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .4143 8.204e-06    72   833       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    164 233.5 2702        .8748\n\u001b[0m\n22:14:08 | \u001b[1;32mnew best accuracy: 0.875 (previous best was 0.7917)\u001b[0m\n22:14:08 | saving best valid model: /tmp/model1\n22:14:13 | saving model checkpoint: /tmp/model1.checkpoint\n22:14:31 | time:98s total_exs:4060 total_steps:203 epochs:20.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9333 9.333e-10               .9301                 .9058   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9558            .9363              .9598   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9139 11.07     1 261.4  1002       0          0 76.65  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9333             32768   5.25    .1190 5.928 .2341 1.015e-05 118.6 454.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  203 379.9 1456 3.841        .9334\n\n22:14:33 | time:100s total_exs:4200 total_steps:210 epochs:21.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9214 9.214e-10               .9252                 .9067   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9444            .9173              .9385   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8971 11.64     1 272.7  1024       0          0 75.06  140   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9214             32768  6.736    .1190 6.029 .2392 1.05e-05 120.6 452.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  210 393.3 1476 3.799        .9213\n\n22:14:33 | running eval: valid\n22:14:33 | eval completed in 0.21s\n22:14:33 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1667       0          0 123.8   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .4026 1.05e-05    72 743.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    210 233.5 2411        .8333\n\u001b[0m\n22:14:33 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 1\u001b[0m\n22:14:33 | saving model checkpoint: /tmp/model1.checkpoint\n22:14:54 | time:120s total_exs:4960 total_steps:248 epochs:24.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9645 9.645e-10               .9638                 .9472   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9809            .9652              .9816   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9492 11.32     1 266.4  1010       0          0 75.79  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9645             32768  5.775    .1190 5.963 .1278 1.24e-05 119.3 451.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  248 385.7 1461 3.798        .9645\n\n22:14:54 | running eval: valid\n22:14:54 | eval completed in 0.20s\n22:14:54 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .6667                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5000            .8000              .6667   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 11.46 161.5  1793       0          0 133.1   24 .7500   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .7941 1.24e-05    72 799.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    248 233.5 2592        .7333\n\u001b[0m\n22:14:54 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 2\u001b[0m\n22:14:54 | saving model checkpoint: /tmp/model1.checkpoint\n22:15:08 | time:135s total_exs:5720 total_steps:286 epochs:28.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9816 9.816e-10               .9824                 .9751   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9899            .9807              .9889   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9726 11.04     1 260.8 986.9       0          0 75.67  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9816             32768  4.769    .1190 6.039 .07757 1.43e-05 120.8   457   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  286 381.6 1444 3.792        .9816\n\n22:15:14 | time:141s total_exs:6120 total_steps:306 epochs:30.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9875 9.875e-10               .9867                 .9840   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9893            .9882              .9906   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9859 11.32     1 266.4 993.7       0          0 74.59  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9875             32768  4.823    .1190 5.935 .05194 1.53e-05 118.7 442.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  306 385.1 1436 3.745        .9875\n\n22:15:14 | running eval: valid\n22:15:14 | eval completed in 0.20s\n22:15:14 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6667 6.667e-10               .6667                 .6667   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .6667              .6667   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .6667 11.46 161.5  1752       0          0 130.2   24 .6667   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6  1.49 1.53e-05    72 781.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    306 233.5 2533        .6667\n\u001b[0m\n22:15:14 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 3\u001b[0m\n22:15:14 | saving model checkpoint: /tmp/model1.checkpoint\n22:15:29 | time:155s total_exs:6860 total_steps:343 epochs:34.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9932 9.932e-10               .9932                 .9892   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9973            .9933              .9973   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9892 11.18 .3243 263.5 966.1       0          0 73.33  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9932             32768  2.231    .1190 5.995 .03529 1.715e-05 119.9 439.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  343 383.4 1406 3.675        .9932\n\n22:15:34 | time:161s total_exs:7280 total_steps:364 epochs:36.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9952 9.952e-10               .9948                 .9948   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9948            .9956              .9956   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9956 11.44 .1429 268.9  1033       0          0 76.85  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9952             32768  7.922    .1190  5.91 .02294 1.82e-05 118.2 454.1   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  364  387 1487 3.858        .9952\n\n22:15:34 | running eval: valid\n22:15:34 | eval completed in 0.21s\n22:15:34 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .6250 6.25e-10               .6087                 .6364   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5833            .6400              .6154   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .6667 11.46 161.5  1688       0          0 125.4   24 .6250   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 1.791 1.82e-05    72 752.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    364 233.5 2441        .6243\n\u001b[0m\n22:15:34 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 4\u001b[0m\n22:15:34 | saving model checkpoint: /tmp/model1.checkpoint\n22:15:49 | time:176s total_exs:8020 total_steps:401 epochs:40.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9824 9.824e-10               .9813                 .9743   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9884            .9834              .9897   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9772 10.97 .3784 259.4 944.9       0          0 72.87  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9824             32768   7.68    .1190 5.932 .08628 2.005e-05 118.6 432.3   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  401  378 1377 3.652        .9824\n\n22:15:55 | time:181s total_exs:8420 total_steps:421 epochs:42.10\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9950 9.95e-10               .9948                 .9948   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9948            .9952              .9952   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9952 10.83 .1500 256.6 945.3       0          0 73.67  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9950             32768  .4246    .1190  5.96 .02901 2.105e-05 119.2 439.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  421 375.8 1384 3.699        .9950\n\n22:15:55 | running eval: valid\n22:15:55 | eval completed in 0.20s\n22:15:55 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6667 6.667e-10               .6667                 .6667   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .6667              .6667   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .6667 11.46 161.5  1824       0          0 135.5   24 .6667   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08095     6 1.724 2.105e-05    72   813       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    421 233.5 2637        .6667\n\u001b[0m\n22:15:55 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 5\u001b[0m\n22:15:55 | saving model checkpoint: /tmp/model1.checkpoint\n22:16:10 | time:196s total_exs:9200 total_steps:460 epochs:46.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9897 9.897e-10               .9897                 .9897   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9897            .9898              .9898   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9898 11.32 .2821 266.4  1016       0          0  76.3  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss      lr  ltpb  ltps  \\\n   .9897             32768  2.631    .1190 5.992 .04664 2.3e-05 119.8 457.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  460 386.2 1473 3.823        .9897\n\n22:16:15 | time:202s total_exs:9580 total_steps:479 epochs:47.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9868 9.868e-10               .9867                 .9947   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9789            .9869              .9793   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9947 11.12 .4737 262.3 949.1       0          0 72.36  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9868             32768  1.734    .1190     6 .05995 2.395e-05   120 434.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  479 382.3 1383 3.634        .9868\n\n22:16:15 | running eval: valid\n22:16:15 | eval completed in 0.20s\n22:16:15 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .6316                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5000            .7586              .6471   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1830       0          0   136   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 1.799 2.395e-05    72 815.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    479 233.5 2646        .6951\n\u001b[0m\n22:16:15 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 6\u001b[0m\n22:16:15 | saving model checkpoint: /tmp/model1.checkpoint\n22:16:30 | time:217s total_exs:10360 total_steps:518 epochs:51.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9974 9.974e-10               .9974                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9948            .9975              .9950   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.95 .1538 259.1 986.7       0          0 76.17  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9974             32768  .2241    .1190 5.977 .01431 2.59e-05 119.5 455.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  518 378.6 1442 3.817        .9974\n\n22:16:35 | time:222s total_exs:10760 total_steps:538 epochs:53.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.97     0 259.4 988.9       0          0 76.23  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .01472    .1190 6.065 .001205 2.69e-05 121.3 462.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  538 380.8 1451 3.828            1\n\n22:16:35 | running eval: valid\n22:16:35 | eval completed in 0.19s\n22:16:35 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .6250 6.25e-10               .5714                 .6667   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5000            .6667              .6000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.46 161.5  1871       0          0   139   24 .6250   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 2.238 2.69e-05    72   834       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    538 233.5 2705        .6190\n\u001b[0m\n22:16:35 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 7\u001b[0m\n22:16:35 | saving model checkpoint: /tmp/model1.checkpoint\n22:16:50 | time:237s total_exs:11500 total_steps:575 epochs:57.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9986 9.986e-10               .9985                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9971            .9987              .9975   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.11 .02703 262.2 969.1       0          0  73.9   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  \\\n    740 .9986             32768 .08865    .1190 5.927 .00862 2.875e-05 118.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     438       0          0                  575 380.8 1407 3.704        .9986\n\n22:16:56 | time:242s total_exs:11920 total_steps:596 epochs:59.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9905 9.905e-10               .9912                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9825            .9896              .9795   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.79 .1905 255.8 999.6       0          0 78.15  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9905             32768  .5822    .1190  6.09 .04435 2.98e-05 121.8   476   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  596 377.6 1476 3.924        .9905\n\n22:16:56 | running eval: valid\n22:16:56 | eval completed in 0.23s\n22:16:56 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .6316                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5000            .7586              .6471   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1630       0          0 121.1   24 .7083   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 1.959 2.98e-05    72 726.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    596 233.5 2357        .6951\n\u001b[0m\n22:16:56 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 8\u001b[0m\n22:16:56 | saving model checkpoint: /tmp/model1.checkpoint\n22:17:10 | time:257s total_exs:12700 total_steps:635 epochs:63.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9897 9.897e-10               .9893                 .9919   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9866            .9902              .9877   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9926 11.11 .3077 262.2  1009       0          0 76.99  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9897             32768  .5618    .1190 5.959 .01642 3.175e-05 119.2 458.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  635 381.3 1468 3.858        .9897\n\n22:17:16 | time:263s total_exs:13120 total_steps:656 epochs:65.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9952 9.952e-10               .9951                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9902            .9954              .9908   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.11 .1905 262.2  1026       0          0 78.25  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9952             32768  .2217    .1190 5.971 .01604 3.28e-05 119.4 467.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  656 381.6 1493 3.929        .9952\n\n22:17:16 | running eval: valid\n22:17:16 | eval completed in 0.20s\n22:17:16 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6667 6.667e-10               .6364                 .7000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5833            .6923              .6429   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.46 161.5  1806       0          0 134.1   24 .6667   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 2.222 3.28e-05    72   805       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    656 233.5 2611        .6643\n\u001b[0m\n22:17:16 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 9\u001b[0m\n22:17:16 | saving model checkpoint: /tmp/model1.checkpoint\n22:17:31 | time:278s total_exs:13880 total_steps:694 epochs:69.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9987                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9973            .9987              .9974   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.23 .02632 264.6  1007       0          0 76.09   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  \\\n    760 .9987             32768  .1670    .1190 5.987 .007961 3.47e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   455.6       0          0                  694 384.3 1462 3.813        .9987\n\n22:17:36 | time:283s total_exs:14280 total_steps:714 epochs:71.40\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9950 9.95e-10               .9949                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9898            .9951              .9903   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.85 .1000 256.9  1000       0          0 77.84  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9950             32768  .2187    .1190  5.98 .0226 3.57e-05 119.6 465.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  714 376.6 1466 3.91        .9950\n\n22:17:36 | running eval: valid\n22:17:37 | eval completed in 0.20s\n22:17:37 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .6957                 .7273   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .7200              .6923   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.46 161.5  1798       0          0 133.6   24 .7083   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 2.046 3.57e-05    72 801.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    714 233.5 2600        .7078\n\u001b[0m\n22:17:37 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 10\u001b[0m\n22:17:37 | saving model checkpoint: /tmp/model1.checkpoint\n22:17:51 | time:298s total_exs:15040 total_steps:752 epochs:75.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9947 9.947e-10               .9944                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9889            .9950              .9901   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.13 .1316 262.5 979.1       0          0 74.59  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9947             32768  .1773    .1191  5.95 .01824 3.76e-05   119 443.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  752 381.5 1423 3.738        .9947\n\n22:17:57 | time:303s total_exs:15460 total_steps:773 epochs:77.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9952 9.952e-10               .9951                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9903            .9953              .9907   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.21 .3333 264.2  1025       0          0  77.6  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9952             32768  .8022    .1191 5.981 .01626 3.865e-05 119.6 464.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  773 383.9 1489 3.896        .9952\n\n22:17:57 | running eval: valid\n22:17:57 | eval completed in 0.19s\n22:17:57 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .5882                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .4167            .7742              .6316   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 11.46 161.5  1880       0          0 139.7   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 2.201 3.865e-05    72 838.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    773 233.5 2719        .6812\n\u001b[0m\n22:17:57 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 11\u001b[0m\n22:17:57 | saving model checkpoint: /tmp/model1.checkpoint\n22:18:11 | time:318s total_exs:16240 total_steps:812 epochs:81.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9936 9.936e-10               .9929                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9860            .9941              .9883   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.86 .2308 257.1 987.9       0          0 76.84  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9936             32768  1.564    .1191 5.913 .02231 4.06e-05 118.3 454.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  812 375.4 1442 3.851        .9936\n\n22:18:17 | time:324s total_exs:16660 total_steps:833 epochs:83.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9929 9.929e-10               .9924                 .9899   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9949            .9933              .9955   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9910 10.81 .2381 256.1   979       0          0 76.44  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9929             32768  .5100    .1191 5.938 .008369 4.165e-05 118.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   453.9       0          0                  833 374.9 1433 3.838        .9929\n\n22:18:17 | running eval: valid\n22:18:17 | eval completed in 0.19s\n22:18:17 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .5882                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .4167            .7742              .6316   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 11.46 161.5  1885       0          0   140   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 2.235 4.165e-05    72 840.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    833 233.5 2725        .6812\n\u001b[0m\n22:18:17 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 12\u001b[0m\n22:18:17 | saving model checkpoint: /tmp/model1.checkpoint\n22:18:36 | time:343s total_exs:17440 total_steps:872 epochs:87.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9936 9.936e-10               .9933                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9866            .9939              .9879   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.97 .2308 259.4  1001       0          0 77.16  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9936             32768  12.52    .1191 5.956 .02291 4.36e-05 119.1 459.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  872 378.5 1460 3.867        .9936\n\n22:18:37 | time:344s total_exs:17500 total_steps:875 epochs:87.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.82     0 256.3  1003       0          0 78.28   60   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n     1             32768 .03483    .1191 5.833 .00191 4.375e-05 116.7 456.6   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  875  373 1460 4.033            1\n\n22:18:37 | running eval: valid\n22:18:37 | eval completed in 0.19s\n22:18:37 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .6250 6.25e-10               .6667                 .6000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .5714              .6667   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .5000 11.46 161.5  1857       0          0 137.9   24 .6250   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 2.832 4.375e-05    72 827.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    875 233.5 2685        .6190\n\u001b[0m\n22:18:37 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 13\u001b[0m\n22:18:37 | saving model checkpoint: /tmp/model1.checkpoint\n22:18:52 | time:359s total_exs:18280 total_steps:914 epochs:91.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9949 9.949e-10               .9948                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9896            .9950              .9900   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.18 .1795 263.5  1008       0          0 76.51  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9949             32768  .1134    .1191 5.982 .01604 4.57e-05 119.6 457.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  914 383.2 1466 3.835        .9949\n\n22:18:58 | time:364s total_exs:18680 total_steps:934 epochs:93.40\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9950 9.95e-10               .9948                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9896            .9952              .9905   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.2 .1000 263.9   970       0          0 73.49  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9950             32768 .09929    .1191  5.96 .01693 4.67e-05 119.2   438   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  934 383.1 1408 3.69        .9950\n\n22:18:58 | running eval: valid\n22:18:58 | eval completed in 0.21s\n22:18:58 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6667 6.667e-10               .6923                 .6429   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .6364              .7000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .5833 11.46 161.5  1749       0          0 129.8   24 .6667   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 2.373 4.67e-05    72 779.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    934 233.5 2529        .6643\n\u001b[0m\n22:18:58 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 14\u001b[0m\n22:18:58 | saving model checkpoint: /tmp/model1.checkpoint\n22:19:13 | time:379s total_exs:19460 total_steps:973 epochs:97.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9897 9.897e-10               .9893                 .9946   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9841            .9901              .9853   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9950 11.02 .2821 260.4 994.7       0          0 76.41  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9897             32768  .2694    .1191 5.967 .0220 4.865e-05 119.3 455.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  973 379.7 1451 3.829        .9897\n\n22:19:18 | time:385s total_exs:19880 total_steps:994 epochs:99.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.1     0   262  1033       0          0 78.86  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768  .0113    .1191 5.924 .0006972 4.97e-05 118.5 467.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  994 380.4 1500 3.96            1\n\n22:19:18 | running eval: valid\n22:19:18 | eval completed in 0.19s\n22:19:18 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .7200                 .6923   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .6957              .7273   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .6667 11.46 161.5  1828       0          0 135.8   24 .7083   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 2.223 4.97e-05    72   815       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    994 233.5 2643        .7078\n\u001b[0m\n22:19:18 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 15\u001b[0m\n22:19:18 | saving model checkpoint: /tmp/model1.checkpoint\n22:19:33 | time:400s total_exs:20640 total_steps:1032 epochs:103.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9974 9.974e-10               .9972                 .9945   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9975                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                  .9950 11.23 .05263 264.6 992.1       0          0 74.99   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  \\\n    760 .9974             32768  .1265    .1191 5.945 .01282 4.995e-05 118.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   445.8       0          0                 1032 383.5 1438 3.758        .9974\n\n22:19:38 | time:405s total_exs:21060 total_steps:1053 epochs:105.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9881 9.881e-10               .9875                 .9801   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9949            .9887              .9954   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9820 10.97 .3810 259.5  1008       0          0 77.68  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9881             32768  .6132    .1191 5.943 .02317 4.995e-05 118.9 461.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1053 378.3 1470 3.901        .9881\n\n22:19:38 | running eval: valid\n22:19:39 | eval completed in 0.19s\n22:19:39 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .6957                 .7273   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .7200              .6923   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.46 161.5  1854       0          0 137.7   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 2.192 4.995e-05    72 826.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1053 233.5 2681        .7078\n\u001b[0m\n22:19:39 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 16\u001b[0m\n22:19:39 | saving model checkpoint: /tmp/model1.checkpoint\n22:19:53 | time:420s total_exs:21840 total_steps:1092 epochs:109.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9936 9.936e-10               .9936                 .9974   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9897            .9936              .9898   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9974 10.84 .2308 256.8 978.2       0          0 76.17  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9936             32768  1.387    .1191     6 .02771 4.995e-05   120   457   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1092 376.8 1435 3.817        .9936\n\n22:19:59 | time:426s total_exs:22240 total_steps:1112 epochs:111.20\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9950 9.95e-10               .9948                 .9948   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9948            .9952              .9952   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9952 11.39 .1000 267.9 986.8       0          0 73.67  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9950             32768  .1527    .1191  5.96 .005829 4.995e-05 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   439.1       0          0                 1112 387.1 1426 3.698        .9950\n\n22:19:59 | running eval: valid\n22:19:59 | eval completed in 0.21s\n22:19:59 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .6250 6.25e-10               .5263                 .7143   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .4167            .6897              .5882   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1725       0          0 128.1   24 .6250   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 2.716 4.995e-05    72 768.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1112 233.5 2494        .6080\n\u001b[0m\n22:19:59 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 17\u001b[0m\n22:19:59 | saving model checkpoint: /tmp/model1.checkpoint\n22:20:14 | time:441s total_exs:23020 total_steps:1151 epochs:115.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9987                 .9973   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9988                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9975 11.27 .1026 265.4  1024       0          0 77.15  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9987             32768 .06526    .1191 5.956 .003824 4.995e-05 119.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.6       0          0                 1151 384.5 1483 3.866        .9987\n\n22:20:19 | time:446s total_exs:23380 total_steps:1169 epochs:116.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9861 9.861e-10               .9853                 .9709   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9869                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9741 11.14 .2222 262.8  1020       0          0 77.65  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9861             32768  .6839    .1191 5.928 .07623 4.995e-05 118.6 460.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1169 381.4 1481 3.901        .9861\n\n22:20:19 | running eval: valid\n22:20:19 | eval completed in 0.19s\n22:20:19 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .6667                 .7778   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5833            .7407              .6667   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1860       0          0 138.1   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 2.039 4.995e-05    72 829.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1169 233.5 2690        .7037\n\u001b[0m\n22:20:19 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 18\u001b[0m\n22:20:19 | saving model checkpoint: /tmp/model1.checkpoint\n22:20:34 | time:461s total_exs:24140 total_steps:1207 epochs:120.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9921 9.921e-10               .9910                 .9940   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9880            .9930              .9907   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9953 10.85 .2368   257 965.2       0          0 75.12  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9921             32768  .5188    .1191 5.879 .03126 4.995e-05 117.6 441.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1207 374.6 1407 3.764        .9921\n\n22:20:39 | time:466s total_exs:24520 total_steps:1226 epochs:122.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9947 9.947e-10               .9941                 .9882   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9953                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9906  11.2 .1053 264.1  1011       0          0 76.59  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9947             32768  .3478    .1191 5.884 .03448 4.995e-05 117.7 450.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1226 381.7 1462 3.847        .9947\n\n22:20:39 | running eval: valid\n22:20:40 | eval completed in 0.20s\n22:20:40 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7692                 .7143   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7273              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .6667 11.46 161.5  1834       0          0 136.2   24 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6  1.58 4.995e-05    72 817.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1226 233.5 2651        .7483\n\u001b[0m\n22:20:40 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 19\u001b[0m\n22:20:40 | saving model checkpoint: /tmp/model1.checkpoint\n22:20:55 | time:482s total_exs:25300 total_steps:1265 epochs:126.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9923 9.923e-10               .9918                 .9837   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9928                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9856 11.09 .1538 261.7 996.9       0          0 76.18  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9923             32768  .1843    .1191 5.928 .02725 4.995e-05 118.6 451.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1265 380.3 1449 3.817        .9923\n\n22:21:00 | time:487s total_exs:25660 total_steps:1283 epochs:128.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9972 9.972e-10               .9969                 .9939   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9975                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9949 11.26 .1667 265.2 976.8       0          0 73.68  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9972             32768  .1231    .1191 5.906 .00602 4.995e-05 118.1 435.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1283 383.3 1412 3.696        .9972\n\n22:21:00 | running eval: valid\n22:21:00 | eval completed in 0.21s\n22:21:00 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6667 6.667e-10               .6000                 .7500   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5000            .7143              .6250   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1708       0          0 126.9   24 .6667   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 2.602 4.995e-05    72 761.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1283 233.5 2469        .6571\n\u001b[0m\n22:21:00 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 20\u001b[0m\n22:21:00 | saving model checkpoint: /tmp/model1.checkpoint\n22:21:15 | time:501s total_exs:26420 total_steps:1321 epochs:132.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9908 9.908e-10               .9894                 .9939   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9850            .9918              .9884   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9953  11.2 .2632 264.1 994.5       0          0 75.32  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9908             32768  .1817    .1192 5.876 .0130 4.995e-05 117.5 442.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1321 381.6 1437 3.775        .9908\n\n22:21:20 | time:507s total_exs:26840 total_steps:1342 epochs:134.20\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9810 9.81e-10               .9799                 .9750   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9848            .9819              .9864   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9775 11.19 .3810 263.7  1017       0          0 77.13  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9810             32768  12.88    .1192 5.943 .03515 4.995e-05 118.9 458.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1342 382.6 1475 3.873        .9810\n\n22:21:20 | running eval: valid\n22:21:20 | eval completed in 0.22s\n22:21:20 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .7586                 .6471   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .6316              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .5000 11.46 161.5  1735       0          0 128.8   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 2.401 4.995e-05    72 773.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1342 233.5 2508        .6951\n\u001b[0m\n22:21:20 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 21\u001b[0m\n22:21:20 | saving model checkpoint: /tmp/model1.checkpoint\n22:21:35 | time:522s total_exs:27580 total_steps:1379 epochs:137.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9946 9.946e-10               .9944                 .9944   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9944            .9947              .9947   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9947 11.24 .1622 264.8 977.6       0          0 73.85  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9946             32768  .1144    .1192 5.973 .006788 4.995e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   441.1       0          0                 1379 384.2 1419 3.701        .9946\n\n22:21:40 | time:527s total_exs:28000 total_steps:1400 epochs:140.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9929 9.929e-10               .9925                 .9950   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9900            .9932              .9910   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9955 10.85 .1429   257  1001       0          0 77.89  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9929             32768 .06889    .1192 5.952 .005923 4.995e-05   119   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.6       0          0                 1400 376.1 1465 3.911        .9929\n\n22:21:40 | running eval: valid\n22:21:41 | eval completed in 0.20s\n22:21:41 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6667 6.667e-10               .5556                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .4167            .7333              .6111   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1818       0          0   135   24 .6667   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 2.544 4.995e-05    72 810.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1400 233.5 2628        .6444\n\u001b[0m\n22:21:41 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 22\u001b[0m\n22:21:41 | saving model checkpoint: /tmp/model1.checkpoint\n22:21:56 | time:542s total_exs:28760 total_steps:1438 epochs:143.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9934 9.934e-10               .9935                 .9922   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9948            .9933              .9947   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9920 10.96 .1579 259.1 982.2       0          0  75.8  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9934             32768 .05995    .1192 6.011 .007002 4.995e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   455.6       0          0                 1438 379.3 1438 3.799        .9934\n\n22:22:01 | time:547s total_exs:29140 total_steps:1457 epochs:145.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9895 9.895e-10               .9886                 .9831   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9943            .9902              .9951   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9854 11.29 .2105 265.8  1032       0          0 77.67  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9895             32768 .09291    .1192 5.921 .008792 4.995e-05 118.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.9       0          0                 1457 384.3 1492 3.902        .9895\n\n22:22:01 | running eval: valid\n22:22:01 | eval completed in 0.19s\n22:22:01 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .6316                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5000            .7586              .6471   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1890       0          0 140.4   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6 2.279 4.995e-05    72 842.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1457 233.5 2733        .6951\n\u001b[0m\nEpoch 00008: reducing learning rate of group 0 to 2.4975e-05.\n22:22:01 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 23\u001b[0m\n22:22:01 | saving model checkpoint: /tmp/model1.checkpoint\n22:22:16 | time:563s total_exs:29920 total_steps:1496 epochs:149.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9962 9.962e-10               .9959                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9918            .9964              .9928   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.37 .1795 267.4  1026       0          0 76.74  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9962             32768 .07102    .1192 5.936 .006654 2.498e-05 118.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   455.6       0          0                 1496 386.1 1482 3.846        .9962\n\n22:22:21 | time:568s total_exs:30300 total_steps:1515 epochs:151.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9868 9.868e-10               .9861                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9727            .9875              .9752   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.28 .2632 265.7  1043       0          0 78.52  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9868             32768  .1518    .1192 5.963 .01585 2.498e-05 119.3 468.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1515 384.9 1511 3.945        .9868\n\n22:22:21 | running eval: valid\n22:22:21 | eval completed in 0.19s\n22:22:21 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .6667                 .7778   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5833            .7407              .6667   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1852       0          0 137.6   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6 2.283 2.498e-05    72 825.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1515 233.5 2678        .7037\n\u001b[0m\n22:22:21 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 24\u001b[0m\n22:22:21 | saving model checkpoint: /tmp/model1.checkpoint\n22:22:36 | time:582s total_exs:31060 total_steps:1553 epochs:155.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9974 9.974e-10               .9973                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9947            .9974              .9948   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.86 .2105 257.2 959.5       0          0 74.61  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9974             32768 .06321    .1192 5.992 .008712 2.498e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     447       0          0                 1553 377.1 1407 3.739        .9974\n\n22:22:41 | time:588s total_exs:31480 total_steps:1574 epochs:157.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9976 9.976e-10               .9975                 .9950   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9977                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9954 11.22 .1429 264.3  1008       0          0 76.28  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9976             32768 .04749    .1192 5.957 .004621 2.498e-05 119.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   454.4       0          0                 1574 383.5 1463 3.83        .9976\n\n22:22:41 | running eval: valid\n22:22:41 | eval completed in 0.19s\n22:22:41 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .6667                 .7778   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5833            .7407              .6667   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1891       0          0 140.4   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 2.348 2.498e-05    72 842.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1574 233.5 2734        .7037\n\u001b[0m\n22:22:41 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 25\u001b[0m\n22:22:41 | saving model checkpoint: /tmp/model1.checkpoint\n22:22:56 | time:603s total_exs:32260 total_steps:1613 epochs:161.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9872 9.872e-10               .9855                 .9715   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9885                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9772 11.39 .2821 267.8  1034       0          0 77.26  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9872             32768  .1623    .1192 5.874 .0210 2.498e-05 117.5 453.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1613 385.3 1488 3.872        .9872\n\n22:23:01 | time:608s total_exs:32680 total_steps:1634 epochs:163.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9952 9.952e-10               .9949                 .9898   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9955                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9911 11.06 .2381 261.1 993.8       0          0 76.11  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9952             32768 .08499    .1192 5.929 .008463 2.498e-05 118.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.2       0          0                 1634 379.7 1445 3.822        .9952\n\n22:23:01 | running eval: valid\n22:23:02 | eval completed in 0.19s\n22:23:02 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .6667                 .7778   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5833            .7407              .6667   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1859       0          0 138.1   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 2.365 2.498e-05    72 828.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1634 233.5 2687        .7037\n\u001b[0m\n22:23:02 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 26\u001b[0m\n22:23:02 | saving model checkpoint: /tmp/model1.checkpoint\n22:23:17 | time:624s total_exs:33460 total_steps:1673 epochs:167.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9936 9.936e-10               .9934                 .9895   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9974            .9937              .9975   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9900 11.33 .1795 266.6  1024       0          0 76.82  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9936             32768 .07455    .1192 5.972 .009122 2.498e-05 119.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   458.8       0          0                 1673 386.1 1483 3.85        .9936\n\n22:23:22 | time:628s total_exs:33820 total_steps:1691 epochs:169.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.38 .05556 267.6  1037       0          0 77.51   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    360   1             32768 .01769    .1192 5.978 .001518 2.498e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.4       0          0                 1691 387.2 1501 3.895            1\n\n22:23:22 | running eval: valid\n22:23:22 | eval completed in 0.19s\n22:23:22 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .6667                 .7778   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5833            .7407              .6667   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1851       0          0 137.5   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 2.326 2.498e-05    72 825.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1691 233.5 2676        .7037\n\u001b[0m\nEpoch 00012: reducing learning rate of group 0 to 1.2488e-05.\n22:23:22 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 27\u001b[0m\n22:23:22 | saving model checkpoint: /tmp/model1.checkpoint\n22:23:37 | time:644s total_exs:34600 total_steps:1730 epochs:173.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9987                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9975            .9987              .9974   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.17 .07692 263.4  1007       0          0 76.48   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    780 .9987             32768 .02923    .1192  6.01 .002941 1.249e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.6       0          0                 1730 383.6 1467 3.832        .9987\n\n22:23:42 | time:649s total_exs:34960 total_steps:1748 epochs:174.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.86 .1111 257.1 969.3       0          0  75.4  360   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .02638    .1192 5.867 .002144 1.249e-05 117.3 442.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1748 374.4 1412 3.788            1\n\n22:23:42 | running eval: valid\n22:23:42 | eval completed in 0.19s\n22:23:42 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .6667                 .7778   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5833            .7407              .6667   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1890       0          0 140.4   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 2.359 1.249e-05    72 842.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1748 233.5 2732        .7037\n\u001b[0m\n22:23:42 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 28\u001b[0m\n22:23:42 | saving model checkpoint: /tmp/model1.checkpoint\n22:23:57 | time:664s total_exs:35740 total_steps:1787 epochs:178.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9949 9.949e-10               .9939                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9880            .9956              .9912   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.04 .1795 260.8  1003       0          0 76.89  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9949             32768  .0764    .1192 5.851 .009356 1.249e-05   117   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.9       0          0                 1787 377.9 1453 3.853        .9949\n\n22:24:02 | time:669s total_exs:36160 total_steps:1808 epochs:180.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9833 9.833e-10               .9825                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9657            .9841              .9686   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.93 .4286 258.6  1010       0          0 78.07  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9833             32768  .1912    .1192 5.971 .02357 1.249e-05 119.4 466.2   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps  ups  weighted_f1  \n         0          0                 1808  378 1476 3.92        .9833\n\n22:24:02 | running eval: valid\n22:24:03 | eval completed in 0.19s\n22:24:03 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .6667                 .7778   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5833            .7407              .6667   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1856       0          0 137.8   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 2.387 1.249e-05    72 827.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1808 233.5 2683        .7037\n\u001b[0m\n22:24:03 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 29\u001b[0m\n22:24:03 | saving model checkpoint: /tmp/model1.checkpoint\n22:24:18 | time:685s total_exs:36900 total_steps:1845 epochs:184.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9959 9.959e-10               .9956                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9913            .9962              .9925   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.97 .1351 259.5 950.2       0          0 73.24  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9959             32768 .05325    .1193 5.927 .005404 1.249e-05 118.5   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps  ups  weighted_f1  \n   434.1       0          0                 1845  378 1384 3.67        .9959\n\n22:24:23 | time:690s total_exs:37280 total_steps:1864 epochs:186.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9974 9.974e-10               .9969                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9938            .9977              .9955   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.07 .1053 261.3  1026       0          0 78.53  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9974             32768 .02743    .1193 5.847 .005661 1.249e-05 116.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.2       0          0                 1864 378.3 1485 3.945        .9974\n\n22:24:23 | running eval: valid\n22:24:23 | eval completed in 0.19s\n22:24:23 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .6667                 .7778   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5833            .7407              .6667   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1851       0          0 137.4   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 2.394 1.249e-05    72 824.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1864 233.5 2676        .7037\n\u001b[0m\n22:24:23 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 30\u001b[0m\n22:24:23 | saving model checkpoint: /tmp/model1.checkpoint\n22:24:28 | ran out of patience! stopping training.\n22:24:28 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n22:24:28 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n22:24:28 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run1/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n22:24:28 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n22:24:28 | Using CUDA\n22:24:28 | loading dictionary from /tmp/model1.dict\n22:24:28 | num words = 54944\n22:24:33 | Loading existing model parameters from /tmp/model1\n22:24:38 | Total parameters: 128,042,498 (128,042,498 trainable)\n22:24:40 | creating task(s): fromfile:parlaiformat\n22:24:40 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run1/data_valid.txt\n22:24:40 | running eval: valid\n22:24:40 | eval completed in 0.20s\n22:24:40 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1804       0          0   134   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297     6 .4143 8.204e-06    72 804.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    164 233.5 2609        .8748\n\u001b[0m\n22:24:40 | creating task(s): fromfile:parlaiformat\n22:24:40 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run1/data_test.txt\n22:24:40 | running eval: test\n22:24:45 | eval completed in 4.91s\n22:24:45 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9130 9.13e-10               .6926                 .5355   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9800            .9493              .9976   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9056 12.07 281.4  2880       0          0 204.6 1000 .9130   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297   5.2 .3048 8.204e-06   104  1064       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    164 385.4 3944        .9237\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type2/run1/data_test.txt -m transformer/classifier -mf /tmp/model1 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-03T22:24:47.173386Z","iopub.execute_input":"2022-12-03T22:24:47.173793Z","iopub.status.idle":"2022-12-03T22:25:17.821404Z","shell.execute_reply.started":"2022-12-03T22:24:47.173738Z","shell.execute_reply":"2022-12-03T22:25:17.820206Z"},"scrolled":true,"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"22:24:55 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr1type2/run1/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr1type2/run1/data)\u001b[0m\n22:24:55 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n22:24:55 | Using CUDA\n22:24:55 | loading dictionary from /tmp/model1.dict\n22:24:56 | num words = 54944\n22:25:00 | Loading existing model parameters from /tmp/model1\n22:25:06 | Total parameters: 128,042,498 (128,042,498 trainable)\n22:25:07 | Opt:\n22:25:07 |     activation: gelu\n22:25:07 |     adafactor_eps: '[1e-30, 0.001]'\n22:25:07 |     adam_eps: 1e-08\n22:25:07 |     add_p1_after_newln: False\n22:25:07 |     aggregate_micro: False\n22:25:07 |     allow_missing_init_opts: False\n22:25:07 |     area_under_curve_class: None\n22:25:07 |     area_under_curve_digits: -1\n22:25:07 |     attention_dropout: 0.1\n22:25:07 |     batchsize: 40\n22:25:07 |     betas: '[0.9, 0.999]'\n22:25:07 |     bpe_add_prefix_space: None\n22:25:07 |     bpe_debug: False\n22:25:07 |     bpe_dropout: None\n22:25:07 |     bpe_merge: None\n22:25:07 |     bpe_vocab: None\n22:25:07 |     candidates: inline\n22:25:07 |     cap_num_predictions: 100\n22:25:07 |     checkpoint_activations: False\n22:25:07 |     class_weights: None\n22:25:07 |     classes: \"['__notok__', '__ok__']\"\n22:25:07 |     classes_from_file: None\n22:25:07 |     data_parallel: True\n22:25:07 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n22:25:07 |     datatype: train\n22:25:07 |     delimiter: '\\n'\n22:25:07 |     dict_class: parlai.core.dict:DictionaryAgent\n22:25:07 |     dict_endtoken: __start__\n22:25:07 |     dict_file: /tmp/model1.dict\n22:25:07 |     dict_include_test: False\n22:25:07 |     dict_include_valid: False\n22:25:07 |     dict_initpath: None\n22:25:07 |     dict_language: english\n22:25:07 |     dict_loaded: True\n22:25:07 |     dict_lower: True\n22:25:07 |     dict_max_ngram_size: -1\n22:25:07 |     dict_maxexs: -1\n22:25:07 |     dict_maxtokens: -1\n22:25:07 |     dict_minfreq: 0\n22:25:07 |     dict_nulltoken: __null__\n22:25:07 |     dict_starttoken: __start__\n22:25:07 |     dict_textfields: text,labels\n22:25:07 |     dict_tokenizer: bpe\n22:25:07 |     dict_unktoken: __unk__\n22:25:07 |     display_examples: False\n22:25:07 |     download_path: None\n22:25:07 |     dropout: 0.1\n22:25:07 |     dynamic_batching: None\n22:25:07 |     embedding_projection: random\n22:25:07 |     embedding_size: 768\n22:25:07 |     embedding_type: random\n22:25:07 |     embeddings_scale: False\n22:25:07 |     encode_candidate_vecs: True\n22:25:07 |     encode_candidate_vecs_batchsize: 256\n22:25:07 |     eval_batchsize: None\n22:25:07 |     eval_candidates: inline\n22:25:07 |     eval_dynamic_batching: None\n22:25:07 |     evaltask: None\n22:25:07 |     ffn_size: 3072\n22:25:07 |     final_extra_opt: \n22:25:07 |     fixed_candidate_vecs: reuse\n22:25:07 |     fixed_candidates_path: None\n22:25:07 |     force_fp16_tokens: True\n22:25:07 |     fp16: True\n22:25:07 |     fp16_impl: safe\n22:25:07 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run1/data_test.txt\n22:25:07 |     fromfile_datatype_extension: True\n22:25:07 |     gpu: -1\n22:25:07 |     gradient_clip: 0.1\n22:25:07 |     hide_labels: False\n22:25:07 |     history_add_global_end_token: None\n22:25:07 |     history_reversed: False\n22:25:07 |     history_size: 20\n22:25:07 |     ignore_bad_candidates: False\n22:25:07 |     ignore_labels: None\n22:25:07 |     image_cropsize: 224\n22:25:07 |     image_mode: raw\n22:25:07 |     image_size: 256\n22:25:07 |     inference: max\n22:25:07 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n22:25:07 |     init_opt: None\n22:25:07 |     interactive_candidates: fixed\n22:25:07 |     interactive_mode: False\n22:25:07 |     invsqrt_lr_decay_gamma: -1\n22:25:07 |     is_debug: False\n22:25:07 |     label_truncate: 72\n22:25:07 |     learn_embeddings: True\n22:25:07 |     learn_positional_embeddings: True\n22:25:07 |     learningrate: 5e-05\n22:25:07 |     load_from_pretrained_ranker: True\n22:25:07 |     log_every_n_secs: 10.0\n22:25:07 |     log_every_n_steps: 50\n22:25:07 |     log_keep_fields: all\n22:25:07 |     loglevel: info\n22:25:07 |     lr_scheduler: reduceonplateau\n22:25:07 |     lr_scheduler_decay: 0.5\n22:25:07 |     lr_scheduler_patience: 3\n22:25:07 |     max_train_steps: -1\n22:25:07 |     max_train_time: 7200.0\n22:25:07 |     memory_attention: sqrt\n22:25:07 |     metrics: default\n22:25:07 |     model: transformer/classifier\n22:25:07 |     model_file: /tmp/model1\n22:25:07 |     model_parallel: False\n22:25:07 |     momentum: 0\n22:25:07 |     multitask_weights: [1]\n22:25:07 |     mutators: None\n22:25:07 |     n_decoder_layers: -1\n22:25:07 |     n_encoder_layers: -1\n22:25:07 |     n_heads: 12\n22:25:07 |     n_layers: 12\n22:25:07 |     n_positions: 1024\n22:25:07 |     n_segments: 2\n22:25:07 |     nesterov: True\n22:25:07 |     no_cuda: False\n22:25:07 |     normalize_sent_emb: False\n22:25:07 |     num_epochs: -1\n22:25:07 |     num_examples: -1\n22:25:07 |     num_workers: 0\n22:25:07 |     nus: [0.7]\n22:25:07 |     optimizer: adamax\n22:25:07 |     output_scaling: 0.06\n22:25:07 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type2/run1/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model1', 'batchsize': 40}\"\n22:25:07 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n22:25:07 |     person_tokens: False\n22:25:07 |     print_scores: False\n22:25:07 |     rank_candidates: False\n22:25:07 |     rank_top_k: -1\n22:25:07 |     reduction_type: mean\n22:25:07 |     ref_class: None\n22:25:07 |     relu_dropout: 0.0\n22:25:07 |     repeat_blocking_heuristic: True\n22:25:07 |     report_filename: \n22:25:07 |     return_cand_scores: False\n22:25:07 |     save_after_valid: True\n22:25:07 |     save_every_n_secs: -1\n22:25:07 |     save_format: conversations\n22:25:07 |     share_encoders: False\n22:25:07 |     share_word_embeddings: False\n22:25:07 |     short_final_eval: False\n22:25:07 |     special_tok_lst: None\n22:25:07 |     split_lines: False\n22:25:07 |     starttime: Dec03_22-12\n22:25:07 |     task: fromfile:parlaiformat\n22:25:07 |     tensorboard_log: False\n22:25:07 |     tensorboard_logdir: None\n22:25:07 |     text_truncate: 360\n22:25:07 |     threshold: 0.5\n22:25:07 |     topk: 5\n22:25:07 |     train_predict: False\n22:25:07 |     truncate: 1024\n22:25:07 |     update_classifier_head_only: False\n22:25:07 |     update_freq: 1\n22:25:07 |     use_memories: False\n22:25:07 |     use_reply: none\n22:25:07 |     validation_cutoff: 1.0\n22:25:07 |     validation_every_n_epochs: -1\n22:25:07 |     validation_every_n_secs: 20.0\n22:25:07 |     validation_every_n_steps: -1\n22:25:07 |     validation_max_exs: -1\n22:25:07 |     validation_metric: accuracy\n22:25:07 |     validation_metric_mode: max\n22:25:07 |     validation_patience: 30\n22:25:07 |     validation_share_agent: False\n22:25:07 |     variant: xlm\n22:25:07 |     verbose: False\n22:25:07 |     wandb_entity: None\n22:25:07 |     wandb_log: False\n22:25:07 |     wandb_name: None\n22:25:07 |     wandb_project: None\n22:25:07 |     warmup_rate: 0.0001\n22:25:07 |     warmup_updates: 1000\n22:25:07 |     weight_decay: None\n22:25:07 |     world_logs: \n22:25:07 |     wrap_memory_encoder: False\n22:25:07 | Evaluating task fromfile:parlaiformat using datatype valid.\n22:25:07 | creating task(s): fromfile:parlaiformat\n22:25:07 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n22:25:07 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run1/data_test.txt\n22:25:16 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9130 9.13e-10               .6926                 .5355   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9800            .9493              .9976   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9056 12.07 562.9  1779       0          0 126.4 1000 .9130   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .3048 8.204e-06   208 657.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    164 770.9 2437        .9237\u001b[0m\n22:25:16 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9130 9.13e-10               .6926                 .5355   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9800            .9493              .9976   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9056 12.07 562.9  1779       0          0 126.4 1000 .9130   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .3048 8.204e-06   208 657.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    164 770.9 2437        .9237\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model1*","metadata":{"execution":{"iopub.status.busy":"2022-12-03T22:25:17.823499Z","iopub.execute_input":"2022-12-03T22:25:17.823890Z","iopub.status.idle":"2022-12-03T22:25:19.009048Z","shell.execute_reply.started":"2022-12-03T22:25:17.823848Z","shell.execute_reply":"2022-12-03T22:25:19.007621Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"run 2","metadata":{}},{"cell_type":"code","source":"# run 2 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type2/run2/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model2","metadata":{"execution":{"iopub.status.busy":"2022-12-03T22:25:19.015234Z","iopub.execute_input":"2022-12-03T22:25:19.015556Z","iopub.status.idle":"2022-12-03T22:37:56.455539Z","shell.execute_reply.started":"2022-12-03T22:25:19.015524Z","shell.execute_reply":"2022-12-03T22:37:56.454327Z"},"scrolled":true,"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"22:25:26 | building dictionary first...\n22:25:26 | No model with opt yet at: /tmp/model2(.opt)\n22:25:26 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run2/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n22:25:26 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n22:25:26 | Using CUDA\n22:25:26 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n22:25:26 | num words = 54944\n22:25:30 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n22:25:40 | Total parameters: 128,042,498 (128,042,498 trainable)\n22:25:40 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n22:25:40 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n22:25:40 | Opt:\n22:25:40 |     activation: gelu\n22:25:40 |     adafactor_eps: '(1e-30, 0.001)'\n22:25:40 |     adam_eps: 1e-08\n22:25:40 |     add_p1_after_newln: False\n22:25:40 |     aggregate_micro: False\n22:25:40 |     allow_missing_init_opts: False\n22:25:40 |     attention_dropout: 0.1\n22:25:40 |     batchsize: 20\n22:25:40 |     betas: '(0.9, 0.999)'\n22:25:40 |     bpe_add_prefix_space: None\n22:25:40 |     bpe_debug: False\n22:25:40 |     bpe_dropout: None\n22:25:40 |     bpe_merge: None\n22:25:40 |     bpe_vocab: None\n22:25:40 |     candidates: inline\n22:25:40 |     cap_num_predictions: 100\n22:25:40 |     checkpoint_activations: False\n22:25:40 |     class_weights: None\n22:25:40 |     classes: \"['__notok__', '__ok__']\"\n22:25:40 |     classes_from_file: None\n22:25:40 |     data_parallel: True\n22:25:40 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n22:25:40 |     datatype: train\n22:25:40 |     delimiter: '\\n'\n22:25:40 |     dict_class: parlai.core.dict:DictionaryAgent\n22:25:40 |     dict_endtoken: __start__\n22:25:40 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n22:25:40 |     dict_include_test: False\n22:25:40 |     dict_include_valid: False\n22:25:40 |     dict_initpath: None\n22:25:40 |     dict_language: english\n22:25:40 |     dict_loaded: True\n22:25:40 |     dict_lower: True\n22:25:40 |     dict_max_ngram_size: -1\n22:25:40 |     dict_maxexs: -1\n22:25:40 |     dict_maxtokens: -1\n22:25:40 |     dict_minfreq: 0\n22:25:40 |     dict_nulltoken: __null__\n22:25:40 |     dict_starttoken: __start__\n22:25:40 |     dict_textfields: text,labels\n22:25:40 |     dict_tokenizer: bpe\n22:25:40 |     dict_unktoken: __unk__\n22:25:40 |     display_examples: False\n22:25:40 |     download_path: None\n22:25:40 |     dropout: 0.1\n22:25:40 |     dynamic_batching: None\n22:25:40 |     embedding_projection: random\n22:25:40 |     embedding_size: 768\n22:25:40 |     embedding_type: random\n22:25:40 |     embeddings_scale: False\n22:25:40 |     encode_candidate_vecs: True\n22:25:40 |     encode_candidate_vecs_batchsize: 256\n22:25:40 |     eval_batchsize: None\n22:25:40 |     eval_candidates: inline\n22:25:40 |     eval_dynamic_batching: None\n22:25:40 |     evaltask: None\n22:25:40 |     ffn_size: 3072\n22:25:40 |     final_extra_opt: \n22:25:40 |     fixed_candidate_vecs: reuse\n22:25:40 |     fixed_candidates_path: None\n22:25:40 |     force_fp16_tokens: False\n22:25:40 |     fp16: True\n22:25:40 |     fp16_impl: safe\n22:25:40 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run2/data\n22:25:40 |     fromfile_datatype_extension: True\n22:25:40 |     gpu: -1\n22:25:40 |     gradient_clip: 0.1\n22:25:40 |     hide_labels: False\n22:25:40 |     history_add_global_end_token: None\n22:25:40 |     history_reversed: False\n22:25:40 |     history_size: 20\n22:25:40 |     ignore_bad_candidates: False\n22:25:40 |     ignore_labels: None\n22:25:40 |     image_cropsize: 224\n22:25:40 |     image_mode: raw\n22:25:40 |     image_size: 256\n22:25:40 |     inference: max\n22:25:40 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n22:25:40 |     init_opt: None\n22:25:40 |     interactive_candidates: fixed\n22:25:40 |     interactive_mode: False\n22:25:40 |     invsqrt_lr_decay_gamma: -1\n22:25:40 |     is_debug: False\n22:25:40 |     label_truncate: 72\n22:25:40 |     learn_embeddings: True\n22:25:40 |     learn_positional_embeddings: True\n22:25:40 |     learningrate: 5e-05\n22:25:40 |     load_from_checkpoint: False\n22:25:40 |     load_from_pretrained_ranker: True\n22:25:40 |     log_every_n_secs: 10.0\n22:25:40 |     log_every_n_steps: 50\n22:25:40 |     log_keep_fields: all\n22:25:40 |     loglevel: info\n22:25:40 |     lr_scheduler: reduceonplateau\n22:25:40 |     lr_scheduler_decay: 0.5\n22:25:40 |     lr_scheduler_patience: 3\n22:25:40 |     max_train_steps: -1\n22:25:40 |     max_train_time: 7200.0\n22:25:40 |     memory_attention: sqrt\n22:25:40 |     metrics: default\n22:25:40 |     model: transformer/classifier\n22:25:40 |     model_file: /tmp/model2\n22:25:40 |     model_parallel: False\n22:25:40 |     momentum: 0\n22:25:40 |     multitask_weights: [1]\n22:25:40 |     mutators: None\n22:25:40 |     n_decoder_layers: -1\n22:25:40 |     n_encoder_layers: -1\n22:25:40 |     n_heads: 12\n22:25:40 |     n_layers: 12\n22:25:40 |     n_positions: 1024\n22:25:40 |     n_segments: 2\n22:25:40 |     nesterov: True\n22:25:40 |     no_cuda: False\n22:25:40 |     normalize_sent_emb: False\n22:25:40 |     num_epochs: -1\n22:25:40 |     num_workers: 0\n22:25:40 |     nus: (0.7,)\n22:25:40 |     optimizer: adamax\n22:25:40 |     output_scaling: 0.06\n22:25:40 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type2/run2/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model2'}\"\n22:25:40 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n22:25:40 |     person_tokens: False\n22:25:40 |     print_scores: False\n22:25:40 |     rank_candidates: False\n22:25:40 |     rank_top_k: -1\n22:25:40 |     reduction_type: mean\n22:25:40 |     ref_class: None\n22:25:40 |     relu_dropout: 0.0\n22:25:40 |     repeat_blocking_heuristic: True\n22:25:40 |     return_cand_scores: False\n22:25:40 |     save_after_valid: True\n22:25:40 |     save_every_n_secs: -1\n22:25:40 |     save_format: conversations\n22:25:40 |     share_encoders: False\n22:25:40 |     share_word_embeddings: False\n22:25:40 |     short_final_eval: False\n22:25:40 |     special_tok_lst: None\n22:25:40 |     split_lines: False\n22:25:40 |     starttime: Dec03_22-25\n22:25:40 |     task: fromfile:parlaiformat\n22:25:40 |     tensorboard_log: False\n22:25:40 |     tensorboard_logdir: None\n22:25:40 |     text_truncate: 360\n22:25:40 |     threshold: 0.5\n22:25:40 |     topk: 5\n22:25:40 |     train_predict: False\n22:25:40 |     truncate: 1024\n22:25:40 |     update_classifier_head_only: False\n22:25:40 |     update_freq: 1\n22:25:40 |     use_memories: False\n22:25:40 |     use_reply: none\n22:25:40 |     validation_cutoff: 1.0\n22:25:40 |     validation_every_n_epochs: -1\n22:25:40 |     validation_every_n_secs: 20.0\n22:25:40 |     validation_every_n_steps: -1\n22:25:40 |     validation_max_exs: -1\n22:25:40 |     validation_metric: accuracy\n22:25:40 |     validation_metric_mode: max\n22:25:40 |     validation_patience: 30\n22:25:40 |     validation_share_agent: False\n22:25:40 |     variant: xlm\n22:25:40 |     verbose: False\n22:25:40 |     wandb_entity: None\n22:25:40 |     wandb_log: False\n22:25:40 |     wandb_name: None\n22:25:40 |     wandb_project: None\n22:25:40 |     warmup_rate: 0.0001\n22:25:40 |     warmup_updates: 1000\n22:25:40 |     weight_decay: None\n22:25:40 |     world_logs: \n22:25:40 |     wrap_memory_encoder: False\n22:25:41 | creating task(s): fromfile:parlaiformat\n22:25:41 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run2/data_train.txt\n22:25:41 | training...\n22:25:51 | time:10s total_exs:360 total_steps:18 epochs:1.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .4639 4.639e-10               .4770                 .4706   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .4835            .4501              .4566   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .4438 11.86     1 277.2 499.3       0          0 36.03  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .4639             32768  2.271    .1206 6.011 .7027 9.049e-07 120.2 216.6   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   18 397.4 715.9 1.805        .4637\n\n22:26:01 | time:20s total_exs:1140 total_steps:57 epochs:5.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5359 5.359e-10               .5800                 .5470   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6173            .4814              .5201   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .4480 11.63     1 272.7  1067       0          0 78.24  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5359             32768  2.768    .1207 6.038 .6936 2.855e-06 120.8 472.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   57 393.4 1539 3.921        .5326\n\n22:26:01 | creating task(s): fromfile:parlaiformat\n22:26:01 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run2/data_valid.txt\n22:26:01 | running eval: valid\n22:26:01 | eval completed in 0.20s\n22:26:01 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .4583 4.583e-10               .4800                 .4615   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5000            .4348              .4545   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .4167    11   156  1766       0          0 135.8   24 .4583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6941 2.855e-06    72 814.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                     57  228 2581        .4574\n\u001b[0m\n22:26:01 | \u001b[1;32mnew best accuracy: 0.4583\u001b[0m\n22:26:01 | saving best valid model: /tmp/model2\n22:26:01 | Saving dictionary to /tmp/model2.dict\n22:26:05 | saving model checkpoint: /tmp/model2.checkpoint\n22:26:05 | Saving dictionary to /tmp/model2.checkpoint.dict\n22:26:20 | time:40s total_exs:1860 total_steps:93 epochs:9.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7278 7.278e-10               .7550                 .6802   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8483            .6937              .8043   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6099  11.4     1 267.9 953.6       0          0 71.17  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7278             32768  2.971    .1207 5.989 .6509 4.655e-06 119.8 426.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   93 387.7 1380 3.567        .7240\n\n22:26:25 | time:44s total_exs:2200 total_steps:110 epochs:11.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8441 8.441e-10               .8427                 .8161   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8712            .8455              .8735   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8192 11.91     1 278.3  1105       0          0 79.41  340   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8441             32768  2.722    .1207 5.959 .5989 5.504e-06 119.2 473.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  110 397.5 1578 3.992        .8442\n\n22:26:25 | running eval: valid\n22:26:25 | eval completed in 0.20s\n22:26:25 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1758       0          0 135.1   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .5957 5.504e-06    72 811.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    110  228 2569        .8748\n\u001b[0m\n22:26:25 | \u001b[1;32mnew best accuracy: 0.875 (previous best was 0.4583)\u001b[0m\n22:26:25 | saving best valid model: /tmp/model2\n22:26:35 | saving model checkpoint: /tmp/model2.checkpoint\n22:26:54 | time:74s total_exs:2980 total_steps:149 epochs:14.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8744 8.744e-10               .8819                 .8777   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8862            .8658              .8705   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8610  11.5     1 269.9  1029       0          0 76.27  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8744             32768  3.408    .1207 6.059 .5054 7.454e-06 121.2 462.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  149 391.1 1492 3.822        .8743\n\n22:26:55 | time:74s total_exs:3040 total_steps:152 epochs:15.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9333 9.333e-10               .9412                 .9697   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9143            .9231              .8889   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9600 11.42     1 268.3  1064       0          0 79.28   60   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9333             32768  4.915    .1207 6.167 .3712 7.604e-06 123.3 488.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  152 391.7 1553 4.085        .9336\n\n22:26:55 | running eval: valid\n22:26:55 | eval completed in 0.19s\n22:26:55 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1771       0          0 136.2   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .4242 7.604e-06    72 817.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    152  228 2588        .8748\n\u001b[0m\n22:26:55 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 1\u001b[0m\n22:26:55 | saving model checkpoint: /tmp/model2.checkpoint\n22:27:11 | time:90s total_exs:3820 total_steps:191 epochs:19.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9064 9.064e-10               .9077                 .8908   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9253            .9051              .9231   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8878 11.75     1 275.1  1062       0          0 77.24  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9064             32768  5.312    .1207 5.995 .3188 9.554e-06 119.9   463   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  191  395 1525 3.871        .9064\n\n22:27:15 | time:95s total_exs:4180 total_steps:209 epochs:20.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8889 8.889e-10               .8883                 .8548   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9244            .8895              .9253   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8564 11.65     1 272.9  1003       0          0 73.49  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8889             32768  8.654    .1207 5.956 .2773 1.045e-05 119.1 437.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  209 392.1 1441 3.691        .8889\n\n22:27:15 | running eval: valid\n22:27:16 | eval completed in 0.19s\n22:27:16 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1769       0          0   136   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .2547 1.045e-05    72 816.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    209  228 2585        .9167\n\u001b[0m\n22:27:16 | \u001b[1;32mnew best accuracy: 0.9167 (previous best was 0.875)\u001b[0m\n22:27:16 | saving best valid model: /tmp/model2\n22:27:20 | saving model checkpoint: /tmp/model2.checkpoint\n22:27:39 | time:118s total_exs:4960 total_steps:248 epochs:24.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9295 9.295e-10               .9320                 .9286   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9355            .9268              .9305   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9231 11.49     1 269.7  1040       0          0  77.1  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9295             32768  7.316    .1207 6.033 .2022 1.24e-05 120.7 465.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  248 390.4 1505 3.864        .9295\n\n22:27:40 | time:119s total_exs:5040 total_steps:252 epochs:25.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9625 9.625e-10               .9630                 .9286   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9620                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9268 11.71     1 274.2  1080       0          0 78.73   80   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9625             32768   8.91    .1207 5.975 .1120 1.26e-05 119.5 470.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  252 393.8 1550 4.025        .9625\n\n22:27:40 | running eval: valid\n22:27:40 | eval completed in 0.19s\n22:27:40 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1778       0          0 136.9   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .2257 1.26e-05    72 820.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    252  228 2599        .9167\n\u001b[0m\n22:27:40 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 1\u001b[0m\n22:27:40 | saving model checkpoint: /tmp/model2.checkpoint\n22:27:56 | time:135s total_exs:5820 total_steps:291 epochs:29.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9603 9.603e-10               .9617                 .9873   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9373            .9587              .9326   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9863 11.93     1 278.5  1067       0          0 76.59  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9603             32768  5.321    .1207 6.064 .1317 1.455e-05 121.3 464.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  291 399.8 1531 3.838        .9603\n\n22:28:00 | time:140s total_exs:6200 total_steps:310 epochs:31.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9579 9.579e-10               .9588                 .9588   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9588            .9570              .9570   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9570 11.52     1 270.5  1053       0          0 77.84  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9579             32768  8.273    .1207 6.021 .1304 1.55e-05 120.4 468.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  310 390.9 1521 3.91        .9579\n\n22:28:00 | running eval: valid\n22:28:01 | eval completed in 0.20s\n22:28:01 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1747       0          0 134.3   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .2829 1.55e-05    72 806.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    310  228 2553        .9167\n\u001b[0m\n22:28:01 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 2\u001b[0m\n22:28:01 | saving model checkpoint: /tmp/model2.checkpoint\n22:28:15 | time:154s total_exs:6980 total_steps:349 epochs:34.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9667 9.667e-10               .9692                 .9715   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9669            .9637              .9610   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9664 11.87     1 277.4  1077       0          0 77.63  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9667             32768  4.004    .1207 6.085 .08633 1.745e-05 121.7 472.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  349 399.1 1549 3.89        .9667\n\n22:28:21 | time:160s total_exs:7420 total_steps:371 epochs:37.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9773 9.773e-10               .9758                 .9854   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9665            .9785              .9702   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9870 11.38 .7727 267.6  1037       0          0  77.5  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9773             32768  9.513    .1207  5.95 .05959 1.855e-05   119 461.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  371 386.6 1498 3.891        .9773\n\n22:28:21 | running eval: valid\n22:28:21 | eval completed in 0.19s\n22:28:21 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1770       0          0 136.1   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08095     6 .4964 1.855e-05    72 816.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    371  228 2587        .8748\n\u001b[0m\n22:28:21 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 3\u001b[0m\n22:28:21 | saving model checkpoint: /tmp/model2.checkpoint\n22:28:36 | time:175s total_exs:8200 total_steps:410 epochs:41.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9885 9.885e-10               .9887                 .9900   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9875            .9882              .9869   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9895 11.56 .4615 271.3  1041       0          0 76.74  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9885             32768  7.783    .1207 6.026 .03674 2.05e-05 120.5 462.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  410 391.8 1503 3.845        .9885\n\n22:28:41 | time:180s total_exs:8600 total_steps:430 epochs:43.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9900 9.9e-10               .9897                 .9948   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9847            .9902              .9854   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9951 11.84 .3000 276.8  1064       0          0 76.86  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9900             32768  6.735    .1207  5.98 .04139 2.15e-05 119.6 459.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  430 396.4 1523 3.859        .9900\n\n22:28:41 | running eval: valid\n22:28:41 | eval completed in 0.19s\n22:28:41 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8000                 .7692   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7826              .8182   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1807       0          0 138.9   24 .7917   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 1.106 2.15e-05    72 833.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    430  228 2641        .7913\n\u001b[0m\n22:28:41 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 4\u001b[0m\n22:28:41 | saving model checkpoint: /tmp/model2.checkpoint\n22:28:56 | time:195s total_exs:9380 total_steps:469 epochs:46.90\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9910 9.91e-10               .9914                 .9901   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9926            .9907              .9920   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9893 11.82 .2564 276.4  1055       0          0  76.3  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9910             32768  2.232    .1207 6.038 .05089 2.345e-05 120.8 460.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  469 397.2 1515 3.819        .9910\n\n22:29:02 | time:201s total_exs:9820 total_steps:491 epochs:49.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9932 9.932e-10               .9932                 .9865   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9931                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9864 11.19 .1818 263.7  1019       0          0 77.27  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9932             32768  7.961    .1207     6 .02613 2.455e-05   120 463.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  491 383.7 1483 3.879        .9932\n\n22:29:02 | running eval: valid\n22:29:02 | eval completed in 0.24s\n22:29:02 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1    11   156  1557       0          0 119.7   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 .7989 2.455e-05    72 718.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    491  228 2275        .8730\n\u001b[0m\n22:29:02 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 5\u001b[0m\n22:29:02 | saving model checkpoint: /tmp/model2.checkpoint\n22:29:16 | time:216s total_exs:10600 total_steps:530 epochs:53.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9974 9.974e-10               .9976                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9952            .9972              .9945   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.84 .1795 276.8  1067       0          0 77.07  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9974             32768  .2416    .1207 6.079 .01855 2.65e-05 121.6 468.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  530 398.4 1535 3.862        .9974\n\n22:29:22 | time:221s total_exs:11020 total_steps:551 epochs:55.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9833 9.833e-10               .9842                 .9954   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9732            .9824              .9701   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9949 11.63 .3810 272.6  1070       0          0  78.5  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9833             32768  8.652    .1207 6.067 .09445 2.755e-05 121.3 476.2   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  551  394 1546 3.941        .9833\n\n22:29:22 | running eval: valid\n22:29:22 | eval completed in 0.19s\n22:29:22 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8000                 .7692   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7826              .8182   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1779       0          0 136.8   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 1.118 2.755e-05    72 820.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    551  228 2600        .7913\n\u001b[0m\n22:29:22 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 6\u001b[0m\n22:29:22 | saving model checkpoint: /tmp/model2.checkpoint\n22:29:37 | time:236s total_exs:11780 total_steps:589 epochs:58.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9882 9.882e-10               .9884                 .9922   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9846            .9879              .9839   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9919  11.8 .3421 276.1  1041       0          0 75.38  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9882             32768  4.205    .1208 6.026 .05675 2.945e-05 120.5 454.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  589 396.6 1495 3.777        .9882\n\n22:29:42 | time:241s total_exs:12220 total_steps:611 epochs:61.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9886 9.886e-10               .9894                 .9873   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9915            .9878              .9902   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9854  11.5 .3182 269.9  1065       0          0 78.95  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9886             32768  1.748    .1208 6.068 .05421 3.055e-05 121.4 479.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  611 391.3 1545 3.963        .9886\n\n22:29:42 | running eval: valid\n22:29:42 | eval completed in 0.20s\n22:29:42 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1757       0          0 135.1   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 .7680 3.055e-05    72 810.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    611  228 2567        .8748\n\u001b[0m\n22:29:42 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 7\u001b[0m\n22:29:42 | saving model checkpoint: /tmp/model2.checkpoint\n22:29:57 | time:256s total_exs:13000 total_steps:650 epochs:65.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9923 9.923e-10               .9927                 .9927   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9927            .9918              .9918   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9918 11.56 .2564 271.3  1051       0          0 77.49  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9923             32768  .8450    .1208 6.056 .0305 3.25e-05 121.1 469.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  650 392.4 1520 3.884        .9923\n\n22:30:03 | time:262s total_exs:13420 total_steps:671 epochs:67.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9952 9.952e-10               .9956                 .9913   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9948                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9896  11.5 .2381 269.9  1017       0          0 75.35  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9952             32768  .3593    .1208 6.086 .01885 3.355e-05 121.7 458.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  671 391.6 1476 3.783        .9952\n\n22:30:03 | running eval: valid\n22:30:03 | eval completed in 0.20s\n22:30:03 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1720       0          0 132.2   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 .8339 3.355e-05    72 793.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    671  228 2513        .8748\n\u001b[0m\n22:30:03 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 8\u001b[0m\n22:30:03 | saving model checkpoint: /tmp/model2.checkpoint\n22:30:17 | time:276s total_exs:14200 total_steps:710 epochs:71.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9846 9.846e-10               .9845                 .9719   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9974            .9847              .9974   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9724 11.92 .2821 278.4  1080       0          0 77.56  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9846             32768  1.002    .1208 5.979 .04526 3.55e-05 119.6 463.8   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  710  398 1543 3.887        .9846\n\n22:30:23 | time:282s total_exs:14640 total_steps:732 epochs:73.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9886 9.886e-10               .9896                 .9835   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9958            .9874              .9949   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9800 11.74 .3636 274.7  1056       0          0  76.9  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9886             32768  .4747    .1208 6.091 .02744 3.66e-05 121.8 468.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  732 396.5 1525 3.86        .9886\n\n22:30:23 | running eval: valid\n22:30:23 | eval completed in 0.20s\n22:30:23 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8000                 .7692   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7826              .8182   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1757       0          0 135.1   24 .7917   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 1.452 3.66e-05    72   811       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    732  228 2568        .7913\n\u001b[0m\n22:30:23 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 9\u001b[0m\n22:30:23 | saving model checkpoint: /tmp/model2.checkpoint\n22:30:37 | time:297s total_exs:15400 total_steps:770 epochs:77.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9895 9.895e-10               .9899                 .9824   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9974            .9890              .9972   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9810 11.55 .3421 271.1  1030       0          0 76.01  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9895             32768  6.571    .1208 6.032 .02746 3.85e-05 120.6 458.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  770 391.7 1489 3.809        .9895\n\n22:30:43 | time:302s total_exs:15840 total_steps:792 epochs:79.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9932 9.932e-10               .9936                 .9873   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9927                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9854 11.99 .3182 279.7  1068       0          0 76.34  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9932             32768  .3192    .1208 6.064 .01654 3.96e-05 121.3 462.9   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  792  401 1531 3.832        .9932\n\n22:30:43 | running eval: valid\n22:30:43 | eval completed in 0.20s\n22:30:43 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1757       0          0 135.1   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 1.164 3.96e-05    72 810.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    792  228 2568        .8333\n\u001b[0m\n22:30:43 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 10\u001b[0m\n22:30:43 | saving model checkpoint: /tmp/model2.checkpoint\n22:30:58 | time:317s total_exs:16620 total_steps:831 epochs:83.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9885 9.885e-10               .9885                 .9772   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9884                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9772 11.73 .2564 274.7  1058       0          0 77.02  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9885             32768  .3087    .1208  5.99 .02641 4.155e-05 119.8 461.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  831 394.5 1519 3.86        .9885\n\n22:31:04 | time:323s total_exs:17060 total_steps:853 epochs:85.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9886 9.886e-10               .9886                 .9774   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9887                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9777  11.7 .3182   274  1029       0          0 75.11  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9886             32768  .2465    .1208 5.982 .01752 4.265e-05 119.6 449.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  853 393.7 1478 3.77        .9886\n\n22:31:04 | running eval: valid\n22:31:04 | eval completed in 0.21s\n22:31:04 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1682       0          0 129.3   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 .9242 4.265e-05    72 776.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    853  228 2459        .8748\n\u001b[0m\n22:31:04 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 11\u001b[0m\n22:31:04 | saving model checkpoint: /tmp/model2.checkpoint\n22:31:18 | time:337s total_exs:17840 total_steps:892 epochs:89.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9923 9.923e-10               .9927                 .9854   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9919                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9840 11.58 .3590 271.6  1052       0          0 77.49  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9923             32768  .2417    .1208 6.041 .0167 4.46e-05 120.8 468.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  892 392.4 1520 3.883        .9923\n\n22:31:24 | time:343s total_exs:18300 total_steps:915 epochs:91.50\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9870 9.87e-10               .9875                 .9753   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9864                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9731 11.73 .3478 274.6  1092       0          0 79.57  460   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9870             32768  .2967    .1208  6.03 .0274 4.575e-05 120.6 479.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  915 395.2 1572 3.994        .9869\n\n22:31:24 | running eval: valid\n22:31:24 | eval completed in 0.19s\n22:31:24 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8000                 .7692   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7826              .8182   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1776       0          0 136.6   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 1.561 4.575e-05    72 819.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    915  228 2596        .7913\n\u001b[0m\n22:31:24 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 12\u001b[0m\n22:31:24 | saving model checkpoint: /tmp/model2.checkpoint\n22:31:39 | time:358s total_exs:19060 total_steps:953 epochs:95.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9895 9.895e-10               .9897                 .9797   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9892                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9786  11.5 .3158 270.1  1020       0          0 75.53  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9895             32768  .2466    .1208 6.016 .01785 4.765e-05 120.3 454.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  953 390.4 1474 3.785        .9895\n\n22:31:44 | time:364s total_exs:19500 total_steps:975 epochs:97.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9886 9.886e-10               .9888                 .9779   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9885                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9772 11.95 .5000   279  1097       0          0 78.62  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9886             32768  .3465    .1208 6.005 .02479 4.875e-05 120.1 472.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  975 399.1 1569 3.947        .9886\n\n22:31:44 | running eval: valid\n22:31:44 | eval completed in 0.20s\n22:31:44 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8000                 .7692   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7826              .8182   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1752       0          0 134.8   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6  1.32 4.875e-05    72 808.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    975  228 2561        .7913\n\u001b[0m\n22:31:44 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 13\u001b[0m\n22:31:44 | saving model checkpoint: /tmp/model2.checkpoint\n22:31:59 | time:378s total_exs:20280 total_steps:1014 epochs:101.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9795 9.795e-10               .9805                 .9853   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9757            .9784              .9731   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9837  11.6 .4872   272  1052       0          0 77.36  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9795             32768  .4049    .1208 6.056 .03068 4.995e-05 121.1 468.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1014 393.2 1521 3.877        .9795\n\n22:32:05 | time:384s total_exs:20720 total_steps:1036 epochs:103.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9773 9.773e-10               .9776                 .9776   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9776            .9770              .9770   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9770 11.48 .4091 269.6  1067       0          0 79.17  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9773             32768  .7047    .1208 6.014 .02879 4.995e-05 120.3 476.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1036 389.9 1543 3.975        .9773\n\n22:32:05 | running eval: valid\n22:32:05 | eval completed in 0.19s\n22:32:05 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8000                 .7692   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7826              .8182   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1765       0          0 135.7   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 1.473 4.995e-05    72 814.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1036  228 2580        .7913\n\u001b[0m\n22:32:05 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 14\u001b[0m\n22:32:05 | saving model checkpoint: /tmp/model2.checkpoint\n22:32:20 | time:399s total_exs:21520 total_steps:1076 epochs:107.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9938 9.937e-10               .9938                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9876            .9937              .9875   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.75 .2500   275  1078       0          0 78.37  800   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9938             32768  11.64    .1208  6.01 .01844 4.995e-05 120.2   471   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1076 395.2 1549 3.926        .9938\n\n22:32:25 | time:404s total_exs:21920 total_steps:1096 epochs:109.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9925 9.925e-10               .9927                 .9951   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9903            .9923              .9897   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9948 11.95 .3500   279  1093       0          0 78.33  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9925             32768  1.488    .1209  6.03 .02757 4.995e-05 120.6 472.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1096 399.6 1565 3.934        .9925\n\n22:32:25 | running eval: valid\n22:32:25 | eval completed in 0.19s\n22:32:25 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1772       0          0 136.3   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 .9797 4.995e-05    72 817.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1096  228 2590        .8748\n\u001b[0m\n22:32:25 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 15\u001b[0m\n22:32:25 | saving model checkpoint: /tmp/model2.checkpoint\n22:32:40 | time:419s total_exs:22700 total_steps:1135 epochs:113.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9936 9.936e-10               .9936                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9874            .9935              .9871   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.97 .2564 279.3  1073       0          0 76.85  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9936             32768  .4590    .1209 6.015 .02853 4.995e-05 120.3 462.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1135 399.6 1536 3.851        .9936\n\n22:32:45 | time:425s total_exs:23140 total_steps:1157 epochs:115.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9818 9.818e-10               .9831                 .9957   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9707            .9804              .9662   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9950 11.76 .2727 275.2  1061       0          0 77.11  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9818             32768  2.151    .1209 6.086 .08236 4.995e-05 121.7 469.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1157 396.9 1530 3.871        .9818\n\n22:32:45 | running eval: valid\n22:32:46 | eval completed in 0.20s\n22:32:46 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1754       0          0 134.9   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6 1.328 4.995e-05    72 809.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1157  228 2564        .8333\n\u001b[0m\n22:32:46 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 16\u001b[0m\n22:32:46 | saving model checkpoint: /tmp/model2.checkpoint\n22:33:00 | time:439s total_exs:23920 total_steps:1196 epochs:119.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9885 9.885e-10               .9892                 .9881   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9904            .9876              .9889   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9862 11.94 .3333 278.8  1083       0          0 77.68  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9885             32768  1.093    .1209 6.072 .0657 4.995e-05 121.4 471.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1196 400.3 1555 3.893        .9885\n\n22:33:06 | time:445s total_exs:24380 total_steps:1219 epochs:121.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9913 9.913e-10               .9917                 .9958   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9876            .9909              .9864   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9954 11.55 .1304   271  1048       0          0  77.3  460   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9913             32768  .1559    .1209 6.048 .03184 4.995e-05   121 467.5   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps  ups  weighted_f1  \n         0          0                 1219  392 1515 3.88        .9913\n\n22:33:06 | running eval: valid\n22:33:06 | eval completed in 0.19s\n22:33:06 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1774       0          0 136.4   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 1.335 4.995e-05    72 818.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1219  228 2593        .7884\n\u001b[0m\n22:33:06 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 17\u001b[0m\n22:33:06 | saving model checkpoint: /tmp/model2.checkpoint\n22:33:21 | time:460s total_exs:25160 total_steps:1258 epochs:125.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9821 9.821e-10               .9830                 .9806   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9854            .9810              .9837   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9784 11.85 .3846 277.1  1077       0          0 77.73  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9821             32768  17.84    .1209 6.051 .07766 4.995e-05   121 470.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1258 398.1 1547 3.895        .9820\n\n22:33:26 | time:465s total_exs:25580 total_steps:1279 epochs:127.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9881 9.881e-10               .9879                 .9903   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9855            .9883              .9860   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9906 11.23 .3810 264.6  1039       0          0 78.52  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9881             32768  .3601    .1209 5.986 .02026 4.995e-05 119.7   470   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1279 384.3 1509 3.943        .9881\n\n22:33:26 | running eval: valid\n22:33:26 | eval completed in 0.22s\n22:33:26 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8000                 .7692   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7826              .8182   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1596       0          0 122.6   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 1.303 4.995e-05    72 736.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1279  228 2332        .7913\n\u001b[0m\n22:33:26 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 18\u001b[0m\n22:33:26 | saving model checkpoint: /tmp/model2.checkpoint\n22:33:41 | time:480s total_exs:26360 total_steps:1318 epochs:131.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9859 9.859e-10               .9859                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9722            .9859              .9722   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.87 .5385 277.4  1073       0          0 77.37  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9859             32768  .3154    .1209 6.015 .03494 4.995e-05 120.3 465.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1318 397.7 1538 3.877        .9859\n\n22:33:47 | time:486s total_exs:26800 total_steps:1340 epochs:134.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9909 9.909e-10               .9912                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9825            .9907              .9815   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.89 .2727 277.7  1043       0          0  75.1  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9909             32768  .2377    .1209 6.036 .01981 4.995e-05 120.7 453.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1340 398.5 1496 3.77        .9909\n\n22:33:47 | running eval: valid\n22:33:47 | eval completed in 0.21s\n22:33:47 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1670       0          0 128.4   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 .9798 4.995e-05    72 770.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1340  228 2441        .8333\n\u001b[0m\nEpoch 00006: reducing learning rate of group 0 to 2.4975e-05.\n22:33:47 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 19\u001b[0m\n22:33:47 | saving model checkpoint: /tmp/model2.checkpoint\n22:34:01 | time:501s total_exs:27580 total_steps:1379 epochs:137.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9923 9.923e-10               .9922                 .9948   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9897            .9924              .9899   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9949 11.84 .2564 276.9  1073       0          0 77.52  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9923             32768  .3534    .1209 5.992 .02857 2.498e-05 119.8 464.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1379 396.7 1538 3.885        .9923\n\n22:34:07 | time:506s total_exs:28020 total_steps:1401 epochs:140.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9886 9.886e-10               .9888                 .9779   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9885                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9772 11.66 .2273 273.2  1084       0          0 79.34  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9886             32768  .8011    .1209 6.005 .05234 2.498e-05 120.1 476.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1401 393.3 1560 3.983        .9886\n\n22:34:07 | running eval: valid\n22:34:07 | eval completed in 0.20s\n22:34:07 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8000                 .7692   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7826              .8182   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1737       0          0 133.5   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6 1.544 2.498e-05    72 801.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1401  228 2538        .7913\n\u001b[0m\n22:34:07 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 20\u001b[0m\n22:34:07 | saving model checkpoint: /tmp/model2.checkpoint\n22:34:22 | time:521s total_exs:28780 total_steps:1439 epochs:143.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9908 9.908e-10               .9903                 .9807   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9913                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9827 11.79 .4211 275.9  1047       0          0  75.9  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9908             32768  .5725    .1209 5.937 .03041 2.498e-05 118.7 450.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1439 394.6 1498 3.804        .9908\n\n22:34:27 | time:526s total_exs:29220 total_steps:1461 epochs:146.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9886 9.886e-10               .9879                 .9761   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9893                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9788 11.96 .2273 279.3  1104       0          0 79.07  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9886             32768  .4197    .1209 5.927 .03716 2.498e-05 118.5 468.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1461 397.8 1573 3.97        .9886\n\n22:34:27 | running eval: valid\n22:34:27 | eval completed in 0.20s\n22:34:27 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8000                 .7692   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7826              .8182   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1756       0          0 135.1   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 1.366 2.498e-05    72 810.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1461  228 2567        .7913\n\u001b[0m\n22:34:27 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 21\u001b[0m\n22:34:27 | saving model checkpoint: /tmp/model2.checkpoint\n22:34:42 | time:541s total_exs:30000 total_steps:1500 epochs:150.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9782 9.782e-10               .9778                 .9715   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9843            .9786              .9848   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9724  11.6 .4615 271.9  1048       0          0 77.11  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9782             32768  .4553    .1209 5.977 .02836 2.498e-05 119.5 460.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1500 391.5 1509 3.864        .9782\n\n22:34:47 | time:547s total_exs:30420 total_steps:1521 epochs:152.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9881 9.881e-10               .9885                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9772            .9877              .9757   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.73 .4286 274.5  1026       0          0 74.76  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9881             32768  .2506    .1209 6.043 .01915 2.498e-05 120.9 451.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1521 395.4 1478 3.753        .9881\n\n22:34:47 | running eval: valid\n22:34:48 | eval completed in 0.20s\n22:34:48 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1699       0          0 130.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 1.164 2.498e-05    72 784.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1521  228 2484        .8333\n\u001b[0m\n22:34:48 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 22\u001b[0m\n22:34:48 | saving model checkpoint: /tmp/model2.checkpoint\n22:35:02 | time:561s total_exs:31200 total_steps:1560 epochs:156.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9885 9.885e-10               .9892                 .9952   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9833            .9876              .9808   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9944 11.89 .2308 277.9  1074       0          0 77.29  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9885             32768  .1484    .1209 6.077 .01261 2.498e-05 121.5 469.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1560 399.4 1544 3.873        .9885\n\n22:35:08 | time:567s total_exs:31640 total_steps:1582 epochs:158.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9932 9.932e-10               .9933                 .9867   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9931                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9862  11.9 .2727   278  1076       0          0 77.44  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9932             32768  .1537    .1209 6.009 .0114 2.498e-05 120.2 465.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1582 398.2 1542 3.887        .9932\n\n22:35:08 | running eval: valid\n22:35:08 | eval completed in 0.20s\n22:35:08 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1762       0          0 135.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 1.263 2.498e-05    72 813.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1582  228 2575        .8333\n\u001b[0m\nEpoch 00010: reducing learning rate of group 0 to 1.2488e-05.\n22:35:08 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 23\u001b[0m\n22:35:08 | saving model checkpoint: /tmp/model2.checkpoint\n22:35:22 | time:581s total_exs:32400 total_steps:1620 epochs:162.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9921 9.921e-10               .9920                 .9947   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9894            .9922              .9896   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9948 11.82 .2895 276.4  1044       0          0 75.57  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9921             32768  .1680    .1210 5.989 .0122 1.249e-05 119.8 452.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1620 396.2 1497 3.787        .9921\n\n22:35:28 | time:587s total_exs:32860 total_steps:1643 epochs:164.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9957 9.957e-10               .9957                 .9915   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9956                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9912 11.34 .4348 266.9  1045       0          0 78.29  460   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9957             32768  .1994    .1210 6.013 .01417 1.249e-05 120.3 470.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1643 387.1 1515 3.929        .9957\n\n22:35:28 | running eval: valid\n22:35:28 | eval completed in 0.20s\n22:35:28 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8000                 .7692   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7826              .8182   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1769       0          0   136   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6  1.59 1.249e-05    72 816.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1643  228 2586        .7913\n\u001b[0m\n22:35:28 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 24\u001b[0m\n22:35:28 | saving model checkpoint: /tmp/model2.checkpoint\n22:35:43 | time:602s total_exs:33640 total_steps:1682 epochs:168.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9923 9.923e-10               .9926                 .9853   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9920                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9841    12 .3077   280  1086       0          0 77.54  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9923             32768  .1663    .1210 6.033 .01459 1.249e-05 120.7 467.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1682 400.7 1553 3.886        .9923\n\n22:35:49 | time:608s total_exs:34100 total_steps:1705 epochs:170.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9913 9.913e-10               .9913                 .9828   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9913                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9827  11.4 .4783   268  1032       0          0 77.03  460   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9913             32768  .2005    .1210 5.996 .01961 1.249e-05 119.9 461.8   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1705  388 1494 3.866        .9913\n\n22:35:49 | running eval: valid\n22:35:49 | eval completed in 0.27s\n22:35:49 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8000                 .7692   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7826              .8182   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1328       0          0 102.1   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 1.578 1.249e-05    72 612.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1705  228 1941        .7913\n\u001b[0m\n22:35:49 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 25\u001b[0m\n22:35:49 | saving model checkpoint: /tmp/model2.checkpoint\n22:36:04 | time:623s total_exs:34880 total_steps:1744 epochs:174.40\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9910 9.91e-10               .9915                 .9831   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9906                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9813 11.63 .2821 272.6  1053       0          0 77.23  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9910             32768  .1899    .1210 6.041 .02348 1.249e-05 120.8 466.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1744 393.5 1519 3.87        .9910\n\n22:36:09 | time:628s total_exs:35300 total_steps:1765 epochs:176.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9952 9.952e-10               .9954                 .9909   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9950                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9901 11.78 .1905 275.7  1082       0          0 78.53  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9952             32768  6.322    .1210 6.038 .02125 1.249e-05 120.8 474.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1765 396.4 1557 3.943        .9952\n\n22:36:09 | running eval: valid\n22:36:09 | eval completed in 0.20s\n22:36:09 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8000                 .7692   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7826              .8182   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1736       0          0 133.5   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 1.444 1.249e-05    72   801       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1765  228 2537        .7913\n\u001b[0m\n22:36:09 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 26\u001b[0m\n22:36:09 | saving model checkpoint: /tmp/model2.checkpoint\n22:36:24 | time:643s total_exs:36060 total_steps:1803 epochs:180.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9947 9.947e-10               .9951                 .9902   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9943                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9887 11.44 .2632 268.8  1022       0          0 76.03  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9947             32768  .1292    .1210 6.066 .01406 1.249e-05 121.3 461.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1803 390.2 1483 3.81        .9947\n\n22:36:29 | time:648s total_exs:36500 total_steps:1825 epochs:182.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9909 9.909e-10               .9902                 .9807   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9915                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9831 11.82 .1818 276.5  1093       0          0 79.04  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9909             32768  .2035    .1210 5.923 .02885 1.249e-05 118.5 468.1   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1825  395 1561 3.968        .9909\n\n22:36:29 | running eval: valid\n22:36:29 | eval completed in 0.20s\n22:36:29 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1772       0          0 136.3   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08122     6 1.011 1.249e-05    72 817.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1825  228 2590        .8748\n\u001b[0m\nEpoch 00014: reducing learning rate of group 0 to 6.2438e-06.\n22:36:29 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 27\u001b[0m\n22:36:29 | saving model checkpoint: /tmp/model2.checkpoint\n22:36:44 | time:663s total_exs:37300 total_steps:1865 epochs:186.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9912 9.912e-10               .9913                 .9828   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9912                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9825  11.8 .1500 276.1  1080       0          0  78.2  800   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9912             32768  .1811    .1210     6 .02574 6.244e-06   120 469.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1865 396.1 1549 3.919        .9912\n\n22:36:49 | time:669s total_exs:37720 total_steps:1886 epochs:188.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9857 9.857e-10               .9856                 .9716   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9858                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9721 11.45 .1905   269  1055       0          0 78.46  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9857             32768  .2908    .1210 5.976 .03912 6.244e-06 119.5 468.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1886 388.5 1524 3.94        .9857\n\n22:36:49 | running eval: valid\n22:36:50 | eval completed in 0.20s\n22:36:50 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1732       0          0 133.2   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08124     6 1.036 6.244e-06    72 799.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1886  228 2532        .8748\n\u001b[0m\n22:36:50 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 28\u001b[0m\n22:36:50 | saving model checkpoint: /tmp/model2.checkpoint\n22:37:05 | time:684s total_exs:38520 total_steps:1926 epochs:192.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9875 9.875e-10               .9882                 .9766   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9868                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9739 11.72 .2500 274.4  1072       0          0 78.12  800   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9875             32768  .2378    .1210 6.043 .03078 6.244e-06 120.8   472   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1926 395.2 1544 3.914        .9875\n\n22:37:10 | time:689s total_exs:38920 total_steps:1946 epochs:194.60\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9950 9.95e-10               .9950                 .9900   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9950                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9901 11.64 .2000 272.8  1015       0          0 74.44  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9950             32768  .1053    .1210  5.99 .01097 6.244e-06 119.8 445.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1946 392.6 1461 3.738        .9950\n\n22:37:10 | running eval: valid\n22:37:10 | eval completed in 0.20s\n22:37:10 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1723       0          0 132.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08125     6 1.031 6.244e-06    72 795.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1946  228 2519        .8748\n\u001b[0m\n22:37:10 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 29\u001b[0m\n22:37:10 | saving model checkpoint: /tmp/model2.checkpoint\n22:37:24 | time:704s total_exs:39680 total_steps:1984 epochs:198.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9882 9.882e-10               .9882                 .9766   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9881                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9766 11.94 .3684 278.9  1058       0          0 75.86  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9882             32768  .2148    .1210 5.989 .02498 6.244e-06 119.8 454.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1984 398.7 1512 3.801        .9882\n\n22:37:30 | time:709s total_exs:40120 total_steps:2006 epochs:200.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9932 9.932e-10               .9934                 .9869   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9929                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9860 11.88 .3636 277.7  1071       0          0 77.12  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9932             43194  .1477    .1210 6.027 .01446 6.244e-06 120.5 464.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 2006 398.2 1536 3.872        .9932\n\n22:37:30 | running eval: valid\n22:37:30 | eval completed in 0.19s\n22:37:30 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1765       0          0 135.8   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08126     6 1.033 6.244e-06    72 814.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   2006  228 2580        .8748\n\u001b[0m\n22:37:30 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 30\u001b[0m\n22:37:30 | saving model checkpoint: /tmp/model2.checkpoint\n22:37:35 | ran out of patience! stopping training.\n22:37:35 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n22:37:35 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n22:37:35 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run2/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n22:37:35 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n22:37:35 | Using CUDA\n22:37:35 | loading dictionary from /tmp/model2.dict\n22:37:35 | num words = 54944\n22:37:39 | Loading existing model parameters from /tmp/model2\n22:37:47 | Total parameters: 128,042,498 (128,042,498 trainable)\n22:37:48 | creating task(s): fromfile:parlaiformat\n22:37:48 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run2/data_valid.txt\n22:37:48 | running eval: valid\n22:37:49 | eval completed in 0.34s\n22:37:49 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1032       0          0 79.25   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298     6 .2547 1.045e-05    72   476       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    209  228 1508        .9167\n\u001b[0m\n22:37:49 | creating task(s): fromfile:parlaiformat\n22:37:49 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run2/data_test.txt\n22:37:49 | running eval: test\n22:37:54 | eval completed in 4.94s\n22:37:54 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9490 9.49e-10               .7866                 .6763   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9400            .9710              .9930   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9500 12.07 281.4  2865       0          0 203.6 1000 .9490   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298   5.2 .1782 1.045e-05   104  1059       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    209 385.4 3923        .9526\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type2/run2/data_test.txt -m transformer/classifier -mf /tmp/model2 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-03T22:37:56.464508Z","iopub.execute_input":"2022-12-03T22:37:56.464943Z","iopub.status.idle":"2022-12-03T22:38:27.746207Z","shell.execute_reply.started":"2022-12-03T22:37:56.464879Z","shell.execute_reply":"2022-12-03T22:38:27.744975Z"},"scrolled":true,"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"22:38:05 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr1type2/run2/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr1type2/run2/data)\u001b[0m\n22:38:05 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n22:38:05 | Using CUDA\n22:38:05 | loading dictionary from /tmp/model2.dict\n22:38:06 | num words = 54944\n22:38:10 | Loading existing model parameters from /tmp/model2\n22:38:16 | Total parameters: 128,042,498 (128,042,498 trainable)\n22:38:17 | Opt:\n22:38:17 |     activation: gelu\n22:38:17 |     adafactor_eps: '[1e-30, 0.001]'\n22:38:17 |     adam_eps: 1e-08\n22:38:17 |     add_p1_after_newln: False\n22:38:17 |     aggregate_micro: False\n22:38:17 |     allow_missing_init_opts: False\n22:38:17 |     area_under_curve_class: None\n22:38:17 |     area_under_curve_digits: -1\n22:38:17 |     attention_dropout: 0.1\n22:38:17 |     batchsize: 40\n22:38:17 |     betas: '[0.9, 0.999]'\n22:38:17 |     bpe_add_prefix_space: None\n22:38:17 |     bpe_debug: False\n22:38:17 |     bpe_dropout: None\n22:38:17 |     bpe_merge: None\n22:38:17 |     bpe_vocab: None\n22:38:17 |     candidates: inline\n22:38:17 |     cap_num_predictions: 100\n22:38:17 |     checkpoint_activations: False\n22:38:17 |     class_weights: None\n22:38:17 |     classes: \"['__notok__', '__ok__']\"\n22:38:17 |     classes_from_file: None\n22:38:17 |     data_parallel: True\n22:38:17 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n22:38:17 |     datatype: train\n22:38:17 |     delimiter: '\\n'\n22:38:17 |     dict_class: parlai.core.dict:DictionaryAgent\n22:38:17 |     dict_endtoken: __start__\n22:38:17 |     dict_file: /tmp/model2.dict\n22:38:17 |     dict_include_test: False\n22:38:17 |     dict_include_valid: False\n22:38:17 |     dict_initpath: None\n22:38:17 |     dict_language: english\n22:38:17 |     dict_loaded: True\n22:38:17 |     dict_lower: True\n22:38:17 |     dict_max_ngram_size: -1\n22:38:17 |     dict_maxexs: -1\n22:38:17 |     dict_maxtokens: -1\n22:38:17 |     dict_minfreq: 0\n22:38:17 |     dict_nulltoken: __null__\n22:38:17 |     dict_starttoken: __start__\n22:38:17 |     dict_textfields: text,labels\n22:38:17 |     dict_tokenizer: bpe\n22:38:17 |     dict_unktoken: __unk__\n22:38:17 |     display_examples: False\n22:38:17 |     download_path: None\n22:38:17 |     dropout: 0.1\n22:38:17 |     dynamic_batching: None\n22:38:17 |     embedding_projection: random\n22:38:17 |     embedding_size: 768\n22:38:17 |     embedding_type: random\n22:38:17 |     embeddings_scale: False\n22:38:17 |     encode_candidate_vecs: True\n22:38:17 |     encode_candidate_vecs_batchsize: 256\n22:38:17 |     eval_batchsize: None\n22:38:17 |     eval_candidates: inline\n22:38:17 |     eval_dynamic_batching: None\n22:38:17 |     evaltask: None\n22:38:17 |     ffn_size: 3072\n22:38:17 |     final_extra_opt: \n22:38:17 |     fixed_candidate_vecs: reuse\n22:38:17 |     fixed_candidates_path: None\n22:38:17 |     force_fp16_tokens: True\n22:38:17 |     fp16: True\n22:38:17 |     fp16_impl: safe\n22:38:17 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run2/data_test.txt\n22:38:17 |     fromfile_datatype_extension: True\n22:38:17 |     gpu: -1\n22:38:17 |     gradient_clip: 0.1\n22:38:17 |     hide_labels: False\n22:38:17 |     history_add_global_end_token: None\n22:38:17 |     history_reversed: False\n22:38:17 |     history_size: 20\n22:38:17 |     ignore_bad_candidates: False\n22:38:17 |     ignore_labels: None\n22:38:17 |     image_cropsize: 224\n22:38:17 |     image_mode: raw\n22:38:17 |     image_size: 256\n22:38:17 |     inference: max\n22:38:17 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n22:38:17 |     init_opt: None\n22:38:17 |     interactive_candidates: fixed\n22:38:17 |     interactive_mode: False\n22:38:17 |     invsqrt_lr_decay_gamma: -1\n22:38:17 |     is_debug: False\n22:38:17 |     label_truncate: 72\n22:38:17 |     learn_embeddings: True\n22:38:17 |     learn_positional_embeddings: True\n22:38:17 |     learningrate: 5e-05\n22:38:17 |     load_from_pretrained_ranker: True\n22:38:17 |     log_every_n_secs: 10.0\n22:38:17 |     log_every_n_steps: 50\n22:38:17 |     log_keep_fields: all\n22:38:17 |     loglevel: info\n22:38:17 |     lr_scheduler: reduceonplateau\n22:38:17 |     lr_scheduler_decay: 0.5\n22:38:17 |     lr_scheduler_patience: 3\n22:38:17 |     max_train_steps: -1\n22:38:17 |     max_train_time: 7200.0\n22:38:17 |     memory_attention: sqrt\n22:38:17 |     metrics: default\n22:38:17 |     model: transformer/classifier\n22:38:17 |     model_file: /tmp/model2\n22:38:17 |     model_parallel: False\n22:38:17 |     momentum: 0\n22:38:17 |     multitask_weights: [1]\n22:38:17 |     mutators: None\n22:38:17 |     n_decoder_layers: -1\n22:38:17 |     n_encoder_layers: -1\n22:38:17 |     n_heads: 12\n22:38:17 |     n_layers: 12\n22:38:17 |     n_positions: 1024\n22:38:17 |     n_segments: 2\n22:38:17 |     nesterov: True\n22:38:17 |     no_cuda: False\n22:38:17 |     normalize_sent_emb: False\n22:38:17 |     num_epochs: -1\n22:38:17 |     num_examples: -1\n22:38:17 |     num_workers: 0\n22:38:17 |     nus: [0.7]\n22:38:17 |     optimizer: adamax\n22:38:17 |     output_scaling: 0.06\n22:38:17 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type2/run2/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model2', 'batchsize': 40}\"\n22:38:17 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n22:38:17 |     person_tokens: False\n22:38:17 |     print_scores: False\n22:38:17 |     rank_candidates: False\n22:38:17 |     rank_top_k: -1\n22:38:17 |     reduction_type: mean\n22:38:17 |     ref_class: None\n22:38:17 |     relu_dropout: 0.0\n22:38:17 |     repeat_blocking_heuristic: True\n22:38:17 |     report_filename: \n22:38:17 |     return_cand_scores: False\n22:38:17 |     save_after_valid: True\n22:38:17 |     save_every_n_secs: -1\n22:38:17 |     save_format: conversations\n22:38:17 |     share_encoders: False\n22:38:17 |     share_word_embeddings: False\n22:38:17 |     short_final_eval: False\n22:38:17 |     special_tok_lst: None\n22:38:17 |     split_lines: False\n22:38:17 |     starttime: Dec03_22-25\n22:38:17 |     task: fromfile:parlaiformat\n22:38:17 |     tensorboard_log: False\n22:38:17 |     tensorboard_logdir: None\n22:38:17 |     text_truncate: 360\n22:38:17 |     threshold: 0.5\n22:38:17 |     topk: 5\n22:38:17 |     train_predict: False\n22:38:17 |     truncate: 1024\n22:38:17 |     update_classifier_head_only: False\n22:38:17 |     update_freq: 1\n22:38:17 |     use_memories: False\n22:38:17 |     use_reply: none\n22:38:17 |     validation_cutoff: 1.0\n22:38:17 |     validation_every_n_epochs: -1\n22:38:17 |     validation_every_n_secs: 20.0\n22:38:17 |     validation_every_n_steps: -1\n22:38:17 |     validation_max_exs: -1\n22:38:17 |     validation_metric: accuracy\n22:38:17 |     validation_metric_mode: max\n22:38:17 |     validation_patience: 30\n22:38:17 |     validation_share_agent: False\n22:38:17 |     variant: xlm\n22:38:17 |     verbose: False\n22:38:17 |     wandb_entity: None\n22:38:17 |     wandb_log: False\n22:38:17 |     wandb_name: None\n22:38:17 |     wandb_project: None\n22:38:17 |     warmup_rate: 0.0001\n22:38:17 |     warmup_updates: 1000\n22:38:17 |     weight_decay: None\n22:38:17 |     world_logs: \n22:38:17 |     wrap_memory_encoder: False\n22:38:17 | Evaluating task fromfile:parlaiformat using datatype valid.\n22:38:17 | creating task(s): fromfile:parlaiformat\n22:38:17 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n22:38:17 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run2/data_test.txt\n22:38:25 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9490 9.49e-10               .7866                 .6763   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9400            .9710              .9930   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9500 12.07 562.9  1876       0          0 133.3 1000 .9490   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .1782 1.045e-05   208 693.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    209 770.9 2569        .9526\u001b[0m\n22:38:25 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9490 9.49e-10               .7866                 .6763   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9400            .9710              .9930   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9500 12.07 562.9  1876       0          0 133.3 1000 .9490   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .1782 1.045e-05   208 693.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    209 770.9 2569        .9526\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model2*","metadata":{"execution":{"iopub.status.busy":"2022-12-03T22:38:27.750976Z","iopub.execute_input":"2022-12-03T22:38:27.751660Z","iopub.status.idle":"2022-12-03T22:38:28.975422Z","shell.execute_reply.started":"2022-12-03T22:38:27.751617Z","shell.execute_reply":"2022-12-03T22:38:28.973982Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"run 3","metadata":{}},{"cell_type":"code","source":"# run 3 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type2/run3/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model3","metadata":{"execution":{"iopub.status.busy":"2022-12-03T22:38:28.978166Z","iopub.execute_input":"2022-12-03T22:38:28.979656Z","iopub.status.idle":"2022-12-03T22:39:54.261806Z","shell.execute_reply.started":"2022-12-03T22:38:28.979608Z","shell.execute_reply":"2022-12-03T22:39:54.260450Z"},"scrolled":true,"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"22:38:36 | building dictionary first...\n22:38:36 | No model with opt yet at: /tmp/model3(.opt)\n22:38:36 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run3/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n22:38:36 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n22:38:36 | Using CUDA\n22:38:36 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n22:38:36 | num words = 54944\n22:38:40 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n22:38:50 | Total parameters: 128,042,498 (128,042,498 trainable)\n22:38:50 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n22:38:50 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n22:38:50 | Opt:\n22:38:50 |     activation: gelu\n22:38:50 |     adafactor_eps: '(1e-30, 0.001)'\n22:38:50 |     adam_eps: 1e-08\n22:38:50 |     add_p1_after_newln: False\n22:38:50 |     aggregate_micro: False\n22:38:50 |     allow_missing_init_opts: False\n22:38:50 |     attention_dropout: 0.1\n22:38:50 |     batchsize: 20\n22:38:50 |     betas: '(0.9, 0.999)'\n22:38:50 |     bpe_add_prefix_space: None\n22:38:50 |     bpe_debug: False\n22:38:50 |     bpe_dropout: None\n22:38:50 |     bpe_merge: None\n22:38:50 |     bpe_vocab: None\n22:38:50 |     candidates: inline\n22:38:50 |     cap_num_predictions: 100\n22:38:50 |     checkpoint_activations: False\n22:38:50 |     class_weights: None\n22:38:50 |     classes: \"['__notok__', '__ok__']\"\n22:38:50 |     classes_from_file: None\n22:38:50 |     data_parallel: True\n22:38:50 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n22:38:50 |     datatype: train\n22:38:50 |     delimiter: '\\n'\n22:38:50 |     dict_class: parlai.core.dict:DictionaryAgent\n22:38:50 |     dict_endtoken: __start__\n22:38:50 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n22:38:50 |     dict_include_test: False\n22:38:50 |     dict_include_valid: False\n22:38:50 |     dict_initpath: None\n22:38:50 |     dict_language: english\n22:38:50 |     dict_loaded: True\n22:38:50 |     dict_lower: True\n22:38:50 |     dict_max_ngram_size: -1\n22:38:50 |     dict_maxexs: -1\n22:38:50 |     dict_maxtokens: -1\n22:38:50 |     dict_minfreq: 0\n22:38:50 |     dict_nulltoken: __null__\n22:38:50 |     dict_starttoken: __start__\n22:38:50 |     dict_textfields: text,labels\n22:38:50 |     dict_tokenizer: bpe\n22:38:50 |     dict_unktoken: __unk__\n22:38:50 |     display_examples: False\n22:38:50 |     download_path: None\n22:38:50 |     dropout: 0.1\n22:38:50 |     dynamic_batching: None\n22:38:50 |     embedding_projection: random\n22:38:50 |     embedding_size: 768\n22:38:50 |     embedding_type: random\n22:38:50 |     embeddings_scale: False\n22:38:50 |     encode_candidate_vecs: True\n22:38:50 |     encode_candidate_vecs_batchsize: 256\n22:38:50 |     eval_batchsize: None\n22:38:50 |     eval_candidates: inline\n22:38:50 |     eval_dynamic_batching: None\n22:38:50 |     evaltask: None\n22:38:50 |     ffn_size: 3072\n22:38:50 |     final_extra_opt: \n22:38:50 |     fixed_candidate_vecs: reuse\n22:38:50 |     fixed_candidates_path: None\n22:38:50 |     force_fp16_tokens: False\n22:38:50 |     fp16: True\n22:38:50 |     fp16_impl: safe\n22:38:50 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run3/data\n22:38:50 |     fromfile_datatype_extension: True\n22:38:50 |     gpu: -1\n22:38:50 |     gradient_clip: 0.1\n22:38:50 |     hide_labels: False\n22:38:50 |     history_add_global_end_token: None\n22:38:50 |     history_reversed: False\n22:38:50 |     history_size: 20\n22:38:50 |     ignore_bad_candidates: False\n22:38:50 |     ignore_labels: None\n22:38:50 |     image_cropsize: 224\n22:38:50 |     image_mode: raw\n22:38:50 |     image_size: 256\n22:38:50 |     inference: max\n22:38:50 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n22:38:50 |     init_opt: None\n22:38:50 |     interactive_candidates: fixed\n22:38:50 |     interactive_mode: False\n22:38:50 |     invsqrt_lr_decay_gamma: -1\n22:38:50 |     is_debug: False\n22:38:50 |     label_truncate: 72\n22:38:50 |     learn_embeddings: True\n22:38:50 |     learn_positional_embeddings: True\n22:38:50 |     learningrate: 5e-05\n22:38:50 |     load_from_checkpoint: False\n22:38:50 |     load_from_pretrained_ranker: True\n22:38:50 |     log_every_n_secs: 10.0\n22:38:50 |     log_every_n_steps: 50\n22:38:50 |     log_keep_fields: all\n22:38:50 |     loglevel: info\n22:38:50 |     lr_scheduler: reduceonplateau\n22:38:50 |     lr_scheduler_decay: 0.5\n22:38:50 |     lr_scheduler_patience: 3\n22:38:50 |     max_train_steps: -1\n22:38:50 |     max_train_time: 7200.0\n22:38:50 |     memory_attention: sqrt\n22:38:50 |     metrics: default\n22:38:50 |     model: transformer/classifier\n22:38:50 |     model_file: /tmp/model3\n22:38:50 |     model_parallel: False\n22:38:50 |     momentum: 0\n22:38:50 |     multitask_weights: [1]\n22:38:50 |     mutators: None\n22:38:50 |     n_decoder_layers: -1\n22:38:50 |     n_encoder_layers: -1\n22:38:50 |     n_heads: 12\n22:38:50 |     n_layers: 12\n22:38:50 |     n_positions: 1024\n22:38:50 |     n_segments: 2\n22:38:50 |     nesterov: True\n22:38:50 |     no_cuda: False\n22:38:50 |     normalize_sent_emb: False\n22:38:50 |     num_epochs: -1\n22:38:50 |     num_workers: 0\n22:38:50 |     nus: (0.7,)\n22:38:50 |     optimizer: adamax\n22:38:50 |     output_scaling: 0.06\n22:38:50 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type2/run3/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model3'}\"\n22:38:50 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n22:38:50 |     person_tokens: False\n22:38:50 |     print_scores: False\n22:38:50 |     rank_candidates: False\n22:38:50 |     rank_top_k: -1\n22:38:50 |     reduction_type: mean\n22:38:50 |     ref_class: None\n22:38:50 |     relu_dropout: 0.0\n22:38:50 |     repeat_blocking_heuristic: True\n22:38:50 |     return_cand_scores: False\n22:38:50 |     save_after_valid: True\n22:38:50 |     save_every_n_secs: -1\n22:38:50 |     save_format: conversations\n22:38:50 |     share_encoders: False\n22:38:50 |     share_word_embeddings: False\n22:38:50 |     short_final_eval: False\n22:38:50 |     special_tok_lst: None\n22:38:50 |     split_lines: False\n22:38:50 |     starttime: Dec03_22-38\n22:38:50 |     task: fromfile:parlaiformat\n22:38:50 |     tensorboard_log: False\n22:38:50 |     tensorboard_logdir: None\n22:38:50 |     text_truncate: 360\n22:38:50 |     threshold: 0.5\n22:38:50 |     topk: 5\n22:38:50 |     train_predict: False\n22:38:50 |     truncate: 1024\n22:38:50 |     update_classifier_head_only: False\n22:38:50 |     update_freq: 1\n22:38:50 |     use_memories: False\n22:38:50 |     use_reply: none\n22:38:50 |     validation_cutoff: 1.0\n22:38:50 |     validation_every_n_epochs: -1\n22:38:50 |     validation_every_n_secs: 20.0\n22:38:50 |     validation_every_n_steps: -1\n22:38:50 |     validation_max_exs: -1\n22:38:50 |     validation_metric: accuracy\n22:38:50 |     validation_metric_mode: max\n22:38:50 |     validation_patience: 30\n22:38:50 |     validation_share_agent: False\n22:38:50 |     variant: xlm\n22:38:50 |     verbose: False\n22:38:50 |     wandb_entity: None\n22:38:50 |     wandb_log: False\n22:38:50 |     wandb_name: None\n22:38:50 |     wandb_project: None\n22:38:50 |     warmup_rate: 0.0001\n22:38:50 |     warmup_updates: 1000\n22:38:50 |     weight_decay: None\n22:38:50 |     world_logs: \n22:38:50 |     wrap_memory_encoder: False\n22:38:50 | creating task(s): fromfile:parlaiformat\n22:38:50 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run3/data_train.txt\n22:38:50 | training...\n22:39:01 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .4975 4.975e-10               .4962                 .5410   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .4583            .4988              .4608   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .5435 11.45     1 268.9 537.2       0          0 39.94  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .4975             32768  2.639    .1206  6.08 .6942 1.005e-06 121.6 242.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   20 390.6  780 2.002        .4974\n\n22:39:10 | time:20s total_exs:1180 total_steps:59 epochs:5.90\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .6090 6.09e-10               .6321                 .6051   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6616            .5828              .6138   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .5547 11.61     1 272.2  1079       0          0 79.27  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6090             32768  2.455    .1207 6.015 .6743 2.955e-06 120.3 476.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   59 392.5 1556 3.973        .6078\n\n22:39:10 | creating task(s): fromfile:parlaiformat\n22:39:10 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run3/data_valid.txt\n22:39:10 | running eval: valid\n22:39:11 | eval completed in 0.20s\n22:39:11 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8462                 .7857   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8182              .9000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.71 164.5  1823       0          0 132.9   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6441 2.955e-06    72 797.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     59 236.5 2620        .8322\n\u001b[0m\n22:39:11 | \u001b[1;32mnew best accuracy: 0.8333\u001b[0m\n22:39:11 | saving best valid model: /tmp/model3\n22:39:11 | Saving dictionary to /tmp/model3.dict\n22:39:14 | saving model checkpoint: /tmp/model3.checkpoint\n22:39:14 | Saving dictionary to /tmp/model3.checkpoint.dict\n22:39:31 | time:40s total_exs:1880 total_steps:94 epochs:9.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7943 7.943e-10               .8022                 .7892   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8156            .7857              .8000   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7719 11.67     1 273.4 955.3       0          0 69.89  700   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7943             32768  2.902    .1207 6.023 .6300 4.705e-06 120.5 420.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   94 393.8 1376 3.502        .7941\n\n22:39:34 | time:44s total_exs:2160 total_steps:108 epochs:10.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9071 9.071e-10               .9044                 .8978   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9111            .9097              .9161   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9034 11.24     1 264.8  1071       0          0 80.88  280   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9071             32768  3.107    .1207 5.964 .5746 5.404e-06 119.3 482.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  108 384.1 1553 4.07        .9072\n\n22:39:34 | running eval: valid\n22:39:34 | eval completed in 0.18s\n22:39:34 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 11.71 164.5  1986       0          0 144.8   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5285 5.404e-06    72 868.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    108 236.5 2855            1\n\u001b[0m\n22:39:34 | \u001b[1;32mnew best accuracy: 1 (previous best was 0.8333)\u001b[0m\n22:39:34 | saving best valid model: /tmp/model3\n22:39:39 | task solved! stopping.\n22:39:40 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n22:39:40 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n22:39:40 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run3/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n22:39:40 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n22:39:40 | Using CUDA\n22:39:40 | loading dictionary from /tmp/model3.dict\n22:39:40 | num words = 54944\n22:39:44 | Loading existing model parameters from /tmp/model3\n22:39:46 | Total parameters: 128,042,498 (128,042,498 trainable)\n22:39:47 | creating task(s): fromfile:parlaiformat\n22:39:47 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run3/data_valid.txt\n22:39:47 | running eval: valid\n22:39:47 | eval completed in 0.20s\n22:39:47 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 11.71 164.5  1849       0          0 134.8   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294     6 .5285 5.404e-06    72 809.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    108 236.5 2659            1\n\u001b[0m\n22:39:47 | creating task(s): fromfile:parlaiformat\n22:39:47 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run3/data_test.txt\n22:39:47 | running eval: test\n22:39:52 | eval completed in 4.78s\n22:39:52 | \u001b[1mtest:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .8900 8.9e-10               .6233                 .4740   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9100            .9356              .9889   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8878 12.07 281.4  2956       0          0 210.1 1000 .8900   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294   5.2 .5509 5.404e-06   104  1092       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    108 385.4 4048        .9044\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type2/run3/data_test.txt -m transformer/classifier -mf /tmp/model3 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-03T22:39:54.265477Z","iopub.execute_input":"2022-12-03T22:39:54.265858Z","iopub.status.idle":"2022-12-03T22:40:24.392190Z","shell.execute_reply.started":"2022-12-03T22:39:54.265815Z","shell.execute_reply":"2022-12-03T22:40:24.390539Z"},"scrolled":true,"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"22:40:03 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr1type2/run3/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr1type2/run3/data)\u001b[0m\n22:40:03 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n22:40:03 | Using CUDA\n22:40:03 | loading dictionary from /tmp/model3.dict\n22:40:03 | num words = 54944\n22:40:07 | Loading existing model parameters from /tmp/model3\n22:40:13 | Total parameters: 128,042,498 (128,042,498 trainable)\n22:40:14 | Opt:\n22:40:14 |     activation: gelu\n22:40:14 |     adafactor_eps: '[1e-30, 0.001]'\n22:40:14 |     adam_eps: 1e-08\n22:40:14 |     add_p1_after_newln: False\n22:40:14 |     aggregate_micro: False\n22:40:14 |     allow_missing_init_opts: False\n22:40:14 |     area_under_curve_class: None\n22:40:14 |     area_under_curve_digits: -1\n22:40:14 |     attention_dropout: 0.1\n22:40:14 |     batchsize: 40\n22:40:14 |     betas: '[0.9, 0.999]'\n22:40:14 |     bpe_add_prefix_space: None\n22:40:14 |     bpe_debug: False\n22:40:14 |     bpe_dropout: None\n22:40:14 |     bpe_merge: None\n22:40:14 |     bpe_vocab: None\n22:40:14 |     candidates: inline\n22:40:14 |     cap_num_predictions: 100\n22:40:14 |     checkpoint_activations: False\n22:40:14 |     class_weights: None\n22:40:14 |     classes: \"['__notok__', '__ok__']\"\n22:40:14 |     classes_from_file: None\n22:40:14 |     data_parallel: True\n22:40:14 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n22:40:14 |     datatype: train\n22:40:14 |     delimiter: '\\n'\n22:40:14 |     dict_class: parlai.core.dict:DictionaryAgent\n22:40:14 |     dict_endtoken: __start__\n22:40:14 |     dict_file: /tmp/model3.dict\n22:40:14 |     dict_include_test: False\n22:40:14 |     dict_include_valid: False\n22:40:14 |     dict_initpath: None\n22:40:14 |     dict_language: english\n22:40:14 |     dict_loaded: True\n22:40:14 |     dict_lower: True\n22:40:14 |     dict_max_ngram_size: -1\n22:40:14 |     dict_maxexs: -1\n22:40:14 |     dict_maxtokens: -1\n22:40:14 |     dict_minfreq: 0\n22:40:14 |     dict_nulltoken: __null__\n22:40:14 |     dict_starttoken: __start__\n22:40:14 |     dict_textfields: text,labels\n22:40:14 |     dict_tokenizer: bpe\n22:40:14 |     dict_unktoken: __unk__\n22:40:14 |     display_examples: False\n22:40:14 |     download_path: None\n22:40:14 |     dropout: 0.1\n22:40:14 |     dynamic_batching: None\n22:40:14 |     embedding_projection: random\n22:40:14 |     embedding_size: 768\n22:40:14 |     embedding_type: random\n22:40:14 |     embeddings_scale: False\n22:40:14 |     encode_candidate_vecs: True\n22:40:14 |     encode_candidate_vecs_batchsize: 256\n22:40:14 |     eval_batchsize: None\n22:40:14 |     eval_candidates: inline\n22:40:14 |     eval_dynamic_batching: None\n22:40:14 |     evaltask: None\n22:40:14 |     ffn_size: 3072\n22:40:14 |     final_extra_opt: \n22:40:14 |     fixed_candidate_vecs: reuse\n22:40:14 |     fixed_candidates_path: None\n22:40:14 |     force_fp16_tokens: True\n22:40:14 |     fp16: True\n22:40:14 |     fp16_impl: safe\n22:40:14 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run3/data_test.txt\n22:40:14 |     fromfile_datatype_extension: True\n22:40:14 |     gpu: -1\n22:40:14 |     gradient_clip: 0.1\n22:40:14 |     hide_labels: False\n22:40:14 |     history_add_global_end_token: None\n22:40:14 |     history_reversed: False\n22:40:14 |     history_size: 20\n22:40:14 |     ignore_bad_candidates: False\n22:40:14 |     ignore_labels: None\n22:40:14 |     image_cropsize: 224\n22:40:14 |     image_mode: raw\n22:40:14 |     image_size: 256\n22:40:14 |     inference: max\n22:40:14 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n22:40:14 |     init_opt: None\n22:40:14 |     interactive_candidates: fixed\n22:40:14 |     interactive_mode: False\n22:40:14 |     invsqrt_lr_decay_gamma: -1\n22:40:14 |     is_debug: False\n22:40:14 |     label_truncate: 72\n22:40:14 |     learn_embeddings: True\n22:40:14 |     learn_positional_embeddings: True\n22:40:14 |     learningrate: 5e-05\n22:40:14 |     load_from_pretrained_ranker: True\n22:40:14 |     log_every_n_secs: 10.0\n22:40:14 |     log_every_n_steps: 50\n22:40:14 |     log_keep_fields: all\n22:40:14 |     loglevel: info\n22:40:14 |     lr_scheduler: reduceonplateau\n22:40:14 |     lr_scheduler_decay: 0.5\n22:40:14 |     lr_scheduler_patience: 3\n22:40:14 |     max_train_steps: -1\n22:40:14 |     max_train_time: 7200.0\n22:40:14 |     memory_attention: sqrt\n22:40:14 |     metrics: default\n22:40:14 |     model: transformer/classifier\n22:40:14 |     model_file: /tmp/model3\n22:40:14 |     model_parallel: False\n22:40:14 |     momentum: 0\n22:40:14 |     multitask_weights: [1]\n22:40:14 |     mutators: None\n22:40:14 |     n_decoder_layers: -1\n22:40:14 |     n_encoder_layers: -1\n22:40:14 |     n_heads: 12\n22:40:14 |     n_layers: 12\n22:40:14 |     n_positions: 1024\n22:40:14 |     n_segments: 2\n22:40:14 |     nesterov: True\n22:40:14 |     no_cuda: False\n22:40:14 |     normalize_sent_emb: False\n22:40:14 |     num_epochs: -1\n22:40:14 |     num_examples: -1\n22:40:14 |     num_workers: 0\n22:40:14 |     nus: [0.7]\n22:40:14 |     optimizer: adamax\n22:40:14 |     output_scaling: 0.06\n22:40:14 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type2/run3/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model3', 'batchsize': 40}\"\n22:40:14 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n22:40:14 |     person_tokens: False\n22:40:14 |     print_scores: False\n22:40:14 |     rank_candidates: False\n22:40:14 |     rank_top_k: -1\n22:40:14 |     reduction_type: mean\n22:40:14 |     ref_class: None\n22:40:14 |     relu_dropout: 0.0\n22:40:14 |     repeat_blocking_heuristic: True\n22:40:14 |     report_filename: \n22:40:14 |     return_cand_scores: False\n22:40:14 |     save_after_valid: True\n22:40:14 |     save_every_n_secs: -1\n22:40:14 |     save_format: conversations\n22:40:14 |     share_encoders: False\n22:40:14 |     share_word_embeddings: False\n22:40:14 |     short_final_eval: False\n22:40:14 |     special_tok_lst: None\n22:40:14 |     split_lines: False\n22:40:14 |     starttime: Dec03_22-38\n22:40:14 |     task: fromfile:parlaiformat\n22:40:14 |     tensorboard_log: False\n22:40:14 |     tensorboard_logdir: None\n22:40:14 |     text_truncate: 360\n22:40:14 |     threshold: 0.5\n22:40:14 |     topk: 5\n22:40:14 |     train_predict: False\n22:40:14 |     truncate: 1024\n22:40:14 |     update_classifier_head_only: False\n22:40:14 |     update_freq: 1\n22:40:14 |     use_memories: False\n22:40:14 |     use_reply: none\n22:40:14 |     validation_cutoff: 1.0\n22:40:14 |     validation_every_n_epochs: -1\n22:40:14 |     validation_every_n_secs: 20.0\n22:40:14 |     validation_every_n_steps: -1\n22:40:14 |     validation_max_exs: -1\n22:40:14 |     validation_metric: accuracy\n22:40:14 |     validation_metric_mode: max\n22:40:14 |     validation_patience: 30\n22:40:14 |     validation_share_agent: False\n22:40:14 |     variant: xlm\n22:40:14 |     verbose: False\n22:40:14 |     wandb_entity: None\n22:40:14 |     wandb_log: False\n22:40:14 |     wandb_name: None\n22:40:14 |     wandb_project: None\n22:40:14 |     warmup_rate: 0.0001\n22:40:14 |     warmup_updates: 1000\n22:40:14 |     weight_decay: None\n22:40:14 |     world_logs: \n22:40:14 |     wrap_memory_encoder: False\n22:40:14 | Evaluating task fromfile:parlaiformat using datatype valid.\n22:40:14 | creating task(s): fromfile:parlaiformat\n22:40:14 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n22:40:14 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run3/data_test.txt\n22:40:22 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .8900 8.9e-10               .6233                 .4740   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9100            .9356              .9889   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8878 12.07 562.9  1904       0          0 135.3 1000 .8900   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5509 5.404e-06   208 703.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    108 770.9 2608        .9044\u001b[0m\n22:40:22 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .8900 8.9e-10               .6233                 .4740   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9100            .9356              .9889   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8878 12.07 562.9  1904       0          0 135.3 1000 .8900   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5509 5.404e-06   208 703.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    108 770.9 2608        .9044\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model3*","metadata":{"execution":{"iopub.status.busy":"2022-12-03T22:40:24.397572Z","iopub.execute_input":"2022-12-03T22:40:24.398260Z","iopub.status.idle":"2022-12-03T22:40:25.730277Z","shell.execute_reply.started":"2022-12-03T22:40:24.398217Z","shell.execute_reply":"2022-12-03T22:40:25.728994Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"run 4","metadata":{}},{"cell_type":"code","source":"# run 4 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type2/run4/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model4","metadata":{"execution":{"iopub.status.busy":"2022-12-03T22:40:25.732327Z","iopub.execute_input":"2022-12-03T22:40:25.732755Z","iopub.status.idle":"2022-12-03T22:52:49.178285Z","shell.execute_reply.started":"2022-12-03T22:40:25.732708Z","shell.execute_reply":"2022-12-03T22:52:49.177041Z"},"scrolled":true,"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"22:40:32 | building dictionary first...\n22:40:32 | No model with opt yet at: /tmp/model4(.opt)\n22:40:32 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run4/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n22:40:32 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n22:40:32 | Using CUDA\n22:40:32 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n22:40:32 | num words = 54944\n22:40:37 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n22:40:47 | Total parameters: 128,042,498 (128,042,498 trainable)\n22:40:47 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n22:40:47 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n22:40:47 | Opt:\n22:40:47 |     activation: gelu\n22:40:47 |     adafactor_eps: '(1e-30, 0.001)'\n22:40:47 |     adam_eps: 1e-08\n22:40:47 |     add_p1_after_newln: False\n22:40:47 |     aggregate_micro: False\n22:40:47 |     allow_missing_init_opts: False\n22:40:47 |     attention_dropout: 0.1\n22:40:47 |     batchsize: 20\n22:40:47 |     betas: '(0.9, 0.999)'\n22:40:47 |     bpe_add_prefix_space: None\n22:40:47 |     bpe_debug: False\n22:40:47 |     bpe_dropout: None\n22:40:47 |     bpe_merge: None\n22:40:47 |     bpe_vocab: None\n22:40:47 |     candidates: inline\n22:40:47 |     cap_num_predictions: 100\n22:40:47 |     checkpoint_activations: False\n22:40:47 |     class_weights: None\n22:40:47 |     classes: \"['__notok__', '__ok__']\"\n22:40:47 |     classes_from_file: None\n22:40:47 |     data_parallel: True\n22:40:47 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n22:40:47 |     datatype: train\n22:40:47 |     delimiter: '\\n'\n22:40:47 |     dict_class: parlai.core.dict:DictionaryAgent\n22:40:47 |     dict_endtoken: __start__\n22:40:47 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n22:40:47 |     dict_include_test: False\n22:40:47 |     dict_include_valid: False\n22:40:47 |     dict_initpath: None\n22:40:47 |     dict_language: english\n22:40:47 |     dict_loaded: True\n22:40:47 |     dict_lower: True\n22:40:47 |     dict_max_ngram_size: -1\n22:40:47 |     dict_maxexs: -1\n22:40:47 |     dict_maxtokens: -1\n22:40:47 |     dict_minfreq: 0\n22:40:47 |     dict_nulltoken: __null__\n22:40:47 |     dict_starttoken: __start__\n22:40:47 |     dict_textfields: text,labels\n22:40:47 |     dict_tokenizer: bpe\n22:40:47 |     dict_unktoken: __unk__\n22:40:47 |     display_examples: False\n22:40:47 |     download_path: None\n22:40:47 |     dropout: 0.1\n22:40:47 |     dynamic_batching: None\n22:40:47 |     embedding_projection: random\n22:40:47 |     embedding_size: 768\n22:40:47 |     embedding_type: random\n22:40:47 |     embeddings_scale: False\n22:40:47 |     encode_candidate_vecs: True\n22:40:47 |     encode_candidate_vecs_batchsize: 256\n22:40:47 |     eval_batchsize: None\n22:40:47 |     eval_candidates: inline\n22:40:47 |     eval_dynamic_batching: None\n22:40:47 |     evaltask: None\n22:40:47 |     ffn_size: 3072\n22:40:47 |     final_extra_opt: \n22:40:47 |     fixed_candidate_vecs: reuse\n22:40:47 |     fixed_candidates_path: None\n22:40:47 |     force_fp16_tokens: False\n22:40:47 |     fp16: True\n22:40:47 |     fp16_impl: safe\n22:40:47 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run4/data\n22:40:47 |     fromfile_datatype_extension: True\n22:40:47 |     gpu: -1\n22:40:47 |     gradient_clip: 0.1\n22:40:47 |     hide_labels: False\n22:40:47 |     history_add_global_end_token: None\n22:40:47 |     history_reversed: False\n22:40:47 |     history_size: 20\n22:40:47 |     ignore_bad_candidates: False\n22:40:47 |     ignore_labels: None\n22:40:47 |     image_cropsize: 224\n22:40:47 |     image_mode: raw\n22:40:47 |     image_size: 256\n22:40:47 |     inference: max\n22:40:47 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n22:40:47 |     init_opt: None\n22:40:47 |     interactive_candidates: fixed\n22:40:47 |     interactive_mode: False\n22:40:47 |     invsqrt_lr_decay_gamma: -1\n22:40:47 |     is_debug: False\n22:40:47 |     label_truncate: 72\n22:40:47 |     learn_embeddings: True\n22:40:47 |     learn_positional_embeddings: True\n22:40:47 |     learningrate: 5e-05\n22:40:47 |     load_from_checkpoint: False\n22:40:47 |     load_from_pretrained_ranker: True\n22:40:47 |     log_every_n_secs: 10.0\n22:40:47 |     log_every_n_steps: 50\n22:40:47 |     log_keep_fields: all\n22:40:47 |     loglevel: info\n22:40:47 |     lr_scheduler: reduceonplateau\n22:40:47 |     lr_scheduler_decay: 0.5\n22:40:47 |     lr_scheduler_patience: 3\n22:40:47 |     max_train_steps: -1\n22:40:47 |     max_train_time: 7200.0\n22:40:47 |     memory_attention: sqrt\n22:40:47 |     metrics: default\n22:40:47 |     model: transformer/classifier\n22:40:47 |     model_file: /tmp/model4\n22:40:47 |     model_parallel: False\n22:40:47 |     momentum: 0\n22:40:47 |     multitask_weights: [1]\n22:40:47 |     mutators: None\n22:40:47 |     n_decoder_layers: -1\n22:40:47 |     n_encoder_layers: -1\n22:40:47 |     n_heads: 12\n22:40:47 |     n_layers: 12\n22:40:47 |     n_positions: 1024\n22:40:47 |     n_segments: 2\n22:40:47 |     nesterov: True\n22:40:47 |     no_cuda: False\n22:40:47 |     normalize_sent_emb: False\n22:40:47 |     num_epochs: -1\n22:40:47 |     num_workers: 0\n22:40:47 |     nus: (0.7,)\n22:40:47 |     optimizer: adamax\n22:40:47 |     output_scaling: 0.06\n22:40:47 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type2/run4/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model4'}\"\n22:40:47 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n22:40:47 |     person_tokens: False\n22:40:47 |     print_scores: False\n22:40:47 |     rank_candidates: False\n22:40:47 |     rank_top_k: -1\n22:40:47 |     reduction_type: mean\n22:40:47 |     ref_class: None\n22:40:47 |     relu_dropout: 0.0\n22:40:47 |     repeat_blocking_heuristic: True\n22:40:47 |     return_cand_scores: False\n22:40:47 |     save_after_valid: True\n22:40:47 |     save_every_n_secs: -1\n22:40:47 |     save_format: conversations\n22:40:47 |     share_encoders: False\n22:40:47 |     share_word_embeddings: False\n22:40:47 |     short_final_eval: False\n22:40:47 |     special_tok_lst: None\n22:40:47 |     split_lines: False\n22:40:47 |     starttime: Dec03_22-40\n22:40:47 |     task: fromfile:parlaiformat\n22:40:47 |     tensorboard_log: False\n22:40:47 |     tensorboard_logdir: None\n22:40:47 |     text_truncate: 360\n22:40:47 |     threshold: 0.5\n22:40:47 |     topk: 5\n22:40:47 |     train_predict: False\n22:40:47 |     truncate: 1024\n22:40:47 |     update_classifier_head_only: False\n22:40:47 |     update_freq: 1\n22:40:47 |     use_memories: False\n22:40:47 |     use_reply: none\n22:40:47 |     validation_cutoff: 1.0\n22:40:47 |     validation_every_n_epochs: -1\n22:40:47 |     validation_every_n_secs: 20.0\n22:40:47 |     validation_every_n_steps: -1\n22:40:47 |     validation_max_exs: -1\n22:40:47 |     validation_metric: accuracy\n22:40:47 |     validation_metric_mode: max\n22:40:47 |     validation_patience: 30\n22:40:47 |     validation_share_agent: False\n22:40:47 |     variant: xlm\n22:40:47 |     verbose: False\n22:40:47 |     wandb_entity: None\n22:40:47 |     wandb_log: False\n22:40:47 |     wandb_name: None\n22:40:47 |     wandb_project: None\n22:40:47 |     warmup_rate: 0.0001\n22:40:47 |     warmup_updates: 1000\n22:40:47 |     weight_decay: None\n22:40:47 |     world_logs: \n22:40:47 |     wrap_memory_encoder: False\n22:40:48 | creating task(s): fromfile:parlaiformat\n22:40:48 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run4/data_train.txt\n22:40:48 | training...\n22:40:58 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .4775 4.775e-10               .3280                 .3984   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .2787            .5726              .5147   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6452 11.52     1 270.4 541.1       0          0 40.01  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .4775             32768   2.61    .1245 5.915 .6992 1.005e-06 118.3 236.7   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 388.8 777.8 2.005        .4607\n\n22:41:08 | time:20s total_exs:1160 total_steps:58 epochs:5.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6105 6.105e-10               .5346                 .6719   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .4439            .6652              .5799   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7798 11.21     1 264.1  1002       0          0 75.86  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6105             32768   2.54    .1245 6.008 .6821 2.905e-06 120.2 455.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   58 384.3 1457 3.802        .5994\n\n22:41:08 | creating task(s): fromfile:parlaiformat\n22:41:08 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run4/data_valid.txt\n22:41:08 | running eval: valid\n22:41:08 | eval completed in 0.22s\n22:41:08 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .6957                 .7273   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .7200              .6923   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 12.04 168.5  1692       0          0 120.4   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6677 2.905e-06    72 722.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     58 240.5 2415        .7078\n\u001b[0m\n22:41:08 | \u001b[1;32mnew best accuracy: 0.7083\u001b[0m\n22:41:08 | saving best valid model: /tmp/model4\n22:41:08 | Saving dictionary to /tmp/model4.dict\n22:41:12 | saving model checkpoint: /tmp/model4.checkpoint\n22:41:12 | Saving dictionary to /tmp/model4.checkpoint.dict\n22:41:30 | time:42s total_exs:1880 total_steps:94 epochs:9.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7417 7.417e-10               .7513                 .7150   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7915            .7312              .7737   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6932 11.34     1 266.9 946.5       0          0 70.94  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7417             32768  2.474    .1245 5.986 .6488 4.705e-06 119.7 424.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   94 386.6 1371 3.555        .7411\n\n22:41:32 | time:44s total_exs:2040 total_steps:102 epochs:10.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .8500 8.5e-10               .8356                 .8971   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7821            .8621              .8152   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9146 11.14     1 262.8 955.4       0          0 72.72  160   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8500             32768  2.472    .1245 5.975 .6104 5.104e-06 119.5 434.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  102 382.2 1390 3.674        .8492\n\n22:41:32 | running eval: valid\n22:41:32 | eval completed in 0.20s\n22:41:32 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.04 168.5  1884       0          0 134.1   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6012 5.104e-06    72 805.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    102 240.5 2690        .8322\n\u001b[0m\n22:41:32 | \u001b[1;32mnew best accuracy: 0.8333 (previous best was 0.7083)\u001b[0m\n22:41:32 | saving best valid model: /tmp/model4\n22:41:42 | saving model checkpoint: /tmp/model4.checkpoint\n22:41:57 | time:69s total_exs:2800 total_steps:140 epochs:14.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8829 8.829e-10               .8866                 .9086   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8657            .8789              .8568   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9022 11.57     1 271.4  1025       0          0  75.5  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8829             32768  2.943    .1245 6.058 .5370 7.004e-06 121.2 457.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  140 392.6 1482 3.784        .8830\n\n22:42:02 | time:74s total_exs:3200 total_steps:160 epochs:16.00\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8950 8.95e-10               .8901                 .8854   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8947            .8995              .9038   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8952 10.89     1 257.8 991.9       0          0 76.96  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8950             32768  3.958    .1207  5.95 .4207 8.004e-06   119 457.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  160 376.8 1450 3.865        .8950\n\n22:42:02 | running eval: valid\n22:42:02 | eval completed in 0.20s\n22:42:02 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.04 168.5  1881       0          0 133.9   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .3463 8.004e-06    72 803.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    160 240.5 2685        .9583\n\u001b[0m\n22:42:02 | \u001b[1;32mnew best accuracy: 0.9583 (previous best was 0.8333)\u001b[0m\n22:42:02 | saving best valid model: /tmp/model4\n22:42:12 | saving model checkpoint: /tmp/model4.checkpoint\n22:42:27 | time:99s total_exs:3960 total_steps:198 epochs:19.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9053 9.053e-10               .9027                 .9151   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8907            .9077              .8962   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9195  11.6     1   272  1030       0          0 75.73  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9053             32768  5.479    .1245 5.987 .3089 9.904e-06 119.7 453.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  198 391.7 1483 3.795        .9052\n\n22:42:32 | time:104s total_exs:4340 total_steps:217 epochs:21.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9026 9.026e-10               .9091                 .9024   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9158            .8952              .9029   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8876 11.48     1 269.5  1044       0          0  77.5  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9026             32768  6.119    .1245 6.063 .2619 1.085e-05 121.3 469.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  217 390.8 1514 3.893        .9026\n\n22:42:32 | running eval: valid\n22:42:32 | eval completed in 0.20s\n22:42:32 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9231                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9091                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 12.04 168.5  1879       0          0 133.8   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .2306 1.085e-05    72 802.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    217 240.5 2682        .9161\n\u001b[0m\n22:42:32 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 1\u001b[0m\n22:42:32 | saving model checkpoint: /tmp/model4.checkpoint\n22:42:52 | time:124s total_exs:5100 total_steps:255 epochs:25.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9500 9.5e-10               .9488                 .9215   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9778            .9512              .9788   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9250 11.62     1 272.5  1034       0          0 75.92  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9500             32768   6.13    .1245 5.947 .1487 1.275e-05 118.9 451.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  255 391.4 1486 3.805        .9500\n\n22:42:52 | time:124s total_exs:5120 total_steps:256 epochs:25.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9500 9.5e-10               .9600                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9231            .9333              .8750   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.25     1   265  1057       0          0 79.73   20   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9500             32768  5.081    .1190   6.3 .1704 1.28e-05   126 502.4   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  256  391 1559 4.385        .9507\n\n22:42:52 | running eval: valid\n22:42:53 | eval completed in 0.20s\n22:42:53 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.04 168.5  1849       0          0 131.7   24 .9583   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .1780 1.28e-05    72 790.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    256 240.5 2640        .9583\n\u001b[0m\n22:42:53 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 2\u001b[0m\n22:42:53 | saving model checkpoint: /tmp/model4.checkpoint\n22:43:07 | time:139s total_exs:5880 total_steps:294 epochs:29.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9618 9.618e-10               .9648                 .9778   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9520            .9584              .9435   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9738 11.28     1 265.7  1000       0          0 75.28  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9618             32768  10.12    .1245 6.097 .1117 1.47e-05 121.9   459   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  294 387.6 1459 3.773        .9619\n\n22:43:13 | time:145s total_exs:6300 total_steps:315 epochs:31.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9881 9.881e-10               .9877                 .9805   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9950            .9885              .9953   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9817 11.33     1 266.6 978.6       0          0  73.4  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9881             32768  2.352    .1245 5.962 .05275 1.575e-05 119.2 437.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  315 385.9 1416 3.685        .9881\n\n22:43:13 | running eval: valid\n22:43:13 | eval completed in 0.21s\n22:43:13 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.04 168.5  1749       0          0 124.5   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 .0913 1.575e-05    72 747.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    315 240.5 2497        .9583\n\u001b[0m\n22:43:13 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 3\u001b[0m\n22:43:13 | saving model checkpoint: /tmp/model4.checkpoint\n22:43:27 | time:160s total_exs:7060 total_steps:353 epochs:35.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9868 9.868e-10               .9879                 .9855   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9903            .9856              .9885   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9828  11.5 .5000 270.1  1021       0          0 75.62  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9868             32768  6.448    .1246 6.082 .0476 1.765e-05 121.6 459.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  353 391.7 1481 3.79        .9868\n\n22:43:33 | time:165s total_exs:7500 total_steps:375 epochs:37.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9841 9.841e-10               .9841                 .9819   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9864            .9841              .9863   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9818 11.62 .4545 272.4  1033       0          0 75.89  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9841             32768  9.747    .1246     6 .0527 1.875e-05   120 455.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  375 392.4 1489 3.809        .9841\n\n22:43:33 | running eval: valid\n22:43:33 | eval completed in 0.20s\n22:43:33 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9231                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9091                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 12.04 168.5  1870       0          0 133.1   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08095     6 .2528 1.875e-05    72 798.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    375 240.5 2668        .9161\n\u001b[0m\n22:43:33 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 4\u001b[0m\n22:43:33 | saving model checkpoint: /tmp/model4.checkpoint\n22:43:48 | time:180s total_exs:8240 total_steps:412 epochs:41.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9838 9.838e-10               .9847                 .9872   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9822            .9828              .9799   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9856 11.34 .4324 266.9 979.1       0          0 73.37  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9838             32768  13.78    .1246 6.062 .05956 2.06e-05 121.2 444.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  412 388.1 1424 3.677        .9838\n\n22:43:54 | time:186s total_exs:8680 total_steps:434 epochs:43.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9795 9.795e-10               .9789                 .9676   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9905            .9801              .9911   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9694  11.6 .3636 272.1  1026       0          0 75.41  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9795             32768  5.149    .1246 5.959 .06507 2.17e-05 119.2 449.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  434 391.3 1475 3.785        .9796\n\n22:43:54 | running eval: valid\n22:43:54 | eval completed in 0.20s\n22:43:54 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 12.04 168.5  1816       0          0 129.3   24 .9583   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 .1651 2.17e-05    72 775.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    434 240.5 2592        .9583\n\u001b[0m\n22:43:54 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 5\u001b[0m\n22:43:54 | saving model checkpoint: /tmp/model4.checkpoint\n22:44:08 | time:200s total_exs:9440 total_steps:472 epochs:47.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9987                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9974            .9986              .9973   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.54 .1579 270.8  1026       0          0 75.79  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9987             32768  .2253    .1246 6.029 .0109 2.36e-05 120.6 456.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  472 391.3 1483 3.798        .9987\n\n22:44:14 | time:206s total_exs:9880 total_steps:494 epochs:49.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9932 9.932e-10               .9926                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9854            .9937              .9874   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.36 .1818 267.1  1005       0          0 75.23  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9932             32768  1.213    .1207 5.932 .04303 2.47e-05 118.6 446.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  494 385.8 1451 3.774        .9932\n\n22:44:14 | running eval: valid\n22:44:14 | eval completed in 0.24s\n22:44:14 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.04 168.5  1601       0          0   114   24 .9583   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 .1018 2.47e-05    72   684       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    494 240.5 2285        .9583\n\u001b[0m\n22:44:14 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 6\u001b[0m\n22:44:14 | saving model checkpoint: /tmp/model4.checkpoint\n22:44:29 | time:221s total_exs:10640 total_steps:532 epochs:53.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9842 9.842e-10               .9834                 .9889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9780            .9850              .9800   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9899 11.81 .3684 276.1  1046       0          0 75.77  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9842             32768  3.052    .1246 5.955 .05461 2.66e-05 119.1 451.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  532 395.2 1497 3.797        .9842\n\n22:44:34 | time:227s total_exs:11060 total_steps:553 epochs:55.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9976 9.976e-10               .9977                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9953            .9976              .9951   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.52 .1905 270.4  1042       0          0 77.11  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9976             32768  2.665    .1246 6.024 .01609 2.765e-05 120.5 464.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  553 390.9 1507 3.871        .9976\n\n22:44:34 | running eval: valid\n22:44:35 | eval completed in 0.21s\n22:44:35 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8571                 .7500   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .8000                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .6667 12.04 168.5  1786       0          0 127.1   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 .9525 2.765e-05    72   763       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    553 240.5 2549        .8286\n\u001b[0m\n22:44:35 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 7\u001b[0m\n22:44:35 | saving model checkpoint: /tmp/model4.checkpoint\n22:44:49 | time:241s total_exs:11820 total_steps:591 epochs:59.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9895 9.895e-10               .9899                 .9924   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9874            .9890              .9863   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9917 11.58 .3158 271.6  1010       0          0 74.37  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9895             32768  1.448    .1246 6.047 .05663 2.955e-05 120.9 449.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  591 392.6 1460 3.727        .9895\n\n22:44:55 | time:247s total_exs:12240 total_steps:612 epochs:61.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9762 9.762e-10               .9756                 .9804   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9709            .9767              .9722   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9813 11.66 .4762 273.1  1063       0          0  77.8  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9762             32768  11.31    .1208 5.981 .07526 3.06e-05 119.6 465.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  612 392.8 1528 3.907        .9762\n\n22:44:55 | running eval: valid\n22:44:55 | eval completed in 0.20s\n22:44:55 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.04 168.5  1890       0          0 134.5   24 .9583   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 .1925 3.06e-05    72 807.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    612 240.5 2698        .9583\n\u001b[0m\n22:44:55 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 8\u001b[0m\n22:44:55 | saving model checkpoint: /tmp/model4.checkpoint\n22:45:10 | time:262s total_exs:13020 total_steps:651 epochs:65.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9897 9.897e-10               .9898                 .9974   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9824            .9896              .9820   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9974  11.4 .3333   268  1030       0          0  76.9  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9897             32768  3.215    .1246 6.018 .04464 3.255e-05 120.4 462.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  651 388.3 1493 3.853        .9897\n\n22:45:15 | time:267s total_exs:13440 total_steps:672 epochs:67.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9905 9.905e-10               .9896                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9794            .9912              .9826   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.49 .3333 269.8  1023       0          0 75.84  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9905             32768  3.933    .1246 5.924 .02555 3.36e-05 118.5 449.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  672 388.2 1472 3.807        .9905\n\n22:45:15 | running eval: valid\n22:45:15 | eval completed in 0.19s\n22:45:15 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.04 168.5  1899       0          0 135.2   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 .3909 3.36e-05    72 811.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    672 240.5 2710        .9167\n\u001b[0m\n22:45:15 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 9\u001b[0m\n22:45:15 | saving model checkpoint: /tmp/model4.checkpoint\n22:45:30 | time:282s total_exs:14200 total_steps:710 epochs:71.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9934 9.934e-10               .9936                 .9923   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9949            .9933              .9946   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9919 11.58 .2368 271.5  1027       0          0 75.67  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9934             32768  .4280    .1246 6.024 .03231 3.55e-05 120.5 455.8   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  710  392 1483 3.792        .9934\n\n22:45:35 | time:288s total_exs:14620 total_steps:731 epochs:73.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9905 9.905e-10               .9907                 .9953   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9862            .9902              .9854   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9951  11.3 .1905   266  1004       0          0 75.51  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9905             32768  .2969    .1246 6.033 .03301 3.655e-05 120.7 455.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  731 386.6 1460 3.791        .9905\n\n22:45:35 | running eval: valid\n22:45:36 | eval completed in 0.20s\n22:45:36 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9231                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9091                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 12.04 168.5  1844       0          0 131.2   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 .5836 3.655e-05    72 787.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    731 240.5 2632        .9161\n\u001b[0m\n22:45:36 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 10\u001b[0m\n22:45:36 | saving model checkpoint: /tmp/model4.checkpoint\n22:45:50 | time:302s total_exs:15380 total_steps:769 epochs:76.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9895 9.895e-10               .9893                 .9893   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9893            .9897              .9897   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9897 11.17 .2368 263.5 983.1       0          0 74.63  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9895             32768  .9855    .1246 5.982 .0364 3.845e-05 119.6 446.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  769 383.1 1430 3.74        .9895\n\n22:45:56 | time:308s total_exs:15800 total_steps:790 epochs:79.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9905 9.905e-10               .9916                 .9958   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9874            .9890              .9836   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9945 11.39 .3333 267.8  1012       0          0 75.59  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9905             32768  .8596    .1208 6.138 .01806 3.95e-05 122.8   464   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  790 390.6 1476 3.795        .9905\n\n22:45:56 | running eval: valid\n22:45:56 | eval completed in 0.20s\n22:45:56 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.04 168.5  1854       0          0   132   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 .2814 3.95e-05    72 791.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    790 240.5 2646        .9167\n\u001b[0m\n22:45:56 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 11\u001b[0m\n22:45:56 | saving model checkpoint: /tmp/model4.checkpoint\n22:46:10 | time:322s total_exs:16580 total_steps:829 epochs:82.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9936 9.936e-10               .9934                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9869            .9938              .9876   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.46 .3077 269.2  1027       0          0  76.3  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9936             32768  .4240    .1247 5.979 .0286 4.145e-05 119.6 456.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  829 388.8 1483 3.824        .9936\n\n22:46:16 | time:328s total_exs:17020 total_steps:851 epochs:85.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9841 9.841e-10               .9832                 .9951   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9716            .9849              .9744   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9956 12.07 .4091 281.4  1071       0          0 76.12  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9841             32768  2.106    .1247 5.959 .06189 4.255e-05 119.2 453.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  851 400.6 1525 3.822        .9841\n\n22:46:16 | running eval: valid\n22:46:16 | eval completed in 0.24s\n22:46:16 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 12.04 168.5  1637       0          0 116.6   24 .9583   \n    gpu_mem  llen   loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 .09379 4.255e-05    72 699.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    851 240.5 2337        .9583\n\u001b[0m\n22:46:16 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 12\u001b[0m\n22:46:16 | saving model checkpoint: /tmp/model4.checkpoint\n22:46:31 | time:343s total_exs:17780 total_steps:889 epochs:88.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9868 9.868e-10               .9868                 .9894   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9842            .9869              .9843   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9895 11.53 .3421 270.7  1012       0          0 74.77  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9868             32768  3.448    .1247 5.997 .0422 4.445e-05 119.9 448.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  889 390.6 1460 3.747        .9868\n\n22:46:36 | time:349s total_exs:18200 total_steps:910 epochs:91.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9881 9.881e-10               .9878                 .9854   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9902            .9884              .9907   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9861 11.42 .4286 268.3  1046       0          0 77.94  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9881             32768  2.723    .1191 5.971 .03807 4.55e-05 119.4 465.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  910 387.8 1511 3.913        .9881\n\n22:46:36 | running eval: valid\n22:46:37 | eval completed in 0.20s\n22:46:37 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8571                 .7500   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .8000                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .6667 12.04 168.5  1870       0          0 133.1   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 1.082 4.55e-05    72 798.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    910 240.5 2669        .8286\n\u001b[0m\n22:46:37 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 13\u001b[0m\n22:46:37 | saving model checkpoint: /tmp/model4.checkpoint\n22:46:51 | time:363s total_exs:18960 total_steps:948 epochs:94.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9947 9.947e-10               .9947                 .9921   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9973            .9948              .9974   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9922 11.28 .2368 265.6  1010       0          0 76.06  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9947             32768  .2007    .1247 5.989 .01316 4.74e-05 119.8 455.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  948 385.4 1466 3.812        .9947\n\n22:46:57 | time:369s total_exs:19380 total_steps:969 epochs:96.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9881 9.881e-10               .9887                 .9909   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9864            .9875              .9850   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9899 11.31 .2857 266.1  1001       0          0 75.19  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9881             32768  .1985    .1208 6.052 .02656 4.845e-05   121 455.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  969 387.2 1456 3.775        .9881\n\n22:46:57 | running eval: valid\n22:46:57 | eval completed in 0.20s\n22:46:57 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9231                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9091                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 12.04 168.5  1907       0          0 135.8   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6 .1108 4.845e-05    72 814.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    969 240.5 2722        .9161\n\u001b[0m\n22:46:57 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 14\u001b[0m\n22:46:57 | saving model checkpoint: /tmp/model4.checkpoint\n22:47:12 | time:384s total_exs:20160 total_steps:1008 epochs:100.80\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9910 9.91e-10               .9914                 .9926   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9902            .9906              .9892   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9919 11.27 .3077 265.4  1010       0          0  76.1  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9910             32768  .1702    .1247 6.049 .01705 4.995e-05   121 460.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1008 386.3 1470 3.814        .9910\n\n22:47:17 | time:389s total_exs:20580 total_steps:1029 epochs:102.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9976 9.976e-10               .9976                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9952            .9976              .9953   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.22 .1429 264.5  1023       0          0 77.39  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9976             32768 .06608    .1247 5.995 .005388 4.995e-05 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.9       0          0                 1029 384.4 1487 3.885        .9976\n\n22:47:17 | running eval: valid\n22:47:17 | eval completed in 0.20s\n22:47:17 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9231                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9091                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 12.04 168.5  1900       0          0 135.3   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 .2499 4.995e-05    72   812       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1029 240.5 2712        .9161\n\u001b[0m\n22:47:17 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 15\u001b[0m\n22:47:17 | saving model checkpoint: /tmp/model4.checkpoint\n22:47:32 | time:404s total_exs:21340 total_steps:1067 epochs:106.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9908 9.908e-10               .9905                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9811            .9911              .9824   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.73 .2368 274.5  1019       0          0 74.23  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9908             32768  .2031    .1247 5.974 .01715 4.995e-05 119.5 443.4   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps  ups  weighted_f1  \n         0          0                 1067  394 1462 3.72        .9908\n\n22:47:37 | time:409s total_exs:21760 total_steps:1088 epochs:108.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9929 9.929e-10               .9934                 .9956   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9912            .9922              .9897   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9948 11.72 .2857 274.4  1039       0          0 75.73  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9929             32768  .7020    .1247 6.081 .01771 4.995e-05 121.6 460.5   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1088  396 1499 3.802        .9929\n\n22:47:37 | running eval: valid\n22:47:37 | eval completed in 0.20s\n22:47:37 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9231                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9091                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 12.04 168.5  1875       0          0 133.5   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 .4808 4.995e-05    72 801.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1088 240.5 2676        .9161\n\u001b[0m\n22:47:37 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 16\u001b[0m\n22:47:37 | saving model checkpoint: /tmp/model4.checkpoint\n22:47:52 | time:424s total_exs:22540 total_steps:1127 epochs:112.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9949 9.949e-10               .9949                 .9924   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9974            .9948              .9974   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9923 11.63 .2308 272.6  1039       0          0 76.23  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9949             32768  .2455    .1247 6.003 .01101 4.995e-05 120.1 457.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1127 392.6 1497 3.82        .9949\n\n22:47:58 | time:430s total_exs:22960 total_steps:1148 epochs:114.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9881 9.881e-10               .9881                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9764            .9881              .9765   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.27 .3333 265.5 971.9       0          0 73.22  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9881             32768  .2196    .1247  6.01 .04057 4.995e-05 120.2   440   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1148 385.7 1412 3.676        .9881\n\n22:47:58 | running eval: valid\n22:47:58 | eval completed in 0.20s\n22:47:58 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 12.04 168.5  1861       0          0 132.5   24 .9583   \n    gpu_mem  llen   loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6 .09356 4.995e-05    72 795.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1148 240.5 2656        .9583\n\u001b[0m\n22:47:58 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 17\u001b[0m\n22:47:58 | saving model checkpoint: /tmp/model4.checkpoint\n22:48:12 | time:444s total_exs:23720 total_steps:1186 epochs:118.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9934 9.934e-10               .9936                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9873            .9932              .9866   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.85 .1316   277  1047       0          0 75.62  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9934             32768  .1218    .1247 6.034 .01838 4.995e-05 120.7 456.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1186 397.7 1504 3.79        .9934\n\n22:48:18 | time:450s total_exs:24160 total_steps:1208 epochs:120.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9818 9.818e-10               .9809                 .9903   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9716            .9827              .9742   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9913 11.57 .5000 271.5  1020       0          0 75.12  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9818             32768  .3204    .1247 5.959 .03531 4.995e-05 119.2 447.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1208 390.6 1467 3.77        .9818\n\n22:48:18 | running eval: valid\n22:48:18 | eval completed in 0.20s\n22:48:18 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8889                 .8000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .8571                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 12.04 168.5  1854       0          0   132   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 .9807 4.995e-05    72 792.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1208 240.5 2647        .8730\n\u001b[0m\n22:48:18 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 18\u001b[0m\n22:48:18 | saving model checkpoint: /tmp/model4.checkpoint\n22:48:33 | time:465s total_exs:24900 total_steps:1245 epochs:124.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9851 9.851e-10               .9843                 .9829   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9857            .9859              .9871   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9846 11.81 .4324 276.2  1009       0          0 73.05  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9851             32768  5.152    .1247 5.946 .06808 4.995e-05 118.9 434.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1245 395.1 1443 3.661        .9851\n\n22:48:39 | time:471s total_exs:25300 total_steps:1265 epochs:126.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9875 9.875e-10               .9884                 .9907   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9861            .9864              .9838   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9891 11.12 .3500 262.3  1015       0          0 77.38  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9875             32768  .2032    .1247  6.08 .02444 4.995e-05 121.6 470.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1265 383.9 1485 3.886        .9875\n\n22:48:39 | running eval: valid\n22:48:39 | eval completed in 0.22s\n22:48:39 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9231                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9091                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 12.04 168.5  1783       0          0   127   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 .6487 4.995e-05    72 761.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1265 240.5 2544        .9161\n\u001b[0m\n22:48:39 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 19\u001b[0m\n22:48:39 | saving model checkpoint: /tmp/model4.checkpoint\n22:48:53 | time:486s total_exs:26080 total_steps:1304 epochs:130.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9949 9.949e-10               .9947                 .9974   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9921            .9950              .9925   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9975 11.45 .1795   269  1031       0          0 76.63  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9949             32768 .08092    .1247 5.977 .007088 4.995e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n     458       0          0                 1304 388.6 1489 3.84        .9949\n\n22:48:59 | time:491s total_exs:26500 total_steps:1325 epochs:132.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9952 9.952e-10               .9953                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9907            .9952              .9904   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.53 .2857 270.6  1048       0          0 77.45  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9952             32768 .09288    .1247 6.019 .01059 4.995e-05 120.4 466.2   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1325  391 1514 3.889        .9952\n\n22:48:59 | running eval: valid\n22:48:59 | eval completed in 0.24s\n22:48:59 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9231                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9091                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 12.04 168.5  1588       0          0   113   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 .6659 4.995e-05    72 678.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1325 240.5 2266        .9161\n\u001b[0m\n22:48:59 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 20\u001b[0m\n22:48:59 | saving model checkpoint: /tmp/model4.checkpoint\n22:49:14 | time:506s total_exs:27280 total_steps:1364 epochs:136.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9897 9.897e-10               .9900                 .9950   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9851            .9895              .9843   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9947 11.54 .3077 270.9  1033       0          0 76.24  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9897             32768  .1529    .1248 6.031 .01914 4.995e-05 120.6 459.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1364 391.5 1492 3.821        .9897\n\n22:49:19 | time:511s total_exs:27680 total_steps:1384 epochs:138.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9925 9.925e-10               .9923                 .9949   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9898            .9927              .9902   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9951 11.24 .2000 264.9  1030       0          0 77.77  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9925             32768  .1017    .1248  5.98 .01439 4.995e-05 119.6 465.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1384 384.5 1495 3.906        .9925\n\n22:49:19 | running eval: valid\n22:49:20 | eval completed in 0.20s\n22:49:20 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8889                 .8000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .8571                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 12.04 168.5  1896       0          0   135   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6 .7935 4.995e-05    72   810       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1384 240.5 2706        .8730\n\u001b[0m\nEpoch 00007: reducing learning rate of group 0 to 2.4975e-05.\n22:49:20 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 21\u001b[0m\n22:49:20 | saving model checkpoint: /tmp/model4.checkpoint\n22:49:34 | time:526s total_exs:28420 total_steps:1421 epochs:142.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9946 9.946e-10               .9942                 .9971   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9914            .9949              .9924   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9975 11.32 .2703 266.5 986.6       0          0 74.05  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9946             32768  .1141    .1248 5.938 .01259 2.498e-05 118.8 439.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1421 385.2 1426 3.711        .9946\n\n22:49:40 | time:532s total_exs:28840 total_steps:1442 epochs:144.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9929 9.929e-10               .9927                 .9903   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9951            .9930              .9953   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9907 11.42 .3333 268.5  1024       0          0 76.26  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9929             32768  .1512    .1248 5.976 .01973 2.498e-05 119.5 455.7   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1442  388 1479 3.829        .9929\n\n22:49:40 | running eval: valid\n22:49:40 | eval completed in 0.23s\n22:49:40 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9231                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9091                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 12.04 168.5  1599       0          0 113.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 .6749 2.498e-05    72 683.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1442 240.5 2283        .9161\n\u001b[0m\n22:49:40 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 22\u001b[0m\n22:49:40 | saving model checkpoint: /tmp/model4.checkpoint\n22:49:54 | time:546s total_exs:29600 total_steps:1480 epochs:148.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9908 9.908e-10               .9910                 .9872   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9949            .9905              .9946   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9865 11.77 .3158 275.3  1043       0          0 75.75  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9908             32768  .1441    .1248 6.024 .0189 2.498e-05 120.5 456.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1480 395.8 1499 3.796        .9908\n\n22:50:00 | time:552s total_exs:30040 total_steps:1502 epochs:150.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9909 9.909e-10               .9900                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9802            .9917              .9835   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.79 .3182 275.8  1047       0          0 75.93  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9909             32768  .1498    .1248 5.918 .02328 2.498e-05 118.4 449.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1502 394.2 1496 3.811        .9909\n\n22:50:00 | running eval: valid\n22:50:00 | eval completed in 0.21s\n22:50:00 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9231                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9091                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 12.04 168.5  1769       0          0 125.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 .6625 2.498e-05    72 755.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1502 240.5 2525        .9161\n\u001b[0m\n22:50:00 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 23\u001b[0m\n22:50:00 | saving model checkpoint: /tmp/model4.checkpoint\n22:50:15 | time:567s total_exs:30820 total_steps:1541 epochs:154.10\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9910 9.91e-10               .9914                 .9901   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9926            .9907              .9920   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9893  11.4 .2051 267.9  1020       0          0 76.12  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9910             32768  .1263    .1248 6.038 .01716 2.498e-05 120.8 459.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1541 388.7 1480 3.815        .9910\n\n22:50:21 | time:573s total_exs:31220 total_steps:1561 epochs:156.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9875 9.875e-10               .9880                 .9903   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9856            .9870              .9845   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9896 11.77 .2500 275.4  1044       0          0 75.84  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9875             32768  .1718    .1248  6.04 .02449 2.498e-05 120.8   458   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1561 396.2 1502 3.808        .9875\n\n22:50:21 | running eval: valid\n22:50:21 | eval completed in 0.20s\n22:50:21 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9231                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9091                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 12.04 168.5  1875       0          0 133.5   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 .6526 2.498e-05    72 801.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1561 240.5 2676        .9161\n\u001b[0m\n22:50:21 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 24\u001b[0m\n22:50:21 | saving model checkpoint: /tmp/model4.checkpoint\n22:50:35 | time:587s total_exs:31980 total_steps:1599 epochs:159.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9921 9.921e-10               .9918                 .9865   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9973            .9923              .9974   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9873 11.64 .2632 272.9  1027       0          0 75.28  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9921             32768  .1399    .1248 5.963 .01304 2.498e-05 119.3 448.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1599 392.1 1476 3.773        .9921\n\n22:50:41 | time:593s total_exs:32400 total_steps:1620 epochs:162.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9929 9.929e-10               .9929                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9859            .9928              .9857   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.94 .1905 278.9  1015       0          0 72.82  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9929             32768  .1048    .1248 6.014 .0168 2.498e-05 120.3   438   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1620 399.1 1453 3.656        .9929\n\n22:50:41 | running eval: valid\n22:50:41 | eval completed in 0.19s\n22:50:41 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9231                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9091                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 12.04 168.5  1921       0          0 136.8   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 .5997 2.498e-05    72 820.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1620 240.5 2742        .9161\n\u001b[0m\nEpoch 00011: reducing learning rate of group 0 to 1.2488e-05.\n22:50:41 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 25\u001b[0m\n22:50:41 | saving model checkpoint: /tmp/model4.checkpoint\n22:50:56 | time:608s total_exs:33140 total_steps:1657 epochs:165.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9932 9.932e-10               .9935                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9871            .9930              .9860   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.35 .2162 267.1 986.3       0          0 73.85  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9932             32768  .1128    .1248 6.046 .01402 1.249e-05 120.9 446.5   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1657  388 1433 3.701        .9932\n\n22:51:01 | time:613s total_exs:33560 total_steps:1678 epochs:167.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9881 9.881e-10               .9881                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9765            .9881              .9764   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.91 .2857 278.3  1073       0          0 77.14  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9881             32768  .1652    .1248 6.014 .0248 1.249e-05 120.3 463.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1678 398.6 1537 3.873        .9881\n\n22:51:01 | running eval: valid\n22:51:01 | eval completed in 0.22s\n22:51:01 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9231                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9091                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 12.04 168.5  1734       0          0 123.5   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 .6707 1.249e-05    72   741       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1678 240.5 2475        .9161\n\u001b[0m\n22:51:01 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 26\u001b[0m\n22:51:01 | saving model checkpoint: /tmp/model4.checkpoint\n22:51:16 | time:628s total_exs:34320 total_steps:1716 epochs:171.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9842 9.842e-10               .9840                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9686            .9844              .9692   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.28 .3684 265.6 990.4       0          0 74.56  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9842             32768  .1954    .1248 6.005 .0296 1.249e-05 120.1 447.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1716 385.7 1438 3.737        .9842\n\n22:51:22 | time:634s total_exs:34740 total_steps:1737 epochs:173.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9881 9.881e-10               .9885                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9772            .9877              .9757   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.65 .5238   273  1051       0          0 77.02  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9881             32768  .1951    .1248 6.043 .02694 1.249e-05 120.9 465.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1737 393.9 1517 3.867        .9881\n\n22:51:22 | running eval: valid\n22:51:22 | eval completed in 0.19s\n22:51:22 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9231                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9091                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 12.04 168.5  1918       0          0 136.6   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08122     6 .6781 1.249e-05    72 819.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1737 240.5 2738        .9161\n\u001b[0m\n22:51:22 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 27\u001b[0m\n22:51:22 | saving model checkpoint: /tmp/model4.checkpoint\n22:51:36 | time:648s total_exs:35500 total_steps:1775 epochs:177.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9868 9.868e-10               .9869                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9742            .9868              .9739   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.26 .3421 265.2  1006       0          0 75.88  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9868             32768  .1728    .1248 6.018 .0196 1.249e-05 120.4 456.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1775 385.6 1463 3.803        .9868\n\n22:51:42 | time:654s total_exs:35920 total_steps:1796 epochs:179.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9881 9.881e-10               .9878                 .9902   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9854            .9884              .9861   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9907 11.45 .3810   269  1014       0          0 75.36  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9881             32768  .1675    .1248 5.976 .02024 1.249e-05 119.5 450.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1796 388.6 1464 3.783        .9881\n\n22:51:42 | running eval: valid\n22:51:42 | eval completed in 0.20s\n22:51:42 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9231                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9091                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 12.04 168.5  1868       0          0   133   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08123     6 .6847 1.249e-05    72   798       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1796 240.5 2666        .9161\n\u001b[0m\n22:51:42 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 28\u001b[0m\n22:51:42 | saving model checkpoint: /tmp/model4.checkpoint\n22:51:57 | time:669s total_exs:36700 total_steps:1835 epochs:183.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9923 9.923e-10               .9925                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9851            .9921              .9844   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.19 .3077 263.9  1010       0          0 76.56  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9923             32768  .1262    .1249 6.031 .01469 1.249e-05 120.6 461.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1835 384.5 1472 3.837        .9923\n\n22:52:02 | time:674s total_exs:37120 total_steps:1856 epochs:185.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9857 9.857e-10               .9865                 .9778   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9955            .9848              .9949   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9749 11.16 .3333 263.3 989.2       0          0 75.14  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9857             32768  .1867    .1249 6.052 .02018 1.249e-05   121 454.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1856 384.3 1444 3.772        .9857\n\n22:52:02 | running eval: valid\n22:52:02 | eval completed in 0.20s\n22:52:02 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9231                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9091                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 12.04 168.5  1878       0          0 133.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08124     6 .6860 1.249e-05    72 802.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1856 240.5 2680        .9161\n\u001b[0m\nEpoch 00015: reducing learning rate of group 0 to 6.2438e-06.\n22:52:02 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 29\u001b[0m\n22:52:02 | saving model checkpoint: /tmp/model4.checkpoint\n22:52:17 | time:689s total_exs:37880 total_steps:1894 epochs:189.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9895 9.895e-10               .9894                 .9868   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9921            .9895              .9921   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9869 11.85 .2895   277  1034       0          0 74.63  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9895             32768  .1303    .1249 5.995 .01636 6.244e-06 119.9 447.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1894 396.9 1481 3.74        .9895\n\n22:52:23 | time:695s total_exs:38300 total_steps:1915 epochs:191.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9905 9.905e-10               .9902                 .9902   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9902            .9907              .9907   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9907 11.63 .1905 272.5  1030       0          0  75.6  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9905             32768  .1151    .1249 5.971 .01341 6.244e-06 119.4 451.4   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1915  392 1482 3.795        .9905\n\n22:52:23 | running eval: valid\n22:52:23 | eval completed in 0.20s\n22:52:23 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9231                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9091                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 12.04 168.5  1895       0          0 134.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08125     6 .6844 6.244e-06    72 809.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1915 240.5 2705        .9161\n\u001b[0m\n22:52:23 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 30\u001b[0m\n22:52:23 | saving model checkpoint: /tmp/model4.checkpoint\n22:52:27 | ran out of patience! stopping training.\n22:52:27 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n22:52:27 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n22:52:27 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run4/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n22:52:27 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n22:52:27 | Using CUDA\n22:52:27 | loading dictionary from /tmp/model4.dict\n22:52:27 | num words = 54944\n22:52:32 | Loading existing model parameters from /tmp/model4\n22:52:40 | Total parameters: 128,042,498 (128,042,498 trainable)\n22:52:41 | creating task(s): fromfile:parlaiformat\n22:52:41 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run4/data_valid.txt\n22:52:41 | running eval: valid\n22:52:42 | eval completed in 0.51s\n22:52:42 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.04 168.5 723.5       0          0 51.51   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298     6 .3463 8.004e-06    72 309.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    160 240.5 1033        .9583\n\u001b[0m\n22:52:42 | creating task(s): fromfile:parlaiformat\n22:52:42 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run4/data_test.txt\n22:52:42 | running eval: test\n22:52:47 | eval completed in 4.92s\n22:52:47 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9310 9.31e-10               .7113                 .6115   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8500            .9608              .9826   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9400 12.07 281.4  2883       0          0 204.9 1000 .9310   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298   5.2 .3254 8.004e-06   104  1065       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    160 385.4 3948        .9359\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type2/run4/data_test.txt -m transformer/classifier -mf /tmp/model4 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-03T22:52:49.182641Z","iopub.execute_input":"2022-12-03T22:52:49.183050Z","iopub.status.idle":"2022-12-03T22:53:19.584567Z","shell.execute_reply.started":"2022-12-03T22:52:49.183007Z","shell.execute_reply":"2022-12-03T22:53:19.583376Z"},"scrolled":true,"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"22:52:57 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr1type2/run4/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr1type2/run4/data)\u001b[0m\n22:52:57 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n22:52:57 | Using CUDA\n22:52:57 | loading dictionary from /tmp/model4.dict\n22:52:57 | num words = 54944\n22:53:02 | Loading existing model parameters from /tmp/model4\n22:53:07 | Total parameters: 128,042,498 (128,042,498 trainable)\n22:53:09 | Opt:\n22:53:09 |     activation: gelu\n22:53:09 |     adafactor_eps: '[1e-30, 0.001]'\n22:53:09 |     adam_eps: 1e-08\n22:53:09 |     add_p1_after_newln: False\n22:53:09 |     aggregate_micro: False\n22:53:09 |     allow_missing_init_opts: False\n22:53:09 |     area_under_curve_class: None\n22:53:09 |     area_under_curve_digits: -1\n22:53:09 |     attention_dropout: 0.1\n22:53:09 |     batchsize: 40\n22:53:09 |     betas: '[0.9, 0.999]'\n22:53:09 |     bpe_add_prefix_space: None\n22:53:09 |     bpe_debug: False\n22:53:09 |     bpe_dropout: None\n22:53:09 |     bpe_merge: None\n22:53:09 |     bpe_vocab: None\n22:53:09 |     candidates: inline\n22:53:09 |     cap_num_predictions: 100\n22:53:09 |     checkpoint_activations: False\n22:53:09 |     class_weights: None\n22:53:09 |     classes: \"['__notok__', '__ok__']\"\n22:53:09 |     classes_from_file: None\n22:53:09 |     data_parallel: True\n22:53:09 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n22:53:09 |     datatype: train\n22:53:09 |     delimiter: '\\n'\n22:53:09 |     dict_class: parlai.core.dict:DictionaryAgent\n22:53:09 |     dict_endtoken: __start__\n22:53:09 |     dict_file: /tmp/model4.dict\n22:53:09 |     dict_include_test: False\n22:53:09 |     dict_include_valid: False\n22:53:09 |     dict_initpath: None\n22:53:09 |     dict_language: english\n22:53:09 |     dict_loaded: True\n22:53:09 |     dict_lower: True\n22:53:09 |     dict_max_ngram_size: -1\n22:53:09 |     dict_maxexs: -1\n22:53:09 |     dict_maxtokens: -1\n22:53:09 |     dict_minfreq: 0\n22:53:09 |     dict_nulltoken: __null__\n22:53:09 |     dict_starttoken: __start__\n22:53:09 |     dict_textfields: text,labels\n22:53:09 |     dict_tokenizer: bpe\n22:53:09 |     dict_unktoken: __unk__\n22:53:09 |     display_examples: False\n22:53:09 |     download_path: None\n22:53:09 |     dropout: 0.1\n22:53:09 |     dynamic_batching: None\n22:53:09 |     embedding_projection: random\n22:53:09 |     embedding_size: 768\n22:53:09 |     embedding_type: random\n22:53:09 |     embeddings_scale: False\n22:53:09 |     encode_candidate_vecs: True\n22:53:09 |     encode_candidate_vecs_batchsize: 256\n22:53:09 |     eval_batchsize: None\n22:53:09 |     eval_candidates: inline\n22:53:09 |     eval_dynamic_batching: None\n22:53:09 |     evaltask: None\n22:53:09 |     ffn_size: 3072\n22:53:09 |     final_extra_opt: \n22:53:09 |     fixed_candidate_vecs: reuse\n22:53:09 |     fixed_candidates_path: None\n22:53:09 |     force_fp16_tokens: True\n22:53:09 |     fp16: True\n22:53:09 |     fp16_impl: safe\n22:53:09 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run4/data_test.txt\n22:53:09 |     fromfile_datatype_extension: True\n22:53:09 |     gpu: -1\n22:53:09 |     gradient_clip: 0.1\n22:53:09 |     hide_labels: False\n22:53:09 |     history_add_global_end_token: None\n22:53:09 |     history_reversed: False\n22:53:09 |     history_size: 20\n22:53:09 |     ignore_bad_candidates: False\n22:53:09 |     ignore_labels: None\n22:53:09 |     image_cropsize: 224\n22:53:09 |     image_mode: raw\n22:53:09 |     image_size: 256\n22:53:09 |     inference: max\n22:53:09 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n22:53:09 |     init_opt: None\n22:53:09 |     interactive_candidates: fixed\n22:53:09 |     interactive_mode: False\n22:53:09 |     invsqrt_lr_decay_gamma: -1\n22:53:09 |     is_debug: False\n22:53:09 |     label_truncate: 72\n22:53:09 |     learn_embeddings: True\n22:53:09 |     learn_positional_embeddings: True\n22:53:09 |     learningrate: 5e-05\n22:53:09 |     load_from_pretrained_ranker: True\n22:53:09 |     log_every_n_secs: 10.0\n22:53:09 |     log_every_n_steps: 50\n22:53:09 |     log_keep_fields: all\n22:53:09 |     loglevel: info\n22:53:09 |     lr_scheduler: reduceonplateau\n22:53:09 |     lr_scheduler_decay: 0.5\n22:53:09 |     lr_scheduler_patience: 3\n22:53:09 |     max_train_steps: -1\n22:53:09 |     max_train_time: 7200.0\n22:53:09 |     memory_attention: sqrt\n22:53:09 |     metrics: default\n22:53:09 |     model: transformer/classifier\n22:53:09 |     model_file: /tmp/model4\n22:53:09 |     model_parallel: False\n22:53:09 |     momentum: 0\n22:53:09 |     multitask_weights: [1]\n22:53:09 |     mutators: None\n22:53:09 |     n_decoder_layers: -1\n22:53:09 |     n_encoder_layers: -1\n22:53:09 |     n_heads: 12\n22:53:09 |     n_layers: 12\n22:53:09 |     n_positions: 1024\n22:53:09 |     n_segments: 2\n22:53:09 |     nesterov: True\n22:53:09 |     no_cuda: False\n22:53:09 |     normalize_sent_emb: False\n22:53:09 |     num_epochs: -1\n22:53:09 |     num_examples: -1\n22:53:09 |     num_workers: 0\n22:53:09 |     nus: [0.7]\n22:53:09 |     optimizer: adamax\n22:53:09 |     output_scaling: 0.06\n22:53:09 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type2/run4/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model4', 'batchsize': 40}\"\n22:53:09 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n22:53:09 |     person_tokens: False\n22:53:09 |     print_scores: False\n22:53:09 |     rank_candidates: False\n22:53:09 |     rank_top_k: -1\n22:53:09 |     reduction_type: mean\n22:53:09 |     ref_class: None\n22:53:09 |     relu_dropout: 0.0\n22:53:09 |     repeat_blocking_heuristic: True\n22:53:09 |     report_filename: \n22:53:09 |     return_cand_scores: False\n22:53:09 |     save_after_valid: True\n22:53:09 |     save_every_n_secs: -1\n22:53:09 |     save_format: conversations\n22:53:09 |     share_encoders: False\n22:53:09 |     share_word_embeddings: False\n22:53:09 |     short_final_eval: False\n22:53:09 |     special_tok_lst: None\n22:53:09 |     split_lines: False\n22:53:09 |     starttime: Dec03_22-40\n22:53:09 |     task: fromfile:parlaiformat\n22:53:09 |     tensorboard_log: False\n22:53:09 |     tensorboard_logdir: None\n22:53:09 |     text_truncate: 360\n22:53:09 |     threshold: 0.5\n22:53:09 |     topk: 5\n22:53:09 |     train_predict: False\n22:53:09 |     truncate: 1024\n22:53:09 |     update_classifier_head_only: False\n22:53:09 |     update_freq: 1\n22:53:09 |     use_memories: False\n22:53:09 |     use_reply: none\n22:53:09 |     validation_cutoff: 1.0\n22:53:09 |     validation_every_n_epochs: -1\n22:53:09 |     validation_every_n_secs: 20.0\n22:53:09 |     validation_every_n_steps: -1\n22:53:09 |     validation_max_exs: -1\n22:53:09 |     validation_metric: accuracy\n22:53:09 |     validation_metric_mode: max\n22:53:09 |     validation_patience: 30\n22:53:09 |     validation_share_agent: False\n22:53:09 |     variant: xlm\n22:53:09 |     verbose: False\n22:53:09 |     wandb_entity: None\n22:53:09 |     wandb_log: False\n22:53:09 |     wandb_name: None\n22:53:09 |     wandb_project: None\n22:53:09 |     warmup_rate: 0.0001\n22:53:09 |     warmup_updates: 1000\n22:53:09 |     weight_decay: None\n22:53:09 |     world_logs: \n22:53:09 |     wrap_memory_encoder: False\n22:53:09 | Evaluating task fromfile:parlaiformat using datatype valid.\n22:53:09 | creating task(s): fromfile:parlaiformat\n22:53:09 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n22:53:09 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run4/data_test.txt\n22:53:18 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9310 9.31e-10               .7113                 .6115   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8500            .9608              .9826   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9400 12.07 562.9  1753       0          0 124.6 1000 .9310   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .3254 8.004e-06   208 647.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    160 770.9 2401        .9359\u001b[0m\n22:53:18 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9310 9.31e-10               .7113                 .6115   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8500            .9608              .9826   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9400 12.07 562.9  1753       0          0 124.6 1000 .9310   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .3254 8.004e-06   208 647.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    160 770.9 2401        .9359\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model4*","metadata":{"execution":{"iopub.status.busy":"2022-12-03T22:53:19.586564Z","iopub.execute_input":"2022-12-03T22:53:19.586971Z","iopub.status.idle":"2022-12-03T22:53:20.833741Z","shell.execute_reply.started":"2022-12-03T22:53:19.586925Z","shell.execute_reply":"2022-12-03T22:53:20.831988Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"run 5","metadata":{}},{"cell_type":"code","source":"# run 5 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type2/run5/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model5","metadata":{"execution":{"iopub.status.busy":"2022-12-03T22:53:20.835890Z","iopub.execute_input":"2022-12-03T22:53:20.836321Z","iopub.status.idle":"2022-12-03T23:05:13.772795Z","shell.execute_reply.started":"2022-12-03T22:53:20.836277Z","shell.execute_reply":"2022-12-03T23:05:13.771243Z"},"scrolled":true,"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"22:53:27 | building dictionary first...\n22:53:27 | No model with opt yet at: /tmp/model5(.opt)\n22:53:27 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run5/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n22:53:27 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n22:53:27 | Using CUDA\n22:53:27 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n22:53:28 | num words = 54944\n22:53:32 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n22:53:42 | Total parameters: 128,042,498 (128,042,498 trainable)\n22:53:42 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n22:53:42 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n22:53:42 | Opt:\n22:53:42 |     activation: gelu\n22:53:42 |     adafactor_eps: '(1e-30, 0.001)'\n22:53:42 |     adam_eps: 1e-08\n22:53:42 |     add_p1_after_newln: False\n22:53:42 |     aggregate_micro: False\n22:53:42 |     allow_missing_init_opts: False\n22:53:42 |     attention_dropout: 0.1\n22:53:42 |     batchsize: 20\n22:53:42 |     betas: '(0.9, 0.999)'\n22:53:42 |     bpe_add_prefix_space: None\n22:53:42 |     bpe_debug: False\n22:53:42 |     bpe_dropout: None\n22:53:42 |     bpe_merge: None\n22:53:42 |     bpe_vocab: None\n22:53:42 |     candidates: inline\n22:53:42 |     cap_num_predictions: 100\n22:53:42 |     checkpoint_activations: False\n22:53:42 |     class_weights: None\n22:53:42 |     classes: \"['__notok__', '__ok__']\"\n22:53:42 |     classes_from_file: None\n22:53:42 |     data_parallel: True\n22:53:42 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n22:53:42 |     datatype: train\n22:53:42 |     delimiter: '\\n'\n22:53:42 |     dict_class: parlai.core.dict:DictionaryAgent\n22:53:42 |     dict_endtoken: __start__\n22:53:42 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n22:53:42 |     dict_include_test: False\n22:53:42 |     dict_include_valid: False\n22:53:42 |     dict_initpath: None\n22:53:42 |     dict_language: english\n22:53:42 |     dict_loaded: True\n22:53:42 |     dict_lower: True\n22:53:42 |     dict_max_ngram_size: -1\n22:53:42 |     dict_maxexs: -1\n22:53:42 |     dict_maxtokens: -1\n22:53:42 |     dict_minfreq: 0\n22:53:42 |     dict_nulltoken: __null__\n22:53:42 |     dict_starttoken: __start__\n22:53:42 |     dict_textfields: text,labels\n22:53:42 |     dict_tokenizer: bpe\n22:53:42 |     dict_unktoken: __unk__\n22:53:42 |     display_examples: False\n22:53:42 |     download_path: None\n22:53:42 |     dropout: 0.1\n22:53:42 |     dynamic_batching: None\n22:53:42 |     embedding_projection: random\n22:53:42 |     embedding_size: 768\n22:53:42 |     embedding_type: random\n22:53:42 |     embeddings_scale: False\n22:53:42 |     encode_candidate_vecs: True\n22:53:42 |     encode_candidate_vecs_batchsize: 256\n22:53:42 |     eval_batchsize: None\n22:53:42 |     eval_candidates: inline\n22:53:42 |     eval_dynamic_batching: None\n22:53:42 |     evaltask: None\n22:53:42 |     ffn_size: 3072\n22:53:42 |     final_extra_opt: \n22:53:42 |     fixed_candidate_vecs: reuse\n22:53:42 |     fixed_candidates_path: None\n22:53:42 |     force_fp16_tokens: False\n22:53:42 |     fp16: True\n22:53:42 |     fp16_impl: safe\n22:53:42 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run5/data\n22:53:42 |     fromfile_datatype_extension: True\n22:53:42 |     gpu: -1\n22:53:42 |     gradient_clip: 0.1\n22:53:42 |     hide_labels: False\n22:53:42 |     history_add_global_end_token: None\n22:53:42 |     history_reversed: False\n22:53:42 |     history_size: 20\n22:53:42 |     ignore_bad_candidates: False\n22:53:42 |     ignore_labels: None\n22:53:42 |     image_cropsize: 224\n22:53:42 |     image_mode: raw\n22:53:42 |     image_size: 256\n22:53:42 |     inference: max\n22:53:42 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n22:53:42 |     init_opt: None\n22:53:42 |     interactive_candidates: fixed\n22:53:42 |     interactive_mode: False\n22:53:42 |     invsqrt_lr_decay_gamma: -1\n22:53:42 |     is_debug: False\n22:53:42 |     label_truncate: 72\n22:53:42 |     learn_embeddings: True\n22:53:42 |     learn_positional_embeddings: True\n22:53:42 |     learningrate: 5e-05\n22:53:42 |     load_from_checkpoint: False\n22:53:42 |     load_from_pretrained_ranker: True\n22:53:42 |     log_every_n_secs: 10.0\n22:53:42 |     log_every_n_steps: 50\n22:53:42 |     log_keep_fields: all\n22:53:42 |     loglevel: info\n22:53:42 |     lr_scheduler: reduceonplateau\n22:53:42 |     lr_scheduler_decay: 0.5\n22:53:42 |     lr_scheduler_patience: 3\n22:53:42 |     max_train_steps: -1\n22:53:42 |     max_train_time: 7200.0\n22:53:42 |     memory_attention: sqrt\n22:53:42 |     metrics: default\n22:53:42 |     model: transformer/classifier\n22:53:42 |     model_file: /tmp/model5\n22:53:42 |     model_parallel: False\n22:53:42 |     momentum: 0\n22:53:42 |     multitask_weights: [1]\n22:53:42 |     mutators: None\n22:53:42 |     n_decoder_layers: -1\n22:53:42 |     n_encoder_layers: -1\n22:53:42 |     n_heads: 12\n22:53:42 |     n_layers: 12\n22:53:42 |     n_positions: 1024\n22:53:42 |     n_segments: 2\n22:53:42 |     nesterov: True\n22:53:42 |     no_cuda: False\n22:53:42 |     normalize_sent_emb: False\n22:53:42 |     num_epochs: -1\n22:53:42 |     num_workers: 0\n22:53:42 |     nus: (0.7,)\n22:53:42 |     optimizer: adamax\n22:53:42 |     output_scaling: 0.06\n22:53:42 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type2/run5/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model5'}\"\n22:53:42 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n22:53:42 |     person_tokens: False\n22:53:42 |     print_scores: False\n22:53:42 |     rank_candidates: False\n22:53:42 |     rank_top_k: -1\n22:53:42 |     reduction_type: mean\n22:53:42 |     ref_class: None\n22:53:42 |     relu_dropout: 0.0\n22:53:42 |     repeat_blocking_heuristic: True\n22:53:42 |     return_cand_scores: False\n22:53:42 |     save_after_valid: True\n22:53:42 |     save_every_n_secs: -1\n22:53:42 |     save_format: conversations\n22:53:42 |     share_encoders: False\n22:53:42 |     share_word_embeddings: False\n22:53:42 |     short_final_eval: False\n22:53:42 |     special_tok_lst: None\n22:53:42 |     split_lines: False\n22:53:42 |     starttime: Dec03_22-53\n22:53:42 |     task: fromfile:parlaiformat\n22:53:42 |     tensorboard_log: False\n22:53:42 |     tensorboard_logdir: None\n22:53:42 |     text_truncate: 360\n22:53:42 |     threshold: 0.5\n22:53:42 |     topk: 5\n22:53:42 |     train_predict: False\n22:53:42 |     truncate: 1024\n22:53:42 |     update_classifier_head_only: False\n22:53:42 |     update_freq: 1\n22:53:42 |     use_memories: False\n22:53:42 |     use_reply: none\n22:53:42 |     validation_cutoff: 1.0\n22:53:42 |     validation_every_n_epochs: -1\n22:53:42 |     validation_every_n_secs: 20.0\n22:53:42 |     validation_every_n_steps: -1\n22:53:42 |     validation_max_exs: -1\n22:53:42 |     validation_metric: accuracy\n22:53:42 |     validation_metric_mode: max\n22:53:42 |     validation_patience: 30\n22:53:42 |     validation_share_agent: False\n22:53:42 |     variant: xlm\n22:53:42 |     verbose: False\n22:53:42 |     wandb_entity: None\n22:53:42 |     wandb_log: False\n22:53:42 |     wandb_name: None\n22:53:42 |     wandb_project: None\n22:53:42 |     warmup_rate: 0.0001\n22:53:42 |     warmup_updates: 1000\n22:53:42 |     weight_decay: None\n22:53:42 |     world_logs: \n22:53:42 |     wrap_memory_encoder: False\n22:53:43 | creating task(s): fromfile:parlaiformat\n22:53:43 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run5/data_train.txt\n22:53:43 | training...\n22:53:53 | time:10s total_exs:380 total_steps:19 epochs:1.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5316 5.316e-10               .5056                 .5028   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5084            .5550              .5578   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .5522 11.75     1 275.1 517.5       0          0 37.63  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5316             32768    2.4    .1206 5.942 .6946 9.549e-07 118.8 223.6   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   19 393.9 741.1 1.886        .5317\n\n22:54:03 | time:20s total_exs:1140 total_steps:57 epochs:5.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6039 6.039e-10               .5894                 .6316   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5524            .6175              .5813   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6585 11.62     1 272.5  1047       0          0 76.86  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6039             32768  2.333    .1207 6.029 .6774 2.855e-06 120.6 463.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   57 393.1 1511 3.852        .6030\n\n22:54:03 | creating task(s): fromfile:parlaiformat\n22:54:03 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run5/data_valid.txt\n22:54:03 | running eval: valid\n22:54:03 | eval completed in 0.20s\n22:54:03 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .6250 6.25e-10               .7097                 .5789   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .4706              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .3333 10.67   152  1674       0          0 132.1   24 .6250   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6647 2.855e-06    72 792.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                     57  224 2467        .5901\n\u001b[0m\n22:54:03 | \u001b[1;32mnew best accuracy: 0.625\u001b[0m\n22:54:03 | saving best valid model: /tmp/model5\n22:54:03 | Saving dictionary to /tmp/model5.dict\n22:54:07 | saving model checkpoint: /tmp/model5.checkpoint\n22:54:07 | Saving dictionary to /tmp/model5.checkpoint.dict\n22:54:23 | time:40s total_exs:1820 total_steps:91 epochs:9.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7779 7.779e-10               .7906                 .7520   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7637              .8106   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7219 11.62     1 272.4 926.2       0          0 68.02  680   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7779             32768  2.642    .1207 6.006 .6297 4.555e-06 120.1 408.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   91 392.5 1335 3.409        .7772\n\n22:54:27 | time:44s total_exs:2140 total_steps:107 epochs:10.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8562 8.563e-10               .8477                 .8366   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8591            .8639              .8743   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8538 12.07     1 281.4  1099       0          0 78.11  320   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8562             32768  3.384    .1207 5.931 .5853 5.354e-06 118.6 463.3   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  107  400 1562 3.927        .8564\n\n22:54:27 | running eval: valid\n22:54:27 | eval completed in 0.19s\n22:54:27 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1736       0          0   137   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5548 5.354e-06    72 822.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    107  224 2558        .8748\n\u001b[0m\n22:54:27 | \u001b[1;32mnew best accuracy: 0.875 (previous best was 0.625)\u001b[0m\n22:54:27 | saving best valid model: /tmp/model5\n22:54:36 | saving model checkpoint: /tmp/model5.checkpoint\n22:54:51 | time:69s total_exs:2900 total_steps:145 epochs:14.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9066 9.066e-10               .9029                 .9322   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8753            .9100              .8842   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9373 12.08     1 281.7  1045       0          0 74.19  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9066             32768  3.714    .1207 5.992 .4699 7.254e-06 119.8 444.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  145 401.5 1490 3.718        .9065\n\n22:54:56 | time:74s total_exs:3280 total_steps:164 epochs:16.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8947 8.947e-10               .8844                 .8547   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9162            .9034              .9303   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8779 11.64     1 272.8  1033       0          0 75.75  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8947             32768  4.797    .1189 5.879 .3362 8.204e-06 117.6 445.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  164 390.4 1478 3.804        .8950\n\n22:54:56 | running eval: valid\n22:54:57 | eval completed in 0.19s\n22:54:57 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1738       0          0 137.2   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .3414 8.204e-06    72 823.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    164  224 2562        .8322\n\u001b[0m\n22:54:57 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 1\u001b[0m\n22:54:57 | saving model checkpoint: /tmp/model5.checkpoint\n22:55:12 | time:89s total_exs:4040 total_steps:202 epochs:20.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9211 9.211e-10               .9198                 .9348   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9053            .9223              .9082   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9368 11.73     1 274.7  1042       0          0 75.87  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9211             32768  6.025    .1207     6 .2444 1.01e-05   120 455.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  202 394.7 1497 3.802        .9210\n\n22:55:17 | time:94s total_exs:4400 total_steps:220 epochs:22.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9611 9.611e-10               .9620                 .9672   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9568            .9602              .9548   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9657 11.56     1 271.2  1020       0          0 75.22  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  \\\n   .9611             32768   6.04    .1207 6.028 .1529 1.1e-05 120.6 453.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  220 391.7 1473 3.779        .9611\n\n22:55:17 | running eval: valid\n22:55:17 | eval completed in 0.20s\n22:55:17 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 10.67   152  1715       0          0 135.3   24 .8333   \n    gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .3478 1.1e-05    72 812.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    220  224 2527        .8333\n\u001b[0m\n22:55:17 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 2\u001b[0m\n22:55:17 | saving model checkpoint: /tmp/model5.checkpoint\n22:55:37 | time:114s total_exs:5120 total_steps:256 epochs:25.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9681 9.681e-10               .9667                 .9709   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9625            .9693              .9654   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9732 11.78     1 275.6  1050       0          0 76.22  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9681             32768  7.709    .1207 5.964 .0947 1.28e-05 119.3 454.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  256 394.9 1505 3.82        .9681\n\n22:55:37 | running eval: valid\n22:55:37 | eval completed in 0.23s\n22:55:37 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7273                 .8000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .7692              .7143   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 10.67   152  1530       0          0 120.7   24 .7500   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .5534 1.28e-05    72 724.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    256  224 2254        .7483\n\u001b[0m\n22:55:37 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 3\u001b[0m\n22:55:37 | saving model checkpoint: /tmp/model5.checkpoint\n22:55:52 | time:129s total_exs:5880 total_steps:294 epochs:29.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9882 9.882e-10               .9884                 .9795   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9974            .9879              .9973   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9787 11.79 .8421 275.8  1042       0          0  75.6  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9882             32768  6.922    .1207 6.011 .04361 1.47e-05 120.2 454.4   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  294  396 1497 3.789        .9882\n\n22:55:58 | time:135s total_exs:6320 total_steps:316 epochs:31.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9932 9.932e-10               .9929                 .9859   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9934                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9870 12.38 .3182 287.7  1092       0          0 75.94  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9932             32768  .5403    .1207 5.955 .03882 1.58e-05 119.1 452.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  316 406.8 1545 3.812        .9932\n\n22:55:58 | running eval: valid\n22:55:58 | eval completed in 0.20s\n22:55:58 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 10.67   152  1675       0          0 132.2   24 .7917   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .8685 1.58e-05    72 793.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    316  224 2469        .7913\n\u001b[0m\n22:55:58 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 4\u001b[0m\n22:55:58 | saving model checkpoint: /tmp/model5.checkpoint\n22:56:13 | time:150s total_exs:7100 total_steps:355 epochs:35.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9923 9.923e-10               .9923                 .9872   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9974            .9923              .9974   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9873 11.85 .2564 277.1  1057       0          0 76.33  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9923             32768  8.551    .1207 5.992 .0299 1.775e-05 119.8 457.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  355 396.9 1515 3.825        .9923\n\n22:56:18 | time:155s total_exs:7500 total_steps:375 epochs:37.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9975 9.975e-10               .9975                 .9951   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9975                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9949 12.26 .1000 285.2  1108       0          0 77.68  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9975             32768  7.551    .1207 6.015 .004999 1.875e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   467.2       0          0                  375 405.6 1575 3.901        .9975\n\n22:56:18 | running eval: valid\n22:56:18 | eval completed in 0.19s\n22:56:18 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8000                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8571              .7500   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1732       0          0 136.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 1.063 1.875e-05    72 820.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    375  224 2553        .8286\n\u001b[0m\n22:56:18 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 5\u001b[0m\n22:56:18 | saving model checkpoint: /tmp/model5.checkpoint\n22:56:33 | time:170s total_exs:8260 total_steps:413 epochs:41.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9987                 .9974   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9987                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                  .9973 11.77 .07895 275.5  1033       0          0 75.02   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    760 .9987             32768  8.211    .1207 6.018 .003738 2.065e-05 120.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.5       0          0                  413 395.8 1485 3.759        .9987\n\n22:56:38 | time:176s total_exs:8660 total_steps:433 epochs:43.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.63     0 272.6  1066       0          0 78.22  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01568    .1207  6.01 .001333 2.165e-05 120.2 470.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  433 392.8 1536 3.928            1\n\n22:56:38 | running eval: valid\n22:56:38 | eval completed in 0.19s\n22:56:38 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1732       0          0 136.7   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08095     6 .7879 2.165e-05    72 820.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    433  224 2552        .8730\n\u001b[0m\n22:56:38 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 6\u001b[0m\n22:56:38 | saving model checkpoint: /tmp/model5.checkpoint\n22:56:53 | time:191s total_exs:9440 total_steps:472 epochs:47.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9987                 .9975   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9987                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                  .9974 11.69 .02564 273.8  1061       0          0 77.49   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  \\\n    780 .9987             32768    6.5    .1207 6.021 .005244 2.36e-05 120.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   466.5       0          0                  472 394.2 1527 3.883        .9987\n\n22:56:59 | time:196s total_exs:9820 total_steps:491 epochs:49.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 12.04 .05263 280.9  1022       0          0 72.74   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    380   1             32768 .03366    .1207 6.016 .001135 2.455e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   437.6       0          0                  491 401.2 1459 3.653            1\n\n22:56:59 | running eval: valid\n22:56:59 | eval completed in 0.20s\n22:56:59 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 10.67   152  1706       0          0 134.7   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 1.117 2.455e-05    72 808.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    491  224 2515        .7913\n\u001b[0m\n22:56:59 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 7\u001b[0m\n22:56:59 | saving model checkpoint: /tmp/model5.checkpoint\n22:57:13 | time:211s total_exs:10580 total_steps:529 epochs:52.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.66     0 273.2  1035       0          0 75.77  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01271    .1207 5.945 .001055 2.645e-05 118.9 450.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  529 392.1 1485 3.797            1\n\n22:57:19 | time:216s total_exs:11000 total_steps:550 epochs:55.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.2  1054       0          0 76.87  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .01139    .1207  5.99 .0009804 2.75e-05 119.8 460.5   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  550  394 1514 3.859            1\n\n22:57:19 | running eval: valid\n22:57:19 | eval completed in 0.19s\n22:57:19 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1728       0          0 136.4   24 .7917   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 1.013 2.75e-05    72 818.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    550  224 2546        .7884\n\u001b[0m\n22:57:19 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 8\u001b[0m\n22:57:19 | saving model checkpoint: /tmp/model5.checkpoint\n22:57:34 | time:231s total_exs:11740 total_steps:587 epochs:58.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.69     0 273.8  1011       0          0 73.83  740   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01077    .1207  6.03 .0009193 2.935e-05 120.6 445.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  587 394.4 1456  3.7            1\n\n22:57:39 | time:236s total_exs:12120 total_steps:606 epochs:60.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.36     0 267.2   997       0          0 74.62  380   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .01122    .1208 5.984 .0008633 3.03e-05 119.7 446.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  606 386.9 1444 3.747            1\n\n22:57:39 | running eval: valid\n22:57:39 | eval completed in 0.19s\n22:57:39 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8462                 .7857   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8182              .9000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 10.67   152  1741       0          0 137.4   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 .9830 3.03e-05    72 824.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    606  224 2566        .8322\n\u001b[0m\n22:57:39 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 9\u001b[0m\n22:57:39 | saving model checkpoint: /tmp/model5.checkpoint\n22:57:54 | time:252s total_exs:12880 total_steps:644 epochs:64.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.91     0 278.3  1054       0          0 75.76  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .009625    .1208 6.029 .0008095 3.22e-05 120.6 456.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  644 398.8 1511 3.796            1\n\n22:58:00 | time:257s total_exs:13280 total_steps:664 epochs:66.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.82     0 276.4  1040       0          0 75.25  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .008847    .1208 6.055 .0007588 3.32e-05 121.1 455.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  664 397.6 1496 3.778            1\n\n22:58:00 | running eval: valid\n22:58:00 | eval completed in 0.27s\n22:58:00 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 10.67   152  1262       0          0 99.57   24 .7917   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 .8291 3.32e-05    72 597.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    664  224 1859        .7913\n\u001b[0m\n22:58:00 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 10\u001b[0m\n22:58:00 | saving model checkpoint: /tmp/model5.checkpoint\n22:58:15 | time:272s total_exs:14040 total_steps:702 epochs:70.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.84     0 276.9  1051       0          0 75.89  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .008293    .1208 5.982 .0007111 3.51e-05 119.6   454   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  702 396.5 1505 3.803            1\n\n22:58:20 | time:277s total_exs:14440 total_steps:722 epochs:72.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.83     0 276.6  1077       0          0 77.83  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .007776    .1208  5.93 .0006659 3.61e-05 118.6 461.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  722 395.2 1538 3.909            1\n\n22:58:20 | running eval: valid\n22:58:20 | eval completed in 0.19s\n22:58:20 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1752       0          0 138.3   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 .8565 3.61e-05    72   830       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    722  224 2583        .8730\n\u001b[0m\n22:58:20 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 11\u001b[0m\n22:58:20 | saving model checkpoint: /tmp/model5.checkpoint\n22:58:35 | time:292s total_exs:15200 total_steps:760 epochs:76.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.3  1025       0          0 74.73  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss      lr  ltpb  ltps  \\\n     1             32768 .007337    .1208 5.995 .0006266 3.8e-05 119.9   448   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  760 394.2 1473 3.745            1\n\n22:58:40 | time:298s total_exs:15600 total_steps:780 epochs:78.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.01     0 280.2  1088       0          0 77.69  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss      lr  ltpb  ltps  \\\n     1             32768 .006861    .1208  6.01 .0005868 3.9e-05 120.2 466.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  780 400.4 1555 3.902            1\n\n22:58:40 | running eval: valid\n22:58:40 | eval completed in 0.20s\n22:58:40 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8000                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8571              .7500   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1719       0          0 135.7   24 .8333   \n    gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 .8517 3.9e-05    72 814.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    780  224 2533        .8286\n\u001b[0m\n22:58:40 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 12\u001b[0m\n22:58:40 | saving model checkpoint: /tmp/model5.checkpoint\n22:58:56 | time:313s total_exs:16380 total_steps:819 epochs:81.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.61     0 272.1  1035       0          0 76.08  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006438    .1208 6.005 .0005508 4.095e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.9       0          0                  819 392.2 1492 3.813            1\n\n22:59:01 | time:318s total_exs:16760 total_steps:838 epochs:83.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.95     0   279  1081       0          0 77.48  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .006043    .1208 5.953 .0005168 4.19e-05 119.1 461.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  838 398.1 1542 3.892            1\n\n22:59:01 | running eval: valid\n22:59:01 | eval completed in 0.20s\n22:59:01 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1663       0          0 131.3   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 .8300 4.19e-05    72 787.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    838  224 2451        .8730\n\u001b[0m\n22:59:01 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 13\u001b[0m\n22:59:01 | saving model checkpoint: /tmp/model5.checkpoint\n22:59:16 | time:333s total_exs:17520 total_steps:876 epochs:87.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.92     0 278.4  1043       0          0 74.92  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .005691    .1208 6.047 .0004862 4.38e-05 120.9 453.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  876 399.3 1496 3.755            1\n\n22:59:21 | time:338s total_exs:17900 total_steps:895 epochs:89.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.96     0 279.1  1049       0          0 75.16  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .005343    .1208 6.016 .0004566 4.475e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   452.2       0          0                  895 399.4 1501 3.775            1\n\n22:59:21 | running eval: valid\n22:59:21 | eval completed in 0.19s\n22:59:21 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1731       0          0 136.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 .8133 4.475e-05    72 819.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    895  224 2551        .8730\n\u001b[0m\n22:59:21 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 14\u001b[0m\n22:59:21 | saving model checkpoint: /tmp/model5.checkpoint\n22:59:36 | time:353s total_exs:18660 total_steps:933 epochs:93.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9961 9.961e-10               .9961                 .9949   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9974            .9960              .9973   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                  .9946 11.74 .07895 274.7  1035       0          0 75.33   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  \\\n    760 .9961             32768  9.455    .1208 6.024 .02545 4.665e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   453.8       0          0                  933 395.2 1489 3.775        .9961\n\n22:59:41 | time:359s total_exs:19060 total_steps:953 epochs:95.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.9 .1500 278.1  1038       0          0 74.63  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768    6.4    .1208  5.95 .001133 4.765e-05   119   444   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  953 397.1 1482 3.747            1\n\n22:59:41 | running eval: valid\n22:59:41 | eval completed in 0.20s\n22:59:41 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1681       0          0 132.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 1.194 4.765e-05    72 796.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    953  224 2477        .8322\n\u001b[0m\n22:59:41 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 15\u001b[0m\n22:59:41 | saving model checkpoint: /tmp/model5.checkpoint\n22:59:56 | time:373s total_exs:19840 total_steps:992 epochs:99.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.74 .02564 274.8  1052       0          0 76.56   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  \\\n    780   1             32768  .0579    .1208 5.974 .0003987 4.96e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.4       0          0                  992 394.3 1510 3.837            1\n\n23:00:02 | time:379s total_exs:20280 total_steps:1014 epochs:101.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9977 9.977e-10               .9976                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9951            .9979              .9957   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.98 .09091 279.6  1070       0          0  76.5   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  \\\n    440 .9977             32768  7.823    .1208 5.936 .01666 4.995e-05 118.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   454.1       0          0                 1014 398.4 1524 3.84        .9977\n\n23:00:02 | running eval: valid\n23:00:02 | eval completed in 0.19s\n23:00:02 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8148                 .7333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .7619              .8889   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .6667 10.67   152  1718       0          0 135.5   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6  1.71 4.995e-05    72 813.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1014  224 2531        .7884\n\u001b[0m\n23:00:02 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 16\u001b[0m\n23:00:02 | saving model checkpoint: /tmp/model5.checkpoint\n23:00:17 | time:395s total_exs:21060 total_steps:1053 epochs:105.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.88 .02564 277.5  1059       0          0 76.35   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n    780   1             32768 .09523    .1208 5.972 .0003552 4.995e-05 119.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   455.9       0          0                 1053 396.9 1515 3.826            1\n\n23:00:22 | time:399s total_exs:21420 total_steps:1071 epochs:107.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.65     0 273.1  1065       0          0 78.02  360   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003764    .1208 5.989 .0003203 4.995e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   467.3       0          0                 1071 392.8 1533 3.92            1\n\n23:00:22 | running eval: valid\n23:00:22 | eval completed in 0.20s\n23:00:22 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1655       0          0 130.6   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 1.043 4.995e-05    72 783.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1071  224 2439        .8748\n\u001b[0m\n23:00:22 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 17\u001b[0m\n23:00:22 | saving model checkpoint: /tmp/model5.checkpoint\n23:00:37 | time:415s total_exs:22200 total_steps:1110 epochs:111.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.77     0 275.3  1060       0          0 76.98  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003648    .1208 6.023 .0003026 4.995e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.7       0          0                 1110 395.8 1523 3.859            1\n\n23:00:42 | time:420s total_exs:22580 total_steps:1129 epochs:112.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.85     0   277  1033       0          0 74.59  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003351    .1191 6.058 .0002852 4.995e-05 121.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.9       0          0                 1129 398.2 1485 3.746            1\n\n23:00:42 | running eval: valid\n23:00:43 | eval completed in 0.20s\n23:00:43 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 10.67   152  1658       0          0 130.9   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 1.223 4.995e-05    72 785.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1129  224 2444        .8333\n\u001b[0m\n23:00:43 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 18\u001b[0m\n23:00:43 | saving model checkpoint: /tmp/model5.checkpoint\n23:00:57 | time:435s total_exs:23360 total_steps:1168 epochs:116.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.74     0 274.9  1050       0          0 76.39  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003173    .1209 5.962 .0002697 4.995e-05 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   455.4       0          0                 1168 394.1 1505 3.828            1\n\n23:01:03 | time:440s total_exs:23780 total_steps:1189 epochs:118.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.51     0 270.2  1040       0          0    77  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002993    .1209 5.981 .0002549 4.995e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.6       0          0                 1189 389.9 1501 3.866            1\n\n23:01:03 | running eval: valid\n23:01:03 | eval completed in 0.19s\n23:01:03 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 10.67   152  1754       0          0 138.4   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6  1.08 4.995e-05    72 830.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1189  224 2584        .8333\n\u001b[0m\n23:01:03 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 19\u001b[0m\n23:01:03 | saving model checkpoint: /tmp/model5.checkpoint\n23:01:17 | time:455s total_exs:24540 total_steps:1227 epochs:122.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.73     0 274.6  1042       0          0  75.9  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002841    .1209 6.005 .0002416 4.995e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   455.8       0          0                 1227 394.7 1498 3.804            1\n\n23:01:23 | time:460s total_exs:24980 total_steps:1249 epochs:124.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0   276  1056       0          0 76.52  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002695    .1209 6.023 .0002293 4.995e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.8       0          0                 1249 396.5 1517 3.841            1\n\n23:01:23 | running eval: valid\n23:01:23 | eval completed in 0.20s\n23:01:23 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1710       0          0   135   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 1.032 4.995e-05    72 810.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1249  224 2521        .8748\n\u001b[0m\n23:01:23 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 20\u001b[0m\n23:01:23 | saving model checkpoint: /tmp/model5.checkpoint\n23:01:38 | time:475s total_exs:25760 total_steps:1288 epochs:128.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.66     0 273.3  1044       0          0 76.39  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002556    .1192 6.031 .0002175 4.995e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.7       0          0                 1288 393.9 1504 3.828            1\n\n23:01:43 | time:481s total_exs:26160 total_steps:1308 epochs:130.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.55     0 271.1 981.1       0          0 72.39  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .002434    .1209  6.12 .000207 4.995e-05 122.4   443   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1308 393.4 1424 3.634            1\n\n23:01:43 | running eval: valid\n23:01:44 | eval completed in 0.19s\n23:01:44 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1765       0          0 139.3   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 1.022 4.995e-05    72   836       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1308  224 2601        .8748\n\u001b[0m\n23:01:44 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 21\u001b[0m\n23:01:44 | saving model checkpoint: /tmp/model5.checkpoint\n23:01:58 | time:495s total_exs:26940 total_steps:1347 epochs:134.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.84     0 276.8  1064       0          0 76.84  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002314    .1209 6.038 .0001968 4.995e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     464       0          0                 1347 397.6 1528 3.851            1\n\n23:02:04 | time:501s total_exs:27380 total_steps:1369 epochs:136.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.83     0 276.5  1053       0          0 76.19  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002203    .1209 6.041 .0001873 4.995e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.2       0          0                 1369 397.4 1514 3.824            1\n\n23:02:04 | running eval: valid\n23:02:04 | eval completed in 0.20s\n23:02:04 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1708       0          0 134.8   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 1.021 4.995e-05    72 809.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1369  224 2518        .8748\n\u001b[0m\n23:02:04 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 22\u001b[0m\n23:02:04 | saving model checkpoint: /tmp/model5.checkpoint\n23:02:19 | time:516s total_exs:28120 total_steps:1406 epochs:140.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.79     0 275.7  1018       0          0 73.87  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002101    .1209 6.016 .0001786 4.995e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   444.4       0          0                 1406 396.1 1463 3.702            1\n\n23:02:24 | time:521s total_exs:28520 total_steps:1426 epochs:142.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.97     0 279.4  1053       0          0  75.4  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002008    .1209  6.01 .0001707 4.995e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   453.2       0          0                 1426 399.6 1507 3.786            1\n\n23:02:24 | running eval: valid\n23:02:24 | eval completed in 0.24s\n23:02:24 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1487       0          0 117.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6 1.011 4.995e-05    72 704.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1426  224 2192        .8748\n\u001b[0m\n23:02:24 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 23\u001b[0m\n23:02:24 | saving model checkpoint: /tmp/model5.checkpoint\n23:02:39 | time:536s total_exs:29280 total_steps:1464 epochs:146.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.72     0 274.4  1042       0          0 75.93  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001998    .1209 6.008 .0001632 4.995e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.2       0          0                 1464 394.5 1498 3.805            1\n\n23:02:45 | time:542s total_exs:29720 total_steps:1486 epochs:148.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.7     0   274  1042       0          0 76.07  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001835    .1209 6.014 .0001559 4.995e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.4       0          0                 1486 394.3 1500 3.819            1\n\n23:02:45 | running eval: valid\n23:02:45 | eval completed in 0.23s\n23:02:45 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1514       0          0 119.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6  1.26 4.995e-05    72   717       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1486  224 2231        .8322\n\u001b[0m\n23:02:45 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 24\u001b[0m\n23:02:45 | saving model checkpoint: /tmp/model5.checkpoint\n23:03:00 | time:557s total_exs:30500 total_steps:1525 epochs:152.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.86     0 277.2  1060       0          0 76.45  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001752    .1209 6.008 .0001488 4.995e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.3       0          0                 1525 397.4 1519 3.831            1\n\n23:03:05 | time:562s total_exs:30880 total_steps:1544 epochs:154.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.9     0 278.1  1075       0          0 77.35  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001675    .1209 5.974 .0001423 4.995e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     462       0          0                 1544 397.5 1537 3.885            1\n\n23:03:05 | running eval: valid\n23:03:05 | eval completed in 0.20s\n23:03:05 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1709       0          0 134.9   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 1.239 4.995e-05    72 809.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1544  224 2519        .8322\n\u001b[0m\n23:03:05 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 25\u001b[0m\n23:03:05 | saving model checkpoint: /tmp/model5.checkpoint\n23:03:20 | time:577s total_exs:31640 total_steps:1582 epochs:158.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.82     0 276.5  1031       0          0 74.56  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001611    .1209 6.058 .0001368 4.995e-05 121.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.7       0          0                 1582 397.6 1482 3.736            1\n\n23:03:25 | time:583s total_exs:32080 total_steps:1604 epochs:160.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.09     0 281.8  1094       0          0 77.65  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00154    .1209     6 .0001308 4.995e-05   120 465.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1604 401.8 1560 3.898            1\n\n23:03:25 | running eval: valid\n23:03:26 | eval completed in 0.19s\n23:03:26 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1729       0          0 136.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 1.215 4.995e-05    72 818.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1604  224 2548        .8322\n\u001b[0m\n23:03:26 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 26\u001b[0m\n23:03:26 | saving model checkpoint: /tmp/model5.checkpoint\n23:03:40 | time:597s total_exs:32860 total_steps:1643 epochs:164.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.79     0 275.8  1062       0          0 76.97  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001476    .1209 5.962 .0001251 4.995e-05 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.9       0          0                 1643 395.1 1520 3.857            1\n\n23:03:46 | time:603s total_exs:33300 total_steps:1665 epochs:166.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.87     0 277.3  1057       0          0 76.26  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001417    .1209 6.077 .0001202 4.995e-05 121.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.4       0          0                 1665 398.9 1521 3.828            1\n\n23:03:46 | running eval: valid\n23:03:46 | eval completed in 0.20s\n23:03:46 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1714       0          0 135.2   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 1.271 4.995e-05    72 811.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1665  224 2526        .8322\n\u001b[0m\nEpoch 00012: reducing learning rate of group 0 to 2.4975e-05.\n23:03:46 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 27\u001b[0m\n23:03:46 | saving model checkpoint: /tmp/model5.checkpoint\n23:04:01 | time:618s total_exs:34080 total_steps:1704 epochs:170.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.2  1044       0          0 76.14  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001374    .1210     6 .0001165 2.498e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.8       0          0                 1704 394.2 1501 3.815            1\n\n23:04:06 | time:623s total_exs:34480 total_steps:1724 epochs:172.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.09     0 281.7  1062       0          0 75.39  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001344    .1210  6.05 .0001141 2.498e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.1       0          0                 1724 402.7 1518 3.786            1\n\n23:04:06 | running eval: valid\n23:04:06 | eval completed in 0.20s\n23:04:06 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1716       0          0 135.4   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6  1.27 2.498e-05    72 812.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1724  224 2529        .8322\n\u001b[0m\n23:04:06 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 28\u001b[0m\n23:04:06 | saving model checkpoint: /tmp/model5.checkpoint\n23:04:21 | time:638s total_exs:35240 total_steps:1762 epochs:176.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.55     0 271.1  1015       0          0 74.91  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001317    .1210 5.955 .0001117 2.498e-05 119.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   446.1       0          0                 1762 390.2 1461 3.754            1\n\n23:04:26 | time:644s total_exs:35680 total_steps:1784 epochs:178.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.85     0   277  1068       0          0 77.13  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001287    .1210     6 .0001092 2.498e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   462.8       0          0                 1784  397 1531 3.872            1\n\n23:04:26 | running eval: valid\n23:04:27 | eval completed in 0.19s\n23:04:27 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1733       0          0 136.8   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 1.313 2.498e-05    72 820.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1784  224 2554        .8322\n\u001b[0m\n23:04:27 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 29\u001b[0m\n23:04:27 | saving model checkpoint: /tmp/model5.checkpoint\n23:04:41 | time:658s total_exs:36460 total_steps:1823 epochs:182.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.73     0 274.5  1058       0          0  77.1  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001264    .1210 6.087 .0001072 2.498e-05 121.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   469.3       0          0                 1823 396.3 1528 3.864            1\n\n23:04:47 | time:664s total_exs:36900 total_steps:1845 epochs:184.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.89     0 277.9  1082       0          0 77.85  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001235    .1210 6.027 .0001047 2.498e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   469.2       0          0                 1845 398.4 1551 3.908            1\n\n23:04:47 | running eval: valid\n23:04:47 | eval completed in 0.25s\n23:04:47 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1392       0          0 109.8   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08122     6 1.261 2.498e-05    72 659.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1845  224 2051        .8322\n\u001b[0m\n23:04:47 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 30\u001b[0m\n23:04:47 | saving model checkpoint: /tmp/model5.checkpoint\n23:04:52 | ran out of patience! stopping training.\n23:04:52 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n23:04:52 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n23:04:52 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run5/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n23:04:52 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n23:04:52 | Using CUDA\n23:04:52 | loading dictionary from /tmp/model5.dict\n23:04:52 | num words = 54944\n23:04:56 | Loading existing model parameters from /tmp/model5\n23:05:05 | Total parameters: 128,042,498 (128,042,498 trainable)\n23:05:06 | creating task(s): fromfile:parlaiformat\n23:05:06 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run5/data_valid.txt\n23:05:06 | running eval: valid\n23:05:06 | eval completed in 0.20s\n23:05:06 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1675       0          0 132.1   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297     6 .5548 5.354e-06    72 793.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    107  224 2468        .8748\n\u001b[0m\n23:05:06 | creating task(s): fromfile:parlaiformat\n23:05:06 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run5/data_test.txt\n23:05:07 | running eval: test\n23:05:11 | eval completed in 4.92s\n23:05:11 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9320 9.32e-10               .7190                 .6127   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8700            .9613              .9848   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9389 12.07 281.4  2874       0          0 204.3 1000 .9320   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297   5.2 .5250 5.354e-06   104  1062       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    107 385.4 3937        .9371\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr1type2/run5/data_test.txt -m transformer/classifier -mf /tmp/model5 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:05:13.776945Z","iopub.execute_input":"2022-12-03T23:05:13.777615Z","iopub.status.idle":"2022-12-03T23:05:44.198162Z","shell.execute_reply.started":"2022-12-03T23:05:13.777567Z","shell.execute_reply":"2022-12-03T23:05:44.196724Z"},"scrolled":true,"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"23:05:22 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr1type2/run5/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr1type2/run5/data)\u001b[0m\n23:05:22 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n23:05:22 | Using CUDA\n23:05:22 | loading dictionary from /tmp/model5.dict\n23:05:22 | num words = 54944\n23:05:27 | Loading existing model parameters from /tmp/model5\n23:05:33 | Total parameters: 128,042,498 (128,042,498 trainable)\n23:05:34 | Opt:\n23:05:34 |     activation: gelu\n23:05:34 |     adafactor_eps: '[1e-30, 0.001]'\n23:05:34 |     adam_eps: 1e-08\n23:05:34 |     add_p1_after_newln: False\n23:05:34 |     aggregate_micro: False\n23:05:34 |     allow_missing_init_opts: False\n23:05:34 |     area_under_curve_class: None\n23:05:34 |     area_under_curve_digits: -1\n23:05:34 |     attention_dropout: 0.1\n23:05:34 |     batchsize: 40\n23:05:34 |     betas: '[0.9, 0.999]'\n23:05:34 |     bpe_add_prefix_space: None\n23:05:34 |     bpe_debug: False\n23:05:34 |     bpe_dropout: None\n23:05:34 |     bpe_merge: None\n23:05:34 |     bpe_vocab: None\n23:05:34 |     candidates: inline\n23:05:34 |     cap_num_predictions: 100\n23:05:34 |     checkpoint_activations: False\n23:05:34 |     class_weights: None\n23:05:34 |     classes: \"['__notok__', '__ok__']\"\n23:05:34 |     classes_from_file: None\n23:05:34 |     data_parallel: True\n23:05:34 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n23:05:34 |     datatype: train\n23:05:34 |     delimiter: '\\n'\n23:05:34 |     dict_class: parlai.core.dict:DictionaryAgent\n23:05:34 |     dict_endtoken: __start__\n23:05:34 |     dict_file: /tmp/model5.dict\n23:05:34 |     dict_include_test: False\n23:05:34 |     dict_include_valid: False\n23:05:34 |     dict_initpath: None\n23:05:34 |     dict_language: english\n23:05:34 |     dict_loaded: True\n23:05:34 |     dict_lower: True\n23:05:34 |     dict_max_ngram_size: -1\n23:05:34 |     dict_maxexs: -1\n23:05:34 |     dict_maxtokens: -1\n23:05:34 |     dict_minfreq: 0\n23:05:34 |     dict_nulltoken: __null__\n23:05:34 |     dict_starttoken: __start__\n23:05:34 |     dict_textfields: text,labels\n23:05:34 |     dict_tokenizer: bpe\n23:05:34 |     dict_unktoken: __unk__\n23:05:34 |     display_examples: False\n23:05:34 |     download_path: None\n23:05:34 |     dropout: 0.1\n23:05:34 |     dynamic_batching: None\n23:05:34 |     embedding_projection: random\n23:05:34 |     embedding_size: 768\n23:05:34 |     embedding_type: random\n23:05:34 |     embeddings_scale: False\n23:05:34 |     encode_candidate_vecs: True\n23:05:34 |     encode_candidate_vecs_batchsize: 256\n23:05:34 |     eval_batchsize: None\n23:05:34 |     eval_candidates: inline\n23:05:34 |     eval_dynamic_batching: None\n23:05:34 |     evaltask: None\n23:05:34 |     ffn_size: 3072\n23:05:34 |     final_extra_opt: \n23:05:34 |     fixed_candidate_vecs: reuse\n23:05:34 |     fixed_candidates_path: None\n23:05:34 |     force_fp16_tokens: True\n23:05:34 |     fp16: True\n23:05:34 |     fp16_impl: safe\n23:05:34 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr1type2/run5/data_test.txt\n23:05:34 |     fromfile_datatype_extension: True\n23:05:34 |     gpu: -1\n23:05:34 |     gradient_clip: 0.1\n23:05:34 |     hide_labels: False\n23:05:34 |     history_add_global_end_token: None\n23:05:34 |     history_reversed: False\n23:05:34 |     history_size: 20\n23:05:34 |     ignore_bad_candidates: False\n23:05:34 |     ignore_labels: None\n23:05:34 |     image_cropsize: 224\n23:05:34 |     image_mode: raw\n23:05:34 |     image_size: 256\n23:05:34 |     inference: max\n23:05:34 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n23:05:34 |     init_opt: None\n23:05:34 |     interactive_candidates: fixed\n23:05:34 |     interactive_mode: False\n23:05:34 |     invsqrt_lr_decay_gamma: -1\n23:05:34 |     is_debug: False\n23:05:34 |     label_truncate: 72\n23:05:34 |     learn_embeddings: True\n23:05:34 |     learn_positional_embeddings: True\n23:05:34 |     learningrate: 5e-05\n23:05:34 |     load_from_pretrained_ranker: True\n23:05:34 |     log_every_n_secs: 10.0\n23:05:34 |     log_every_n_steps: 50\n23:05:34 |     log_keep_fields: all\n23:05:34 |     loglevel: info\n23:05:34 |     lr_scheduler: reduceonplateau\n23:05:34 |     lr_scheduler_decay: 0.5\n23:05:34 |     lr_scheduler_patience: 3\n23:05:34 |     max_train_steps: -1\n23:05:34 |     max_train_time: 7200.0\n23:05:34 |     memory_attention: sqrt\n23:05:34 |     metrics: default\n23:05:34 |     model: transformer/classifier\n23:05:34 |     model_file: /tmp/model5\n23:05:34 |     model_parallel: False\n23:05:34 |     momentum: 0\n23:05:34 |     multitask_weights: [1]\n23:05:34 |     mutators: None\n23:05:34 |     n_decoder_layers: -1\n23:05:34 |     n_encoder_layers: -1\n23:05:34 |     n_heads: 12\n23:05:34 |     n_layers: 12\n23:05:34 |     n_positions: 1024\n23:05:34 |     n_segments: 2\n23:05:34 |     nesterov: True\n23:05:34 |     no_cuda: False\n23:05:34 |     normalize_sent_emb: False\n23:05:34 |     num_epochs: -1\n23:05:34 |     num_examples: -1\n23:05:34 |     num_workers: 0\n23:05:34 |     nus: [0.7]\n23:05:34 |     optimizer: adamax\n23:05:34 |     output_scaling: 0.06\n23:05:34 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr1type2/run5/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model5', 'batchsize': 40}\"\n23:05:34 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n23:05:34 |     person_tokens: False\n23:05:34 |     print_scores: False\n23:05:34 |     rank_candidates: False\n23:05:34 |     rank_top_k: -1\n23:05:34 |     reduction_type: mean\n23:05:34 |     ref_class: None\n23:05:34 |     relu_dropout: 0.0\n23:05:34 |     repeat_blocking_heuristic: True\n23:05:34 |     report_filename: \n23:05:34 |     return_cand_scores: False\n23:05:34 |     save_after_valid: True\n23:05:34 |     save_every_n_secs: -1\n23:05:34 |     save_format: conversations\n23:05:34 |     share_encoders: False\n23:05:34 |     share_word_embeddings: False\n23:05:34 |     short_final_eval: False\n23:05:34 |     special_tok_lst: None\n23:05:34 |     split_lines: False\n23:05:34 |     starttime: Dec03_22-53\n23:05:34 |     task: fromfile:parlaiformat\n23:05:34 |     tensorboard_log: False\n23:05:34 |     tensorboard_logdir: None\n23:05:34 |     text_truncate: 360\n23:05:34 |     threshold: 0.5\n23:05:34 |     topk: 5\n23:05:34 |     train_predict: False\n23:05:34 |     truncate: 1024\n23:05:34 |     update_classifier_head_only: False\n23:05:34 |     update_freq: 1\n23:05:34 |     use_memories: False\n23:05:34 |     use_reply: none\n23:05:34 |     validation_cutoff: 1.0\n23:05:34 |     validation_every_n_epochs: -1\n23:05:34 |     validation_every_n_secs: 20.0\n23:05:34 |     validation_every_n_steps: -1\n23:05:34 |     validation_max_exs: -1\n23:05:34 |     validation_metric: accuracy\n23:05:34 |     validation_metric_mode: max\n23:05:34 |     validation_patience: 30\n23:05:34 |     validation_share_agent: False\n23:05:34 |     variant: xlm\n23:05:34 |     verbose: False\n23:05:34 |     wandb_entity: None\n23:05:34 |     wandb_log: False\n23:05:34 |     wandb_name: None\n23:05:34 |     wandb_project: None\n23:05:34 |     warmup_rate: 0.0001\n23:05:34 |     warmup_updates: 1000\n23:05:34 |     weight_decay: None\n23:05:34 |     world_logs: \n23:05:34 |     wrap_memory_encoder: False\n23:05:34 | Evaluating task fromfile:parlaiformat using datatype valid.\n23:05:34 | creating task(s): fromfile:parlaiformat\n23:05:34 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n23:05:34 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr1type2/run5/data_test.txt\n23:05:42 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9320 9.32e-10               .7190                 .6127   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8700            .9613              .9848   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9389 12.07 562.9  1912       0          0 135.9 1000 .9320   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5250 5.354e-06   208 706.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    107 770.9 2619        .9371\u001b[0m\n23:05:42 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9320 9.32e-10               .7190                 .6127   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8700            .9613              .9848   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9389 12.07 562.9  1912       0          0 135.9 1000 .9320   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5250 5.354e-06   208 706.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    107 770.9 2619        .9371\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model5*","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:05:44.200209Z","iopub.execute_input":"2022-12-03T23:05:44.200637Z","iopub.status.idle":"2022-12-03T23:05:45.443834Z","shell.execute_reply.started":"2022-12-03T23:05:44.200585Z","shell.execute_reply":"2022-12-03T23:05:45.442417Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Actual code prev1corr2type1","metadata":{}},{"cell_type":"markdown","source":"run 1","metadata":{}},{"cell_type":"code","source":"# run 1 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type1/run1/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model1","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:05:45.445705Z","iopub.execute_input":"2022-12-03T23:05:45.446264Z","iopub.status.idle":"2022-12-03T23:17:39.090700Z","shell.execute_reply.started":"2022-12-03T23:05:45.446190Z","shell.execute_reply":"2022-12-03T23:17:39.089496Z"},"scrolled":true,"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"23:05:52 | building dictionary first...\n23:05:52 | No model with opt yet at: /tmp/model1(.opt)\n23:05:52 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run1/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n23:05:52 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n23:05:52 | Using CUDA\n23:05:52 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n23:05:52 | num words = 54944\n23:05:57 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n23:06:07 | Total parameters: 128,042,498 (128,042,498 trainable)\n23:06:07 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n23:06:07 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n23:06:07 | Opt:\n23:06:07 |     activation: gelu\n23:06:07 |     adafactor_eps: '(1e-30, 0.001)'\n23:06:07 |     adam_eps: 1e-08\n23:06:07 |     add_p1_after_newln: False\n23:06:07 |     aggregate_micro: False\n23:06:07 |     allow_missing_init_opts: False\n23:06:07 |     attention_dropout: 0.1\n23:06:07 |     batchsize: 20\n23:06:07 |     betas: '(0.9, 0.999)'\n23:06:07 |     bpe_add_prefix_space: None\n23:06:07 |     bpe_debug: False\n23:06:07 |     bpe_dropout: None\n23:06:07 |     bpe_merge: None\n23:06:07 |     bpe_vocab: None\n23:06:07 |     candidates: inline\n23:06:07 |     cap_num_predictions: 100\n23:06:07 |     checkpoint_activations: False\n23:06:07 |     class_weights: None\n23:06:07 |     classes: \"['__notok__', '__ok__']\"\n23:06:07 |     classes_from_file: None\n23:06:07 |     data_parallel: True\n23:06:07 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n23:06:07 |     datatype: train\n23:06:07 |     delimiter: '\\n'\n23:06:07 |     dict_class: parlai.core.dict:DictionaryAgent\n23:06:07 |     dict_endtoken: __start__\n23:06:07 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n23:06:07 |     dict_include_test: False\n23:06:07 |     dict_include_valid: False\n23:06:07 |     dict_initpath: None\n23:06:07 |     dict_language: english\n23:06:07 |     dict_loaded: True\n23:06:07 |     dict_lower: True\n23:06:07 |     dict_max_ngram_size: -1\n23:06:07 |     dict_maxexs: -1\n23:06:07 |     dict_maxtokens: -1\n23:06:07 |     dict_minfreq: 0\n23:06:07 |     dict_nulltoken: __null__\n23:06:07 |     dict_starttoken: __start__\n23:06:07 |     dict_textfields: text,labels\n23:06:07 |     dict_tokenizer: bpe\n23:06:07 |     dict_unktoken: __unk__\n23:06:07 |     display_examples: False\n23:06:07 |     download_path: None\n23:06:07 |     dropout: 0.1\n23:06:07 |     dynamic_batching: None\n23:06:07 |     embedding_projection: random\n23:06:07 |     embedding_size: 768\n23:06:07 |     embedding_type: random\n23:06:07 |     embeddings_scale: False\n23:06:07 |     encode_candidate_vecs: True\n23:06:07 |     encode_candidate_vecs_batchsize: 256\n23:06:07 |     eval_batchsize: None\n23:06:07 |     eval_candidates: inline\n23:06:07 |     eval_dynamic_batching: None\n23:06:07 |     evaltask: None\n23:06:07 |     ffn_size: 3072\n23:06:07 |     final_extra_opt: \n23:06:07 |     fixed_candidate_vecs: reuse\n23:06:07 |     fixed_candidates_path: None\n23:06:07 |     force_fp16_tokens: False\n23:06:07 |     fp16: True\n23:06:07 |     fp16_impl: safe\n23:06:07 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run1/data\n23:06:07 |     fromfile_datatype_extension: True\n23:06:07 |     gpu: -1\n23:06:07 |     gradient_clip: 0.1\n23:06:07 |     hide_labels: False\n23:06:07 |     history_add_global_end_token: None\n23:06:07 |     history_reversed: False\n23:06:07 |     history_size: 20\n23:06:07 |     ignore_bad_candidates: False\n23:06:07 |     ignore_labels: None\n23:06:07 |     image_cropsize: 224\n23:06:07 |     image_mode: raw\n23:06:07 |     image_size: 256\n23:06:07 |     inference: max\n23:06:07 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n23:06:07 |     init_opt: None\n23:06:07 |     interactive_candidates: fixed\n23:06:07 |     interactive_mode: False\n23:06:07 |     invsqrt_lr_decay_gamma: -1\n23:06:07 |     is_debug: False\n23:06:07 |     label_truncate: 72\n23:06:07 |     learn_embeddings: True\n23:06:07 |     learn_positional_embeddings: True\n23:06:07 |     learningrate: 5e-05\n23:06:07 |     load_from_checkpoint: False\n23:06:07 |     load_from_pretrained_ranker: True\n23:06:07 |     log_every_n_secs: 10.0\n23:06:07 |     log_every_n_steps: 50\n23:06:07 |     log_keep_fields: all\n23:06:07 |     loglevel: info\n23:06:07 |     lr_scheduler: reduceonplateau\n23:06:07 |     lr_scheduler_decay: 0.5\n23:06:07 |     lr_scheduler_patience: 3\n23:06:07 |     max_train_steps: -1\n23:06:07 |     max_train_time: 7200.0\n23:06:07 |     memory_attention: sqrt\n23:06:07 |     metrics: default\n23:06:07 |     model: transformer/classifier\n23:06:07 |     model_file: /tmp/model1\n23:06:07 |     model_parallel: False\n23:06:07 |     momentum: 0\n23:06:07 |     multitask_weights: [1]\n23:06:07 |     mutators: None\n23:06:07 |     n_decoder_layers: -1\n23:06:07 |     n_encoder_layers: -1\n23:06:07 |     n_heads: 12\n23:06:07 |     n_layers: 12\n23:06:07 |     n_positions: 1024\n23:06:07 |     n_segments: 2\n23:06:07 |     nesterov: True\n23:06:07 |     no_cuda: False\n23:06:07 |     normalize_sent_emb: False\n23:06:07 |     num_epochs: -1\n23:06:07 |     num_workers: 0\n23:06:07 |     nus: (0.7,)\n23:06:07 |     optimizer: adamax\n23:06:07 |     output_scaling: 0.06\n23:06:07 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type1/run1/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model1'}\"\n23:06:07 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n23:06:07 |     person_tokens: False\n23:06:07 |     print_scores: False\n23:06:07 |     rank_candidates: False\n23:06:07 |     rank_top_k: -1\n23:06:07 |     reduction_type: mean\n23:06:07 |     ref_class: None\n23:06:07 |     relu_dropout: 0.0\n23:06:07 |     repeat_blocking_heuristic: True\n23:06:07 |     return_cand_scores: False\n23:06:07 |     save_after_valid: True\n23:06:07 |     save_every_n_secs: -1\n23:06:07 |     save_format: conversations\n23:06:07 |     share_encoders: False\n23:06:07 |     share_word_embeddings: False\n23:06:07 |     short_final_eval: False\n23:06:07 |     special_tok_lst: None\n23:06:07 |     split_lines: False\n23:06:07 |     starttime: Dec03_23-05\n23:06:07 |     task: fromfile:parlaiformat\n23:06:07 |     tensorboard_log: False\n23:06:07 |     tensorboard_logdir: None\n23:06:07 |     text_truncate: 360\n23:06:07 |     threshold: 0.5\n23:06:07 |     topk: 5\n23:06:07 |     train_predict: False\n23:06:07 |     truncate: 1024\n23:06:07 |     update_classifier_head_only: False\n23:06:07 |     update_freq: 1\n23:06:07 |     use_memories: False\n23:06:07 |     use_reply: none\n23:06:07 |     validation_cutoff: 1.0\n23:06:07 |     validation_every_n_epochs: -1\n23:06:07 |     validation_every_n_secs: 20.0\n23:06:07 |     validation_every_n_steps: -1\n23:06:07 |     validation_max_exs: -1\n23:06:07 |     validation_metric: accuracy\n23:06:07 |     validation_metric_mode: max\n23:06:07 |     validation_patience: 30\n23:06:07 |     validation_share_agent: False\n23:06:07 |     variant: xlm\n23:06:07 |     verbose: False\n23:06:07 |     wandb_entity: None\n23:06:07 |     wandb_log: False\n23:06:07 |     wandb_name: None\n23:06:07 |     wandb_project: None\n23:06:07 |     warmup_rate: 0.0001\n23:06:07 |     warmup_updates: 1000\n23:06:07 |     weight_decay: None\n23:06:07 |     world_logs: \n23:06:07 |     wrap_memory_encoder: False\n23:06:08 | creating task(s): fromfile:parlaiformat\n23:06:08 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run1/data_train.txt\n23:06:08 | training...\n23:06:18 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .4900 4.9e-10               .5143                 .4909   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5400            .4632              .4889   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .4400 11.33     1 266.6 530.2       0          0 39.78  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .4900             32768  2.568    .1189     6 .6994 1.005e-06   120 238.7   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 386.6 768.9 1.994        .4887\n\n23:06:28 | time:20s total_exs:1140 total_steps:57 epochs:5.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5932 5.932e-10               .6343                 .5826   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6960            .5419              .6096   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .4877 11.14     1 262.8 980.5       0          0 74.63  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5932             32768  2.576    .1189 6.014 .6756 2.855e-06 120.3 448.8   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps  ups  weighted_f1  \n         0          0                   57  383 1429 3.74        .5887\n\n23:06:28 | creating task(s): fromfile:parlaiformat\n23:06:28 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run1/data_valid.txt\n23:06:28 | running eval: valid\n23:06:28 | eval completed in 0.20s\n23:06:28 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7857                 .6875   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .7000              .8750   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .5833 11.46 161.5  1778       0          0   132   24 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6568 2.855e-06    72 792.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     57 233.5 2571        .7429\n\u001b[0m\n23:06:28 | \u001b[1;32mnew best accuracy: 0.75\u001b[0m\n23:06:28 | saving best valid model: /tmp/model1\n23:06:28 | Saving dictionary to /tmp/model1.dict\n23:06:32 | saving model checkpoint: /tmp/model1.checkpoint\n23:06:32 | Saving dictionary to /tmp/model1.checkpoint.dict\n23:06:49 | time:41s total_exs:1860 total_steps:93 epochs:9.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8208 8.208e-10               .8268                 .7758   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8851            .8144              .8762   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7608  11.1     1 261.9 924.6       0          0  70.6  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8208             32768  2.517    .1189 5.967 .6191 4.655e-06 119.3 421.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   93 381.2 1346 3.538        .8204\n\n23:06:52 | time:45s total_exs:2140 total_steps:107 epochs:10.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9321 9.321e-10               .9329                 .9429   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9231            .9314              .9214   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9416 11.01     1 260.1  1027       0          0 78.95  280   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9321             32768  2.891    .1189 6.021 .5502 5.354e-06 120.4 475.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  107 380.6 1502 3.973        .9322\n\n23:06:52 | running eval: valid\n23:06:53 | eval completed in 0.20s\n23:06:53 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 11.46 161.5  1764       0          0 131.1   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5630 5.354e-06    72 786.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    107 233.5 2551        .9161\n\u001b[0m\n23:06:53 | \u001b[1;32mnew best accuracy: 0.9167 (previous best was 0.75)\u001b[0m\n23:06:53 | saving best valid model: /tmp/model1\n23:07:02 | saving model checkpoint: /tmp/model1.checkpoint\n23:07:17 | time:70s total_exs:2920 total_steps:146 epochs:14.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9667 9.667e-10               .9682                 .9706   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9659            .9650              .9624   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9676 11.34     1 266.7  1024       0          0 76.78  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9667             32768  3.388    .1189 6.051 .3942 7.304e-06   121 464.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  146 387.7 1489 3.848        .9667\n\n23:07:22 | time:75s total_exs:3320 total_steps:166 epochs:16.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9900 9.9e-10               .9901                 .9950   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9853            .9898              .9848   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9949 11.19     1 263.7  1012       0          0 76.72  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9900             32768  3.178    .1189  6.02 .1698 8.304e-06 120.4 461.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  166 384.1 1473 3.853        .9900\n\n23:07:22 | running eval: valid\n23:07:23 | eval completed in 0.20s\n23:07:23 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1771       0          0 131.6   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .3182 8.304e-06    72 789.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    166 233.5 2561        .8748\n\u001b[0m\n23:07:23 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 1\u001b[0m\n23:07:23 | saving model checkpoint: /tmp/model1.checkpoint\n23:07:43 | time:95s total_exs:4100 total_steps:205 epochs:20.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9821 9.821e-10               .9834                 .9787   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9881            .9805              .9860   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9751 11.01     1 260.2 998.3       0          0 76.74  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9821             32768  4.221    .1190 6.074 .08271 1.025e-05 121.5 466.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  205 381.6 1464 3.846        .9820\n\n23:07:43 | time:95s total_exs:4120 total_steps:206 epochs:20.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.55     1   251   920       0          0  73.3   20   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n     1             32768  .2893    .1190   6.3 .01928 1.03e-05   126 461.8   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  206  377 1382 3.863            1\n\n23:07:43 | running eval: valid\n23:07:43 | eval completed in 0.23s\n23:07:43 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1601       0          0 118.9   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .4482 1.03e-05    72 713.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    206 233.5 2315        .8322\n\u001b[0m\n23:07:43 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 2\u001b[0m\n23:07:43 | saving model checkpoint: /tmp/model1.checkpoint\n23:07:58 | time:111s total_exs:4900 total_steps:245 epochs:24.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9962 9.962e-10               .9963                 .9951   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9975            .9960              .9973   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9946 11.22 .5385 264.3  1007       0          0  76.2  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9962             32768  2.119    .1190 6.044 .02429 1.225e-05 120.9 460.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  245 385.2 1468 3.819        .9962\n\n23:08:03 | time:116s total_exs:5260 total_steps:263 epochs:26.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9944 9.944e-10               .9951                 .9903   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9935                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9872 11.01 .1667 260.1 967.8       0          0 74.42  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9944             32768  3.296    .1190 6.133 .01688 1.315e-05 122.7 456.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  263 382.8 1424 3.738        .9944\n\n23:08:03 | running eval: valid\n23:08:03 | eval completed in 0.20s\n23:08:03 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8000                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8571              .7500   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 11.46 161.5  1813       0          0 134.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .9484 1.315e-05    72 808.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    263 233.5 2622        .8286\n\u001b[0m\n23:08:03 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 3\u001b[0m\n23:08:03 | saving model checkpoint: /tmp/model1.checkpoint\n23:08:18 | time:131s total_exs:6040 total_steps:302 epochs:30.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.31     0 266.3  1024       0          0 76.91  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .02424    .1190 6.023 .001993 1.51e-05 120.5 463.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  302 386.7 1487 3.854            1\n\n23:08:24 | time:136s total_exs:6440 total_steps:322 epochs:32.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.11     0 262.2  1016       0          0 77.46  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768  .0185    .1190 5.955 .001541 1.61e-05 119.1 461.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  322 381.4 1477 3.89            1\n\n23:08:24 | running eval: valid\n23:08:24 | eval completed in 0.21s\n23:08:24 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1723       0          0 127.9   24 .7917   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 1.046 1.61e-05    72 767.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    322 233.5 2491        .7913\n\u001b[0m\n23:08:24 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 4\u001b[0m\n23:08:24 | saving model checkpoint: /tmp/model1.checkpoint\n23:08:39 | time:151s total_exs:7200 total_steps:360 epochs:36.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.1     0 261.9 980.2       0          0 74.84  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss      lr  ltpb  ltps  \\\n     1             32768 .01572    .1190 5.966 .001329 1.8e-05 119.3 446.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  360 381.3 1427 3.75            1\n\n23:08:44 | time:156s total_exs:7620 total_steps:381 epochs:38.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.06     0 261.1  1012       0          0 77.51  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01402    .1190 5.986 .001193 1.905e-05 119.7   464   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  381 380.9 1476 3.892            1\n\n23:08:44 | running eval: valid\n23:08:44 | eval completed in 0.20s\n23:08:44 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1809       0          0 134.4   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6  1.14 1.905e-05    72 806.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    381 233.5 2616        .7884\n\u001b[0m\n23:08:44 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 5\u001b[0m\n23:08:44 | saving model checkpoint: /tmp/model1.checkpoint\n23:08:59 | time:171s total_exs:8400 total_steps:420 epochs:42.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.09     0 261.8  1007       0          0  76.9  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss      lr  ltpb  ltps  \\\n     1             32768 .01288    .1190 5.959 .001097 2.1e-05 119.2 458.2   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  420  381 1465 3.853            1\n\n23:09:04 | time:177s total_exs:8780 total_steps:439 epochs:43.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.13     0 262.7   955       0          0 72.71  380   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01197    .1190 5.958 .001021 2.195e-05 119.2 433.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  439 381.8 1388 3.651            1\n\n23:09:04 | running eval: valid\n23:09:04 | eval completed in 0.22s\n23:09:04 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1605       0          0 119.2   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08095     6 1.132 2.195e-05    72 715.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    439 233.5 2320        .8322\n\u001b[0m\n23:09:04 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 6\u001b[0m\n23:09:04 | saving model checkpoint: /tmp/model1.checkpoint\n23:09:19 | time:191s total_exs:9560 total_steps:478 epochs:47.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.22     0 264.3  1013       0          0 76.63  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .01128    .1190 5.969 .0009595 2.39e-05 119.4 457.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  478 383.7 1470 3.84            1\n\n23:09:25 | time:197s total_exs:9980 total_steps:499 epochs:49.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.08     0 261.5 974.9       0          0 74.55  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01052    .1190 5.957 .0009008 2.495e-05 119.1 444.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  499 380.7 1419 3.743            1\n\n23:09:25 | running eval: valid\n23:09:25 | eval completed in 0.20s\n23:09:25 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1776       0          0 131.9   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 1.163 2.495e-05    72 791.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    499 233.5 2567        .8322\n\u001b[0m\n23:09:25 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 7\u001b[0m\n23:09:25 | saving model checkpoint: /tmp/model1.checkpoint\n23:09:39 | time:212s total_exs:10740 total_steps:537 epochs:53.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.1     0 262.1 991.2       0          0 75.65  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .009974    .1190 6.011 .0008503 2.685e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   454.7       0          0                  537 382.3 1446 3.791            1\n\n23:09:45 | time:217s total_exs:11160 total_steps:558 epochs:55.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.95     0 259.1 997.3       0          0 76.98  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .009772    .1190 6.057 .0008044 2.79e-05 121.1 466.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  558 380.2 1464 3.865            1\n\n23:09:45 | running eval: valid\n23:09:45 | eval completed in 0.20s\n23:09:45 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1771       0          0 131.5   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 1.183 2.79e-05    72 789.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    558 233.5 2560        .8322\n\u001b[0m\n23:09:45 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 8\u001b[0m\n23:09:45 | saving model checkpoint: /tmp/model1.checkpoint\n23:10:00 | time:232s total_exs:11940 total_steps:597 epochs:59.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.94     0 258.9 990.8       0          0 76.55  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .008888    .1190 6.003 .0007573 2.985e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.5       0          0                  597 378.9 1450 3.836            1\n\n23:10:05 | time:238s total_exs:12380 total_steps:619 epochs:61.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.27     0 265.4  1033       0          0 77.82  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .008345    .1190 6.055 .0007126 3.095e-05 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   471.2       0          0                  619 386.5 1504 3.907            1\n\n23:10:05 | running eval: valid\n23:10:06 | eval completed in 0.20s\n23:10:06 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1804       0          0   134   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 1.216 3.095e-05    72   804       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    619 233.5 2608        .8322\n\u001b[0m\n23:10:06 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 9\u001b[0m\n23:10:06 | saving model checkpoint: /tmp/model1.checkpoint\n23:10:21 | time:253s total_exs:13160 total_steps:658 epochs:65.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.14     0 262.8  1009       0          0 76.76  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .007881    .1190 6.023 .0006718 3.29e-05 120.5 462.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  658 383.2 1471 3.847            1\n\n23:10:26 | time:258s total_exs:13540 total_steps:677 epochs:67.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.08     0 261.7  1026       0          0 78.42  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .007484    .1190 6.016 .0006345 3.385e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   471.8       0          0                  677  382 1498 3.939            1\n\n23:10:26 | running eval: valid\n23:10:26 | eval completed in 0.20s\n23:10:26 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1787       0          0 132.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 1.238 3.385e-05    72 796.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    677 233.5 2584        .8322\n\u001b[0m\n23:10:26 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 10\u001b[0m\n23:10:26 | saving model checkpoint: /tmp/model1.checkpoint\n23:10:40 | time:273s total_exs:14300 total_steps:715 epochs:71.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.03     0 260.7 972.2       0          0 74.59  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .007043    .1190 6.021 .0005995 3.575e-05 120.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.1       0          0                  715 381.1 1421 3.738            1\n\n23:10:46 | time:278s total_exs:14720 total_steps:736 epochs:73.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.95     0 259.1  1008       0          0 77.79  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .006657    .1190  6.01 .0005658 3.68e-05 120.2 467.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  736 379.3 1475 3.906            1\n\n23:10:46 | running eval: valid\n23:10:46 | eval completed in 0.20s\n23:10:46 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1782       0          0 132.4   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 1.258 3.68e-05    72 794.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    736 233.5 2576        .8322\n\u001b[0m\n23:10:46 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 11\u001b[0m\n23:10:46 | saving model checkpoint: /tmp/model1.checkpoint\n23:11:00 | time:293s total_exs:15500 total_steps:775 epochs:77.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.27     0 265.5  1029       0          0 77.51  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006259    .1191 5.967 .0005327 3.875e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   462.5       0          0                  775 384.8 1491 3.884            1\n\n23:11:06 | time:298s total_exs:15920 total_steps:796 epochs:79.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.11     0 262.3 994.6       0          0 75.84  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .005887    .1191 5.986 .0005007 3.98e-05 119.7   454   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  796  382 1449 3.808            1\n\n23:11:06 | running eval: valid\n23:11:06 | eval completed in 0.20s\n23:11:06 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1794       0          0 133.3   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 1.283 3.98e-05    72 799.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    796 233.5 2594        .8322\n\u001b[0m\n23:11:06 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 12\u001b[0m\n23:11:06 | saving model checkpoint: /tmp/model1.checkpoint\n23:11:21 | time:313s total_exs:16700 total_steps:835 epochs:83.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.38     0 267.6  1028       0          0 76.85  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .005542    .1191 6.026 .0004712 4.175e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.1       0          0                  835 388.1 1491 3.851            1\n\n23:11:26 | time:319s total_exs:17120 total_steps:856 epochs:85.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.18     0 263.6  1002       0          0 76.03  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .005225    .1191 5.995 .000444 4.28e-05 119.9 455.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  856 383.5 1458 3.817            1\n\n23:11:26 | running eval: valid\n23:11:27 | eval completed in 0.20s\n23:11:27 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1801       0          0 133.8   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 1.298 4.28e-05    72 802.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    856 233.5 2604        .8322\n\u001b[0m\n23:11:27 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 13\u001b[0m\n23:11:27 | saving model checkpoint: /tmp/model1.checkpoint\n23:11:41 | time:333s total_exs:17900 total_steps:895 epochs:89.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.83     0 256.7 985.3       0          0 76.78  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004928    .1191 5.962 .0004184 4.475e-05 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.7       0          0                  895 375.9 1443 3.847            1\n\n23:11:47 | time:339s total_exs:18320 total_steps:916 epochs:91.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.35     0   267 980.1       0          0  73.4  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .004636    .1191 5.957 .0003933 4.58e-05 119.1 437.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  916 386.2 1417 3.685            1\n\n23:11:47 | running eval: valid\n23:11:47 | eval completed in 0.19s\n23:11:47 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1838       0          0 136.6   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 1.313 4.58e-05    72 819.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    916 233.5 2658        .8322\n\u001b[0m\n23:11:47 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 14\u001b[0m\n23:11:47 | saving model checkpoint: /tmp/model1.checkpoint\n23:12:02 | time:354s total_exs:19100 total_steps:955 epochs:95.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.85     0 257.1 988.6       0          0 76.91  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00436    .1191 5.992 .0003698 4.775e-05 119.8 460.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  955 376.9 1450 3.854            1\n\n23:12:07 | time:360s total_exs:19520 total_steps:976 epochs:97.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.4     0 268.1  1027       0          0  76.6  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .004098    .1191 5.957 .0003478 4.88e-05 119.1 456.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  976 387.2 1483 3.846            1\n\n23:12:07 | running eval: valid\n23:12:08 | eval completed in 0.22s\n23:12:08 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1686       0          0 125.2   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 1.312 4.88e-05    72 751.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    976 233.5 2437        .8322\n\u001b[0m\n23:12:08 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 15\u001b[0m\n23:12:08 | saving model checkpoint: /tmp/model1.checkpoint\n23:12:22 | time:374s total_exs:20280 total_steps:1014 epochs:101.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.03     0 260.7 984.4       0          0 75.52  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003859    .1191 6.034 .0003273 4.995e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   455.7       0          0                 1014 381.4 1440 3.785            1\n\n23:12:28 | time:380s total_exs:20720 total_steps:1036 epochs:103.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.99     0 259.9  1012       0          0 77.88  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003636    .1191     6 .0003083 4.995e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   467.3       0          0                 1036 379.9 1479 3.91            1\n\n23:12:28 | running eval: valid\n23:12:28 | eval completed in 0.20s\n23:12:28 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1787       0          0 132.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6 1.324 4.995e-05    72 796.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1036 233.5 2583        .8322\n\u001b[0m\n23:12:28 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 16\u001b[0m\n23:12:28 | saving model checkpoint: /tmp/model1.checkpoint\n23:12:42 | time:395s total_exs:21500 total_steps:1075 epochs:107.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.12     0 262.5  1016       0          0 77.45  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003638    .1191 5.949 .0002911 4.995e-05   119   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.7       0          0                 1075 381.5 1477 3.881            1\n\n23:12:48 | time:400s total_exs:21920 total_steps:1096 epochs:109.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.25     0   265   986       0          0 74.42  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003242    .1191 5.962 .0002745 4.995e-05 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   443.7       0          0                 1096 384.2 1430 3.736            1\n\n23:12:48 | running eval: valid\n23:12:48 | eval completed in 0.20s\n23:12:48 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1805       0          0 134.1   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 1.397 4.995e-05    72 804.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1096 233.5 2610        .8322\n\u001b[0m\n23:12:48 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 17\u001b[0m\n23:12:48 | saving model checkpoint: /tmp/model1.checkpoint\n23:13:03 | time:415s total_exs:22700 total_steps:1135 epochs:113.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.97     0 259.5 995.3       0          0 76.72  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003067    .1191 5.977 .0002596 4.995e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   458.5       0          0                 1135  379 1454 3.844            1\n\n23:13:09 | time:421s total_exs:23140 total_steps:1157 epochs:115.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.85     0   257  1005       0          0 78.19  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002897    .1191 6.095 .0002454 4.995e-05 121.9   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   476.6       0          0                 1157  379 1482 3.926            1\n\n23:13:09 | running eval: valid\n23:13:09 | eval completed in 0.20s\n23:13:09 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1789       0          0 132.9   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 1.403 4.995e-05    72 797.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1157 233.5 2587        .8322\n\u001b[0m\n23:13:09 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 18\u001b[0m\n23:13:09 | saving model checkpoint: /tmp/model1.checkpoint\n23:13:23 | time:435s total_exs:23900 total_steps:1195 epochs:119.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.22     0 264.4  1000       0          0 75.67  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .002754    .1191 5.966 .000233 4.995e-05 119.3 451.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1195 383.7 1452 3.792            1\n\n23:13:29 | time:441s total_exs:24340 total_steps:1217 epochs:121.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.04     0 260.8 999.3       0          0 76.64  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002608    .1191 6.023 .0002207 4.995e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.6       0          0                 1217 381.2 1461 3.848            1\n\n23:13:29 | running eval: valid\n23:13:29 | eval completed in 0.21s\n23:13:29 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1719       0          0 127.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6 1.425 4.995e-05    72 766.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1217 233.5 2485        .8322\n\u001b[0m\n23:13:29 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 19\u001b[0m\n23:13:29 | saving model checkpoint: /tmp/model1.checkpoint\n23:13:44 | time:456s total_exs:25120 total_steps:1256 epochs:125.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  10.9     0 258.1 994.4       0          0 77.06  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002484    .1191 5.982 .0002102 4.995e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     461       0          0                 1256 377.7 1455 3.862            1\n\n23:13:49 | time:461s total_exs:25500 total_steps:1275 epochs:127.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.2     0   264 965.4       0          0 73.13  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002368    .1191 5.958 .0002003 4.995e-05 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   435.7       0          0                 1275 383.2 1401 3.673            1\n\n23:13:49 | running eval: valid\n23:13:49 | eval completed in 0.21s\n23:13:49 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1682       0          0 124.9   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 1.446 4.995e-05    72 749.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1275 233.5 2432        .8322\n\u001b[0m\nEpoch 00005: reducing learning rate of group 0 to 2.4975e-05.\n23:13:49 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 20\u001b[0m\n23:13:49 | saving model checkpoint: /tmp/model1.checkpoint\n23:14:04 | time:477s total_exs:26280 total_steps:1314 epochs:131.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.21     0 264.1  1008       0          0  76.3  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002291    .1192 6.013 .0001938 2.498e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.8       0          0                 1314 384.4 1466 3.823            1\n\n23:14:09 | time:482s total_exs:26660 total_steps:1333 epochs:133.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.39     0 267.8  1024       0          0 76.48  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002238    .1192 5.974 .0001893 2.498e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.8       0          0                 1333 387.3 1481 3.841            1\n\n23:14:09 | running eval: valid\n23:14:10 | eval completed in 0.20s\n23:14:10 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1803       0          0 133.9   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6  1.45 2.498e-05    72 803.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1333 233.5 2607        .8322\n\u001b[0m\n23:14:10 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 21\u001b[0m\n23:14:10 | saving model checkpoint: /tmp/model1.checkpoint\n23:14:24 | time:496s total_exs:27420 total_steps:1371 epochs:137.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1    11     0 259.9 978.8       0          0  75.3  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002189    .1192 5.939 .0001851 2.498e-05 118.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   447.3       0          0                 1371 378.7 1426 3.774            1\n\n23:14:30 | time:502s total_exs:27860 total_steps:1393 epochs:139.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.98     0 259.6  1010       0          0 77.79  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002183    .1192 5.945 .0001807 2.498e-05 118.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   462.5       0          0                 1393 378.5 1472 3.899            1\n\n23:14:30 | running eval: valid\n23:14:30 | eval completed in 0.23s\n23:14:30 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1594       0          0 118.3   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 1.456 2.498e-05    72 710.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1393 233.5 2305        .8322\n\u001b[0m\n23:14:30 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 22\u001b[0m\n23:14:30 | saving model checkpoint: /tmp/model1.checkpoint\n23:14:45 | time:517s total_exs:28640 total_steps:1432 epochs:143.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.71     0 254.2 975.2       0          0 76.73  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002083    .1192 6.064 .0001759 2.498e-05 121.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   465.3       0          0                 1432 375.5 1440 3.845            1\n\n23:14:50 | time:523s total_exs:29060 total_steps:1453 epochs:145.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.37     0 267.4  1048       0          0 78.37  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00203    .1192     6 .0001716 2.498e-05   120 470.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1453 387.4 1518 3.935            1\n\n23:14:50 | running eval: valid\n23:14:51 | eval completed in 0.20s\n23:14:51 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1768       0          0 131.3   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6 1.468 2.498e-05    72 788.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1453 233.5 2557        .8322\n\u001b[0m\n23:14:51 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 23\u001b[0m\n23:14:51 | saving model checkpoint: /tmp/model1.checkpoint\n23:15:06 | time:538s total_exs:29840 total_steps:1492 epochs:149.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.39     0 267.8  1027       0          0 76.67  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00198    .1192 5.979 .0001674 2.498e-05 119.6 458.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1492 387.4 1485 3.842            1\n\n23:15:11 | time:543s total_exs:30220 total_steps:1511 epochs:151.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.05     0   261  1025       0          0 78.58  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001931    .1192 6.026 .0001632 2.498e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   473.5       0          0                 1511 381.5 1499 3.947            1\n\n23:15:11 | running eval: valid\n23:15:11 | eval completed in 0.20s\n23:15:11 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1772       0          0 131.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6 1.472 2.498e-05    72 789.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1511 233.5 2562        .8322\n\u001b[0m\nEpoch 00009: reducing learning rate of group 0 to 1.2488e-05.\n23:15:11 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 24\u001b[0m\n23:15:11 | saving model checkpoint: /tmp/model1.checkpoint\n23:15:26 | time:558s total_exs:30980 total_steps:1549 epochs:154.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.2     0   264 994.1       0          0 75.31  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001905    .1192 5.932 .0001608 1.249e-05 118.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   446.7       0          0                 1549 382.6 1441 3.774            1\n\n23:15:31 | time:563s total_exs:31360 total_steps:1568 epochs:156.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.93     0 258.5  1006       0          0 77.81  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001877    .1192 5.989 .0001587 1.249e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     466       0          0                 1568 378.3 1472 3.909            1\n\n23:15:31 | running eval: valid\n23:15:31 | eval completed in 0.20s\n23:15:31 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1800       0          0 133.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 1.475 1.249e-05    72 802.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1568 233.5 2602        .8322\n\u001b[0m\n23:15:31 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 25\u001b[0m\n23:15:31 | saving model checkpoint: /tmp/model1.checkpoint\n23:15:46 | time:578s total_exs:32140 total_steps:1607 epochs:160.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.98     0 259.6 997.1       0          0 76.83  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001855    .1192 5.951 .0001568 1.249e-05   119   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   457.2       0          0                 1607 378.6 1454 3.85            1\n\n23:15:51 | time:584s total_exs:32540 total_steps:1627 epochs:162.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.01     0 260.1 995.6       0          0 76.54  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001828    .1192 6.025 .0001545 1.249e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.1       0          0                 1627 380.6 1457 3.844            1\n\n23:15:51 | running eval: valid\n23:15:52 | eval completed in 0.20s\n23:15:52 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1780       0          0 132.2   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6  1.48 1.249e-05    72 793.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1627 233.5 2573        .8322\n\u001b[0m\n23:15:52 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 26\u001b[0m\n23:15:52 | saving model checkpoint: /tmp/model1.checkpoint\n23:16:12 | time:604s total_exs:33280 total_steps:1664 epochs:166.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.21     0 264.3  1024       0          0 77.46  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001807    .1192 6.024 .0001526 1.249e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   466.6       0          0                 1664 384.8 1490 3.882            1\n\n23:16:12 | running eval: valid\n23:16:12 | eval completed in 0.20s\n23:16:12 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1797       0          0 133.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6  1.48 1.249e-05    72 801.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1664 233.5 2598        .8322\n\u001b[0m\n23:16:12 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 27\u001b[0m\n23:16:12 | saving model checkpoint: /tmp/model1.checkpoint\n23:16:27 | time:619s total_exs:34060 total_steps:1703 epochs:170.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.15     0   263  1002       0          0 76.18  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001778    .1192 5.964 .0001501 1.249e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   454.4       0          0                 1703 382.3 1456 3.817            1\n\n23:16:32 | time:624s total_exs:34460 total_steps:1723 epochs:172.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.5     0 269.9 994.6       0          0 73.69  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001752    .1192 5.935 .0001479 1.249e-05 118.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   437.3       0          0                 1723 388.6 1432  3.7            1\n\n23:16:32 | running eval: valid\n23:16:32 | eval completed in 0.20s\n23:16:32 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1785       0          0 132.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 1.489 1.249e-05    72 795.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1723 233.5 2581        .8322\n\u001b[0m\nEpoch 00013: reducing learning rate of group 0 to 6.2438e-06.\n23:16:32 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 28\u001b[0m\n23:16:32 | saving model checkpoint: /tmp/model1.checkpoint\n23:16:47 | time:639s total_exs:35240 total_steps:1762 epochs:176.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.91     0 258.3 999.3       0          0 77.38  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001735    .1192  6.01 .0001466 6.244e-06 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   465.1       0          0                 1762 378.5 1464 3.878            1\n\n23:16:52 | time:645s total_exs:35700 total_steps:1785 epochs:178.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.92     0 258.4  1008       0          0 77.99  460   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00172    .1192 5.978 .0001453 6.244e-06 119.6 466.2   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1785  378 1474 3.914            1\n\n23:16:52 | running eval: valid\n23:16:53 | eval completed in 0.20s\n23:16:53 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1785       0          0 132.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 1.491 6.244e-06    72 795.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1785 233.5 2581        .8322\n\u001b[0m\n23:16:53 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 29\u001b[0m\n23:16:53 | saving model checkpoint: /tmp/model1.checkpoint\n23:17:07 | time:660s total_exs:36460 total_steps:1823 epochs:182.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.36     0 267.2  1002       0          0    75  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001709    .1192 5.992 .0001443 6.244e-06 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.4       0          0                 1823 387.1 1452 3.758            1\n\n23:17:13 | time:665s total_exs:36880 total_steps:1844 epochs:184.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.02     0 260.5  1017       0          0 78.11  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001697    .1193 5.967 .0001433 6.244e-06 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   466.1       0          0                 1844 379.8 1483 3.922            1\n\n23:17:13 | running eval: valid\n23:17:13 | eval completed in 0.20s\n23:17:13 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1770       0          0 131.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 1.494 6.244e-06    72 789.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1844 233.5 2559        .8322\n\u001b[0m\n23:17:13 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 30\u001b[0m\n23:17:13 | saving model checkpoint: /tmp/model1.checkpoint\n23:17:17 | ran out of patience! stopping training.\n23:17:17 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n23:17:17 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n23:17:17 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run1/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n23:17:17 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n23:17:17 | Using CUDA\n23:17:17 | loading dictionary from /tmp/model1.dict\n23:17:18 | num words = 54944\n23:17:22 | Loading existing model parameters from /tmp/model1\n23:17:30 | Total parameters: 128,042,498 (128,042,498 trainable)\n23:17:31 | creating task(s): fromfile:parlaiformat\n23:17:31 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run1/data_valid.txt\n23:17:31 | running eval: valid\n23:17:32 | eval completed in 0.37s\n23:17:32 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 11.46 161.5 933.9       0          0 69.37   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297     6 .5630 5.354e-06    72 416.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    107 233.5 1350        .9161\n\u001b[0m\n23:17:32 | creating task(s): fromfile:parlaiformat\n23:17:32 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run1/data_test.txt\n23:17:32 | running eval: test\n23:17:37 | eval completed in 4.92s\n23:17:37 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9410 9.41e-10               .7572                 .6434   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9200            .9664              .9907   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9433 12.07 281.4  2877       0          0 204.4 1000 .9410   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297   5.2 .5282 5.354e-06   104  1063       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    107 385.4 3940        .9455\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type1/run1/data_test.txt -m transformer/classifier -mf /tmp/model1 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:17:39.099935Z","iopub.execute_input":"2022-12-03T23:17:39.100367Z","iopub.status.idle":"2022-12-03T23:18:10.543629Z","shell.execute_reply.started":"2022-12-03T23:17:39.100324Z","shell.execute_reply":"2022-12-03T23:18:10.542354Z"},"scrolled":true,"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"23:17:48 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr2type1/run1/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr2type1/run1/data)\u001b[0m\n23:17:48 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n23:17:48 | Using CUDA\n23:17:48 | loading dictionary from /tmp/model1.dict\n23:17:48 | num words = 54944\n23:17:52 | Loading existing model parameters from /tmp/model1\n23:17:58 | Total parameters: 128,042,498 (128,042,498 trainable)\n23:18:00 | Opt:\n23:18:00 |     activation: gelu\n23:18:00 |     adafactor_eps: '[1e-30, 0.001]'\n23:18:00 |     adam_eps: 1e-08\n23:18:00 |     add_p1_after_newln: False\n23:18:00 |     aggregate_micro: False\n23:18:00 |     allow_missing_init_opts: False\n23:18:00 |     area_under_curve_class: None\n23:18:00 |     area_under_curve_digits: -1\n23:18:00 |     attention_dropout: 0.1\n23:18:00 |     batchsize: 40\n23:18:00 |     betas: '[0.9, 0.999]'\n23:18:00 |     bpe_add_prefix_space: None\n23:18:00 |     bpe_debug: False\n23:18:00 |     bpe_dropout: None\n23:18:00 |     bpe_merge: None\n23:18:00 |     bpe_vocab: None\n23:18:00 |     candidates: inline\n23:18:00 |     cap_num_predictions: 100\n23:18:00 |     checkpoint_activations: False\n23:18:00 |     class_weights: None\n23:18:00 |     classes: \"['__notok__', '__ok__']\"\n23:18:00 |     classes_from_file: None\n23:18:00 |     data_parallel: True\n23:18:00 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n23:18:00 |     datatype: train\n23:18:00 |     delimiter: '\\n'\n23:18:00 |     dict_class: parlai.core.dict:DictionaryAgent\n23:18:00 |     dict_endtoken: __start__\n23:18:00 |     dict_file: /tmp/model1.dict\n23:18:00 |     dict_include_test: False\n23:18:00 |     dict_include_valid: False\n23:18:00 |     dict_initpath: None\n23:18:00 |     dict_language: english\n23:18:00 |     dict_loaded: True\n23:18:00 |     dict_lower: True\n23:18:00 |     dict_max_ngram_size: -1\n23:18:00 |     dict_maxexs: -1\n23:18:00 |     dict_maxtokens: -1\n23:18:00 |     dict_minfreq: 0\n23:18:00 |     dict_nulltoken: __null__\n23:18:00 |     dict_starttoken: __start__\n23:18:00 |     dict_textfields: text,labels\n23:18:00 |     dict_tokenizer: bpe\n23:18:00 |     dict_unktoken: __unk__\n23:18:00 |     display_examples: False\n23:18:00 |     download_path: None\n23:18:00 |     dropout: 0.1\n23:18:00 |     dynamic_batching: None\n23:18:00 |     embedding_projection: random\n23:18:00 |     embedding_size: 768\n23:18:00 |     embedding_type: random\n23:18:00 |     embeddings_scale: False\n23:18:00 |     encode_candidate_vecs: True\n23:18:00 |     encode_candidate_vecs_batchsize: 256\n23:18:00 |     eval_batchsize: None\n23:18:00 |     eval_candidates: inline\n23:18:00 |     eval_dynamic_batching: None\n23:18:00 |     evaltask: None\n23:18:00 |     ffn_size: 3072\n23:18:00 |     final_extra_opt: \n23:18:00 |     fixed_candidate_vecs: reuse\n23:18:00 |     fixed_candidates_path: None\n23:18:00 |     force_fp16_tokens: True\n23:18:00 |     fp16: True\n23:18:00 |     fp16_impl: safe\n23:18:00 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run1/data_test.txt\n23:18:00 |     fromfile_datatype_extension: True\n23:18:00 |     gpu: -1\n23:18:00 |     gradient_clip: 0.1\n23:18:00 |     hide_labels: False\n23:18:00 |     history_add_global_end_token: None\n23:18:00 |     history_reversed: False\n23:18:00 |     history_size: 20\n23:18:00 |     ignore_bad_candidates: False\n23:18:00 |     ignore_labels: None\n23:18:00 |     image_cropsize: 224\n23:18:00 |     image_mode: raw\n23:18:00 |     image_size: 256\n23:18:00 |     inference: max\n23:18:00 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n23:18:00 |     init_opt: None\n23:18:00 |     interactive_candidates: fixed\n23:18:00 |     interactive_mode: False\n23:18:00 |     invsqrt_lr_decay_gamma: -1\n23:18:00 |     is_debug: False\n23:18:00 |     label_truncate: 72\n23:18:00 |     learn_embeddings: True\n23:18:00 |     learn_positional_embeddings: True\n23:18:00 |     learningrate: 5e-05\n23:18:00 |     load_from_pretrained_ranker: True\n23:18:00 |     log_every_n_secs: 10.0\n23:18:00 |     log_every_n_steps: 50\n23:18:00 |     log_keep_fields: all\n23:18:00 |     loglevel: info\n23:18:00 |     lr_scheduler: reduceonplateau\n23:18:00 |     lr_scheduler_decay: 0.5\n23:18:00 |     lr_scheduler_patience: 3\n23:18:00 |     max_train_steps: -1\n23:18:00 |     max_train_time: 7200.0\n23:18:00 |     memory_attention: sqrt\n23:18:00 |     metrics: default\n23:18:00 |     model: transformer/classifier\n23:18:00 |     model_file: /tmp/model1\n23:18:00 |     model_parallel: False\n23:18:00 |     momentum: 0\n23:18:00 |     multitask_weights: [1]\n23:18:00 |     mutators: None\n23:18:00 |     n_decoder_layers: -1\n23:18:00 |     n_encoder_layers: -1\n23:18:00 |     n_heads: 12\n23:18:00 |     n_layers: 12\n23:18:00 |     n_positions: 1024\n23:18:00 |     n_segments: 2\n23:18:00 |     nesterov: True\n23:18:00 |     no_cuda: False\n23:18:00 |     normalize_sent_emb: False\n23:18:00 |     num_epochs: -1\n23:18:00 |     num_examples: -1\n23:18:00 |     num_workers: 0\n23:18:00 |     nus: [0.7]\n23:18:00 |     optimizer: adamax\n23:18:00 |     output_scaling: 0.06\n23:18:00 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type1/run1/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model1', 'batchsize': 40}\"\n23:18:00 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n23:18:00 |     person_tokens: False\n23:18:00 |     print_scores: False\n23:18:00 |     rank_candidates: False\n23:18:00 |     rank_top_k: -1\n23:18:00 |     reduction_type: mean\n23:18:00 |     ref_class: None\n23:18:00 |     relu_dropout: 0.0\n23:18:00 |     repeat_blocking_heuristic: True\n23:18:00 |     report_filename: \n23:18:00 |     return_cand_scores: False\n23:18:00 |     save_after_valid: True\n23:18:00 |     save_every_n_secs: -1\n23:18:00 |     save_format: conversations\n23:18:00 |     share_encoders: False\n23:18:00 |     share_word_embeddings: False\n23:18:00 |     short_final_eval: False\n23:18:00 |     special_tok_lst: None\n23:18:00 |     split_lines: False\n23:18:00 |     starttime: Dec03_23-05\n23:18:00 |     task: fromfile:parlaiformat\n23:18:00 |     tensorboard_log: False\n23:18:00 |     tensorboard_logdir: None\n23:18:00 |     text_truncate: 360\n23:18:00 |     threshold: 0.5\n23:18:00 |     topk: 5\n23:18:00 |     train_predict: False\n23:18:00 |     truncate: 1024\n23:18:00 |     update_classifier_head_only: False\n23:18:00 |     update_freq: 1\n23:18:00 |     use_memories: False\n23:18:00 |     use_reply: none\n23:18:00 |     validation_cutoff: 1.0\n23:18:00 |     validation_every_n_epochs: -1\n23:18:00 |     validation_every_n_secs: 20.0\n23:18:00 |     validation_every_n_steps: -1\n23:18:00 |     validation_max_exs: -1\n23:18:00 |     validation_metric: accuracy\n23:18:00 |     validation_metric_mode: max\n23:18:00 |     validation_patience: 30\n23:18:00 |     validation_share_agent: False\n23:18:00 |     variant: xlm\n23:18:00 |     verbose: False\n23:18:00 |     wandb_entity: None\n23:18:00 |     wandb_log: False\n23:18:00 |     wandb_name: None\n23:18:00 |     wandb_project: None\n23:18:00 |     warmup_rate: 0.0001\n23:18:00 |     warmup_updates: 1000\n23:18:00 |     weight_decay: None\n23:18:00 |     world_logs: \n23:18:00 |     wrap_memory_encoder: False\n23:18:00 | Evaluating task fromfile:parlaiformat using datatype valid.\n23:18:00 | creating task(s): fromfile:parlaiformat\n23:18:00 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n23:18:00 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run1/data_test.txt\n23:18:08 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9410 9.41e-10               .7572                 .6434   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9200            .9664              .9907   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9433 12.07 562.9  1815       0          0 128.9 1000 .9410   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5282 5.354e-06   208 670.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    107 770.9 2485        .9455\u001b[0m\n23:18:08 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9410 9.41e-10               .7572                 .6434   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9200            .9664              .9907   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9433 12.07 562.9  1815       0          0 128.9 1000 .9410   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5282 5.354e-06   208 670.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    107 770.9 2485        .9455\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model1*","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:18:10.548591Z","iopub.execute_input":"2022-12-03T23:18:10.549206Z","iopub.status.idle":"2022-12-03T23:18:11.879686Z","shell.execute_reply.started":"2022-12-03T23:18:10.549170Z","shell.execute_reply":"2022-12-03T23:18:11.878392Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"run 2","metadata":{}},{"cell_type":"code","source":"# run 2 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type1/run2/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model2","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:18:11.882882Z","iopub.execute_input":"2022-12-03T23:18:11.883314Z","iopub.status.idle":"2022-12-03T23:30:54.199532Z","shell.execute_reply.started":"2022-12-03T23:18:11.883266Z","shell.execute_reply":"2022-12-03T23:30:54.198230Z"},"scrolled":true,"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"23:18:18 | building dictionary first...\n23:18:18 | No model with opt yet at: /tmp/model2(.opt)\n23:18:18 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run2/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n23:18:18 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n23:18:18 | Using CUDA\n23:18:18 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n23:18:19 | num words = 54944\n23:18:23 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n23:18:33 | Total parameters: 128,042,498 (128,042,498 trainable)\n23:18:33 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n23:18:33 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n23:18:33 | Opt:\n23:18:33 |     activation: gelu\n23:18:33 |     adafactor_eps: '(1e-30, 0.001)'\n23:18:33 |     adam_eps: 1e-08\n23:18:33 |     add_p1_after_newln: False\n23:18:33 |     aggregate_micro: False\n23:18:33 |     allow_missing_init_opts: False\n23:18:33 |     attention_dropout: 0.1\n23:18:33 |     batchsize: 20\n23:18:33 |     betas: '(0.9, 0.999)'\n23:18:33 |     bpe_add_prefix_space: None\n23:18:33 |     bpe_debug: False\n23:18:33 |     bpe_dropout: None\n23:18:33 |     bpe_merge: None\n23:18:33 |     bpe_vocab: None\n23:18:33 |     candidates: inline\n23:18:33 |     cap_num_predictions: 100\n23:18:33 |     checkpoint_activations: False\n23:18:33 |     class_weights: None\n23:18:33 |     classes: \"['__notok__', '__ok__']\"\n23:18:33 |     classes_from_file: None\n23:18:33 |     data_parallel: True\n23:18:33 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n23:18:33 |     datatype: train\n23:18:33 |     delimiter: '\\n'\n23:18:33 |     dict_class: parlai.core.dict:DictionaryAgent\n23:18:33 |     dict_endtoken: __start__\n23:18:33 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n23:18:33 |     dict_include_test: False\n23:18:33 |     dict_include_valid: False\n23:18:33 |     dict_initpath: None\n23:18:33 |     dict_language: english\n23:18:33 |     dict_loaded: True\n23:18:33 |     dict_lower: True\n23:18:33 |     dict_max_ngram_size: -1\n23:18:33 |     dict_maxexs: -1\n23:18:33 |     dict_maxtokens: -1\n23:18:33 |     dict_minfreq: 0\n23:18:33 |     dict_nulltoken: __null__\n23:18:33 |     dict_starttoken: __start__\n23:18:33 |     dict_textfields: text,labels\n23:18:33 |     dict_tokenizer: bpe\n23:18:33 |     dict_unktoken: __unk__\n23:18:33 |     display_examples: False\n23:18:33 |     download_path: None\n23:18:33 |     dropout: 0.1\n23:18:33 |     dynamic_batching: None\n23:18:33 |     embedding_projection: random\n23:18:33 |     embedding_size: 768\n23:18:33 |     embedding_type: random\n23:18:33 |     embeddings_scale: False\n23:18:33 |     encode_candidate_vecs: True\n23:18:33 |     encode_candidate_vecs_batchsize: 256\n23:18:33 |     eval_batchsize: None\n23:18:33 |     eval_candidates: inline\n23:18:33 |     eval_dynamic_batching: None\n23:18:33 |     evaltask: None\n23:18:33 |     ffn_size: 3072\n23:18:33 |     final_extra_opt: \n23:18:33 |     fixed_candidate_vecs: reuse\n23:18:33 |     fixed_candidates_path: None\n23:18:33 |     force_fp16_tokens: False\n23:18:33 |     fp16: True\n23:18:33 |     fp16_impl: safe\n23:18:33 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run2/data\n23:18:33 |     fromfile_datatype_extension: True\n23:18:33 |     gpu: -1\n23:18:33 |     gradient_clip: 0.1\n23:18:33 |     hide_labels: False\n23:18:33 |     history_add_global_end_token: None\n23:18:33 |     history_reversed: False\n23:18:33 |     history_size: 20\n23:18:33 |     ignore_bad_candidates: False\n23:18:33 |     ignore_labels: None\n23:18:33 |     image_cropsize: 224\n23:18:33 |     image_mode: raw\n23:18:33 |     image_size: 256\n23:18:33 |     inference: max\n23:18:33 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n23:18:33 |     init_opt: None\n23:18:33 |     interactive_candidates: fixed\n23:18:33 |     interactive_mode: False\n23:18:33 |     invsqrt_lr_decay_gamma: -1\n23:18:33 |     is_debug: False\n23:18:33 |     label_truncate: 72\n23:18:33 |     learn_embeddings: True\n23:18:33 |     learn_positional_embeddings: True\n23:18:33 |     learningrate: 5e-05\n23:18:33 |     load_from_checkpoint: False\n23:18:33 |     load_from_pretrained_ranker: True\n23:18:33 |     log_every_n_secs: 10.0\n23:18:33 |     log_every_n_steps: 50\n23:18:33 |     log_keep_fields: all\n23:18:33 |     loglevel: info\n23:18:33 |     lr_scheduler: reduceonplateau\n23:18:33 |     lr_scheduler_decay: 0.5\n23:18:33 |     lr_scheduler_patience: 3\n23:18:33 |     max_train_steps: -1\n23:18:33 |     max_train_time: 7200.0\n23:18:33 |     memory_attention: sqrt\n23:18:33 |     metrics: default\n23:18:33 |     model: transformer/classifier\n23:18:33 |     model_file: /tmp/model2\n23:18:33 |     model_parallel: False\n23:18:33 |     momentum: 0\n23:18:33 |     multitask_weights: [1]\n23:18:33 |     mutators: None\n23:18:33 |     n_decoder_layers: -1\n23:18:33 |     n_encoder_layers: -1\n23:18:33 |     n_heads: 12\n23:18:33 |     n_layers: 12\n23:18:33 |     n_positions: 1024\n23:18:33 |     n_segments: 2\n23:18:33 |     nesterov: True\n23:18:33 |     no_cuda: False\n23:18:33 |     normalize_sent_emb: False\n23:18:33 |     num_epochs: -1\n23:18:33 |     num_workers: 0\n23:18:33 |     nus: (0.7,)\n23:18:33 |     optimizer: adamax\n23:18:33 |     output_scaling: 0.06\n23:18:33 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type1/run2/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model2'}\"\n23:18:33 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n23:18:33 |     person_tokens: False\n23:18:33 |     print_scores: False\n23:18:33 |     rank_candidates: False\n23:18:33 |     rank_top_k: -1\n23:18:33 |     reduction_type: mean\n23:18:33 |     ref_class: None\n23:18:33 |     relu_dropout: 0.0\n23:18:33 |     repeat_blocking_heuristic: True\n23:18:33 |     return_cand_scores: False\n23:18:33 |     save_after_valid: True\n23:18:33 |     save_every_n_secs: -1\n23:18:33 |     save_format: conversations\n23:18:33 |     share_encoders: False\n23:18:33 |     share_word_embeddings: False\n23:18:33 |     short_final_eval: False\n23:18:33 |     special_tok_lst: None\n23:18:33 |     split_lines: False\n23:18:33 |     starttime: Dec03_23-18\n23:18:33 |     task: fromfile:parlaiformat\n23:18:33 |     tensorboard_log: False\n23:18:33 |     tensorboard_logdir: None\n23:18:33 |     text_truncate: 360\n23:18:33 |     threshold: 0.5\n23:18:33 |     topk: 5\n23:18:33 |     train_predict: False\n23:18:33 |     truncate: 1024\n23:18:33 |     update_classifier_head_only: False\n23:18:33 |     update_freq: 1\n23:18:33 |     use_memories: False\n23:18:33 |     use_reply: none\n23:18:33 |     validation_cutoff: 1.0\n23:18:33 |     validation_every_n_epochs: -1\n23:18:33 |     validation_every_n_secs: 20.0\n23:18:33 |     validation_every_n_steps: -1\n23:18:33 |     validation_max_exs: -1\n23:18:33 |     validation_metric: accuracy\n23:18:33 |     validation_metric_mode: max\n23:18:33 |     validation_patience: 30\n23:18:33 |     validation_share_agent: False\n23:18:33 |     variant: xlm\n23:18:33 |     verbose: False\n23:18:33 |     wandb_entity: None\n23:18:33 |     wandb_log: False\n23:18:33 |     wandb_name: None\n23:18:33 |     wandb_project: None\n23:18:33 |     warmup_rate: 0.0001\n23:18:33 |     warmup_updates: 1000\n23:18:33 |     weight_decay: None\n23:18:33 |     world_logs: \n23:18:33 |     wrap_memory_encoder: False\n23:18:34 | creating task(s): fromfile:parlaiformat\n23:18:34 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run2/data_train.txt\n23:18:34 | training...\n23:18:44 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .3725 3.725e-10               .4435                 .3937   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5076            .2808              .3356   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .2414  11.4     1 268.1 526.4       0          0 39.27  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .3725             32768  2.691    .1206 5.985 .7192 1.005e-06 119.7 235.1   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 387.8 761.4 1.968        .3609\n\n23:18:54 | time:20s total_exs:1160 total_steps:58 epochs:5.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5132 5.132e-10               .5363                 .4942   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5863            .4875              .5382   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .4456 11.64     1 272.8  1056       0          0 77.43  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5132             32768   2.54    .1207 5.961 .6936 2.905e-06 119.2 461.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   58 392.1 1518 3.881        .5110\n\n23:18:54 | creating task(s): fromfile:parlaiformat\n23:18:54 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run2/data_valid.txt\n23:18:54 | running eval: valid\n23:18:54 | eval completed in 0.23s\n23:18:54 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .6957                 .7273   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .7200              .6923   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1515       0          0 116.5   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6543 2.905e-06    72 699.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                     58  228 2215        .7078\n\u001b[0m\n23:18:54 | \u001b[1;32mnew best accuracy: 0.7083\u001b[0m\n23:18:54 | saving best valid model: /tmp/model2\n23:18:54 | Saving dictionary to /tmp/model2.dict\n23:18:58 | saving model checkpoint: /tmp/model2.checkpoint\n23:18:58 | Saving dictionary to /tmp/model2.checkpoint.dict\n23:19:15 | time:41s total_exs:1800 total_steps:90 epochs:9.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7922 7.922e-10               .8006                 .8018   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7994            .7830              .7818   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7843 11.59     1 271.8 849.4       0          0 62.51  640   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7922             32768  2.649    .1207 6.044 .6377 4.505e-06 120.9 377.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   90 392.7 1227 3.132        .7922\n\n23:19:18 | time:44s total_exs:2040 total_steps:102 epochs:10.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9000   9e-10               .9137                 .8467   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9922            .8812              .9889   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7946  11.5     1   270  1001       0          0 74.18  240   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9000             32768  2.705    .1207 6.067 .5774 5.104e-06 121.3   450   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  102 391.3 1451 3.735        .8985\n\n23:19:18 | running eval: valid\n23:19:18 | eval completed in 0.20s\n23:19:18 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8571                 .7500   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .8000                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .6667    11   156  1746       0          0 134.2   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5627 5.104e-06    72 805.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    102  228 2552        .8286\n\u001b[0m\n23:19:18 | \u001b[1;32mnew best accuracy: 0.8333 (previous best was 0.7083)\u001b[0m\n23:19:18 | saving best valid model: /tmp/model2\n23:19:23 | saving model checkpoint: /tmp/model2.checkpoint\n23:19:42 | time:68s total_exs:2780 total_steps:139 epochs:13.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9378 9.378e-10               .9396                 .9063   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9755            .9359              .9739   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9008 11.42     1 268.4 982.1       0          0 73.18  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9378             32768  3.104    .1207 5.992 .4719 6.954e-06 119.8 438.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  139 388.3 1421 3.667        .9378\n\n23:19:43 | time:70s total_exs:2880 total_steps:144 epochs:14.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9800 9.8e-10               .9787                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9583            .9811              .9630   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.09     1 281.8  1104       0          0 78.33  100   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9800             32768  3.611    .1189  5.96 .3396 7.204e-06 119.2 466.8   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  144  401 1570 3.989        .9800\n\n23:19:43 | running eval: valid\n23:19:44 | eval completed in 0.20s\n23:19:44 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1    11   156  1726       0          0 132.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .3485 7.204e-06    72 796.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    144  228 2523        .9161\n\u001b[0m\n23:19:44 | \u001b[1;32mnew best accuracy: 0.9167 (previous best was 0.8333)\u001b[0m\n23:19:44 | saving best valid model: /tmp/model2\n23:19:48 | saving model checkpoint: /tmp/model2.checkpoint\n23:20:07 | time:94s total_exs:3640 total_steps:182 epochs:18.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9618 9.618e-10               .9635                 .9599   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9672            .9600              .9640   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9560 11.83     1 276.6  1049       0          0 75.87  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9618             32768  4.585    .1207 6.042 .2127 9.104e-06 120.8 458.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  182 397.5 1508 3.802        .9618\n\n23:20:08 | time:95s total_exs:3720 total_steps:186 epochs:18.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9625 9.625e-10               .9577                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9189            .9663              .9348   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.35     1   287  1131       0          0 78.81   80   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9625             32768  4.417    .1207 5.925 .1333 9.304e-06 118.5   467   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  186 405.5 1598 4.029        .9623\n\n23:20:08 | running eval: valid\n23:20:09 | eval completed in 0.20s\n23:20:09 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1    11   156  1728       0          0 132.9   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .1959 9.304e-06    72 797.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    186  228 2525        .9583\n\u001b[0m\n23:20:09 | \u001b[1;32mnew best accuracy: 0.9583 (previous best was 0.9167)\u001b[0m\n23:20:09 | saving best valid model: /tmp/model2\n23:20:18 | saving model checkpoint: /tmp/model2.checkpoint\n23:20:33 | time:120s total_exs:4500 total_steps:225 epochs:22.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9833 9.833e-10               .9825                 .9785   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9864            .9841              .9877   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9805 11.72     1 274.4  1057       0          0 77.02  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9833             32768  4.257    .1207 5.946 .07153 1.125e-05 118.9   458   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  225 393.3 1515 3.86        .9833\n\n23:20:38 | time:124s total_exs:4840 total_steps:242 epochs:24.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9941 9.941e-10               .9939                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9880            .9943              .9886   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.4     1 267.9  1024       0          0 76.41  340   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9941             32768  5.216    .1207 5.976 .02313 1.21e-05 119.5 456.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  242 387.5 1480 3.84        .9941\n\n23:20:38 | running eval: valid\n23:20:38 | eval completed in 0.20s\n23:20:38 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1681       0          0 129.3   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .2684 1.21e-05    72 775.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    242  228 2457        .9167\n\u001b[0m\n23:20:38 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 1\u001b[0m\n23:20:38 | saving model checkpoint: /tmp/model2.checkpoint\n23:20:58 | time:144s total_exs:5600 total_steps:280 epochs:28.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.91 .2632 278.2  1049       0          0 75.43  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss      lr  ltpb  ltps  \\\n     1             32768  .1936    .1207 5.997 .004563 1.4e-05 119.9 452.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  280 398.1 1502 3.78            1\n\n23:20:58 | time:144s total_exs:5620 total_steps:281 epochs:28.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.35     0   247 985.4       0          0 79.76   20   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .03291    .1190   5.8 .002573 1.405e-05   116 462.7   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  281  363 1448 4.386            1\n\n23:20:58 | running eval: valid\n23:20:58 | eval completed in 0.20s\n23:20:58 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1735       0          0 133.4   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .3949 1.405e-05    72 800.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    281  228 2536        .9167\n\u001b[0m\n23:20:58 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 2\u001b[0m\n23:20:58 | saving model checkpoint: /tmp/model2.checkpoint\n23:21:13 | time:159s total_exs:6380 total_steps:319 epochs:31.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.57     0 271.3  1028       0          0 75.77  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .02573    .1207 6.018 .002049 1.595e-05 120.4   456   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  319 391.7 1484 3.797            1\n\n23:21:18 | time:165s total_exs:6800 total_steps:340 epochs:34.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.7     0   274  1020       0          0 74.43  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss      lr  ltpb  ltps  \\\n     1             32768 .01972    .1207 6.067 .001638 1.7e-05 121.3 451.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  340 395.4 1471 3.736            1\n\n23:21:18 | running eval: valid\n23:21:19 | eval completed in 0.20s\n23:21:19 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1731       0          0 133.1   24 .9167   \n    gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 .3841 1.7e-05    72 798.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    340  228 2530        .9167\n\u001b[0m\n23:21:19 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 3\u001b[0m\n23:21:19 | saving model checkpoint: /tmp/model2.checkpoint\n23:21:33 | time:179s total_exs:7580 total_steps:379 epochs:37.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.54     0 270.8  1031       0          0 76.18  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01751    .1207 6.028 .001446 1.895e-05 120.6 459.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  379 391.3 1491 3.817            1\n\n23:21:39 | time:185s total_exs:8020 total_steps:401 epochs:40.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.71 .09091 274.2  1046       0          0 76.29   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    440   1             32768 .05212    .1207 5.973 .001339 2.005e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   455.6       0          0                  401 393.6 1501 3.83            1\n\n23:21:39 | running eval: valid\n23:21:39 | eval completed in 0.23s\n23:21:39 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1538       0          0 118.2   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08095     6 .5160 2.005e-05    72 709.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    401  228 2248        .9167\n\u001b[0m\n23:21:39 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 4\u001b[0m\n23:21:39 | saving model checkpoint: /tmp/model2.checkpoint\n23:21:54 | time:200s total_exs:8780 total_steps:439 epochs:43.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.41     0 268.3  1002       0          0 74.72  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01465    .1207  5.95 .001219 2.195e-05   119 444.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  439 387.3 1447 3.744            1\n\n23:21:59 | time:206s total_exs:9220 total_steps:461 epochs:46.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.72     0 274.4  1067       0          0 77.79  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01323    .1207 6.014 .001127 2.305e-05 120.3 467.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  461 394.7 1535 3.905            1\n\n23:21:59 | running eval: valid\n23:22:00 | eval completed in 0.20s\n23:22:00 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1725       0          0 132.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 .4951 2.305e-05    72 796.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    461  228 2522        .9167\n\u001b[0m\n23:22:00 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 5\u001b[0m\n23:22:00 | saving model checkpoint: /tmp/model2.checkpoint\n23:22:14 | time:220s total_exs:10000 total_steps:500 epochs:50.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.41     0 268.1  1025       0          0 76.44  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss      lr  ltpb  ltps  \\\n     1             32768 .01319    .1207 6.064 .001055 2.5e-05 121.3 463.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  500 389.4 1488 3.83            1\n\n23:22:20 | time:226s total_exs:10420 total_steps:521 epochs:52.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.09     0 281.7  1062       0          0 75.37  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01164    .1207 5.995 .0009902 2.605e-05 119.9 451.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  521 401.6 1514 3.784            1\n\n23:22:20 | running eval: valid\n23:22:20 | eval completed in 0.20s\n23:22:20 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1754       0          0 134.8   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 .5209 2.605e-05    72 809.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    521  228 2563        .9167\n\u001b[0m\n23:22:20 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 6\u001b[0m\n23:22:20 | saving model checkpoint: /tmp/model2.checkpoint\n23:22:35 | time:241s total_exs:11200 total_steps:560 epochs:56.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.58     0 271.6  1044       0          0 76.88  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss      lr  ltpb  ltps  \\\n     1             32768 .01174    .1207 5.915 .0009341 2.8e-05 118.3 454.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  560 389.9 1499 3.853            1\n\n23:22:40 | time:246s total_exs:11620 total_steps:581 epochs:58.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.66     0 273.2  1063       0          0 77.83  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01076    .1208 6.048 .0008693 2.905e-05   121 470.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  581 394.1 1534 3.908            1\n\n23:22:40 | running eval: valid\n23:22:40 | eval completed in 0.20s\n23:22:40 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1740       0          0 133.8   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 .5840 2.905e-05    72 802.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    581  228 2543        .9167\n\u001b[0m\n23:22:40 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 7\u001b[0m\n23:22:40 | saving model checkpoint: /tmp/model2.checkpoint\n23:22:55 | time:261s total_exs:12380 total_steps:619 epochs:61.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.68     0 273.6  1028       0          0  75.1  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01029    .1208 6.061 .0008157 3.095e-05 121.2 455.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  619 394.8 1483 3.764            1\n\n23:23:00 | time:267s total_exs:12820 total_steps:641 epochs:64.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.84     0 276.9  1056       0          0 76.32  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .008939    .1208 6.059 .0007622 3.205e-05 121.2   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   462.4       0          0                  641  398 1519 3.831            1\n\n23:23:00 | running eval: valid\n23:23:01 | eval completed in 0.20s\n23:23:01 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1688       0          0 129.8   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 .5670 3.205e-05    72 779.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    641  228 2468        .9167\n\u001b[0m\n23:23:01 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 8\u001b[0m\n23:23:01 | saving model checkpoint: /tmp/model2.checkpoint\n23:23:15 | time:281s total_exs:13600 total_steps:680 epochs:68.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.53     0 270.6  1037       0          0 76.64  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss      lr  ltpb  ltps  \\\n     1             32768 .008444    .1208 5.972 .0007194 3.4e-05 119.4 457.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  680 390.1 1495 3.841            1\n\n23:23:21 | time:287s total_exs:14020 total_steps:701 epochs:70.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.63     0 272.7  1018       0          0 74.66  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .007915    .1208 6.014 .0006734 3.505e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n     449       0          0                  701  393 1467 3.748            1\n\n23:23:21 | running eval: valid\n23:23:21 | eval completed in 0.23s\n23:23:21 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1526       0          0 117.1   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 .5897 3.505e-05    72   704       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    701  228 2230        .9167\n\u001b[0m\n23:23:21 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 9\u001b[0m\n23:23:21 | saving model checkpoint: /tmp/model2.checkpoint\n23:23:36 | time:302s total_exs:14800 total_steps:740 epochs:74.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0 275.9  1054       0          0 76.37  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss      lr  ltpb  ltps  \\\n     1             32768 .007385    .1208 6.038 .000629 3.7e-05 120.8 461.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  740 396.7 1515 3.827            1\n\n23:23:41 | time:307s total_exs:15220 total_steps:761 epochs:76.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.82     0 276.5  1037       0          0 75.01  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006944    .1208  5.99 .0005909 3.805e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.3       0          0                  761 396.3 1486 3.766            1\n\n23:23:41 | running eval: valid\n23:23:41 | eval completed in 0.20s\n23:23:41 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1739       0          0 133.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 .5821 3.805e-05    72 802.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    761  228 2541        .9167\n\u001b[0m\n23:23:41 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 10\u001b[0m\n23:23:41 | saving model checkpoint: /tmp/model2.checkpoint\n23:23:56 | time:322s total_exs:15980 total_steps:799 epochs:79.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.7     0   274  1032       0          0 75.34  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006512    .1208     6 .0005543 3.995e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n     452       0          0                  799  394 1484 3.775            1\n\n23:24:01 | time:328s total_exs:16420 total_steps:821 epochs:82.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.38     0 267.5  1041       0          0 77.84  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006123    .1208     6 .0005196 4.105e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     467       0          0                  821 387.5 1508 3.907            1\n\n23:24:01 | running eval: valid\n23:24:02 | eval completed in 0.21s\n23:24:02 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1659       0          0 127.6   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 .6109 4.105e-05    72 765.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    821  228 2425        .9167\n\u001b[0m\n23:24:02 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 11\u001b[0m\n23:24:02 | saving model checkpoint: /tmp/model2.checkpoint\n23:24:16 | time:342s total_exs:17200 total_steps:860 epochs:86.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.52     0 270.4  1034       0          0 76.49  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss      lr  ltpb  ltps  \\\n     1             32768 .005734    .1208 5.974 .0004873 4.3e-05 119.5   457   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  860 389.8 1491 3.833            1\n\n23:24:22 | time:348s total_exs:17620 total_steps:881 epochs:88.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.82     0 276.5  1071       0          0 77.44  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .005376    .1208 5.948 .0004568 4.405e-05   119   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.6       0          0                  881 395.4 1531 3.888            1\n\n23:24:22 | running eval: valid\n23:24:22 | eval completed in 0.20s\n23:24:22 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1728       0          0 132.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 .5986 4.405e-05    72 797.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    881  228 2526        .9167\n\u001b[0m\n23:24:22 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 12\u001b[0m\n23:24:22 | saving model checkpoint: /tmp/model2.checkpoint\n23:24:37 | time:363s total_exs:18400 total_steps:920 epochs:92.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.84     0 276.8  1062       0          0 76.72  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss      lr  ltpb  ltps  \\\n     1             32768 .005059    .1208 5.915 .0004292 4.6e-05 118.3 453.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  920 395.1 1516 3.845            1\n\n23:24:42 | time:368s total_exs:18780 total_steps:939 epochs:93.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.76     0 275.2  1057       0          0 76.81  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004712    .1208     6 .0004001 4.695e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.9       0          0                  939 395.2 1518 3.858            1\n\n23:24:42 | running eval: valid\n23:24:42 | eval completed in 0.20s\n23:24:42 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1719       0          0 132.1   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 .6220 4.695e-05    72 793.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    939  228 2512        .9167\n\u001b[0m\n23:24:42 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 13\u001b[0m\n23:24:42 | saving model checkpoint: /tmp/model2.checkpoint\n23:24:57 | time:383s total_exs:19540 total_steps:977 epochs:97.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.66     0 273.3  1037       0          0 75.88  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004432    .1208 6.024 .0003764 4.885e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.1       0          0                  977 393.7 1494 3.802            1\n\n23:25:02 | time:388s total_exs:19960 total_steps:998 epochs:99.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0 276.1  1052       0          0 76.24  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .004145    .1208 6.086 .0003519 4.99e-05 121.7   464   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  998 397.8 1516 3.828            1\n\n23:25:02 | running eval: valid\n23:25:02 | eval completed in 0.20s\n23:25:02 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1752       0          0 134.8   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 .6512 4.99e-05    72 808.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    998  228 2561        .9167\n\u001b[0m\n23:25:02 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 14\u001b[0m\n23:25:02 | saving model checkpoint: /tmp/model2.checkpoint\n23:25:17 | time:403s total_exs:20720 total_steps:1036 epochs:103.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.99     0 279.8  1063       0          0 75.94  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003921    .1208 6.024 .0003317 4.995e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.5       0          0                 1036 400.3 1520 3.806            1\n\n23:25:22 | time:409s total_exs:21160 total_steps:1058 epochs:105.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.52     0 270.3  1026       0          0 75.92  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .00369    .1208 5.968 .000313 4.995e-05 119.4 453.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1058 389.7 1479 3.811            1\n\n23:25:22 | running eval: valid\n23:25:23 | eval completed in 0.20s\n23:25:23 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1697       0          0 130.5   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 .6438 4.995e-05    72 783.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1058  228 2480        .9167\n\u001b[0m\n23:25:23 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 15\u001b[0m\n23:25:23 | saving model checkpoint: /tmp/model2.checkpoint\n23:25:37 | time:423s total_exs:21940 total_steps:1097 epochs:109.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.83     0 276.7  1053       0          0 76.14  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003463    .1209  6.01 .0002935 4.995e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.6       0          0                 1097 396.9 1511 3.815            1\n\n23:25:43 | time:429s total_exs:22360 total_steps:1118 epochs:111.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.69     0 273.8  1033       0          0 75.46  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003267    .1209 6.076 .0002758 4.995e-05 121.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.5       0          0                 1118 395.3 1492 3.789            1\n\n23:25:43 | running eval: valid\n23:25:43 | eval completed in 0.19s\n23:25:43 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1772       0          0 136.2   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 .6672 4.995e-05    72 817.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1118  228 2589        .9167\n\u001b[0m\n23:25:43 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 16\u001b[0m\n23:25:43 | saving model checkpoint: /tmp/model2.checkpoint\n23:25:58 | time:444s total_exs:23140 total_steps:1157 epochs:115.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.52     0 270.5  1033       0          0 76.37  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768  .0031    .1209 5.941 .0002627 4.995e-05 118.8 453.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1157 389.3 1487 3.827            1\n\n23:26:03 | time:449s total_exs:23560 total_steps:1178 epochs:117.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.77     0 275.4  1019       0          0 74.01  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002925    .1209 5.995 .0002478 4.995e-05 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   443.7       0          0                 1178 395.3 1463 3.715            1\n\n23:26:03 | running eval: valid\n23:26:03 | eval completed in 0.22s\n23:26:03 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1589       0          0 122.2   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6 .6771 4.995e-05    72 733.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1178  228 2323        .9167\n\u001b[0m\n23:26:03 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 17\u001b[0m\n23:26:03 | saving model checkpoint: /tmp/model2.checkpoint\n23:26:18 | time:464s total_exs:24320 total_steps:1216 epochs:121.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.67     0 273.4  1038       0          0 75.94  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002781    .1209 5.958 .0002355 4.995e-05 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   452.5       0          0                 1216 392.5 1490 3.806            1\n\n23:26:24 | time:470s total_exs:24780 total_steps:1239 epochs:123.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.76     0 275.2  1072       0          0 77.89  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002639    .1209 5.922 .0002234 4.995e-05 118.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.2       0          0                 1239 393.6 1533 3.909            1\n\n23:26:24 | running eval: valid\n23:26:24 | eval completed in 0.20s\n23:26:24 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1688       0          0 129.8   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 .6753 4.995e-05    72 779.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1239  228 2468        .9167\n\u001b[0m\n23:26:24 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 18\u001b[0m\n23:26:24 | saving model checkpoint: /tmp/model2.checkpoint\n23:26:38 | time:485s total_exs:25520 total_steps:1276 epochs:127.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.51     0 270.2  1000       0          0 74.02  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002503    .1209 5.943 .0002119 4.995e-05 118.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   439.9       0          0                 1276 389.1 1440 3.709            1\n\n23:26:44 | time:490s total_exs:25960 total_steps:1298 epochs:129.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.76     0 275.2  1059       0          0 76.95  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002378    .1209 5.977 .0002013 4.995e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     460       0          0                 1298 394.8 1519 3.863            1\n\n23:26:44 | running eval: valid\n23:26:44 | eval completed in 0.20s\n23:26:44 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1761       0          0 135.4   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 .6808 4.995e-05    72 812.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1298  228 2574        .9167\n\u001b[0m\nEpoch 00005: reducing learning rate of group 0 to 2.4975e-05.\n23:26:44 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 19\u001b[0m\n23:26:44 | saving model checkpoint: /tmp/model2.checkpoint\n23:26:59 | time:505s total_exs:26740 total_steps:1337 epochs:133.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.55     0 271.1  1037       0          0 76.51  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002291    .1209     6 .0001939 2.498e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.1       0          0                 1337 391.1 1496 3.834            1\n\n23:27:05 | time:511s total_exs:27160 total_steps:1358 epochs:135.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.84     0 276.8  1044       0          0 75.46  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002235    .1209  6.01 .0001891 2.498e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   453.5       0          0                 1358  397 1498 3.789            1\n\n23:27:05 | running eval: valid\n23:27:05 | eval completed in 0.20s\n23:27:05 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1732       0          0 133.2   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 .6929 2.498e-05    72 799.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1358  228 2532        .9167\n\u001b[0m\n23:27:05 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 20\u001b[0m\n23:27:05 | saving model checkpoint: /tmp/model2.checkpoint\n23:27:19 | time:525s total_exs:27940 total_steps:1397 epochs:139.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.77     0 275.4  1056       0          0 76.65  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002183    .1209 5.995 .0001847 2.498e-05 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.5       0          0                 1397 395.3 1515 3.841            1\n\n23:27:25 | time:531s total_exs:28360 total_steps:1418 epochs:141.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0 275.9  1050       0          0 76.11  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .00214    .1209 5.895 .000181 2.498e-05 117.9 448.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1418 393.8 1499 3.821            1\n\n23:27:25 | running eval: valid\n23:27:25 | eval completed in 0.20s\n23:27:25 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1713       0          0 131.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6 .6895 2.498e-05    72 790.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1418  228 2503        .9167\n\u001b[0m\n23:27:25 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 21\u001b[0m\n23:27:25 | saving model checkpoint: /tmp/model2.checkpoint\n23:27:39 | time:546s total_exs:29120 total_steps:1456 epochs:145.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.51     0 270.1  1013       0          0 74.97  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002075    .1209 6.013 .0001754 2.498e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   450.8       0          0                 1456 390.4 1463 3.757            1\n\n23:27:45 | time:551s total_exs:29560 total_steps:1478 epochs:147.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.81     0 276.2  1048       0          0 75.87  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002019    .1209 6.014 .0001708 2.498e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.2       0          0                 1478 396.5 1504 3.808            1\n\n23:27:45 | running eval: valid\n23:27:45 | eval completed in 0.20s\n23:27:45 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1753       0          0 134.8   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 .6920 2.498e-05    72 808.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1478  228 2561        .9167\n\u001b[0m\n23:27:45 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 22\u001b[0m\n23:27:45 | saving model checkpoint: /tmp/model2.checkpoint\n23:28:00 | time:566s total_exs:30340 total_steps:1517 epochs:151.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.58     0 271.6  1047       0          0 77.07  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001987    .1209 5.962 .0001672 2.498e-05 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.4       0          0                 1517 390.8 1506 3.862            1\n\n23:28:05 | time:572s total_exs:30760 total_steps:1538 epochs:153.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.56     0 271.2  1009       0          0 74.44  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001924    .1209 5.967 .0001628 2.498e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   444.2       0          0                 1538 390.5 1454 3.738            1\n\n23:28:05 | running eval: valid\n23:28:06 | eval completed in 0.23s\n23:28:06 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1554       0          0 119.5   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 .7185 2.498e-05    72 717.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1538  228 2272        .9167\n\u001b[0m\nEpoch 00009: reducing learning rate of group 0 to 1.2488e-05.\n23:28:06 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 23\u001b[0m\n23:28:06 | saving model checkpoint: /tmp/model2.checkpoint\n23:28:20 | time:586s total_exs:31520 total_steps:1576 epochs:157.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.89     0 277.9  1056       0          0 75.98  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001899    .1209 5.916 .0001605 1.249e-05 118.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.5       0          0                 1576 396.2 1505 3.807            1\n\n23:28:26 | time:592s total_exs:31960 total_steps:1598 epochs:159.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.79     0 275.8  1070       0          0 77.58  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001854    .1209 6.082 .0001569 1.249e-05 121.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   471.8       0          0                 1598 397.5 1542 3.895            1\n\n23:28:26 | running eval: valid\n23:28:26 | eval completed in 0.26s\n23:28:26 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1335       0          0 102.6   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 .7157 1.249e-05    72 616.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1598  228 1952        .9167\n\u001b[0m\n23:28:26 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 24\u001b[0m\n23:28:26 | saving model checkpoint: /tmp/model2.checkpoint\n23:28:40 | time:607s total_exs:32700 total_steps:1635 epochs:163.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.58     0 271.6  1003       0          0 73.85  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001845    .1210 5.957 .0001561 1.249e-05 119.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   439.9       0          0                 1635 390.8 1443 3.701            1\n\n23:28:46 | time:612s total_exs:33140 total_steps:1657 epochs:165.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.77     0 275.4  1058       0          0 76.82  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001821    .1210  5.95 .000154 1.249e-05   119 457.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1657 394.4 1515 3.856            1\n\n23:28:46 | running eval: valid\n23:28:46 | eval completed in 0.20s\n23:28:46 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1702       0          0 130.8   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 .7168 1.249e-05    72 785.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1657  228 2487        .9167\n\u001b[0m\n23:28:46 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 25\u001b[0m\n23:28:46 | saving model checkpoint: /tmp/model2.checkpoint\n23:29:01 | time:627s total_exs:33920 total_steps:1696 epochs:169.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.91     0 278.2  1061       0          0 76.29  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00179    .1210 5.995 .0001514 1.249e-05 119.9 457.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1696 398.1 1518 3.823            1\n\n23:29:06 | time:633s total_exs:34340 total_steps:1717 epochs:171.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.75     0 275.1  1060       0          0 77.04  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00176    .1210 6.033 .0001488 1.249e-05 120.7 464.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1717 395.8 1524 3.868            1\n\n23:29:06 | running eval: valid\n23:29:07 | eval completed in 0.20s\n23:29:07 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1730       0          0   133   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 .7147 1.249e-05    72 798.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1717  228 2528        .9167\n\u001b[0m\n23:29:07 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 26\u001b[0m\n23:29:07 | saving model checkpoint: /tmp/model2.checkpoint\n23:29:27 | time:653s total_exs:35060 total_steps:1753 epochs:175.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.58     0 271.6  1040       0          0 76.54  720   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001742    .1210 6.014 .0001471 1.249e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.3       0          0                 1753 391.9 1500 3.836            1\n\n23:29:27 | running eval: valid\n23:29:27 | eval completed in 0.20s\n23:29:27 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1737       0          0 133.6   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 .7131 1.249e-05    72 801.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1753  228 2539        .9167\n\u001b[0m\nEpoch 00013: reducing learning rate of group 0 to 6.2438e-06.\n23:29:27 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 27\u001b[0m\n23:29:27 | saving model checkpoint: /tmp/model2.checkpoint\n23:29:41 | time:668s total_exs:35820 total_steps:1791 epochs:179.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.88     0 277.7  1037       0          0 74.71  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001716    .1210 6.013 .0001451 6.244e-06 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.2       0          0                 1791 397.9 1486 3.744            1\n\n23:29:47 | time:673s total_exs:36240 total_steps:1812 epochs:181.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.6     0   272  1029       0          0 75.67  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001705    .1210 6.005 .0001442 6.244e-06 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   454.4       0          0                 1812 392.1 1484 3.799            1\n\n23:29:47 | running eval: valid\n23:29:47 | eval completed in 0.20s\n23:29:47 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1745       0          0 134.2   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08122     6 .7172 6.244e-06    72 805.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1812  228 2550        .9167\n\u001b[0m\n23:29:47 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 28\u001b[0m\n23:29:47 | saving model checkpoint: /tmp/model2.checkpoint\n23:30:02 | time:688s total_exs:37000 total_steps:1850 epochs:185.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.77     0 275.4  1045       0          0 75.85  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001696    .1210 5.958 .0001434 6.244e-06 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.9       0          0                 1850 394.6 1496 3.801            1\n\n23:30:07 | time:694s total_exs:37400 total_steps:1870 epochs:187.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.89     0 277.8  1053       0          0 75.85  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001675    .1210 6.035 .0001416 6.244e-06 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.8       0          0                 1870 398.4 1511 3.809            1\n\n23:30:07 | running eval: valid\n23:30:08 | eval completed in 0.20s\n23:30:08 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1711       0          0 131.5   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08123     6 .7210 6.244e-06    72 789.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1870  228 2500        .9167\n\u001b[0m\n23:30:08 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 29\u001b[0m\n23:30:08 | saving model checkpoint: /tmp/model2.checkpoint\n23:30:22 | time:708s total_exs:38160 total_steps:1908 epochs:190.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.73     0 274.6  1037       0          0  75.5  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001668    .1210 5.989 .000141 6.244e-06 119.8 452.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1908 394.4 1489 3.783            1\n\n23:30:28 | time:714s total_exs:38580 total_steps:1929 epochs:192.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.56     0 271.3  1026       0          0 75.63  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001666    .1210  5.91 .0001408 6.244e-06 118.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   446.9       0          0                 1929 389.5 1473 3.797            1\n\n23:30:28 | running eval: valid\n23:30:28 | eval completed in 0.20s\n23:30:28 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1709       0          0 131.4   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08124     6 .7250 6.244e-06    72 788.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1929  228 2498        .9167\n\u001b[0m\n23:30:28 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 30\u001b[0m\n23:30:28 | saving model checkpoint: /tmp/model2.checkpoint\n23:30:32 | ran out of patience! stopping training.\n23:30:32 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n23:30:32 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n23:30:32 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run2/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n23:30:32 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n23:30:32 | Using CUDA\n23:30:32 | loading dictionary from /tmp/model2.dict\n23:30:33 | num words = 54944\n23:30:37 | Loading existing model parameters from /tmp/model2\n23:30:45 | Total parameters: 128,042,498 (128,042,498 trainable)\n23:30:46 | creating task(s): fromfile:parlaiformat\n23:30:46 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run2/data_valid.txt\n23:30:46 | running eval: valid\n23:30:47 | eval completed in 0.30s\n23:30:47 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1    11   156  1155       0          0 88.81   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298     6 .1959 9.304e-06    72 533.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    186  228 1689        .9583\n\u001b[0m\n23:30:47 | creating task(s): fromfile:parlaiformat\n23:30:47 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run2/data_test.txt\n23:30:47 | running eval: test\n23:30:52 | eval completed in 5.13s\n23:30:52 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9380 9.38e-10               .7540                 .6250   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9645              .9941   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9367 12.07 281.4  2755       0          0 195.8 1000 .9380   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298   5.2 .1753 9.304e-06   104  1018       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    186 385.4 3773        .9435\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type1/run2/data_test.txt -m transformer/classifier -mf /tmp/model2 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:30:54.203371Z","iopub.execute_input":"2022-12-03T23:30:54.203765Z","iopub.status.idle":"2022-12-03T23:31:24.764604Z","shell.execute_reply.started":"2022-12-03T23:30:54.203723Z","shell.execute_reply":"2022-12-03T23:31:24.763435Z"},"scrolled":true,"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"23:31:02 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr2type1/run2/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr2type1/run2/data)\u001b[0m\n23:31:02 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n23:31:02 | Using CUDA\n23:31:02 | loading dictionary from /tmp/model2.dict\n23:31:03 | num words = 54944\n23:31:07 | Loading existing model parameters from /tmp/model2\n23:31:13 | Total parameters: 128,042,498 (128,042,498 trainable)\n23:31:14 | Opt:\n23:31:14 |     activation: gelu\n23:31:14 |     adafactor_eps: '[1e-30, 0.001]'\n23:31:14 |     adam_eps: 1e-08\n23:31:14 |     add_p1_after_newln: False\n23:31:14 |     aggregate_micro: False\n23:31:14 |     allow_missing_init_opts: False\n23:31:14 |     area_under_curve_class: None\n23:31:14 |     area_under_curve_digits: -1\n23:31:14 |     attention_dropout: 0.1\n23:31:14 |     batchsize: 40\n23:31:14 |     betas: '[0.9, 0.999]'\n23:31:14 |     bpe_add_prefix_space: None\n23:31:14 |     bpe_debug: False\n23:31:14 |     bpe_dropout: None\n23:31:14 |     bpe_merge: None\n23:31:14 |     bpe_vocab: None\n23:31:14 |     candidates: inline\n23:31:14 |     cap_num_predictions: 100\n23:31:14 |     checkpoint_activations: False\n23:31:14 |     class_weights: None\n23:31:14 |     classes: \"['__notok__', '__ok__']\"\n23:31:14 |     classes_from_file: None\n23:31:14 |     data_parallel: True\n23:31:14 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n23:31:14 |     datatype: train\n23:31:14 |     delimiter: '\\n'\n23:31:14 |     dict_class: parlai.core.dict:DictionaryAgent\n23:31:14 |     dict_endtoken: __start__\n23:31:14 |     dict_file: /tmp/model2.dict\n23:31:14 |     dict_include_test: False\n23:31:14 |     dict_include_valid: False\n23:31:14 |     dict_initpath: None\n23:31:14 |     dict_language: english\n23:31:14 |     dict_loaded: True\n23:31:14 |     dict_lower: True\n23:31:14 |     dict_max_ngram_size: -1\n23:31:14 |     dict_maxexs: -1\n23:31:14 |     dict_maxtokens: -1\n23:31:14 |     dict_minfreq: 0\n23:31:14 |     dict_nulltoken: __null__\n23:31:14 |     dict_starttoken: __start__\n23:31:14 |     dict_textfields: text,labels\n23:31:14 |     dict_tokenizer: bpe\n23:31:14 |     dict_unktoken: __unk__\n23:31:14 |     display_examples: False\n23:31:14 |     download_path: None\n23:31:14 |     dropout: 0.1\n23:31:14 |     dynamic_batching: None\n23:31:14 |     embedding_projection: random\n23:31:14 |     embedding_size: 768\n23:31:14 |     embedding_type: random\n23:31:14 |     embeddings_scale: False\n23:31:14 |     encode_candidate_vecs: True\n23:31:14 |     encode_candidate_vecs_batchsize: 256\n23:31:14 |     eval_batchsize: None\n23:31:14 |     eval_candidates: inline\n23:31:14 |     eval_dynamic_batching: None\n23:31:14 |     evaltask: None\n23:31:14 |     ffn_size: 3072\n23:31:14 |     final_extra_opt: \n23:31:14 |     fixed_candidate_vecs: reuse\n23:31:14 |     fixed_candidates_path: None\n23:31:14 |     force_fp16_tokens: True\n23:31:14 |     fp16: True\n23:31:14 |     fp16_impl: safe\n23:31:14 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run2/data_test.txt\n23:31:14 |     fromfile_datatype_extension: True\n23:31:14 |     gpu: -1\n23:31:14 |     gradient_clip: 0.1\n23:31:14 |     hide_labels: False\n23:31:14 |     history_add_global_end_token: None\n23:31:14 |     history_reversed: False\n23:31:14 |     history_size: 20\n23:31:14 |     ignore_bad_candidates: False\n23:31:14 |     ignore_labels: None\n23:31:14 |     image_cropsize: 224\n23:31:14 |     image_mode: raw\n23:31:14 |     image_size: 256\n23:31:14 |     inference: max\n23:31:14 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n23:31:14 |     init_opt: None\n23:31:14 |     interactive_candidates: fixed\n23:31:14 |     interactive_mode: False\n23:31:14 |     invsqrt_lr_decay_gamma: -1\n23:31:14 |     is_debug: False\n23:31:14 |     label_truncate: 72\n23:31:14 |     learn_embeddings: True\n23:31:14 |     learn_positional_embeddings: True\n23:31:14 |     learningrate: 5e-05\n23:31:14 |     load_from_pretrained_ranker: True\n23:31:14 |     log_every_n_secs: 10.0\n23:31:14 |     log_every_n_steps: 50\n23:31:14 |     log_keep_fields: all\n23:31:14 |     loglevel: info\n23:31:14 |     lr_scheduler: reduceonplateau\n23:31:14 |     lr_scheduler_decay: 0.5\n23:31:14 |     lr_scheduler_patience: 3\n23:31:14 |     max_train_steps: -1\n23:31:14 |     max_train_time: 7200.0\n23:31:14 |     memory_attention: sqrt\n23:31:14 |     metrics: default\n23:31:14 |     model: transformer/classifier\n23:31:14 |     model_file: /tmp/model2\n23:31:14 |     model_parallel: False\n23:31:14 |     momentum: 0\n23:31:14 |     multitask_weights: [1]\n23:31:14 |     mutators: None\n23:31:14 |     n_decoder_layers: -1\n23:31:14 |     n_encoder_layers: -1\n23:31:14 |     n_heads: 12\n23:31:14 |     n_layers: 12\n23:31:14 |     n_positions: 1024\n23:31:14 |     n_segments: 2\n23:31:14 |     nesterov: True\n23:31:14 |     no_cuda: False\n23:31:14 |     normalize_sent_emb: False\n23:31:14 |     num_epochs: -1\n23:31:14 |     num_examples: -1\n23:31:14 |     num_workers: 0\n23:31:14 |     nus: [0.7]\n23:31:14 |     optimizer: adamax\n23:31:14 |     output_scaling: 0.06\n23:31:14 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type1/run2/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model2', 'batchsize': 40}\"\n23:31:14 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n23:31:14 |     person_tokens: False\n23:31:14 |     print_scores: False\n23:31:14 |     rank_candidates: False\n23:31:14 |     rank_top_k: -1\n23:31:14 |     reduction_type: mean\n23:31:14 |     ref_class: None\n23:31:14 |     relu_dropout: 0.0\n23:31:14 |     repeat_blocking_heuristic: True\n23:31:14 |     report_filename: \n23:31:14 |     return_cand_scores: False\n23:31:14 |     save_after_valid: True\n23:31:14 |     save_every_n_secs: -1\n23:31:14 |     save_format: conversations\n23:31:14 |     share_encoders: False\n23:31:14 |     share_word_embeddings: False\n23:31:14 |     short_final_eval: False\n23:31:14 |     special_tok_lst: None\n23:31:14 |     split_lines: False\n23:31:14 |     starttime: Dec03_23-18\n23:31:14 |     task: fromfile:parlaiformat\n23:31:14 |     tensorboard_log: False\n23:31:14 |     tensorboard_logdir: None\n23:31:14 |     text_truncate: 360\n23:31:14 |     threshold: 0.5\n23:31:14 |     topk: 5\n23:31:14 |     train_predict: False\n23:31:14 |     truncate: 1024\n23:31:14 |     update_classifier_head_only: False\n23:31:14 |     update_freq: 1\n23:31:14 |     use_memories: False\n23:31:14 |     use_reply: none\n23:31:14 |     validation_cutoff: 1.0\n23:31:14 |     validation_every_n_epochs: -1\n23:31:14 |     validation_every_n_secs: 20.0\n23:31:14 |     validation_every_n_steps: -1\n23:31:14 |     validation_max_exs: -1\n23:31:14 |     validation_metric: accuracy\n23:31:14 |     validation_metric_mode: max\n23:31:14 |     validation_patience: 30\n23:31:14 |     validation_share_agent: False\n23:31:14 |     variant: xlm\n23:31:14 |     verbose: False\n23:31:14 |     wandb_entity: None\n23:31:14 |     wandb_log: False\n23:31:14 |     wandb_name: None\n23:31:14 |     wandb_project: None\n23:31:14 |     warmup_rate: 0.0001\n23:31:14 |     warmup_updates: 1000\n23:31:14 |     weight_decay: None\n23:31:14 |     world_logs: \n23:31:14 |     wrap_memory_encoder: False\n23:31:14 | Evaluating task fromfile:parlaiformat using datatype valid.\n23:31:14 | creating task(s): fromfile:parlaiformat\n23:31:14 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n23:31:14 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run2/data_test.txt\n23:31:23 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9380 9.38e-10               .7540                 .6250   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9645              .9941   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9367 12.07 562.9  1776       0          0 126.2 1000 .9380   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .1753 9.304e-06   208 656.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    186 770.9 2432        .9435\u001b[0m\n23:31:23 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9380 9.38e-10               .7540                 .6250   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9645              .9941   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9367 12.07 562.9  1776       0          0 126.2 1000 .9380   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .1753 9.304e-06   208 656.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    186 770.9 2432        .9435\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model2*","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:31:24.766824Z","iopub.execute_input":"2022-12-03T23:31:24.767250Z","iopub.status.idle":"2022-12-03T23:31:26.002425Z","shell.execute_reply.started":"2022-12-03T23:31:24.767197Z","shell.execute_reply":"2022-12-03T23:31:26.001112Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"run 3","metadata":{}},{"cell_type":"code","source":"# run 3 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type1/run3/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model3","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:31:26.011956Z","iopub.execute_input":"2022-12-03T23:31:26.012329Z","iopub.status.idle":"2022-12-03T23:33:22.549321Z","shell.execute_reply.started":"2022-12-03T23:31:26.012295Z","shell.execute_reply":"2022-12-03T23:33:22.547793Z"},"scrolled":true,"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"23:31:33 | building dictionary first...\n23:31:33 | No model with opt yet at: /tmp/model3(.opt)\n23:31:33 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run3/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n23:31:33 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n23:31:33 | Using CUDA\n23:31:33 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n23:31:33 | num words = 54944\n23:31:37 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n23:31:48 | Total parameters: 128,042,498 (128,042,498 trainable)\n23:31:48 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n23:31:48 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n23:31:48 | Opt:\n23:31:48 |     activation: gelu\n23:31:48 |     adafactor_eps: '(1e-30, 0.001)'\n23:31:48 |     adam_eps: 1e-08\n23:31:48 |     add_p1_after_newln: False\n23:31:48 |     aggregate_micro: False\n23:31:48 |     allow_missing_init_opts: False\n23:31:48 |     attention_dropout: 0.1\n23:31:48 |     batchsize: 20\n23:31:48 |     betas: '(0.9, 0.999)'\n23:31:48 |     bpe_add_prefix_space: None\n23:31:48 |     bpe_debug: False\n23:31:48 |     bpe_dropout: None\n23:31:48 |     bpe_merge: None\n23:31:48 |     bpe_vocab: None\n23:31:48 |     candidates: inline\n23:31:48 |     cap_num_predictions: 100\n23:31:48 |     checkpoint_activations: False\n23:31:48 |     class_weights: None\n23:31:48 |     classes: \"['__notok__', '__ok__']\"\n23:31:48 |     classes_from_file: None\n23:31:48 |     data_parallel: True\n23:31:48 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n23:31:48 |     datatype: train\n23:31:48 |     delimiter: '\\n'\n23:31:48 |     dict_class: parlai.core.dict:DictionaryAgent\n23:31:48 |     dict_endtoken: __start__\n23:31:48 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n23:31:48 |     dict_include_test: False\n23:31:48 |     dict_include_valid: False\n23:31:48 |     dict_initpath: None\n23:31:48 |     dict_language: english\n23:31:48 |     dict_loaded: True\n23:31:48 |     dict_lower: True\n23:31:48 |     dict_max_ngram_size: -1\n23:31:48 |     dict_maxexs: -1\n23:31:48 |     dict_maxtokens: -1\n23:31:48 |     dict_minfreq: 0\n23:31:48 |     dict_nulltoken: __null__\n23:31:48 |     dict_starttoken: __start__\n23:31:48 |     dict_textfields: text,labels\n23:31:48 |     dict_tokenizer: bpe\n23:31:48 |     dict_unktoken: __unk__\n23:31:48 |     display_examples: False\n23:31:48 |     download_path: None\n23:31:48 |     dropout: 0.1\n23:31:48 |     dynamic_batching: None\n23:31:48 |     embedding_projection: random\n23:31:48 |     embedding_size: 768\n23:31:48 |     embedding_type: random\n23:31:48 |     embeddings_scale: False\n23:31:48 |     encode_candidate_vecs: True\n23:31:48 |     encode_candidate_vecs_batchsize: 256\n23:31:48 |     eval_batchsize: None\n23:31:48 |     eval_candidates: inline\n23:31:48 |     eval_dynamic_batching: None\n23:31:48 |     evaltask: None\n23:31:48 |     ffn_size: 3072\n23:31:48 |     final_extra_opt: \n23:31:48 |     fixed_candidate_vecs: reuse\n23:31:48 |     fixed_candidates_path: None\n23:31:48 |     force_fp16_tokens: False\n23:31:48 |     fp16: True\n23:31:48 |     fp16_impl: safe\n23:31:48 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run3/data\n23:31:48 |     fromfile_datatype_extension: True\n23:31:48 |     gpu: -1\n23:31:48 |     gradient_clip: 0.1\n23:31:48 |     hide_labels: False\n23:31:48 |     history_add_global_end_token: None\n23:31:48 |     history_reversed: False\n23:31:48 |     history_size: 20\n23:31:48 |     ignore_bad_candidates: False\n23:31:48 |     ignore_labels: None\n23:31:48 |     image_cropsize: 224\n23:31:48 |     image_mode: raw\n23:31:48 |     image_size: 256\n23:31:48 |     inference: max\n23:31:48 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n23:31:48 |     init_opt: None\n23:31:48 |     interactive_candidates: fixed\n23:31:48 |     interactive_mode: False\n23:31:48 |     invsqrt_lr_decay_gamma: -1\n23:31:48 |     is_debug: False\n23:31:48 |     label_truncate: 72\n23:31:48 |     learn_embeddings: True\n23:31:48 |     learn_positional_embeddings: True\n23:31:48 |     learningrate: 5e-05\n23:31:48 |     load_from_checkpoint: False\n23:31:48 |     load_from_pretrained_ranker: True\n23:31:48 |     log_every_n_secs: 10.0\n23:31:48 |     log_every_n_steps: 50\n23:31:48 |     log_keep_fields: all\n23:31:48 |     loglevel: info\n23:31:48 |     lr_scheduler: reduceonplateau\n23:31:48 |     lr_scheduler_decay: 0.5\n23:31:48 |     lr_scheduler_patience: 3\n23:31:48 |     max_train_steps: -1\n23:31:48 |     max_train_time: 7200.0\n23:31:48 |     memory_attention: sqrt\n23:31:48 |     metrics: default\n23:31:48 |     model: transformer/classifier\n23:31:48 |     model_file: /tmp/model3\n23:31:48 |     model_parallel: False\n23:31:48 |     momentum: 0\n23:31:48 |     multitask_weights: [1]\n23:31:48 |     mutators: None\n23:31:48 |     n_decoder_layers: -1\n23:31:48 |     n_encoder_layers: -1\n23:31:48 |     n_heads: 12\n23:31:48 |     n_layers: 12\n23:31:48 |     n_positions: 1024\n23:31:48 |     n_segments: 2\n23:31:48 |     nesterov: True\n23:31:48 |     no_cuda: False\n23:31:48 |     normalize_sent_emb: False\n23:31:48 |     num_epochs: -1\n23:31:48 |     num_workers: 0\n23:31:48 |     nus: (0.7,)\n23:31:48 |     optimizer: adamax\n23:31:48 |     output_scaling: 0.06\n23:31:48 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type1/run3/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model3'}\"\n23:31:48 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n23:31:48 |     person_tokens: False\n23:31:48 |     print_scores: False\n23:31:48 |     rank_candidates: False\n23:31:48 |     rank_top_k: -1\n23:31:48 |     reduction_type: mean\n23:31:48 |     ref_class: None\n23:31:48 |     relu_dropout: 0.0\n23:31:48 |     repeat_blocking_heuristic: True\n23:31:48 |     return_cand_scores: False\n23:31:48 |     save_after_valid: True\n23:31:48 |     save_every_n_secs: -1\n23:31:48 |     save_format: conversations\n23:31:48 |     share_encoders: False\n23:31:48 |     share_word_embeddings: False\n23:31:48 |     short_final_eval: False\n23:31:48 |     special_tok_lst: None\n23:31:48 |     split_lines: False\n23:31:48 |     starttime: Dec03_23-31\n23:31:48 |     task: fromfile:parlaiformat\n23:31:48 |     tensorboard_log: False\n23:31:48 |     tensorboard_logdir: None\n23:31:48 |     text_truncate: 360\n23:31:48 |     threshold: 0.5\n23:31:48 |     topk: 5\n23:31:48 |     train_predict: False\n23:31:48 |     truncate: 1024\n23:31:48 |     update_classifier_head_only: False\n23:31:48 |     update_freq: 1\n23:31:48 |     use_memories: False\n23:31:48 |     use_reply: none\n23:31:48 |     validation_cutoff: 1.0\n23:31:48 |     validation_every_n_epochs: -1\n23:31:48 |     validation_every_n_secs: 20.0\n23:31:48 |     validation_every_n_steps: -1\n23:31:48 |     validation_max_exs: -1\n23:31:48 |     validation_metric: accuracy\n23:31:48 |     validation_metric_mode: max\n23:31:48 |     validation_patience: 30\n23:31:48 |     validation_share_agent: False\n23:31:48 |     variant: xlm\n23:31:48 |     verbose: False\n23:31:48 |     wandb_entity: None\n23:31:48 |     wandb_log: False\n23:31:48 |     wandb_name: None\n23:31:48 |     wandb_project: None\n23:31:48 |     warmup_rate: 0.0001\n23:31:48 |     warmup_updates: 1000\n23:31:48 |     weight_decay: None\n23:31:48 |     world_logs: \n23:31:48 |     wrap_memory_encoder: False\n23:31:48 | creating task(s): fromfile:parlaiformat\n23:31:48 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run3/data_train.txt\n23:31:48 | training...\n23:31:59 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .4525 4.525e-10               .4847                 .4598   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5124            .4160              .4432   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .3920  11.8     1   276 546.2       0          0 39.58  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .4525             32768  2.659    .1206 6.005 .7010 1.005e-06 120.1 237.7   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 396.1 783.9 1.983        .4505\n\n23:32:09 | time:20s total_exs:1160 total_steps:58 epochs:5.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5658 5.658e-10               .6325                 .5669   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7154            .4695              .5637   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .4022 11.57     1 271.5  1040       0          0 76.59  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5658             32768  2.653    .1207 6.045 .6822 2.905e-06 120.9   463   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   58 392.4 1503 3.838        .5546\n\n23:32:09 | creating task(s): fromfile:parlaiformat\n23:32:09 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run3/data_valid.txt\n23:32:09 | running eval: valid\n23:32:09 | eval completed in 0.20s\n23:32:09 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .7407                 .6667   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .6667              .7778   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .5833 11.71 164.5  1817       0          0 132.5   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6557 2.905e-06    72 795.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     58 236.5 2612        .7037\n\u001b[0m\n23:32:09 | \u001b[1;32mnew best accuracy: 0.7083\u001b[0m\n23:32:09 | saving best valid model: /tmp/model3\n23:32:09 | Saving dictionary to /tmp/model3.dict\n23:32:12 | saving model checkpoint: /tmp/model3.checkpoint\n23:32:12 | Saving dictionary to /tmp/model3.checkpoint.dict\n23:32:29 | time:41s total_exs:1860 total_steps:93 epochs:9.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8457 8.457e-10               .8479                 .8292   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8674            .8435              .8635   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8244 11.85     1   277 950.5       0          0 68.62  700   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8457             32768  2.944    .1207 5.991 .6209 4.655e-06 119.8 411.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   93 396.9 1362 3.439        .8457\n\n23:32:32 | time:44s total_exs:2100 total_steps:105 epochs:10.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .8925                 .9540   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8384            .9320              .8954   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9716 12.05     1   281  1081       0          0 76.95  240   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9167             32768  4.056    .1207 5.825 .5332 5.254e-06 116.5 448.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  105 397.5 1529 3.875        .9157\n\n23:32:32 | running eval: valid\n23:32:32 | eval completed in 0.20s\n23:32:32 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 11.71 164.5  1791       0          0 130.6   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5131 5.254e-06    72 783.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    105 236.5 2575        .9583\n\u001b[0m\n23:32:32 | \u001b[1;32mnew best accuracy: 0.9583 (previous best was 0.7083)\u001b[0m\n23:32:32 | saving best valid model: /tmp/model3\n23:32:37 | saving model checkpoint: /tmp/model3.checkpoint\n23:32:56 | time:68s total_exs:2840 total_steps:142 epochs:14.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9243 9.243e-10               .9231                 .9307   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9155            .9255              .9182   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9330 11.59     1 271.8   994       0          0 73.14  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9243             32768  3.548    .1207 5.992 .4120 7.104e-06 119.8 438.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  142 391.6 1432 3.665        .9243\n\n23:32:57 | time:69s total_exs:2940 total_steps:147 epochs:14.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9600 9.6e-10               .9535                 .9535   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9535            .9649              .9649   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9649 11.58     1 271.6  1045       0          0 76.94  100   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9600             32768  3.869    .1207  5.86 .2373 7.354e-06 117.2 450.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  147 388.8 1496 3.915        .9600\n\n23:32:57 | running eval: valid\n23:32:58 | eval completed in 0.20s\n23:32:58 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 11.71 164.5  1790       0          0 130.5   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .2105 7.354e-06    72 783.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    147 236.5 2573            1\n\u001b[0m\n23:32:58 | \u001b[1;32mnew best accuracy: 1 (previous best was 0.9583)\u001b[0m\n23:32:58 | saving best valid model: /tmp/model3\n23:33:07 | task solved! stopping.\n23:33:07 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n23:33:07 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n23:33:07 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run3/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n23:33:07 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n23:33:07 | Using CUDA\n23:33:07 | loading dictionary from /tmp/model3.dict\n23:33:07 | num words = 54944\n23:33:12 | Loading existing model parameters from /tmp/model3\n23:33:13 | Total parameters: 128,042,498 (128,042,498 trainable)\n23:33:15 | creating task(s): fromfile:parlaiformat\n23:33:15 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run3/data_valid.txt\n23:33:15 | running eval: valid\n23:33:15 | eval completed in 0.22s\n23:33:15 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 11.71 164.5  1707       0          0 124.4   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294     6 .2105 7.354e-06    72   747       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    147 236.5 2454            1\n\u001b[0m\n23:33:15 | creating task(s): fromfile:parlaiformat\n23:33:15 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run3/data_test.txt\n23:33:15 | running eval: test\n23:33:20 | eval completed in 5.06s\n23:33:20 | \u001b[1mtest:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9500 9.5e-10               .7917                 .6786   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9716              .9942   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9500 12.07 281.4  2794       0          0 198.5 1000 .9500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294   5.2 .2426 7.354e-06   104  1032       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    147 385.4 3826        .9536\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type1/run3/data_test.txt -m transformer/classifier -mf /tmp/model3 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:33:22.555240Z","iopub.execute_input":"2022-12-03T23:33:22.555589Z","iopub.status.idle":"2022-12-03T23:33:53.065861Z","shell.execute_reply.started":"2022-12-03T23:33:22.555554Z","shell.execute_reply":"2022-12-03T23:33:53.064630Z"},"scrolled":true,"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"23:33:31 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr2type1/run3/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr2type1/run3/data)\u001b[0m\n23:33:31 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n23:33:31 | Using CUDA\n23:33:31 | loading dictionary from /tmp/model3.dict\n23:33:31 | num words = 54944\n23:33:35 | Loading existing model parameters from /tmp/model3\n23:33:41 | Total parameters: 128,042,498 (128,042,498 trainable)\n23:33:42 | Opt:\n23:33:42 |     activation: gelu\n23:33:42 |     adafactor_eps: '[1e-30, 0.001]'\n23:33:42 |     adam_eps: 1e-08\n23:33:42 |     add_p1_after_newln: False\n23:33:42 |     aggregate_micro: False\n23:33:42 |     allow_missing_init_opts: False\n23:33:42 |     area_under_curve_class: None\n23:33:42 |     area_under_curve_digits: -1\n23:33:42 |     attention_dropout: 0.1\n23:33:42 |     batchsize: 40\n23:33:42 |     betas: '[0.9, 0.999]'\n23:33:42 |     bpe_add_prefix_space: None\n23:33:42 |     bpe_debug: False\n23:33:42 |     bpe_dropout: None\n23:33:42 |     bpe_merge: None\n23:33:42 |     bpe_vocab: None\n23:33:42 |     candidates: inline\n23:33:42 |     cap_num_predictions: 100\n23:33:42 |     checkpoint_activations: False\n23:33:42 |     class_weights: None\n23:33:42 |     classes: \"['__notok__', '__ok__']\"\n23:33:42 |     classes_from_file: None\n23:33:42 |     data_parallel: True\n23:33:42 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n23:33:42 |     datatype: train\n23:33:42 |     delimiter: '\\n'\n23:33:42 |     dict_class: parlai.core.dict:DictionaryAgent\n23:33:42 |     dict_endtoken: __start__\n23:33:42 |     dict_file: /tmp/model3.dict\n23:33:42 |     dict_include_test: False\n23:33:42 |     dict_include_valid: False\n23:33:42 |     dict_initpath: None\n23:33:42 |     dict_language: english\n23:33:42 |     dict_loaded: True\n23:33:42 |     dict_lower: True\n23:33:42 |     dict_max_ngram_size: -1\n23:33:42 |     dict_maxexs: -1\n23:33:42 |     dict_maxtokens: -1\n23:33:42 |     dict_minfreq: 0\n23:33:42 |     dict_nulltoken: __null__\n23:33:42 |     dict_starttoken: __start__\n23:33:42 |     dict_textfields: text,labels\n23:33:42 |     dict_tokenizer: bpe\n23:33:42 |     dict_unktoken: __unk__\n23:33:42 |     display_examples: False\n23:33:42 |     download_path: None\n23:33:42 |     dropout: 0.1\n23:33:42 |     dynamic_batching: None\n23:33:42 |     embedding_projection: random\n23:33:42 |     embedding_size: 768\n23:33:42 |     embedding_type: random\n23:33:42 |     embeddings_scale: False\n23:33:42 |     encode_candidate_vecs: True\n23:33:42 |     encode_candidate_vecs_batchsize: 256\n23:33:42 |     eval_batchsize: None\n23:33:42 |     eval_candidates: inline\n23:33:42 |     eval_dynamic_batching: None\n23:33:42 |     evaltask: None\n23:33:42 |     ffn_size: 3072\n23:33:42 |     final_extra_opt: \n23:33:42 |     fixed_candidate_vecs: reuse\n23:33:42 |     fixed_candidates_path: None\n23:33:42 |     force_fp16_tokens: True\n23:33:42 |     fp16: True\n23:33:42 |     fp16_impl: safe\n23:33:42 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run3/data_test.txt\n23:33:42 |     fromfile_datatype_extension: True\n23:33:42 |     gpu: -1\n23:33:42 |     gradient_clip: 0.1\n23:33:42 |     hide_labels: False\n23:33:42 |     history_add_global_end_token: None\n23:33:42 |     history_reversed: False\n23:33:42 |     history_size: 20\n23:33:42 |     ignore_bad_candidates: False\n23:33:42 |     ignore_labels: None\n23:33:42 |     image_cropsize: 224\n23:33:42 |     image_mode: raw\n23:33:42 |     image_size: 256\n23:33:42 |     inference: max\n23:33:42 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n23:33:42 |     init_opt: None\n23:33:42 |     interactive_candidates: fixed\n23:33:42 |     interactive_mode: False\n23:33:42 |     invsqrt_lr_decay_gamma: -1\n23:33:42 |     is_debug: False\n23:33:42 |     label_truncate: 72\n23:33:42 |     learn_embeddings: True\n23:33:42 |     learn_positional_embeddings: True\n23:33:42 |     learningrate: 5e-05\n23:33:42 |     load_from_pretrained_ranker: True\n23:33:42 |     log_every_n_secs: 10.0\n23:33:42 |     log_every_n_steps: 50\n23:33:42 |     log_keep_fields: all\n23:33:42 |     loglevel: info\n23:33:42 |     lr_scheduler: reduceonplateau\n23:33:42 |     lr_scheduler_decay: 0.5\n23:33:42 |     lr_scheduler_patience: 3\n23:33:42 |     max_train_steps: -1\n23:33:42 |     max_train_time: 7200.0\n23:33:42 |     memory_attention: sqrt\n23:33:42 |     metrics: default\n23:33:42 |     model: transformer/classifier\n23:33:42 |     model_file: /tmp/model3\n23:33:42 |     model_parallel: False\n23:33:42 |     momentum: 0\n23:33:42 |     multitask_weights: [1]\n23:33:42 |     mutators: None\n23:33:42 |     n_decoder_layers: -1\n23:33:42 |     n_encoder_layers: -1\n23:33:42 |     n_heads: 12\n23:33:42 |     n_layers: 12\n23:33:42 |     n_positions: 1024\n23:33:42 |     n_segments: 2\n23:33:42 |     nesterov: True\n23:33:42 |     no_cuda: False\n23:33:42 |     normalize_sent_emb: False\n23:33:42 |     num_epochs: -1\n23:33:42 |     num_examples: -1\n23:33:42 |     num_workers: 0\n23:33:42 |     nus: [0.7]\n23:33:42 |     optimizer: adamax\n23:33:42 |     output_scaling: 0.06\n23:33:42 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type1/run3/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model3', 'batchsize': 40}\"\n23:33:42 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n23:33:42 |     person_tokens: False\n23:33:42 |     print_scores: False\n23:33:42 |     rank_candidates: False\n23:33:42 |     rank_top_k: -1\n23:33:42 |     reduction_type: mean\n23:33:42 |     ref_class: None\n23:33:42 |     relu_dropout: 0.0\n23:33:42 |     repeat_blocking_heuristic: True\n23:33:42 |     report_filename: \n23:33:42 |     return_cand_scores: False\n23:33:42 |     save_after_valid: True\n23:33:42 |     save_every_n_secs: -1\n23:33:42 |     save_format: conversations\n23:33:42 |     share_encoders: False\n23:33:42 |     share_word_embeddings: False\n23:33:42 |     short_final_eval: False\n23:33:42 |     special_tok_lst: None\n23:33:42 |     split_lines: False\n23:33:42 |     starttime: Dec03_23-31\n23:33:42 |     task: fromfile:parlaiformat\n23:33:42 |     tensorboard_log: False\n23:33:42 |     tensorboard_logdir: None\n23:33:42 |     text_truncate: 360\n23:33:42 |     threshold: 0.5\n23:33:42 |     topk: 5\n23:33:42 |     train_predict: False\n23:33:42 |     truncate: 1024\n23:33:42 |     update_classifier_head_only: False\n23:33:42 |     update_freq: 1\n23:33:42 |     use_memories: False\n23:33:42 |     use_reply: none\n23:33:42 |     validation_cutoff: 1.0\n23:33:42 |     validation_every_n_epochs: -1\n23:33:42 |     validation_every_n_secs: 20.0\n23:33:42 |     validation_every_n_steps: -1\n23:33:42 |     validation_max_exs: -1\n23:33:42 |     validation_metric: accuracy\n23:33:42 |     validation_metric_mode: max\n23:33:42 |     validation_patience: 30\n23:33:42 |     validation_share_agent: False\n23:33:42 |     variant: xlm\n23:33:42 |     verbose: False\n23:33:42 |     wandb_entity: None\n23:33:42 |     wandb_log: False\n23:33:42 |     wandb_name: None\n23:33:42 |     wandb_project: None\n23:33:42 |     warmup_rate: 0.0001\n23:33:42 |     warmup_updates: 1000\n23:33:42 |     weight_decay: None\n23:33:42 |     world_logs: \n23:33:42 |     wrap_memory_encoder: False\n23:33:43 | Evaluating task fromfile:parlaiformat using datatype valid.\n23:33:43 | creating task(s): fromfile:parlaiformat\n23:33:43 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n23:33:43 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run3/data_test.txt\n23:33:51 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9500 9.5e-10               .7917                 .6786   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9716              .9942   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9500 12.07 562.9  1826       0          0 129.7 1000 .9500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2426 7.354e-06   208 674.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    147 770.9 2500        .9536\u001b[0m\n23:33:51 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9500 9.5e-10               .7917                 .6786   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9716              .9942   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9500 12.07 562.9  1826       0          0 129.7 1000 .9500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2426 7.354e-06   208 674.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    147 770.9 2500        .9536\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model3*","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:33:53.069054Z","iopub.execute_input":"2022-12-03T23:33:53.069502Z","iopub.status.idle":"2022-12-03T23:33:54.642320Z","shell.execute_reply.started":"2022-12-03T23:33:53.069452Z","shell.execute_reply":"2022-12-03T23:33:54.640672Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"run 4","metadata":{}},{"cell_type":"code","source":"# run 4 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type1/run4/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model4","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:33:54.643991Z","iopub.execute_input":"2022-12-03T23:33:54.644368Z","iopub.status.idle":"2022-12-03T23:35:54.326121Z","shell.execute_reply.started":"2022-12-03T23:33:54.644322Z","shell.execute_reply":"2022-12-03T23:35:54.324776Z"},"scrolled":true,"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"23:34:01 | building dictionary first...\n23:34:01 | No model with opt yet at: /tmp/model4(.opt)\n23:34:01 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run4/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n23:34:01 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n23:34:01 | Using CUDA\n23:34:01 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n23:34:01 | num words = 54944\n23:34:06 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n23:34:16 | Total parameters: 128,042,498 (128,042,498 trainable)\n23:34:16 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n23:34:16 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n23:34:16 | Opt:\n23:34:16 |     activation: gelu\n23:34:16 |     adafactor_eps: '(1e-30, 0.001)'\n23:34:16 |     adam_eps: 1e-08\n23:34:16 |     add_p1_after_newln: False\n23:34:16 |     aggregate_micro: False\n23:34:16 |     allow_missing_init_opts: False\n23:34:16 |     attention_dropout: 0.1\n23:34:16 |     batchsize: 20\n23:34:16 |     betas: '(0.9, 0.999)'\n23:34:16 |     bpe_add_prefix_space: None\n23:34:16 |     bpe_debug: False\n23:34:16 |     bpe_dropout: None\n23:34:16 |     bpe_merge: None\n23:34:16 |     bpe_vocab: None\n23:34:16 |     candidates: inline\n23:34:16 |     cap_num_predictions: 100\n23:34:16 |     checkpoint_activations: False\n23:34:16 |     class_weights: None\n23:34:16 |     classes: \"['__notok__', '__ok__']\"\n23:34:16 |     classes_from_file: None\n23:34:16 |     data_parallel: True\n23:34:16 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n23:34:16 |     datatype: train\n23:34:16 |     delimiter: '\\n'\n23:34:16 |     dict_class: parlai.core.dict:DictionaryAgent\n23:34:16 |     dict_endtoken: __start__\n23:34:16 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n23:34:16 |     dict_include_test: False\n23:34:16 |     dict_include_valid: False\n23:34:16 |     dict_initpath: None\n23:34:16 |     dict_language: english\n23:34:16 |     dict_loaded: True\n23:34:16 |     dict_lower: True\n23:34:16 |     dict_max_ngram_size: -1\n23:34:16 |     dict_maxexs: -1\n23:34:16 |     dict_maxtokens: -1\n23:34:16 |     dict_minfreq: 0\n23:34:16 |     dict_nulltoken: __null__\n23:34:16 |     dict_starttoken: __start__\n23:34:16 |     dict_textfields: text,labels\n23:34:16 |     dict_tokenizer: bpe\n23:34:16 |     dict_unktoken: __unk__\n23:34:16 |     display_examples: False\n23:34:16 |     download_path: None\n23:34:16 |     dropout: 0.1\n23:34:16 |     dynamic_batching: None\n23:34:16 |     embedding_projection: random\n23:34:16 |     embedding_size: 768\n23:34:16 |     embedding_type: random\n23:34:16 |     embeddings_scale: False\n23:34:16 |     encode_candidate_vecs: True\n23:34:16 |     encode_candidate_vecs_batchsize: 256\n23:34:16 |     eval_batchsize: None\n23:34:16 |     eval_candidates: inline\n23:34:16 |     eval_dynamic_batching: None\n23:34:16 |     evaltask: None\n23:34:16 |     ffn_size: 3072\n23:34:16 |     final_extra_opt: \n23:34:16 |     fixed_candidate_vecs: reuse\n23:34:16 |     fixed_candidates_path: None\n23:34:16 |     force_fp16_tokens: False\n23:34:16 |     fp16: True\n23:34:16 |     fp16_impl: safe\n23:34:16 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run4/data\n23:34:16 |     fromfile_datatype_extension: True\n23:34:16 |     gpu: -1\n23:34:16 |     gradient_clip: 0.1\n23:34:16 |     hide_labels: False\n23:34:16 |     history_add_global_end_token: None\n23:34:16 |     history_reversed: False\n23:34:16 |     history_size: 20\n23:34:16 |     ignore_bad_candidates: False\n23:34:16 |     ignore_labels: None\n23:34:16 |     image_cropsize: 224\n23:34:16 |     image_mode: raw\n23:34:16 |     image_size: 256\n23:34:16 |     inference: max\n23:34:16 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n23:34:16 |     init_opt: None\n23:34:16 |     interactive_candidates: fixed\n23:34:16 |     interactive_mode: False\n23:34:16 |     invsqrt_lr_decay_gamma: -1\n23:34:16 |     is_debug: False\n23:34:16 |     label_truncate: 72\n23:34:16 |     learn_embeddings: True\n23:34:16 |     learn_positional_embeddings: True\n23:34:16 |     learningrate: 5e-05\n23:34:16 |     load_from_checkpoint: False\n23:34:16 |     load_from_pretrained_ranker: True\n23:34:16 |     log_every_n_secs: 10.0\n23:34:16 |     log_every_n_steps: 50\n23:34:16 |     log_keep_fields: all\n23:34:16 |     loglevel: info\n23:34:16 |     lr_scheduler: reduceonplateau\n23:34:16 |     lr_scheduler_decay: 0.5\n23:34:16 |     lr_scheduler_patience: 3\n23:34:16 |     max_train_steps: -1\n23:34:16 |     max_train_time: 7200.0\n23:34:16 |     memory_attention: sqrt\n23:34:16 |     metrics: default\n23:34:16 |     model: transformer/classifier\n23:34:16 |     model_file: /tmp/model4\n23:34:16 |     model_parallel: False\n23:34:16 |     momentum: 0\n23:34:16 |     multitask_weights: [1]\n23:34:16 |     mutators: None\n23:34:16 |     n_decoder_layers: -1\n23:34:16 |     n_encoder_layers: -1\n23:34:16 |     n_heads: 12\n23:34:16 |     n_layers: 12\n23:34:16 |     n_positions: 1024\n23:34:16 |     n_segments: 2\n23:34:16 |     nesterov: True\n23:34:16 |     no_cuda: False\n23:34:16 |     normalize_sent_emb: False\n23:34:16 |     num_epochs: -1\n23:34:16 |     num_workers: 0\n23:34:16 |     nus: (0.7,)\n23:34:16 |     optimizer: adamax\n23:34:16 |     output_scaling: 0.06\n23:34:16 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type1/run4/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model4'}\"\n23:34:16 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n23:34:16 |     person_tokens: False\n23:34:16 |     print_scores: False\n23:34:16 |     rank_candidates: False\n23:34:16 |     rank_top_k: -1\n23:34:16 |     reduction_type: mean\n23:34:16 |     ref_class: None\n23:34:16 |     relu_dropout: 0.0\n23:34:16 |     repeat_blocking_heuristic: True\n23:34:16 |     return_cand_scores: False\n23:34:16 |     save_after_valid: True\n23:34:16 |     save_every_n_secs: -1\n23:34:16 |     save_format: conversations\n23:34:16 |     share_encoders: False\n23:34:16 |     share_word_embeddings: False\n23:34:16 |     short_final_eval: False\n23:34:16 |     special_tok_lst: None\n23:34:16 |     split_lines: False\n23:34:16 |     starttime: Dec03_23-34\n23:34:16 |     task: fromfile:parlaiformat\n23:34:16 |     tensorboard_log: False\n23:34:16 |     tensorboard_logdir: None\n23:34:16 |     text_truncate: 360\n23:34:16 |     threshold: 0.5\n23:34:16 |     topk: 5\n23:34:16 |     train_predict: False\n23:34:16 |     truncate: 1024\n23:34:16 |     update_classifier_head_only: False\n23:34:16 |     update_freq: 1\n23:34:16 |     use_memories: False\n23:34:16 |     use_reply: none\n23:34:16 |     validation_cutoff: 1.0\n23:34:16 |     validation_every_n_epochs: -1\n23:34:16 |     validation_every_n_secs: 20.0\n23:34:16 |     validation_every_n_steps: -1\n23:34:16 |     validation_max_exs: -1\n23:34:16 |     validation_metric: accuracy\n23:34:16 |     validation_metric_mode: max\n23:34:16 |     validation_patience: 30\n23:34:16 |     validation_share_agent: False\n23:34:16 |     variant: xlm\n23:34:16 |     verbose: False\n23:34:16 |     wandb_entity: None\n23:34:16 |     wandb_log: False\n23:34:16 |     wandb_name: None\n23:34:16 |     wandb_project: None\n23:34:16 |     warmup_rate: 0.0001\n23:34:16 |     warmup_updates: 1000\n23:34:16 |     weight_decay: None\n23:34:16 |     world_logs: \n23:34:16 |     wrap_memory_encoder: False\n23:34:16 | creating task(s): fromfile:parlaiformat\n23:34:16 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run4/data_train.txt\n23:34:16 | training...\n23:34:26 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6475 6.475e-10               .6553                 .6734   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6381            .6394              .6219   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6579 11.62     1 272.4 539.6       0          0 39.62  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6475             32768   2.41    .1245  6.05 .6738 1.005e-06   121 239.7   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 393.4 779.3 1.985        .6477\n\n23:34:36 | time:20s total_exs:1180 total_steps:59 epochs:5.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7436 7.436e-10               .7416                 .7378   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7455            .7455              .7494   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7418 11.61     1 272.2  1076       0          0 79.06  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7436             32768  2.425    .1245 5.987 .6533 2.955e-06 119.7 473.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   59 391.9 1549 3.962        .7436\n\n23:34:36 | creating task(s): fromfile:parlaiformat\n23:34:36 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run4/data_valid.txt\n23:34:36 | running eval: valid\n23:34:36 | eval completed in 0.20s\n23:34:36 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.04 168.5  1923       0          0 136.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6171 2.955e-06    72 821.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     59 240.5 2744        .9167\n\u001b[0m\n23:34:36 | \u001b[1;32mnew best accuracy: 0.9167\u001b[0m\n23:34:36 | saving best valid model: /tmp/model4\n23:34:36 | Saving dictionary to /tmp/model4.dict\n23:34:40 | saving model checkpoint: /tmp/model4.checkpoint\n23:34:40 | Saving dictionary to /tmp/model4.checkpoint.dict\n23:34:57 | time:41s total_exs:1900 total_steps:95 epochs:9.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8708 8.708e-10               .8654                 .8692   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8617            .8758              .8723   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8794 11.61     1 272.2 969.3       0          0 71.22  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8708             32768  2.829    .1245 5.964 .5879 4.755e-06 119.3 424.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   95 391.5 1394 3.569        .8708\n\n23:35:00 | time:44s total_exs:2120 total_steps:106 epochs:10.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9455 9.455e-10               .9459                 .9633   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9292            .9450              .9279   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9626 11.42     1 268.4  1064       0          0 79.27  220   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9455             32768  3.219    .1207 6.027 .4957 5.304e-06 120.5 477.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  106 388.9 1541 3.996        .9455\n\n23:35:00 | running eval: valid\n23:35:00 | eval completed in 0.19s\n23:35:00 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.04 168.5  1966       0          0   140   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .4740 5.304e-06    72 840.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    106 240.5 2806        .9583\n\u001b[0m\n23:35:00 | \u001b[1;32mnew best accuracy: 0.9583 (previous best was 0.9167)\u001b[0m\n23:35:00 | saving best valid model: /tmp/model4\n23:35:10 | saving model checkpoint: /tmp/model4.checkpoint\n23:35:25 | time:69s total_exs:2900 total_steps:145 epochs:14.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9538 9.538e-10               .9529                 .9681   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9381            .9548              .9406   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9694 11.13     1 262.6  1023       0          0 77.94  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9538             32768  4.085    .1245 5.995 .3510 7.254e-06 119.9 467.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  145 382.5 1491 3.906        .9538\n\n23:35:30 | time:74s total_exs:3280 total_steps:164 epochs:16.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9737 9.737e-10               .9746                 .9846   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9648            .9727              .9622   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9834 11.29     1 265.8  1024       0          0 77.05  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9737             32768  4.518    .1245 6.047 .1772 8.204e-06 120.9 465.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  164 386.7 1490 3.87        .9737\n\n23:35:30 | running eval: valid\n23:35:30 | eval completed in 0.19s\n23:35:30 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 12.04 168.5  1976       0          0 140.7   24   1   \n    gpu_mem  llen   loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .09514 8.204e-06    72 844.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    164 240.5 2821            1\n\u001b[0m\n23:35:30 | \u001b[1;32mnew best accuracy: 1 (previous best was 0.9583)\u001b[0m\n23:35:30 | saving best valid model: /tmp/model4\n23:35:39 | task solved! stopping.\n23:35:39 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n23:35:39 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n23:35:39 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run4/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n23:35:39 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n23:35:39 | Using CUDA\n23:35:39 | loading dictionary from /tmp/model4.dict\n23:35:40 | num words = 54944\n23:35:44 | Loading existing model parameters from /tmp/model4\n23:35:46 | Total parameters: 128,042,498 (128,042,498 trainable)\n23:35:47 | creating task(s): fromfile:parlaiformat\n23:35:47 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run4/data_valid.txt\n23:35:47 | running eval: valid\n23:35:47 | eval completed in 0.20s\n23:35:47 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 12.04 168.5  1893       0          0 134.7   24   1   \n    gpu_mem  llen   loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294     6 .09514 8.204e-06    72 808.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    164 240.5 2701            1\n\u001b[0m\n23:35:47 | creating task(s): fromfile:parlaiformat\n23:35:47 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run4/data_test.txt\n23:35:47 | running eval: test\n23:35:52 | eval completed in 4.75s\n23:35:52 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9440 9.44e-10               .7742                 .6486   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9600            .9680              .9953   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9422 12.07 281.4  2978       0          0 211.6 1000 .9440   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294   5.2 .1850 8.204e-06   104  1100       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    164 385.4 4078        .9487\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type1/run4/data_test.txt -m transformer/classifier -mf /tmp/model4 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:35:54.329664Z","iopub.execute_input":"2022-12-03T23:35:54.330163Z","iopub.status.idle":"2022-12-03T23:36:24.604701Z","shell.execute_reply.started":"2022-12-03T23:35:54.330100Z","shell.execute_reply":"2022-12-03T23:36:24.603515Z"},"scrolled":true,"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"23:36:03 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr2type1/run4/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr2type1/run4/data)\u001b[0m\n23:36:03 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n23:36:03 | Using CUDA\n23:36:03 | loading dictionary from /tmp/model4.dict\n23:36:03 | num words = 54944\n23:36:07 | Loading existing model parameters from /tmp/model4\n23:36:13 | Total parameters: 128,042,498 (128,042,498 trainable)\n23:36:14 | Opt:\n23:36:14 |     activation: gelu\n23:36:14 |     adafactor_eps: '[1e-30, 0.001]'\n23:36:14 |     adam_eps: 1e-08\n23:36:14 |     add_p1_after_newln: False\n23:36:14 |     aggregate_micro: False\n23:36:14 |     allow_missing_init_opts: False\n23:36:14 |     area_under_curve_class: None\n23:36:14 |     area_under_curve_digits: -1\n23:36:14 |     attention_dropout: 0.1\n23:36:14 |     batchsize: 40\n23:36:14 |     betas: '[0.9, 0.999]'\n23:36:14 |     bpe_add_prefix_space: None\n23:36:14 |     bpe_debug: False\n23:36:14 |     bpe_dropout: None\n23:36:14 |     bpe_merge: None\n23:36:14 |     bpe_vocab: None\n23:36:14 |     candidates: inline\n23:36:14 |     cap_num_predictions: 100\n23:36:14 |     checkpoint_activations: False\n23:36:14 |     class_weights: None\n23:36:14 |     classes: \"['__notok__', '__ok__']\"\n23:36:14 |     classes_from_file: None\n23:36:14 |     data_parallel: True\n23:36:14 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n23:36:14 |     datatype: train\n23:36:14 |     delimiter: '\\n'\n23:36:14 |     dict_class: parlai.core.dict:DictionaryAgent\n23:36:14 |     dict_endtoken: __start__\n23:36:14 |     dict_file: /tmp/model4.dict\n23:36:14 |     dict_include_test: False\n23:36:14 |     dict_include_valid: False\n23:36:14 |     dict_initpath: None\n23:36:14 |     dict_language: english\n23:36:14 |     dict_loaded: True\n23:36:14 |     dict_lower: True\n23:36:14 |     dict_max_ngram_size: -1\n23:36:14 |     dict_maxexs: -1\n23:36:14 |     dict_maxtokens: -1\n23:36:14 |     dict_minfreq: 0\n23:36:14 |     dict_nulltoken: __null__\n23:36:14 |     dict_starttoken: __start__\n23:36:14 |     dict_textfields: text,labels\n23:36:14 |     dict_tokenizer: bpe\n23:36:14 |     dict_unktoken: __unk__\n23:36:14 |     display_examples: False\n23:36:14 |     download_path: None\n23:36:14 |     dropout: 0.1\n23:36:14 |     dynamic_batching: None\n23:36:14 |     embedding_projection: random\n23:36:14 |     embedding_size: 768\n23:36:14 |     embedding_type: random\n23:36:14 |     embeddings_scale: False\n23:36:14 |     encode_candidate_vecs: True\n23:36:14 |     encode_candidate_vecs_batchsize: 256\n23:36:14 |     eval_batchsize: None\n23:36:14 |     eval_candidates: inline\n23:36:14 |     eval_dynamic_batching: None\n23:36:14 |     evaltask: None\n23:36:14 |     ffn_size: 3072\n23:36:14 |     final_extra_opt: \n23:36:14 |     fixed_candidate_vecs: reuse\n23:36:14 |     fixed_candidates_path: None\n23:36:14 |     force_fp16_tokens: True\n23:36:14 |     fp16: True\n23:36:14 |     fp16_impl: safe\n23:36:14 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run4/data_test.txt\n23:36:14 |     fromfile_datatype_extension: True\n23:36:14 |     gpu: -1\n23:36:14 |     gradient_clip: 0.1\n23:36:14 |     hide_labels: False\n23:36:14 |     history_add_global_end_token: None\n23:36:14 |     history_reversed: False\n23:36:14 |     history_size: 20\n23:36:14 |     ignore_bad_candidates: False\n23:36:14 |     ignore_labels: None\n23:36:14 |     image_cropsize: 224\n23:36:14 |     image_mode: raw\n23:36:14 |     image_size: 256\n23:36:14 |     inference: max\n23:36:14 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n23:36:14 |     init_opt: None\n23:36:14 |     interactive_candidates: fixed\n23:36:14 |     interactive_mode: False\n23:36:14 |     invsqrt_lr_decay_gamma: -1\n23:36:14 |     is_debug: False\n23:36:14 |     label_truncate: 72\n23:36:14 |     learn_embeddings: True\n23:36:14 |     learn_positional_embeddings: True\n23:36:14 |     learningrate: 5e-05\n23:36:14 |     load_from_pretrained_ranker: True\n23:36:14 |     log_every_n_secs: 10.0\n23:36:14 |     log_every_n_steps: 50\n23:36:14 |     log_keep_fields: all\n23:36:14 |     loglevel: info\n23:36:14 |     lr_scheduler: reduceonplateau\n23:36:14 |     lr_scheduler_decay: 0.5\n23:36:14 |     lr_scheduler_patience: 3\n23:36:14 |     max_train_steps: -1\n23:36:14 |     max_train_time: 7200.0\n23:36:14 |     memory_attention: sqrt\n23:36:14 |     metrics: default\n23:36:14 |     model: transformer/classifier\n23:36:14 |     model_file: /tmp/model4\n23:36:14 |     model_parallel: False\n23:36:14 |     momentum: 0\n23:36:14 |     multitask_weights: [1]\n23:36:14 |     mutators: None\n23:36:14 |     n_decoder_layers: -1\n23:36:14 |     n_encoder_layers: -1\n23:36:14 |     n_heads: 12\n23:36:14 |     n_layers: 12\n23:36:14 |     n_positions: 1024\n23:36:14 |     n_segments: 2\n23:36:14 |     nesterov: True\n23:36:14 |     no_cuda: False\n23:36:14 |     normalize_sent_emb: False\n23:36:14 |     num_epochs: -1\n23:36:14 |     num_examples: -1\n23:36:14 |     num_workers: 0\n23:36:14 |     nus: [0.7]\n23:36:14 |     optimizer: adamax\n23:36:14 |     output_scaling: 0.06\n23:36:14 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type1/run4/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model4', 'batchsize': 40}\"\n23:36:14 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n23:36:14 |     person_tokens: False\n23:36:14 |     print_scores: False\n23:36:14 |     rank_candidates: False\n23:36:14 |     rank_top_k: -1\n23:36:14 |     reduction_type: mean\n23:36:14 |     ref_class: None\n23:36:14 |     relu_dropout: 0.0\n23:36:14 |     repeat_blocking_heuristic: True\n23:36:14 |     report_filename: \n23:36:14 |     return_cand_scores: False\n23:36:14 |     save_after_valid: True\n23:36:14 |     save_every_n_secs: -1\n23:36:14 |     save_format: conversations\n23:36:14 |     share_encoders: False\n23:36:14 |     share_word_embeddings: False\n23:36:14 |     short_final_eval: False\n23:36:14 |     special_tok_lst: None\n23:36:14 |     split_lines: False\n23:36:14 |     starttime: Dec03_23-34\n23:36:14 |     task: fromfile:parlaiformat\n23:36:14 |     tensorboard_log: False\n23:36:14 |     tensorboard_logdir: None\n23:36:14 |     text_truncate: 360\n23:36:14 |     threshold: 0.5\n23:36:14 |     topk: 5\n23:36:14 |     train_predict: False\n23:36:14 |     truncate: 1024\n23:36:14 |     update_classifier_head_only: False\n23:36:14 |     update_freq: 1\n23:36:14 |     use_memories: False\n23:36:14 |     use_reply: none\n23:36:14 |     validation_cutoff: 1.0\n23:36:14 |     validation_every_n_epochs: -1\n23:36:14 |     validation_every_n_secs: 20.0\n23:36:14 |     validation_every_n_steps: -1\n23:36:14 |     validation_max_exs: -1\n23:36:14 |     validation_metric: accuracy\n23:36:14 |     validation_metric_mode: max\n23:36:14 |     validation_patience: 30\n23:36:14 |     validation_share_agent: False\n23:36:14 |     variant: xlm\n23:36:14 |     verbose: False\n23:36:14 |     wandb_entity: None\n23:36:14 |     wandb_log: False\n23:36:14 |     wandb_name: None\n23:36:14 |     wandb_project: None\n23:36:14 |     warmup_rate: 0.0001\n23:36:14 |     warmup_updates: 1000\n23:36:14 |     weight_decay: None\n23:36:14 |     world_logs: \n23:36:14 |     wrap_memory_encoder: False\n23:36:14 | Evaluating task fromfile:parlaiformat using datatype valid.\n23:36:14 | creating task(s): fromfile:parlaiformat\n23:36:14 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n23:36:14 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run4/data_test.txt\n23:36:23 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9440 9.44e-10               .7742                 .6486   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9600            .9680              .9953   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9422 12.07 562.9  1844       0          0 131.1 1000 .9440   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .1850 8.204e-06   208 681.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    164 770.9 2526        .9487\u001b[0m\n23:36:23 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9440 9.44e-10               .7742                 .6486   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9600            .9680              .9953   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9422 12.07 562.9  1844       0          0 131.1 1000 .9440   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .1850 8.204e-06   208 681.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    164 770.9 2526        .9487\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model4*","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:36:24.606796Z","iopub.execute_input":"2022-12-03T23:36:24.607235Z","iopub.status.idle":"2022-12-03T23:36:25.867087Z","shell.execute_reply.started":"2022-12-03T23:36:24.607193Z","shell.execute_reply":"2022-12-03T23:36:25.865761Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"run 5","metadata":{}},{"cell_type":"code","source":"# run 5 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type1/run5/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model5","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:36:25.870981Z","iopub.execute_input":"2022-12-03T23:36:25.871342Z","iopub.status.idle":"2022-12-03T23:48:18.602855Z","shell.execute_reply.started":"2022-12-03T23:36:25.871306Z","shell.execute_reply":"2022-12-03T23:48:18.601412Z"},"scrolled":true,"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"23:36:33 | building dictionary first...\n23:36:33 | No model with opt yet at: /tmp/model5(.opt)\n23:36:33 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run5/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n23:36:33 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n23:36:33 | Using CUDA\n23:36:33 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n23:36:33 | num words = 54944\n23:36:38 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n23:36:48 | Total parameters: 128,042,498 (128,042,498 trainable)\n23:36:48 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n23:36:48 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n23:36:48 | Opt:\n23:36:48 |     activation: gelu\n23:36:48 |     adafactor_eps: '(1e-30, 0.001)'\n23:36:48 |     adam_eps: 1e-08\n23:36:48 |     add_p1_after_newln: False\n23:36:48 |     aggregate_micro: False\n23:36:48 |     allow_missing_init_opts: False\n23:36:48 |     attention_dropout: 0.1\n23:36:48 |     batchsize: 20\n23:36:48 |     betas: '(0.9, 0.999)'\n23:36:48 |     bpe_add_prefix_space: None\n23:36:48 |     bpe_debug: False\n23:36:48 |     bpe_dropout: None\n23:36:48 |     bpe_merge: None\n23:36:48 |     bpe_vocab: None\n23:36:48 |     candidates: inline\n23:36:48 |     cap_num_predictions: 100\n23:36:48 |     checkpoint_activations: False\n23:36:48 |     class_weights: None\n23:36:48 |     classes: \"['__notok__', '__ok__']\"\n23:36:48 |     classes_from_file: None\n23:36:48 |     data_parallel: True\n23:36:48 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n23:36:48 |     datatype: train\n23:36:48 |     delimiter: '\\n'\n23:36:48 |     dict_class: parlai.core.dict:DictionaryAgent\n23:36:48 |     dict_endtoken: __start__\n23:36:48 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n23:36:48 |     dict_include_test: False\n23:36:48 |     dict_include_valid: False\n23:36:48 |     dict_initpath: None\n23:36:48 |     dict_language: english\n23:36:48 |     dict_loaded: True\n23:36:48 |     dict_lower: True\n23:36:48 |     dict_max_ngram_size: -1\n23:36:48 |     dict_maxexs: -1\n23:36:48 |     dict_maxtokens: -1\n23:36:48 |     dict_minfreq: 0\n23:36:48 |     dict_nulltoken: __null__\n23:36:48 |     dict_starttoken: __start__\n23:36:48 |     dict_textfields: text,labels\n23:36:48 |     dict_tokenizer: bpe\n23:36:48 |     dict_unktoken: __unk__\n23:36:48 |     display_examples: False\n23:36:48 |     download_path: None\n23:36:48 |     dropout: 0.1\n23:36:48 |     dynamic_batching: None\n23:36:48 |     embedding_projection: random\n23:36:48 |     embedding_size: 768\n23:36:48 |     embedding_type: random\n23:36:48 |     embeddings_scale: False\n23:36:48 |     encode_candidate_vecs: True\n23:36:48 |     encode_candidate_vecs_batchsize: 256\n23:36:48 |     eval_batchsize: None\n23:36:48 |     eval_candidates: inline\n23:36:48 |     eval_dynamic_batching: None\n23:36:48 |     evaltask: None\n23:36:48 |     ffn_size: 3072\n23:36:48 |     final_extra_opt: \n23:36:48 |     fixed_candidate_vecs: reuse\n23:36:48 |     fixed_candidates_path: None\n23:36:48 |     force_fp16_tokens: False\n23:36:48 |     fp16: True\n23:36:48 |     fp16_impl: safe\n23:36:48 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run5/data\n23:36:48 |     fromfile_datatype_extension: True\n23:36:48 |     gpu: -1\n23:36:48 |     gradient_clip: 0.1\n23:36:48 |     hide_labels: False\n23:36:48 |     history_add_global_end_token: None\n23:36:48 |     history_reversed: False\n23:36:48 |     history_size: 20\n23:36:48 |     ignore_bad_candidates: False\n23:36:48 |     ignore_labels: None\n23:36:48 |     image_cropsize: 224\n23:36:48 |     image_mode: raw\n23:36:48 |     image_size: 256\n23:36:48 |     inference: max\n23:36:48 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n23:36:48 |     init_opt: None\n23:36:48 |     interactive_candidates: fixed\n23:36:48 |     interactive_mode: False\n23:36:48 |     invsqrt_lr_decay_gamma: -1\n23:36:48 |     is_debug: False\n23:36:48 |     label_truncate: 72\n23:36:48 |     learn_embeddings: True\n23:36:48 |     learn_positional_embeddings: True\n23:36:48 |     learningrate: 5e-05\n23:36:48 |     load_from_checkpoint: False\n23:36:48 |     load_from_pretrained_ranker: True\n23:36:48 |     log_every_n_secs: 10.0\n23:36:48 |     log_every_n_steps: 50\n23:36:48 |     log_keep_fields: all\n23:36:48 |     loglevel: info\n23:36:48 |     lr_scheduler: reduceonplateau\n23:36:48 |     lr_scheduler_decay: 0.5\n23:36:48 |     lr_scheduler_patience: 3\n23:36:48 |     max_train_steps: -1\n23:36:48 |     max_train_time: 7200.0\n23:36:48 |     memory_attention: sqrt\n23:36:48 |     metrics: default\n23:36:48 |     model: transformer/classifier\n23:36:48 |     model_file: /tmp/model5\n23:36:48 |     model_parallel: False\n23:36:48 |     momentum: 0\n23:36:48 |     multitask_weights: [1]\n23:36:48 |     mutators: None\n23:36:48 |     n_decoder_layers: -1\n23:36:48 |     n_encoder_layers: -1\n23:36:48 |     n_heads: 12\n23:36:48 |     n_layers: 12\n23:36:48 |     n_positions: 1024\n23:36:48 |     n_segments: 2\n23:36:48 |     nesterov: True\n23:36:48 |     no_cuda: False\n23:36:48 |     normalize_sent_emb: False\n23:36:48 |     num_epochs: -1\n23:36:48 |     num_workers: 0\n23:36:48 |     nus: (0.7,)\n23:36:48 |     optimizer: adamax\n23:36:48 |     output_scaling: 0.06\n23:36:48 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type1/run5/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model5'}\"\n23:36:48 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n23:36:48 |     person_tokens: False\n23:36:48 |     print_scores: False\n23:36:48 |     rank_candidates: False\n23:36:48 |     rank_top_k: -1\n23:36:48 |     reduction_type: mean\n23:36:48 |     ref_class: None\n23:36:48 |     relu_dropout: 0.0\n23:36:48 |     repeat_blocking_heuristic: True\n23:36:48 |     return_cand_scores: False\n23:36:48 |     save_after_valid: True\n23:36:48 |     save_every_n_secs: -1\n23:36:48 |     save_format: conversations\n23:36:48 |     share_encoders: False\n23:36:48 |     share_word_embeddings: False\n23:36:48 |     short_final_eval: False\n23:36:48 |     special_tok_lst: None\n23:36:48 |     split_lines: False\n23:36:48 |     starttime: Dec03_23-36\n23:36:48 |     task: fromfile:parlaiformat\n23:36:48 |     tensorboard_log: False\n23:36:48 |     tensorboard_logdir: None\n23:36:48 |     text_truncate: 360\n23:36:48 |     threshold: 0.5\n23:36:48 |     topk: 5\n23:36:48 |     train_predict: False\n23:36:48 |     truncate: 1024\n23:36:48 |     update_classifier_head_only: False\n23:36:48 |     update_freq: 1\n23:36:48 |     use_memories: False\n23:36:48 |     use_reply: none\n23:36:48 |     validation_cutoff: 1.0\n23:36:48 |     validation_every_n_epochs: -1\n23:36:48 |     validation_every_n_secs: 20.0\n23:36:48 |     validation_every_n_steps: -1\n23:36:48 |     validation_max_exs: -1\n23:36:48 |     validation_metric: accuracy\n23:36:48 |     validation_metric_mode: max\n23:36:48 |     validation_patience: 30\n23:36:48 |     validation_share_agent: False\n23:36:48 |     variant: xlm\n23:36:48 |     verbose: False\n23:36:48 |     wandb_entity: None\n23:36:48 |     wandb_log: False\n23:36:48 |     wandb_name: None\n23:36:48 |     wandb_project: None\n23:36:48 |     warmup_rate: 0.0001\n23:36:48 |     warmup_updates: 1000\n23:36:48 |     weight_decay: None\n23:36:48 |     world_logs: \n23:36:48 |     wrap_memory_encoder: False\n23:36:48 | creating task(s): fromfile:parlaiformat\n23:36:48 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run5/data_train.txt\n23:36:48 | training...\n23:36:59 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .4375 4.375e-10               .5243                 .4610   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6078            .3119              .3893   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .2602 11.57     1 271.5 540.3       0          0  39.8  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .4375             32768  2.467    .1206  6.02 .7073 1.005e-06 120.4 239.6   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 391.9 779.9 1.994        .4202\n\n23:37:09 | time:20s total_exs:1140 total_steps:57 epochs:5.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5608 5.608e-10               .6471                 .5623   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7621            .4186              .5571   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .3352 11.85     1   277  1034       0          0 74.65  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5608             32768  2.587    .1206 6.057 .6844 2.855e-06 121.1 452.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   57 398.1 1486 3.741        .5393\n\n23:37:09 | creating task(s): fromfile:parlaiformat\n23:37:09 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run5/data_valid.txt\n23:37:09 | running eval: valid\n23:37:09 | eval completed in 0.20s\n23:37:09 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7857                 .6875   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .7000              .8750   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .5833 10.67   152  1697       0          0 133.9   24 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6530 2.855e-06    72 803.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                     57  224 2500        .7429\n\u001b[0m\n23:37:09 | \u001b[1;32mnew best accuracy: 0.75\u001b[0m\n23:37:09 | saving best valid model: /tmp/model5\n23:37:09 | Saving dictionary to /tmp/model5.dict\n23:37:12 | saving model checkpoint: /tmp/model5.checkpoint\n23:37:12 | Saving dictionary to /tmp/model5.checkpoint.dict\n23:37:29 | time:41s total_exs:1860 total_steps:93 epochs:9.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7694 7.694e-10               .7904                 .7347   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8552            .7438              .8197   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6808 11.74     1 274.9 983.1       0          0 71.53  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7694             32768  2.683    .1207 6.017 .6290 4.655e-06 120.3 430.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   93 395.2 1413 3.584        .7675\n\n23:37:32 | time:44s total_exs:2100 total_steps:105 epochs:10.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9000   9e-10               .8974                 .9052   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8898            .9024              .8952   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9098 11.42     1 268.3  1043       0          0 77.77  240   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9000             32768   3.09    .1189 5.983 .5671 5.254e-06 119.7 465.3   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  105  388 1509 3.917        .9000\n\n23:37:32 | running eval: valid\n23:37:33 | eval completed in 0.20s\n23:37:33 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1696       0          0 133.8   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .5311 5.254e-06    72 803.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    105  224 2499        .9583\n\u001b[0m\n23:37:33 | \u001b[1;32mnew best accuracy: 0.9583 (previous best was 0.75)\u001b[0m\n23:37:33 | saving best valid model: /tmp/model5\n23:37:42 | saving model checkpoint: /tmp/model5.checkpoint\n23:37:58 | time:69s total_exs:2860 total_steps:143 epochs:14.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9316 9.316e-10               .9350                 .9257   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9444            .9278              .9382   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9176 11.82     1 276.3  1049       0          0  75.9  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9316             32768   3.68    .1207 6.042 .4518 7.154e-06 120.8 458.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  143 397.2 1507 3.803        .9315\n\n23:38:03 | time:74s total_exs:3240 total_steps:162 epochs:16.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9658 9.658e-10               .9661                 .9487   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9840            .9655              .9838   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9479  11.6     1 271.9  1033       0          0    76  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9658             32768  4.205    .1207 5.989 .2921 8.104e-06 119.8 455.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  162 391.7 1489 3.817        .9658\n\n23:38:03 | running eval: valid\n23:38:03 | eval completed in 0.21s\n23:38:03 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1618       0          0 127.7   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .2392 8.104e-06    72 766.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    162  224 2384        .9583\n\u001b[0m\n23:38:03 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 1\u001b[0m\n23:38:03 | saving model checkpoint: /tmp/model5.checkpoint\n23:38:23 | time:95s total_exs:4000 total_steps:200 epochs:20.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9724 9.724e-10               .9710                 .9643   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9777            .9737              .9798   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9676 11.94     1 278.8  1033       0          0 74.14  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n   .9724             32768  4.963    .1207 5.945 .1475 1e-05 118.9 440.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  200 397.7 1474 3.715        .9724\n\n23:38:23 | running eval: valid\n23:38:23 | eval completed in 0.20s\n23:38:23 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1677       0          0 132.3   24 .9583   \n    gpu_mem  llen  loss    lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .1445 1e-05    72 794.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    200  224 2472        .9583\n\u001b[0m\n23:38:23 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 2\u001b[0m\n23:38:23 | saving model checkpoint: /tmp/model5.checkpoint\n23:38:38 | time:109s total_exs:4760 total_steps:238 epochs:23.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9921 9.921e-10               .9920                 .9842   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9922                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9845 11.86     1 277.2  1051       0          0 75.83  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9921             32768  2.728    .1207 5.984 .05425 1.19e-05 119.7 453.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  238 396.9 1505  3.8        .9921\n\n23:38:44 | time:115s total_exs:5180 total_steps:259 epochs:25.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.17 .4762 283.5  1039       0          0 73.33  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768  .1106    .1207 5.843 .007305 1.295e-05 116.9 428.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  259 400.3 1468 3.681            1\n\n23:38:44 | running eval: valid\n23:38:44 | eval completed in 0.20s\n23:38:44 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1676       0          0 132.2   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .2441 1.295e-05    72 793.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    259  224 2469        .9161\n\u001b[0m\n23:38:44 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 3\u001b[0m\n23:38:44 | saving model checkpoint: /tmp/model5.checkpoint\n23:38:58 | time:130s total_exs:5940 total_steps:297 epochs:29.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9987                 .9975   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9986                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                  .9973 11.58 .02632 271.5  1023       0          0 75.36   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    760 .9987             32768  .4550    .1207 6.037 .009052 1.485e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   454.9       0          0                  297 392.3 1478 3.777        .9987\n\n23:39:04 | time:135s total_exs:6380 total_steps:319 epochs:31.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9977 9.977e-10               .9977                 .9954   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9978                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9955 12.45 .1364 288.9  1113       0          0 77.05  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9977             32768  3.167    .1207 5.982 .003829 1.595e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.9       0          0                  319 408.5 1574 3.866        .9977\n\n23:39:04 | running eval: valid\n23:39:04 | eval completed in 0.24s\n23:39:04 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1456       0          0 114.9   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .7063 1.595e-05    72 689.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    319  224 2146        .8730\n\u001b[0m\n23:39:04 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 4\u001b[0m\n23:39:04 | saving model checkpoint: /tmp/model5.checkpoint\n23:39:19 | time:150s total_exs:7120 total_steps:356 epochs:35.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1  11.9 .05405 277.9  1021       0          0 73.44   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  \\\n    740   1             32768 .03774    .1190 5.997 .001736 1.78e-05 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   440.5       0          0                  356 397.9 1461 3.68            1\n\n23:39:24 | time:156s total_exs:7560 total_steps:378 epochs:37.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.69 .04545 273.8  1052       0          0 76.82   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  \\\n    440   1             32768 .02673    .1207 5.982 .001544 1.89e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.5       0          0                  378 393.4 1511 3.856            1\n\n23:39:24 | running eval: valid\n23:39:25 | eval completed in 0.20s\n23:39:25 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1664       0          0 131.3   24 .9583   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 .2543 1.89e-05    72 787.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    378  224 2452        .9583\n\u001b[0m\n23:39:25 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 5\u001b[0m\n23:39:25 | saving model checkpoint: /tmp/model5.checkpoint\n23:39:39 | time:171s total_exs:8320 total_steps:416 epochs:41.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.62 .02632 272.3  1029       0          0 75.58   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  \\\n    760   1             32768 .03446    .1207 6.005 .001414 2.08e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   453.9       0          0                  416 392.4 1483 3.788            1\n\n23:39:45 | time:176s total_exs:8740 total_steps:437 epochs:43.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9976 9.976e-10               .9975                 .9950   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9977                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                  .9955 11.89 .04762 277.8  1044       0          0 75.18   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  \\\n    420 .9976             32768  3.589    .1207 5.948 .01373 2.185e-05   119   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   447.1       0          0                  437 396.7 1491 3.774        .9976\n\n23:39:45 | running eval: valid\n23:39:45 | eval completed in 0.21s\n23:39:45 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1618       0          0 127.7   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 .7342 2.185e-05    72 766.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    437  224 2385        .8730\n\u001b[0m\n23:39:45 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 6\u001b[0m\n23:39:45 | saving model checkpoint: /tmp/model5.checkpoint\n23:39:59 | time:191s total_exs:9500 total_steps:475 epochs:47.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.09     0 281.8  1069       0          0 75.88  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n     1             32768  .0142    .1207 6.055 .00122 2.375e-05 121.1 459.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  475 402.9 1529 3.803            1\n\n23:40:05 | time:197s total_exs:9940 total_steps:497 epochs:49.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.86     0 277.3  1068       0          0 77.02  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01416    .1207 5.927 .001144 2.485e-05 118.5 456.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  497 395.8 1524 3.866            1\n\n23:40:05 | running eval: valid\n23:40:05 | eval completed in 0.20s\n23:40:05 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1649       0          0 130.1   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 .7869 2.485e-05    72   781       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    497  224 2430        .8730\n\u001b[0m\n23:40:05 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 7\u001b[0m\n23:40:05 | saving model checkpoint: /tmp/model5.checkpoint\n23:40:20 | time:211s total_exs:10700 total_steps:535 epochs:53.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.48     0 269.6  1010       0          0 74.95  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01239    .1207 6.061 .001063 2.675e-05 121.2 454.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  535 390.8 1465 3.756            1\n\n23:40:25 | time:217s total_exs:11120 total_steps:556 epochs:55.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.95     0 278.9  1054       0          0 75.59  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768  .0116    .1207 5.976 .0009968 2.78e-05 119.5 451.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  556 398.4 1506 3.795            1\n\n23:40:25 | running eval: valid\n23:40:25 | eval completed in 0.20s\n23:40:25 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1643       0          0 129.6   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 .5507 2.78e-05    72   778       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    556  224 2421        .9161\n\u001b[0m\n23:40:25 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 8\u001b[0m\n23:40:25 | saving model checkpoint: /tmp/model5.checkpoint\n23:40:40 | time:231s total_exs:11840 total_steps:592 epochs:59.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.01     0 280.2  1000       0          0 71.38  720   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .01087    .1207     6 .0009342 2.96e-05   120 428.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  592 400.2 1428 3.577            1\n\n23:40:46 | time:237s total_exs:12280 total_steps:614 epochs:61.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.03     0 280.6  1055       0          0 75.22  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .01019    .1208 6.005 .0008745 3.07e-05 120.1 451.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  614 400.7 1507 3.776            1\n\n23:40:46 | running eval: valid\n23:40:46 | eval completed in 0.23s\n23:40:46 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1519       0          0 119.9   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 .6063 3.07e-05    72 719.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    614  224 2240        .9161\n\u001b[0m\n23:40:46 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 9\u001b[0m\n23:40:46 | saving model checkpoint: /tmp/model5.checkpoint\n23:41:00 | time:252s total_exs:13060 total_steps:653 epochs:65.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.72     0 274.4  1055       0          0 76.93  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .009515    .1208 6.031 .0008185 3.265e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n     464       0          0                  653  395 1519 3.855            1\n\n23:41:06 | time:258s total_exs:13500 total_steps:675 epochs:67.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.01     0 280.2  1081       0          0 77.18  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .008892    .1208 6.005 .0007634 3.375e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.4       0          0                  675 400.3 1545 3.874            1\n\n23:41:06 | running eval: valid\n23:41:06 | eval completed in 0.21s\n23:41:06 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1603       0          0 126.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 .6679 3.375e-05    72 759.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    675  224 2363        .8730\n\u001b[0m\n23:41:06 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 10\u001b[0m\n23:41:06 | saving model checkpoint: /tmp/model5.checkpoint\n23:41:21 | time:272s total_exs:14260 total_steps:713 epochs:71.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.42     0 268.4  1018       0          0 75.83  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .008329    .1208 6.013 .0007148 3.565e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n     456       0          0                  713 388.7 1474  3.8            1\n\n23:41:27 | time:278s total_exs:14700 total_steps:735 epochs:73.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.91     0 278.2  1060       0          0 76.18  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .007781    .1191 6.005 .0006679 3.675e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.4       0          0                  735 398.3 1517 3.824            1\n\n23:41:27 | running eval: valid\n23:41:27 | eval completed in 0.21s\n23:41:27 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1593       0          0 125.7   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 .6935 3.675e-05    72 754.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    735  224 2348        .8730\n\u001b[0m\n23:41:27 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 11\u001b[0m\n23:41:27 | saving model checkpoint: /tmp/model5.checkpoint\n23:41:41 | time:293s total_exs:15460 total_steps:773 epochs:77.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.73     0 274.6  1035       0          0 75.41  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .007334    .1208 6.026 .0006248 3.865e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   454.5       0          0                  773 395.1 1490 3.779            1\n\n23:41:47 | time:298s total_exs:15900 total_steps:795 epochs:79.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.92     0 278.3  1059       0          0 76.07  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006827    .1208 5.991 .0005842 3.975e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   455.7       0          0                  795 398.1 1514 3.818            1\n\n23:41:47 | running eval: valid\n23:41:47 | eval completed in 0.20s\n23:41:47 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1662       0          0 131.2   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 .6623 3.975e-05    72 787.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    795  224 2449        .8730\n\u001b[0m\n23:41:47 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 12\u001b[0m\n23:41:47 | saving model checkpoint: /tmp/model5.checkpoint\n23:42:02 | time:313s total_exs:16660 total_steps:833 epochs:83.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0 276.1  1037       0          0 75.13  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006375    .1208 6.018 .0005464 4.165e-05 120.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   452.2       0          0                  833 396.4 1489 3.765            1\n\n23:42:07 | time:319s total_exs:17060 total_steps:853 epochs:85.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9975 9.975e-10               .9976                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9953            .9974              .9947   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1    12 .0500 279.9  1066       0          0 76.19  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9975             32768  1.474    .1208 6.055 .0183 4.265e-05 121.1 461.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  853 401.1 1528 3.827        .9975\n\n23:42:07 | running eval: valid\n23:42:07 | eval completed in 0.20s\n23:42:07 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1690       0          0 133.4   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 .3037 4.265e-05    72 800.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    853  224 2491        .9167\n\u001b[0m\n23:42:07 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 13\u001b[0m\n23:42:07 | saving model checkpoint: /tmp/model5.checkpoint\n23:42:22 | time:334s total_exs:17820 total_steps:891 epochs:89.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.56     0 271.1  1009       0          0  74.4  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .005624    .1208 6.037 .0004805 4.455e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.2       0          0                  891 391.8 1458 3.728            1\n\n23:42:27 | time:339s total_exs:18240 total_steps:912 epochs:91.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.12     0 282.5  1092       0          0 77.32  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .005271    .1208 5.971 .0004511 4.56e-05 119.4 461.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  912 401.9 1554 3.882            1\n\n23:42:27 | running eval: valid\n23:42:28 | eval completed in 0.20s\n23:42:28 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1646       0          0 129.9   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 .3808 4.56e-05    72 779.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    912  224 2425        .9161\n\u001b[0m\n23:42:28 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 14\u001b[0m\n23:42:28 | saving model checkpoint: /tmp/model5.checkpoint\n23:42:42 | time:354s total_exs:19020 total_steps:951 epochs:95.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.83     0 276.6  1053       0          0  76.1  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004942    .1208 5.979 .0004217 4.755e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     455       0          0                  951 396.2 1508 3.813            1\n\n23:42:48 | time:359s total_exs:19440 total_steps:972 epochs:97.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.26     0 265.3  1031       0          0 77.74  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .004615    .1208 5.995 .0003947 4.86e-05 119.9 466.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  972 385.2 1497 3.903            1\n\n23:42:48 | running eval: valid\n23:42:48 | eval completed in 0.20s\n23:42:48 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1708       0          0 134.8   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 .6027 4.86e-05    72   809       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    972  224 2517        .8730\n\u001b[0m\n23:42:48 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 15\u001b[0m\n23:42:48 | saving model checkpoint: /tmp/model5.checkpoint\n23:43:03 | time:375s total_exs:20200 total_steps:1010 epochs:101.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.91     0 278.2  1054       0          0 75.77  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004322    .1208 6.042 .0003692 4.995e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.8       0          0                 1010 399.1 1512 3.797            1\n\n23:43:08 | time:380s total_exs:20600 total_steps:1030 epochs:103.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.72     0 274.4  1067       0          0 77.76  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004097    .1208  6.11 .0003457 4.995e-05 122.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   475.1       0          0                 1030 396.6 1542 3.905            1\n\n23:43:08 | running eval: valid\n23:43:08 | eval completed in 0.20s\n23:43:08 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1680       0          0 132.6   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6 .5211 4.995e-05    72 795.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1030  224 2476        .9161\n\u001b[0m\n23:43:08 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 16\u001b[0m\n23:43:08 | saving model checkpoint: /tmp/model5.checkpoint\n23:43:23 | time:394s total_exs:21360 total_steps:1068 epochs:106.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.83     0 276.7  1051       0          0 75.96  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003822    .1208 5.992 .0003264 4.995e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   455.2       0          0                 1068 396.5 1506 3.807            1\n\n23:43:29 | time:400s total_exs:21780 total_steps:1089 epochs:108.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.93     0 278.6 990.6       0          0 71.12  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003591    .1208 6.043 .0003066 4.995e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   429.8       0          0                 1089 399.4 1420 3.57            1\n\n23:43:29 | running eval: valid\n23:43:29 | eval completed in 0.20s\n23:43:29 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1707       0          0 134.5   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 .4226 4.995e-05    72 807.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1089  224 2516        .9161\n\u001b[0m\n23:43:29 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 17\u001b[0m\n23:43:29 | saving model checkpoint: /tmp/model5.checkpoint\n23:43:43 | time:415s total_exs:22560 total_steps:1128 epochs:112.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.74     0 274.8  1048       0          0 76.27  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003392    .1208 5.985 .0002897 4.995e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.5       0          0                 1128 394.5 1505 3.822            1\n\n23:43:49 | time:421s total_exs:23000 total_steps:1150 epochs:115.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.94     0 278.9  1071       0          0 76.84  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003195    .1209 5.995 .0002727 4.995e-05 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.7       0          0                 1150 398.8 1532 3.857            1\n\n23:43:49 | running eval: valid\n23:43:49 | eval completed in 0.20s\n23:43:49 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1672       0          0   132   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 .3551 4.995e-05    72   792       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1150  224 2464        .9583\n\u001b[0m\n23:43:49 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 18\u001b[0m\n23:43:49 | saving model checkpoint: /tmp/model5.checkpoint\n23:44:04 | time:435s total_exs:23760 total_steps:1188 epochs:118.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.16     0 283.1  1058       0          0 74.76  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003049    .1209 5.984 .0002581 4.995e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   447.4       0          0                 1188 402.8 1506 3.746            1\n\n23:44:09 | time:441s total_exs:24180 total_steps:1209 epochs:120.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.84     0 276.7  1045       0          0  75.5  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002875    .1209 5.881 .0002453 4.995e-05 117.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n     444       0          0                 1209 394.3 1489 3.79            1\n\n23:44:09 | running eval: valid\n23:44:09 | eval completed in 0.20s\n23:44:09 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1666       0          0 131.5   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6 .3517 4.995e-05    72 789.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1209  224 2456        .9583\n\u001b[0m\n23:44:09 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 19\u001b[0m\n23:44:09 | saving model checkpoint: /tmp/model5.checkpoint\n23:44:24 | time:455s total_exs:24940 total_steps:1247 epochs:124.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.95     0   279  1056       0          0 75.67  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002715    .1209 6.003 .0002316 4.995e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   454.2       0          0                 1247 399.1 1510 3.792            1\n\n23:44:30 | time:461s total_exs:25360 total_steps:1268 epochs:126.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.2  1020       0          0 74.43  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002585    .1209 5.995 .0002203 4.995e-05 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   446.2       0          0                 1268 394.1 1467 3.737            1\n\n23:44:30 | running eval: valid\n23:44:30 | eval completed in 0.25s\n23:44:30 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1383       0          0 109.2   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 .3606 4.995e-05    72 655.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1268  224 2039        .9583\n\u001b[0m\n23:44:30 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 20\u001b[0m\n23:44:30 | saving model checkpoint: /tmp/model5.checkpoint\n23:44:44 | time:476s total_exs:26140 total_steps:1307 epochs:130.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.83     0 276.6  1056       0          0 76.36  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002451    .1192 5.992 .0002089 4.995e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.6       0          0                 1307 396.4 1514 3.827            1\n\n23:44:50 | time:481s total_exs:26560 total_steps:1328 epochs:132.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.83     0 276.6  1073       0          0 77.61  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002328    .1209 6.062 .0001984 4.995e-05 121.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   470.5       0          0                 1328 397.8 1544 3.897            1\n\n23:44:50 | running eval: valid\n23:44:50 | eval completed in 0.19s\n23:44:50 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1721       0          0 135.9   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 .3797 4.995e-05    72 815.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1328  224 2537        .9583\n\u001b[0m\n23:44:50 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 21\u001b[0m\n23:44:50 | saving model checkpoint: /tmp/model5.checkpoint\n23:45:05 | time:496s total_exs:27300 total_steps:1365 epochs:136.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.54     0 270.7 990.4       0          0 73.17  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002222    .1192 6.027 .0001891 4.995e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     441       0          0                 1365 391.3 1431 3.667            1\n\n23:45:10 | time:502s total_exs:27720 total_steps:1386 epochs:138.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.53     0 270.7  1038       0          0 76.73  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002117    .1209 6.033 .0001803 4.995e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   462.9       0          0                 1386 391.3 1501 3.852            1\n\n23:45:10 | running eval: valid\n23:45:10 | eval completed in 0.20s\n23:45:10 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1704       0          0 134.5   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 .3826 4.995e-05    72 807.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1386  224 2512        .9583\n\u001b[0m\n23:45:10 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 22\u001b[0m\n23:45:10 | saving model checkpoint: /tmp/model5.checkpoint\n23:45:25 | time:517s total_exs:28500 total_steps:1425 epochs:142.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.3  1050       0          0 76.58  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002023    .1209 5.995 .0001723 4.995e-05 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.1       0          0                 1425 394.2 1509 3.838            1\n\n23:45:31 | time:522s total_exs:28920 total_steps:1446 epochs:144.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.86     0 277.1  1057       0          0 76.31  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001926    .1209 6.048 .0001639 4.995e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.5       0          0                 1446 398.1 1519 3.831            1\n\n23:45:31 | running eval: valid\n23:45:31 | eval completed in 0.24s\n23:45:31 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1421       0          0 112.1   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6 .3718 4.995e-05    72 672.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1446  224 2094        .9583\n\u001b[0m\nEpoch 00008: reducing learning rate of group 0 to 2.4975e-05.\n23:45:31 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 23\u001b[0m\n23:45:31 | saving model checkpoint: /tmp/model5.checkpoint\n23:45:45 | time:537s total_exs:29680 total_steps:1484 epochs:148.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.92     0 278.5  1058       0          0 76.02  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001873    .1209 5.961 .0001594 2.498e-05 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   453.1       0          0                 1484 397.7 1512 3.81            1\n\n23:45:51 | time:543s total_exs:30120 total_steps:1506 epochs:150.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.17     0 283.3  1091       0          0 77.03  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001822    .1209 6.073 .0001549 2.498e-05 121.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   467.8       0          0                 1506 404.8 1559 3.867            1\n\n23:45:51 | running eval: valid\n23:45:51 | eval completed in 0.21s\n23:45:51 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1567       0          0 123.7   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6 .3844 2.498e-05    72 742.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1506  224 2309        .9583\n\u001b[0m\n23:45:51 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 24\u001b[0m\n23:45:51 | saving model checkpoint: /tmp/model5.checkpoint\n23:46:06 | time:557s total_exs:30880 total_steps:1544 epochs:154.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.85     0 277.1  1032       0          0 74.47  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001785    .1209 6.011 .0001519 2.498e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   447.6       0          0                 1544 397.3 1479 3.732            1\n\n23:46:11 | time:563s total_exs:31320 total_steps:1566 epochs:156.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.06     0 281.2  1089       0          0 77.46  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001736    .1209 6.105 .0001477 2.498e-05 122.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   472.8       0          0                 1566 403.3 1562 3.888            1\n\n23:46:11 | running eval: valid\n23:46:12 | eval completed in 0.20s\n23:46:12 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1660       0          0   131   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 .3851 2.498e-05    72 786.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1566  224 2447        .9583\n\u001b[0m\n23:46:12 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 25\u001b[0m\n23:46:12 | saving model checkpoint: /tmp/model5.checkpoint\n23:46:26 | time:577s total_exs:32080 total_steps:1604 epochs:160.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.83     0 276.7  1051       0          0 75.98  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768  .0017    .1209 6.058 .0001445 2.498e-05 121.2 460.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1604 397.8 1511 3.808            1\n\n23:46:32 | time:583s total_exs:32520 total_steps:1626 epochs:162.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.52     0 270.5  1016       0          0 75.12  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001661    .1209  6.05 .0001413 2.498e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   454.5       0          0                 1626 391.5 1470 3.771            1\n\n23:46:32 | running eval: valid\n23:46:32 | eval completed in 0.20s\n23:46:32 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1686       0          0 133.1   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 .3759 2.498e-05    72 798.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1626  224 2485        .9583\n\u001b[0m\n23:46:32 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 26\u001b[0m\n23:46:32 | saving model checkpoint: /tmp/model5.checkpoint\n23:46:47 | time:598s total_exs:33280 total_steps:1664 epochs:166.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.9     0 277.9  1053       0          0  75.8  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001625    .1209 5.982 .0001383 2.498e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   453.4       0          0                 1664 397.6 1507 3.798            1\n\n23:46:52 | time:604s total_exs:33700 total_steps:1685 epochs:168.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.45     0 269.1  1044       0          0 77.61  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001582    .1210 6.081 .0001345 2.498e-05 121.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     472       0          0                 1685 390.7 1516 3.897            1\n\n23:46:52 | running eval: valid\n23:46:52 | eval completed in 0.23s\n23:46:52 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1521       0          0 120.1   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 .3804 2.498e-05    72 720.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1685  224 2242        .9583\n\u001b[0m\nEpoch 00012: reducing learning rate of group 0 to 1.2488e-05.\n23:46:52 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 27\u001b[0m\n23:46:52 | saving model checkpoint: /tmp/model5.checkpoint\n23:47:07 | time:619s total_exs:34460 total_steps:1723 epochs:172.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.7     0   274  1022       0          0 74.59  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001559    .1210 6.026 .0001326 1.249e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.5       0          0                 1723 394.5 1471 3.736            1\n\n23:47:12 | time:624s total_exs:34880 total_steps:1744 epochs:174.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.74     0 274.8  1070       0          0 77.84  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00154    .1210 6.067 .0001308 1.249e-05 121.3 472.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1744 396.1 1542 3.909            1\n\n23:47:12 | running eval: valid\n23:47:13 | eval completed in 0.20s\n23:47:13 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1725       0          0 136.1   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 .3808 1.249e-05    72 816.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1744  224 2542        .9583\n\u001b[0m\n23:47:13 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 28\u001b[0m\n23:47:13 | saving model checkpoint: /tmp/model5.checkpoint\n23:47:27 | time:639s total_exs:35660 total_steps:1783 epochs:178.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.64     0 272.9  1042       0          0 76.35  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001519    .1210 6.067 .0001291 1.249e-05 121.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.2       0          0                 1783 394.2 1505 3.826            1\n\n23:47:33 | time:644s total_exs:36080 total_steps:1804 epochs:180.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.93     0 278.5  1080       0          0 77.54  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001501    .1210 6.005 .0001276 1.249e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   465.6       0          0                 1804 398.6 1545 3.893            1\n\n23:47:33 | running eval: valid\n23:47:33 | eval completed in 0.20s\n23:47:33 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1673       0          0   132   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 .3804 1.249e-05    72 792.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1804  224 2465        .9583\n\u001b[0m\n23:47:33 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 29\u001b[0m\n23:47:33 | saving model checkpoint: /tmp/model5.checkpoint\n23:47:48 | time:659s total_exs:36820 total_steps:1841 epochs:184.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.9     0 278.1  1031       0          0 74.14  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001485    .1210 5.986 .0001262 1.249e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   443.9       0          0                 1841 397.8 1475 3.717            1\n\n23:47:53 | time:665s total_exs:37240 total_steps:1862 epochs:186.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.88     0 277.6  1066       0          0 76.76  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001463    .1193 6.014 .0001244 1.249e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.7       0          0                 1862 397.9 1527 3.854            1\n\n23:47:53 | running eval: valid\n23:47:53 | eval completed in 0.20s\n23:47:53 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1685       0          0   133   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08122     6 .3829 1.249e-05    72 798.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1862  224 2483        .9583\n\u001b[0m\n23:47:53 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 30\u001b[0m\n23:47:53 | saving model checkpoint: /tmp/model5.checkpoint\n23:47:58 | ran out of patience! stopping training.\n23:47:58 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n23:47:58 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n23:47:58 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run5/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n23:47:58 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n23:47:58 | Using CUDA\n23:47:58 | loading dictionary from /tmp/model5.dict\n23:47:58 | num words = 54944\n23:48:02 | Loading existing model parameters from /tmp/model5\n23:48:10 | Total parameters: 128,042,498 (128,042,498 trainable)\n23:48:11 | creating task(s): fromfile:parlaiformat\n23:48:11 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run5/data_valid.txt\n23:48:11 | running eval: valid\n23:48:11 | eval completed in 0.21s\n23:48:11 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1634       0          0 128.9   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297     6 .5311 5.254e-06    72 773.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    105  224 2408        .9583\n\u001b[0m\n23:48:11 | creating task(s): fromfile:parlaiformat\n23:48:11 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run5/data_test.txt\n23:48:12 | running eval: test\n23:48:16 | eval completed in 4.86s\n23:48:16 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8840 8.84e-10               .6107                 .4596   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9100            .9318              .9888   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8811 12.07 281.4  2908       0          0 206.6 1000 .8840   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298   5.2 .5590 5.254e-06   104  1074       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    105 385.4 3982        .8997\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type1/run5/data_test.txt -m transformer/classifier -mf /tmp/model5 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:48:18.611187Z","iopub.execute_input":"2022-12-03T23:48:18.611606Z","iopub.status.idle":"2022-12-03T23:48:49.808751Z","shell.execute_reply.started":"2022-12-03T23:48:18.611561Z","shell.execute_reply":"2022-12-03T23:48:49.807611Z"},"scrolled":true,"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"23:48:28 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr2type1/run5/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr2type1/run5/data)\u001b[0m\n23:48:28 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n23:48:28 | Using CUDA\n23:48:28 | loading dictionary from /tmp/model5.dict\n23:48:28 | num words = 54944\n23:48:32 | Loading existing model parameters from /tmp/model5\n23:48:38 | Total parameters: 128,042,498 (128,042,498 trainable)\n23:48:39 | Opt:\n23:48:39 |     activation: gelu\n23:48:39 |     adafactor_eps: '[1e-30, 0.001]'\n23:48:39 |     adam_eps: 1e-08\n23:48:39 |     add_p1_after_newln: False\n23:48:39 |     aggregate_micro: False\n23:48:39 |     allow_missing_init_opts: False\n23:48:39 |     area_under_curve_class: None\n23:48:39 |     area_under_curve_digits: -1\n23:48:39 |     attention_dropout: 0.1\n23:48:39 |     batchsize: 40\n23:48:39 |     betas: '[0.9, 0.999]'\n23:48:39 |     bpe_add_prefix_space: None\n23:48:39 |     bpe_debug: False\n23:48:39 |     bpe_dropout: None\n23:48:39 |     bpe_merge: None\n23:48:39 |     bpe_vocab: None\n23:48:39 |     candidates: inline\n23:48:39 |     cap_num_predictions: 100\n23:48:39 |     checkpoint_activations: False\n23:48:39 |     class_weights: None\n23:48:39 |     classes: \"['__notok__', '__ok__']\"\n23:48:39 |     classes_from_file: None\n23:48:39 |     data_parallel: True\n23:48:39 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n23:48:39 |     datatype: train\n23:48:39 |     delimiter: '\\n'\n23:48:39 |     dict_class: parlai.core.dict:DictionaryAgent\n23:48:39 |     dict_endtoken: __start__\n23:48:39 |     dict_file: /tmp/model5.dict\n23:48:39 |     dict_include_test: False\n23:48:39 |     dict_include_valid: False\n23:48:39 |     dict_initpath: None\n23:48:39 |     dict_language: english\n23:48:39 |     dict_loaded: True\n23:48:39 |     dict_lower: True\n23:48:39 |     dict_max_ngram_size: -1\n23:48:39 |     dict_maxexs: -1\n23:48:39 |     dict_maxtokens: -1\n23:48:39 |     dict_minfreq: 0\n23:48:39 |     dict_nulltoken: __null__\n23:48:39 |     dict_starttoken: __start__\n23:48:39 |     dict_textfields: text,labels\n23:48:39 |     dict_tokenizer: bpe\n23:48:39 |     dict_unktoken: __unk__\n23:48:39 |     display_examples: False\n23:48:39 |     download_path: None\n23:48:39 |     dropout: 0.1\n23:48:39 |     dynamic_batching: None\n23:48:39 |     embedding_projection: random\n23:48:39 |     embedding_size: 768\n23:48:39 |     embedding_type: random\n23:48:39 |     embeddings_scale: False\n23:48:39 |     encode_candidate_vecs: True\n23:48:39 |     encode_candidate_vecs_batchsize: 256\n23:48:39 |     eval_batchsize: None\n23:48:39 |     eval_candidates: inline\n23:48:39 |     eval_dynamic_batching: None\n23:48:39 |     evaltask: None\n23:48:39 |     ffn_size: 3072\n23:48:39 |     final_extra_opt: \n23:48:39 |     fixed_candidate_vecs: reuse\n23:48:39 |     fixed_candidates_path: None\n23:48:39 |     force_fp16_tokens: True\n23:48:39 |     fp16: True\n23:48:39 |     fp16_impl: safe\n23:48:39 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type1/run5/data_test.txt\n23:48:39 |     fromfile_datatype_extension: True\n23:48:39 |     gpu: -1\n23:48:39 |     gradient_clip: 0.1\n23:48:39 |     hide_labels: False\n23:48:39 |     history_add_global_end_token: None\n23:48:39 |     history_reversed: False\n23:48:39 |     history_size: 20\n23:48:39 |     ignore_bad_candidates: False\n23:48:39 |     ignore_labels: None\n23:48:39 |     image_cropsize: 224\n23:48:39 |     image_mode: raw\n23:48:39 |     image_size: 256\n23:48:39 |     inference: max\n23:48:39 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n23:48:39 |     init_opt: None\n23:48:39 |     interactive_candidates: fixed\n23:48:39 |     interactive_mode: False\n23:48:39 |     invsqrt_lr_decay_gamma: -1\n23:48:39 |     is_debug: False\n23:48:39 |     label_truncate: 72\n23:48:39 |     learn_embeddings: True\n23:48:39 |     learn_positional_embeddings: True\n23:48:39 |     learningrate: 5e-05\n23:48:39 |     load_from_pretrained_ranker: True\n23:48:39 |     log_every_n_secs: 10.0\n23:48:39 |     log_every_n_steps: 50\n23:48:39 |     log_keep_fields: all\n23:48:39 |     loglevel: info\n23:48:39 |     lr_scheduler: reduceonplateau\n23:48:39 |     lr_scheduler_decay: 0.5\n23:48:39 |     lr_scheduler_patience: 3\n23:48:39 |     max_train_steps: -1\n23:48:39 |     max_train_time: 7200.0\n23:48:39 |     memory_attention: sqrt\n23:48:39 |     metrics: default\n23:48:39 |     model: transformer/classifier\n23:48:39 |     model_file: /tmp/model5\n23:48:39 |     model_parallel: False\n23:48:39 |     momentum: 0\n23:48:39 |     multitask_weights: [1]\n23:48:39 |     mutators: None\n23:48:39 |     n_decoder_layers: -1\n23:48:39 |     n_encoder_layers: -1\n23:48:39 |     n_heads: 12\n23:48:39 |     n_layers: 12\n23:48:39 |     n_positions: 1024\n23:48:39 |     n_segments: 2\n23:48:39 |     nesterov: True\n23:48:39 |     no_cuda: False\n23:48:39 |     normalize_sent_emb: False\n23:48:39 |     num_epochs: -1\n23:48:39 |     num_examples: -1\n23:48:39 |     num_workers: 0\n23:48:39 |     nus: [0.7]\n23:48:39 |     optimizer: adamax\n23:48:39 |     output_scaling: 0.06\n23:48:39 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type1/run5/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model5', 'batchsize': 40}\"\n23:48:39 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n23:48:39 |     person_tokens: False\n23:48:39 |     print_scores: False\n23:48:39 |     rank_candidates: False\n23:48:39 |     rank_top_k: -1\n23:48:39 |     reduction_type: mean\n23:48:39 |     ref_class: None\n23:48:39 |     relu_dropout: 0.0\n23:48:39 |     repeat_blocking_heuristic: True\n23:48:39 |     report_filename: \n23:48:39 |     return_cand_scores: False\n23:48:39 |     save_after_valid: True\n23:48:39 |     save_every_n_secs: -1\n23:48:39 |     save_format: conversations\n23:48:39 |     share_encoders: False\n23:48:39 |     share_word_embeddings: False\n23:48:39 |     short_final_eval: False\n23:48:39 |     special_tok_lst: None\n23:48:39 |     split_lines: False\n23:48:39 |     starttime: Dec03_23-36\n23:48:39 |     task: fromfile:parlaiformat\n23:48:39 |     tensorboard_log: False\n23:48:39 |     tensorboard_logdir: None\n23:48:39 |     text_truncate: 360\n23:48:39 |     threshold: 0.5\n23:48:39 |     topk: 5\n23:48:39 |     train_predict: False\n23:48:39 |     truncate: 1024\n23:48:39 |     update_classifier_head_only: False\n23:48:39 |     update_freq: 1\n23:48:39 |     use_memories: False\n23:48:39 |     use_reply: none\n23:48:39 |     validation_cutoff: 1.0\n23:48:39 |     validation_every_n_epochs: -1\n23:48:39 |     validation_every_n_secs: 20.0\n23:48:39 |     validation_every_n_steps: -1\n23:48:39 |     validation_max_exs: -1\n23:48:39 |     validation_metric: accuracy\n23:48:39 |     validation_metric_mode: max\n23:48:39 |     validation_patience: 30\n23:48:39 |     validation_share_agent: False\n23:48:39 |     variant: xlm\n23:48:39 |     verbose: False\n23:48:39 |     wandb_entity: None\n23:48:39 |     wandb_log: False\n23:48:39 |     wandb_name: None\n23:48:39 |     wandb_project: None\n23:48:39 |     warmup_rate: 0.0001\n23:48:39 |     warmup_updates: 1000\n23:48:39 |     weight_decay: None\n23:48:39 |     world_logs: \n23:48:39 |     wrap_memory_encoder: False\n23:48:39 | Evaluating task fromfile:parlaiformat using datatype valid.\n23:48:39 | creating task(s): fromfile:parlaiformat\n23:48:39 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n23:48:39 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type1/run5/data_test.txt\n23:48:48 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8840 8.84e-10               .6107                 .4596   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9100            .9318              .9888   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8811 12.07 562.9  1795       0          0 127.5 1000 .8840   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5590 5.254e-06   208 663.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    105 770.9 2458        .8997\u001b[0m\n23:48:48 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8840 8.84e-10               .6107                 .4596   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9100            .9318              .9888   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8811 12.07 562.9  1795       0          0 127.5 1000 .8840   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5590 5.254e-06   208 663.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    105 770.9 2458        .8997\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model5*","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:48:49.810519Z","iopub.execute_input":"2022-12-03T23:48:49.811119Z","iopub.status.idle":"2022-12-03T23:48:51.085497Z","shell.execute_reply.started":"2022-12-03T23:48:49.811084Z","shell.execute_reply":"2022-12-03T23:48:51.084005Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"# Actual code prev1corr2type2","metadata":{}},{"cell_type":"markdown","source":"run 1","metadata":{}},{"cell_type":"code","source":"# run 1 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type2/run1/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model1","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:48:51.087444Z","iopub.execute_input":"2022-12-03T23:48:51.087807Z","iopub.status.idle":"2022-12-04T00:01:39.735652Z","shell.execute_reply.started":"2022-12-03T23:48:51.087774Z","shell.execute_reply":"2022-12-04T00:01:39.734468Z"},"scrolled":true,"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"23:48:58 | building dictionary first...\n23:48:58 | No model with opt yet at: /tmp/model1(.opt)\n23:48:58 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run1/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n23:48:58 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n23:48:58 | Using CUDA\n23:48:58 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n23:48:58 | num words = 54944\n23:49:02 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n23:49:13 | Total parameters: 128,042,498 (128,042,498 trainable)\n23:49:13 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n23:49:13 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n23:49:13 | Opt:\n23:49:13 |     activation: gelu\n23:49:13 |     adafactor_eps: '(1e-30, 0.001)'\n23:49:13 |     adam_eps: 1e-08\n23:49:13 |     add_p1_after_newln: False\n23:49:13 |     aggregate_micro: False\n23:49:13 |     allow_missing_init_opts: False\n23:49:13 |     attention_dropout: 0.1\n23:49:13 |     batchsize: 20\n23:49:13 |     betas: '(0.9, 0.999)'\n23:49:13 |     bpe_add_prefix_space: None\n23:49:13 |     bpe_debug: False\n23:49:13 |     bpe_dropout: None\n23:49:13 |     bpe_merge: None\n23:49:13 |     bpe_vocab: None\n23:49:13 |     candidates: inline\n23:49:13 |     cap_num_predictions: 100\n23:49:13 |     checkpoint_activations: False\n23:49:13 |     class_weights: None\n23:49:13 |     classes: \"['__notok__', '__ok__']\"\n23:49:13 |     classes_from_file: None\n23:49:13 |     data_parallel: True\n23:49:13 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n23:49:13 |     datatype: train\n23:49:13 |     delimiter: '\\n'\n23:49:13 |     dict_class: parlai.core.dict:DictionaryAgent\n23:49:13 |     dict_endtoken: __start__\n23:49:13 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n23:49:13 |     dict_include_test: False\n23:49:13 |     dict_include_valid: False\n23:49:13 |     dict_initpath: None\n23:49:13 |     dict_language: english\n23:49:13 |     dict_loaded: True\n23:49:13 |     dict_lower: True\n23:49:13 |     dict_max_ngram_size: -1\n23:49:13 |     dict_maxexs: -1\n23:49:13 |     dict_maxtokens: -1\n23:49:13 |     dict_minfreq: 0\n23:49:13 |     dict_nulltoken: __null__\n23:49:13 |     dict_starttoken: __start__\n23:49:13 |     dict_textfields: text,labels\n23:49:13 |     dict_tokenizer: bpe\n23:49:13 |     dict_unktoken: __unk__\n23:49:13 |     display_examples: False\n23:49:13 |     download_path: None\n23:49:13 |     dropout: 0.1\n23:49:13 |     dynamic_batching: None\n23:49:13 |     embedding_projection: random\n23:49:13 |     embedding_size: 768\n23:49:13 |     embedding_type: random\n23:49:13 |     embeddings_scale: False\n23:49:13 |     encode_candidate_vecs: True\n23:49:13 |     encode_candidate_vecs_batchsize: 256\n23:49:13 |     eval_batchsize: None\n23:49:13 |     eval_candidates: inline\n23:49:13 |     eval_dynamic_batching: None\n23:49:13 |     evaltask: None\n23:49:13 |     ffn_size: 3072\n23:49:13 |     final_extra_opt: \n23:49:13 |     fixed_candidate_vecs: reuse\n23:49:13 |     fixed_candidates_path: None\n23:49:13 |     force_fp16_tokens: False\n23:49:13 |     fp16: True\n23:49:13 |     fp16_impl: safe\n23:49:13 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run1/data\n23:49:13 |     fromfile_datatype_extension: True\n23:49:13 |     gpu: -1\n23:49:13 |     gradient_clip: 0.1\n23:49:13 |     hide_labels: False\n23:49:13 |     history_add_global_end_token: None\n23:49:13 |     history_reversed: False\n23:49:13 |     history_size: 20\n23:49:13 |     ignore_bad_candidates: False\n23:49:13 |     ignore_labels: None\n23:49:13 |     image_cropsize: 224\n23:49:13 |     image_mode: raw\n23:49:13 |     image_size: 256\n23:49:13 |     inference: max\n23:49:13 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n23:49:13 |     init_opt: None\n23:49:13 |     interactive_candidates: fixed\n23:49:13 |     interactive_mode: False\n23:49:13 |     invsqrt_lr_decay_gamma: -1\n23:49:13 |     is_debug: False\n23:49:13 |     label_truncate: 72\n23:49:13 |     learn_embeddings: True\n23:49:13 |     learn_positional_embeddings: True\n23:49:13 |     learningrate: 5e-05\n23:49:13 |     load_from_checkpoint: False\n23:49:13 |     load_from_pretrained_ranker: True\n23:49:13 |     log_every_n_secs: 10.0\n23:49:13 |     log_every_n_steps: 50\n23:49:13 |     log_keep_fields: all\n23:49:13 |     loglevel: info\n23:49:13 |     lr_scheduler: reduceonplateau\n23:49:13 |     lr_scheduler_decay: 0.5\n23:49:13 |     lr_scheduler_patience: 3\n23:49:13 |     max_train_steps: -1\n23:49:13 |     max_train_time: 7200.0\n23:49:13 |     memory_attention: sqrt\n23:49:13 |     metrics: default\n23:49:13 |     model: transformer/classifier\n23:49:13 |     model_file: /tmp/model1\n23:49:13 |     model_parallel: False\n23:49:13 |     momentum: 0\n23:49:13 |     multitask_weights: [1]\n23:49:13 |     mutators: None\n23:49:13 |     n_decoder_layers: -1\n23:49:13 |     n_encoder_layers: -1\n23:49:13 |     n_heads: 12\n23:49:13 |     n_layers: 12\n23:49:13 |     n_positions: 1024\n23:49:13 |     n_segments: 2\n23:49:13 |     nesterov: True\n23:49:13 |     no_cuda: False\n23:49:13 |     normalize_sent_emb: False\n23:49:13 |     num_epochs: -1\n23:49:13 |     num_workers: 0\n23:49:13 |     nus: (0.7,)\n23:49:13 |     optimizer: adamax\n23:49:13 |     output_scaling: 0.06\n23:49:13 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type2/run1/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model1'}\"\n23:49:13 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n23:49:13 |     person_tokens: False\n23:49:13 |     print_scores: False\n23:49:13 |     rank_candidates: False\n23:49:13 |     rank_top_k: -1\n23:49:13 |     reduction_type: mean\n23:49:13 |     ref_class: None\n23:49:13 |     relu_dropout: 0.0\n23:49:13 |     repeat_blocking_heuristic: True\n23:49:13 |     return_cand_scores: False\n23:49:13 |     save_after_valid: True\n23:49:13 |     save_every_n_secs: -1\n23:49:13 |     save_format: conversations\n23:49:13 |     share_encoders: False\n23:49:13 |     share_word_embeddings: False\n23:49:13 |     short_final_eval: False\n23:49:13 |     special_tok_lst: None\n23:49:13 |     split_lines: False\n23:49:13 |     starttime: Dec03_23-48\n23:49:13 |     task: fromfile:parlaiformat\n23:49:13 |     tensorboard_log: False\n23:49:13 |     tensorboard_logdir: None\n23:49:13 |     text_truncate: 360\n23:49:13 |     threshold: 0.5\n23:49:13 |     topk: 5\n23:49:13 |     train_predict: False\n23:49:13 |     truncate: 1024\n23:49:13 |     update_classifier_head_only: False\n23:49:13 |     update_freq: 1\n23:49:13 |     use_memories: False\n23:49:13 |     use_reply: none\n23:49:13 |     validation_cutoff: 1.0\n23:49:13 |     validation_every_n_epochs: -1\n23:49:13 |     validation_every_n_secs: 20.0\n23:49:13 |     validation_every_n_steps: -1\n23:49:13 |     validation_max_exs: -1\n23:49:13 |     validation_metric: accuracy\n23:49:13 |     validation_metric_mode: max\n23:49:13 |     validation_patience: 30\n23:49:13 |     validation_share_agent: False\n23:49:13 |     variant: xlm\n23:49:13 |     verbose: False\n23:49:13 |     wandb_entity: None\n23:49:13 |     wandb_log: False\n23:49:13 |     wandb_name: None\n23:49:13 |     wandb_project: None\n23:49:13 |     warmup_rate: 0.0001\n23:49:13 |     warmup_updates: 1000\n23:49:13 |     weight_decay: None\n23:49:13 |     world_logs: \n23:49:13 |     wrap_memory_encoder: False\n23:49:13 | creating task(s): fromfile:parlaiformat\n23:49:13 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run1/data_train.txt\n23:49:13 | training...\n23:49:24 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .5050 5.05e-10               .5099                 .4791   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5450            .5000              .5351   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .4692 11.07     1 261.4 520.2       0          0  39.8  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5050             32768  2.605    .1189 5.945 .6950 1.005e-06 118.9 236.6   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 380.3 756.8 1.995        .5047\n\n23:49:33 | time:20s total_exs:1160 total_steps:58 epochs:5.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6118 6.118e-10               .6164                 .5985   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6354            .6072              .6264   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .5891 11.04     1 260.9  1010       0          0  77.4  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6118             32768  2.586    .1189 5.982 .6691 2.905e-06 119.6   463   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   58 380.5 1473 3.879        .6117\n\n23:49:33 | creating task(s): fromfile:parlaiformat\n23:49:33 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run1/data_valid.txt\n23:49:34 | running eval: valid\n23:49:34 | eval completed in 0.20s\n23:49:34 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5833 5.833e-10               .5833                 .5833   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5833            .5833              .5833   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .5833 11.46 161.5  1806       0          0 134.1   24 .5833   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6799 2.905e-06    72 804.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     58 233.5 2611        .5833\n\u001b[0m\n23:49:34 | \u001b[1;32mnew best accuracy: 0.5833\u001b[0m\n23:49:34 | saving best valid model: /tmp/model1\n23:49:34 | Saving dictionary to /tmp/model1.dict\n23:49:37 | saving model checkpoint: /tmp/model1.checkpoint\n23:49:37 | Saving dictionary to /tmp/model1.checkpoint.dict\n23:49:54 | time:41s total_exs:1860 total_steps:93 epochs:9.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7743 7.743e-10               .7492                 .8110   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6962            .7948              .7482   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8476    11     1 259.9 909.3       0          0 69.97  700   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7743             32768  3.446    .1189 5.969 .6149 4.655e-06 119.4 417.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   93 379.3 1327 3.506        .7727\n\n23:49:57 | time:44s total_exs:2100 total_steps:105 epochs:10.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8458 8.458e-10               .8490                 .9123   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7939            .8426              .7857   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9083  11.4     1   268  1052       0          0 78.53  240   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8458             32768   3.76    .1189 6.092 .5538 5.254e-06 121.8 478.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  105 389.8 1531 3.956        .8461\n\n23:49:57 | running eval: valid\n23:49:58 | eval completed in 0.20s\n23:49:58 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7273                 .8000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .7692              .7143   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1774       0          0 131.8   24 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5931 5.254e-06    72 790.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    105 233.5 2565        .7483\n\u001b[0m\n23:49:58 | \u001b[1;32mnew best accuracy: 0.75 (previous best was 0.5833)\u001b[0m\n23:49:58 | saving best valid model: /tmp/model1\n23:50:07 | saving model checkpoint: /tmp/model1.checkpoint\n23:50:23 | time:69s total_exs:2860 total_steps:143 epochs:14.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9000   9e-10               .8962                 .9011   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8913            .9036              .8990   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9082 11.13     1 262.6 985.5       0          0 75.06  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9000             32768  3.999    .1189 5.968 .4663 7.154e-06 119.4   448   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  143 381.9 1433 3.761        .9000\n\n23:50:28 | time:74s total_exs:3220 total_steps:161 epochs:16.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9102                 .9157   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9048            .9223              .9175   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9271 11.04     1 260.7  1008       0          0 77.29  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9167             32768  4.936    .1189 5.933 .3469 8.054e-06 118.7 458.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  161 379.4 1466 3.883        .9166\n\n23:50:28 | running eval: valid\n23:50:28 | eval completed in 0.20s\n23:50:28 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1762       0          0 130.8   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .4371 8.054e-06    72 785.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    161 233.5 2547        .7884\n\u001b[0m\n23:50:28 | \u001b[1;32mnew best accuracy: 0.7917 (previous best was 0.75)\u001b[0m\n23:50:28 | saving best valid model: /tmp/model1\n23:50:33 | saving model checkpoint: /tmp/model1.checkpoint\n23:50:52 | time:99s total_exs:3980 total_steps:199 epochs:19.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9132 9.132e-10               .9152                 .9223   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9082            .9111              .9037   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9185 11.04     1 260.7 974.1       0          0 74.73  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9132             32768  6.235    .1190 6.032 .2788 9.954e-06 120.6 450.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  199 381.3 1425 3.745        .9132\n\n23:50:53 | time:99s total_exs:4040 total_steps:202 epochs:20.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9500 9.5e-10               .9565                 .9706   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9429            .9412              .9231   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9600 11.07     1 261.3  1031       0          0 78.89   60   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9500             32768  5.956    .1190 6.167 .1996 1.01e-05 123.3 486.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  202 384.7 1517 4.065        .9501\n\n23:50:53 | running eval: valid\n23:50:53 | eval completed in 0.20s\n23:50:53 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1770       0          0 131.4   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .4019 1.01e-05    72 788.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    202 233.5 2559        .8322\n\u001b[0m\n23:50:53 | \u001b[1;32mnew best accuracy: 0.8333 (previous best was 0.7917)\u001b[0m\n23:50:53 | saving best valid model: /tmp/model1\n23:51:03 | saving model checkpoint: /tmp/model1.checkpoint\n23:51:18 | time:125s total_exs:4800 total_steps:240 epochs:24.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9618 9.618e-10               .9639                 .9485   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9797            .9596              .9773   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9425 10.84     1 256.8 975.4       0          0 75.96  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  \\\n   .9618             32768   3.64    .1190 6.039 .1602 1.2e-05 120.8 458.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  240 377.6 1434 3.806        .9618\n\n23:51:23 | time:129s total_exs:5160 total_steps:258 epochs:25.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9500 9.5e-10               .9458                 .9458   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9458            .9536              .9536   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9536 10.98     1 259.6 964.3       0          0  74.3  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9500             32768  8.481    .1190 5.922 .1695 1.29e-05 118.4   440   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  258  378 1404 3.732        .9500\n\n23:51:23 | running eval: valid\n23:51:23 | eval completed in 0.20s\n23:51:23 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1785       0          0 132.6   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .6611 1.29e-05    72 795.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    258 233.5 2581        .8322\n\u001b[0m\n23:51:23 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 1\u001b[0m\n23:51:23 | saving model checkpoint: /tmp/model1.checkpoint\n23:51:39 | time:145s total_exs:5920 total_steps:296 epochs:29.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9711 9.711e-10               .9722                 .9577   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9872            .9698              .9860   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9541 11.26     1 265.2   990       0          0 74.66  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9711             32768  3.952    .1190 6.026 .1000 1.48e-05 120.5 449.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  296 385.7 1440 3.739        .9710\n\n23:51:43 | time:150s total_exs:6260 total_steps:313 epochs:31.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9735 9.735e-10               .9731                 .9588   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9879            .9739              .9882   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9600  10.9     1 258.1 979.7       0          0 75.93  340   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9735             32768  4.703    .1190 5.971 .0949 1.565e-05 119.4 453.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  313 377.5 1433 3.816        .9735\n\n23:51:43 | running eval: valid\n23:51:43 | eval completed in 0.20s\n23:51:43 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1750       0          0   130   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 1.074 1.565e-05    72 780.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    313 233.5 2531        .7913\n\u001b[0m\n23:51:43 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 2\u001b[0m\n23:51:43 | saving model checkpoint: /tmp/model1.checkpoint\n23:51:58 | time:164s total_exs:7000 total_steps:350 epochs:35.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9851 9.851e-10               .9854                 .9814   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9893            .9849              .9890   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9809 11.02 .6757 260.4 950.9       0          0 73.03  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9851             32768  4.839    .1190 6.011 .05413 1.75e-05 120.2 438.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  350 380.6 1390 3.659        .9851\n\n23:52:03 | time:170s total_exs:7420 total_steps:371 epochs:37.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9952 9.952e-10               .9951                 .9903   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9953                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9907 11.21 .5238 264.2  1002       0          0 75.82  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9952             32768   2.83    .1190 5.971 .01878 1.855e-05 119.4 452.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  371 383.6 1454 3.807        .9952\n\n23:52:03 | running eval: valid\n23:52:04 | eval completed in 0.20s\n23:52:04 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1777       0          0   132   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 1.363 1.855e-05    72 791.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    371 233.5 2569        .7913\n\u001b[0m\n23:52:04 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 3\u001b[0m\n23:52:04 | saving model checkpoint: /tmp/model1.checkpoint\n23:52:18 | time:184s total_exs:8180 total_steps:409 epochs:40.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9908 9.908e-10               .9908                 .9947   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9868            .9908              .9869   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9947 10.98 .2632 259.6 985.6       0          0 75.92  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9908             32768  1.421    .1190     6 .04959 2.045e-05   120 455.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  409 379.6 1441 3.805        .9908\n\n23:52:24 | time:190s total_exs:8600 total_steps:430 epochs:43.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9833 9.833e-10               .9838                 .9907   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9771            .9828              .9756   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9901 11.13 .6667 262.5 962.3       0          0 73.31  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9833             32768  4.878    .1190 6.038 .05624 2.15e-05 120.8 442.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  430 383.3 1405 3.68        .9833\n\n23:52:24 | running eval: valid\n23:52:24 | eval completed in 0.20s\n23:52:24 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1771       0          0 131.5   24 .7917   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08095     6 1.384 2.15e-05    72 789.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    430 233.5 2561        .7913\n\u001b[0m\n23:52:24 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 4\u001b[0m\n23:52:24 | saving model checkpoint: /tmp/model1.checkpoint\n23:52:38 | time:205s total_exs:9380 total_steps:469 epochs:46.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9859 9.859e-10               .9856                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9716            .9862              .9728   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.76 .3590 255.2 974.1       0          0 76.36  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9859             32768  1.365    .1190 5.992 .05966 2.345e-05 119.8 457.6   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  469  375 1432 3.826        .9859\n\n23:52:44 | time:211s total_exs:9820 total_steps:491 epochs:49.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9886 9.886e-10               .9892                 .9914   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9871            .9880              .9856   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9903 11.18 .4091 263.6  1022       0          0 77.56  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9886             32768  1.797    .1190 6.059 .04137 2.455e-05 121.2 469.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  491 384.8 1492 3.893        .9886\n\n23:52:44 | running eval: valid\n23:52:44 | eval completed in 0.21s\n23:52:44 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1758       0          0 130.6   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 1.486 2.455e-05    72 783.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    491 233.5 2541        .7913\n\u001b[0m\n23:52:44 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 5\u001b[0m\n23:52:44 | saving model checkpoint: /tmp/model1.checkpoint\n23:52:59 | time:225s total_exs:10580 total_steps:529 epochs:52.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9921 9.921e-10               .9920                 .9947   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9894            .9922              .9896   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9948 11.19 .2368 263.9 983.6       0          0 74.54  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9921             32768  1.019    .1190 5.989 .03995 2.645e-05 119.8 446.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  529 383.7 1430 3.735        .9921\n\n23:53:04 | time:231s total_exs:11000 total_steps:550 epochs:55.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9857 9.857e-10               .9866                 .9822   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9910            .9847              .9897   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9797 11.14 .3333 262.9 993.5       0          0 75.59  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9857             32768  1.676    .1190 6.062 .03031 2.75e-05 121.2 458.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  550 384.1 1452 3.795        .9857\n\n23:53:04 | running eval: valid\n23:53:05 | eval completed in 0.20s\n23:53:05 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1785       0          0 132.6   24 .7917   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6  1.38 2.75e-05    72 795.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    550 233.5 2581        .7913\n\u001b[0m\n23:53:05 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 6\u001b[0m\n23:53:05 | saving model checkpoint: /tmp/model1.checkpoint\n23:53:19 | time:246s total_exs:11760 total_steps:588 epochs:58.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9895 9.895e-10               .9896                 .9922   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9870            .9894              .9867   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9920    11 .3158   260 986.2       0          0 75.86  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9895             32768  .6646    .1190 6.013 .02674 2.94e-05 120.3 456.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  588 380.3 1442 3.802        .9895\n\n23:53:25 | time:251s total_exs:12200 total_steps:610 epochs:61.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9864 9.864e-10               .9853                 .9757   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9950            .9873              .9957   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9790 11.15 .5000   263  1015       0          0  77.2  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9864             32768  2.227    .1190 5.918 .02639 3.05e-05 118.4 456.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  610 381.4 1472 3.875        .9864\n\n23:53:25 | running eval: valid\n23:53:25 | eval completed in 0.24s\n23:53:25 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1595       0          0 118.5   24 .7917   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 1.516 3.05e-05    72 711.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    610 233.5 2307        .7913\n\u001b[0m\n23:53:25 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 7\u001b[0m\n23:53:25 | saving model checkpoint: /tmp/model1.checkpoint\n23:53:40 | time:267s total_exs:12980 total_steps:649 epochs:64.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9885 9.885e-10               .9877                 .9918   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9837            .9891              .9856   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9927 11.35 .3846 266.9  1021       0          0 76.46  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9885             32768  .3210    .1190 5.941 .01861 3.245e-05 118.8 454.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  649 385.8 1475 3.831        .9885\n\n23:53:45 | time:272s total_exs:13380 total_steps:669 epochs:66.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9900 9.9e-10               .9907                 .9815   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9892                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9787 11.06 .5000 261.2  1011       0          0 77.39  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9900             32768  .3995    .1190  6.06 .02638 3.345e-05 121.2   469   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  669 382.4 1480 3.887        .9900\n\n23:53:45 | running eval: valid\n23:53:45 | eval completed in 0.21s\n23:53:45 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1655       0          0 122.9   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 1.461 3.345e-05    72 737.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    669 233.5 2393        .7913\n\u001b[0m\n23:53:45 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 8\u001b[0m\n23:53:45 | saving model checkpoint: /tmp/model1.checkpoint\n23:54:00 | time:286s total_exs:14140 total_steps:707 epochs:70.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9829 9.829e-10               .9833                 .9770   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9897            .9825              .9891   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9759 10.89 .3421 257.9 962.7       0          0 74.66  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9829             32768  .2956    .1190 6.018 .02872 3.535e-05 120.4 449.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  707 378.3 1412 3.741        .9829\n\n23:54:06 | time:292s total_exs:14580 total_steps:729 epochs:72.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9909 9.909e-10               .9909                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9820            .9909              .9820   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.15 .3182   263 994.1       0          0 75.58  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9909             32768  .1863    .1190 6.009 .01464 3.645e-05 120.2 454.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  729 383.2 1448 3.794        .9909\n\n23:54:06 | running eval: valid\n23:54:06 | eval completed in 0.20s\n23:54:06 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1735       0          0 128.9   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6  1.55 3.645e-05    72 773.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    729 233.5 2509        .7913\n\u001b[0m\n23:54:06 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 9\u001b[0m\n23:54:06 | saving model checkpoint: /tmp/model1.checkpoint\n23:54:21 | time:307s total_exs:15340 total_steps:767 epochs:76.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9895 9.895e-10               .9890                 .9863   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9917            .9899              .9924   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9874 11.51 .3684 270.3  1024       0          0 75.74  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9895             32768  .4262    .1191 5.955 .01877 3.835e-05 119.1 451.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  767 389.4 1475 3.796        .9895\n\n23:54:26 | time:313s total_exs:15740 total_steps:787 epochs:78.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9925 9.925e-10               .9929                 .9859   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9920                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9842 11.37 .3500 267.3  1010       0          0 75.58  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9925             32768  .1780    .1191  6.05 .01397 3.935e-05   121 457.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  787 388.3 1467 3.795        .9925\n\n23:54:26 | running eval: valid\n23:54:26 | eval completed in 0.20s\n23:54:26 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .7200                 .6923   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .6957              .7273   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .6667 11.46 161.5  1775       0          0 131.9   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 1.963 3.935e-05    72 791.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    787 233.5 2567        .7078\n\u001b[0m\n23:54:26 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 10\u001b[0m\n23:54:26 | saving model checkpoint: /tmp/model1.checkpoint\n23:54:41 | time:328s total_exs:16500 total_steps:825 epochs:82.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9908 9.908e-10               .9907                 .9815   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9909                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9820 10.85 .2895 257.1 972.6       0          0 75.66  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9908             32768  .3243    .1191 5.976 .02579 4.125e-05 119.5 452.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  825 376.6 1425 3.792        .9908\n\n23:54:46 | time:333s total_exs:16860 total_steps:843 epochs:84.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9861 9.861e-10               .9845                 .9755   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9938            .9874              .9949   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9800 11.33 .2778 266.7  1008       0          0 75.63  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9861             32768  .6441    .1191 5.889 .02834 4.215e-05 117.8 445.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  843 384.4 1454 3.795        .9861\n\n23:54:46 | running eval: valid\n23:54:46 | eval completed in 0.20s\n23:54:46 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7500                 .7500   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .7500              .7500   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.46 161.5  1742       0          0 129.4   24 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 1.858 4.215e-05    72 776.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    843 233.5 2519        .7500\n\u001b[0m\n23:54:46 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 11\u001b[0m\n23:54:46 | saving model checkpoint: /tmp/model1.checkpoint\n23:55:01 | time:348s total_exs:17640 total_steps:882 epochs:88.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9936 9.936e-10               .9934                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9869            .9937              .9876   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.39 .2051 267.7  1015       0          0 75.85  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9936             32768  .1294    .1191 5.982 .01194 4.41e-05 119.6 453.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  882 387.4 1469 3.801        .9936\n\n23:55:07 | time:353s total_exs:18060 total_steps:903 epochs:90.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9952 9.952e-10               .9954                 .9908   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9951                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9902 10.98 .2857 259.7 991.7       0          0 76.38  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9952             32768  .1362    .1191 6.029 .01037 4.515e-05 120.6 460.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  903 380.2 1452 3.835        .9952\n\n23:55:07 | running eval: valid\n23:55:07 | eval completed in 0.20s\n23:55:07 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1803       0          0   134   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 1.626 4.515e-05    72 803.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    903 233.5 2607        .7913\n\u001b[0m\n23:55:07 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 12\u001b[0m\n23:55:07 | saving model checkpoint: /tmp/model1.checkpoint\n23:55:22 | time:368s total_exs:18820 total_steps:941 epochs:94.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9855 9.855e-10               .9858                 .9896   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9820            .9852              .9813   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9892    11 .3421 260.1 983.4       0          0 75.63  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9855             32768  .3069    .1191 6.024 .03082 4.705e-05 120.5 455.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  941 380.5 1439 3.79        .9855\n\n23:55:27 | time:373s total_exs:19200 total_steps:960 epochs:96.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9868 9.868e-10               .9867                 .9946   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9788            .9870              .9794   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9948 10.81 .3684 256.2 994.7       0          0 77.65  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss      lr  ltpb  ltps  \\\n   .9868             32768  .4540    .1191 5.995 .01915 4.8e-05 119.9 465.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  960 376.1 1460  3.9        .9868\n\n23:55:27 | running eval: valid\n23:55:27 | eval completed in 0.20s\n23:55:27 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1812       0          0 134.6   24 .7917   \n    gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 1.633 4.8e-05    72 807.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    960 233.5 2620        .7913\n\u001b[0m\n23:55:27 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 13\u001b[0m\n23:55:27 | saving model checkpoint: /tmp/model1.checkpoint\n23:55:42 | time:388s total_exs:19940 total_steps:997 epochs:99.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9851 9.851e-10               .9852                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9708            .9851              .9706   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.04 .3243 260.8 957.6       0          0 73.42  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9851             32768  2.968    .1191 6.019 .06236 4.985e-05 120.4 441.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  997 381.2 1399 3.68        .9851\n\n23:55:47 | time:394s total_exs:20380 total_steps:1019 epochs:101.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9909 9.909e-10               .9906                 .9953   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9859            .9912              .9869   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9956 11.16 .3636 263.3  1019       0          0  77.4  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9909             32768  .4167    .1191 5.968 .01539 4.995e-05 119.4   462   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1019 382.6 1481 3.886        .9909\n\n23:55:47 | running eval: valid\n23:55:47 | eval completed in 0.21s\n23:55:47 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1724       0          0 128.1   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6 1.584 4.995e-05    72 768.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1019 233.5 2493        .7884\n\u001b[0m\n23:55:47 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 14\u001b[0m\n23:55:47 | saving model checkpoint: /tmp/model1.checkpoint\n23:56:03 | time:409s total_exs:21160 total_steps:1058 epochs:105.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9949 9.949e-10               .9950                 .9950   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9950            .9947              .9947   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9947 10.93 .2051 258.6 985.4       0          0 76.22  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9949             32768  .2122    .1191 6.026 .01807 4.995e-05 120.5 459.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1058 379.1 1445 3.816        .9949\n\n23:56:08 | time:414s total_exs:21540 total_steps:1077 epochs:107.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9711 9.711e-10               .9734                 .9710   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9757            .9683              .9711   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9655  11.1 .5789   262 971.7       0          0 74.17  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9711             32768  .7376    .1191 6.084 .06632 4.995e-05 121.7 451.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1077 383.7 1423 3.725        .9710\n\n23:56:08 | running eval: valid\n23:56:08 | eval completed in 0.20s\n23:56:08 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7273                 .8000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .7692              .7143   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1785       0          0 132.6   24 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 1.639 4.995e-05    72 795.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1077 233.5 2580        .7483\n\u001b[0m\n23:56:08 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 15\u001b[0m\n23:56:08 | saving model checkpoint: /tmp/model1.checkpoint\n23:56:22 | time:429s total_exs:22300 total_steps:1115 epochs:111.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9895 9.895e-10               .9886                 .9943   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9831            .9902              .9854   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9951 10.97 .4211 259.4 968.8       0          0 74.68  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9895             32768  .2372    .1191 5.932 .01831 4.995e-05 118.6   443   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1115 378.1 1412 3.743        .9895\n\n23:56:28 | time:435s total_exs:22720 total_steps:1136 epochs:113.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9881 9.881e-10               .9881                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9764            .9881              .9765   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.21 .3333 264.3  1001       0          0 75.74  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9881             32768  .2030    .1191  6.01 .03332 4.995e-05 120.2 455.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1136 384.5 1456 3.803        .9881\n\n23:56:28 | running eval: valid\n23:56:28 | eval completed in 0.20s\n23:56:28 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1744       0          0 129.6   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 1.659 4.995e-05    72 777.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1136 233.5 2522        .7913\n\u001b[0m\n23:56:28 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 16\u001b[0m\n23:56:28 | saving model checkpoint: /tmp/model1.checkpoint\n23:56:43 | time:449s total_exs:23460 total_steps:1173 epochs:117.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9865 9.865e-10               .9869                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9741            .9861              .9725   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.14 .4324 262.7 958.6       0          0 72.97  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9865             32768  .2368    .1191 6.043 .02388 4.995e-05 120.9   441   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1173 383.6 1400 3.657        .9865\n\n23:56:48 | time:455s total_exs:23900 total_steps:1195 epochs:119.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9909 9.909e-10               .9904                 .9856   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9952            .9914              .9957   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9871 10.88 .2727 257.5 979.7       0          0 76.08  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9909             32768  .1513    .1191 5.941 .0144 4.995e-05 118.8   452   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1195 376.4 1432 3.819        .9909\n\n23:56:48 | running eval: valid\n23:56:49 | eval completed in 0.20s\n23:56:49 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7500                 .7500   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .7500              .7500   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.46 161.5  1733       0          0 128.7   24 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 1.943 4.995e-05    72 772.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1195 233.5 2505        .7500\n\u001b[0m\n23:56:49 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 17\u001b[0m\n23:56:49 | saving model checkpoint: /tmp/model1.checkpoint\n23:57:03 | time:470s total_exs:24660 total_steps:1233 epochs:123.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9895 9.895e-10               .9894                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9789            .9896              .9794   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.21 .3158 264.2 995.5       0          0 75.37  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9895             32768  .1280    .1191     6 .01769 4.995e-05   120 452.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1233 384.2 1448 3.777        .9895\n\n23:57:09 | time:475s total_exs:25080 total_steps:1254 epochs:125.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9929 9.929e-10               .9931                 .9954   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9908            .9926              .9902   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9951 10.82 .1905 256.5 943.5       0          0 73.57  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9929             32768 .08382    .1191 6.033 .009143 4.995e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   443.9       0          0                 1254 377.1 1387 3.693        .9929\n\n23:57:09 | running eval: valid\n23:57:09 | eval completed in 0.24s\n23:57:09 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7500                 .7500   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .7500              .7500   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.46 161.5  1546       0          0 114.8   24 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6 1.838 4.995e-05    72 689.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1254 233.5 2236        .7500\n\u001b[0m\nEpoch 00005: reducing learning rate of group 0 to 2.4975e-05.\n23:57:09 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 18\u001b[0m\n23:57:09 | saving model checkpoint: /tmp/model1.checkpoint\n23:57:24 | time:490s total_exs:25840 total_steps:1292 epochs:129.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9921 9.921e-10               .9927                 .9854   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9915                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9831 11.46 .2895 269.2  1017       0          0 75.58  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9921             32768  .1245    .1192 6.068 .01371 2.498e-05 121.4 458.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1292 390.5 1476 3.788        .9921\n\n23:57:29 | time:496s total_exs:26280 total_steps:1314 epochs:131.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9841 9.841e-10               .9827                 .9660   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9853                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9710    11 .4091 260.1  1010       0          0 77.66  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9841             32768  .1668    .1192 5.905 .01866 2.498e-05 118.1 458.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1314 378.2 1468 3.898        .9841\n\n23:57:29 | running eval: valid\n23:57:29 | eval completed in 0.21s\n23:57:29 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1717       0          0 127.6   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 1.681 2.498e-05    72 765.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1314 233.5 2483        .7913\n\u001b[0m\n23:57:29 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 19\u001b[0m\n23:57:29 | saving model checkpoint: /tmp/model1.checkpoint\n23:57:44 | time:511s total_exs:27040 total_steps:1352 epochs:135.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9868 9.868e-10               .9858                 .9858   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9858            .9878              .9878   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9878 10.83 .3684 256.5 952.9       0          0 74.29  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9868             32768  .1297    .1192 5.924 .0178 2.498e-05 118.5 440.1   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1352  375 1393 3.723        .9868\n\n23:57:50 | time:516s total_exs:27460 total_steps:1373 epochs:137.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9905 9.905e-10               .9901                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9804            .9908              .9818   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1    11 .3810   260  1012       0          0 77.84  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9905             32768  .1306    .1192 5.971 .01602 2.498e-05 119.4 464.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1373 379.4 1477 3.909        .9905\n\n23:57:50 | running eval: valid\n23:57:50 | eval completed in 0.21s\n23:57:50 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1730       0          0 128.5   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 1.688 2.498e-05    72   771       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1373 233.5 2501        .7913\n\u001b[0m\n23:57:50 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 20\u001b[0m\n23:57:50 | saving model checkpoint: /tmp/model1.checkpoint\n23:58:04 | time:531s total_exs:28240 total_steps:1412 epochs:141.20\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9910 9.91e-10               .9911                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9824            .9909              .9821   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.41 .2308 268.2  1022       0          0 76.23  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9910             32768 .09986    .1192 6.018 .0137 2.498e-05 120.4 458.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1412 388.6 1481 3.82        .9910\n\n23:58:10 | time:536s total_exs:28660 total_steps:1433 epochs:143.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9952 9.952e-10               .9953                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9906            .9952              .9904   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.28 .1429 265.7  1029       0          0 77.44  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9952             32768 .05576    .1192 6.014 .006121 2.498e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   465.8       0          0                 1433  386 1494 3.888        .9952\n\n23:58:10 | running eval: valid\n23:58:10 | eval completed in 0.20s\n23:58:10 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7500                 .7500   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .7500              .7500   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.46 161.5  1764       0          0   131   24 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 1.883 2.498e-05    72 786.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1433 233.5 2551        .7500\n\u001b[0m\n23:58:10 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 21\u001b[0m\n23:58:10 | saving model checkpoint: /tmp/model1.checkpoint\n23:58:25 | time:552s total_exs:29420 total_steps:1471 epochs:147.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9947 9.947e-10               .9948                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9897            .9946              .9893   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.91 .3684 258.1 981.7       0          0 76.06  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9947             32768  .1249    .1192 6.024 .01314 2.498e-05 120.5 458.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1471 378.6 1440 3.811        .9947\n\n23:58:30 | time:557s total_exs:29800 total_steps:1490 epochs:149.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9921 9.921e-10               .9924                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9850            .9917              .9836   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.41 .3158 268.1  1019       0          0 76.03  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9921             32768  .1068    .1192 6.053 .01254 2.498e-05 121.1 460.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1490 389.2 1479 3.819        .9921\n\n23:58:30 | running eval: valid\n23:58:30 | eval completed in 0.20s\n23:58:30 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1747       0          0 129.8   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6 1.704 2.498e-05    72 778.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1490 233.5 2526        .7913\n\u001b[0m\nEpoch 00009: reducing learning rate of group 0 to 1.2488e-05.\n23:58:30 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 22\u001b[0m\n23:58:30 | saving model checkpoint: /tmp/model1.checkpoint\n23:58:45 | time:572s total_exs:30560 total_steps:1528 epochs:152.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9868 9.868e-10               .9859                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9721            .9877              .9757   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.08 .3947 261.6 973.2       0          0 74.42  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9868             32768  .1513    .1192 5.945 .02062 1.249e-05 118.9 442.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1528 380.4 1416 3.729        .9868\n\n23:58:50 | time:577s total_exs:30980 total_steps:1549 epochs:154.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9881 9.881e-10               .9875                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9754            .9886              .9775   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.06 .2857 261.3   998       0          0 76.39  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9881             32768  .1198    .1192 5.967 .01662 1.249e-05 119.3 455.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1549 380.6 1454 3.835        .9881\n\n23:58:50 | running eval: valid\n23:58:51 | eval completed in 0.20s\n23:58:51 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1742       0          0 129.4   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 1.709 1.249e-05    72 776.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1549 233.5 2519        .7913\n\u001b[0m\n23:58:51 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 23\u001b[0m\n23:58:51 | saving model checkpoint: /tmp/model1.checkpoint\n23:59:05 | time:592s total_exs:31740 total_steps:1587 epochs:158.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9882 9.882e-10               .9881                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9765            .9882              .9767   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.92 .4211 258.4 981.4       0          0 75.96  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9882             32768  .1540    .1192 6.008 .01887 1.249e-05 120.2 456.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1587 378.5 1438 3.807        .9882\n\n23:59:11 | time:597s total_exs:32180 total_steps:1609 epochs:160.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9932 9.932e-10               .9929                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9858            .9935              .9870   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.82 .3636 256.5 986.2       0          0 76.91  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9932             32768  .1143    .1192 5.964 .01454 1.249e-05 119.3 458.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1609 375.7 1445 3.861        .9932\n\n23:59:11 | running eval: valid\n23:59:11 | eval completed in 0.20s\n23:59:11 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1747       0          0 129.7   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 1.713 1.249e-05    72 778.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1609 233.5 2525        .7913\n\u001b[0m\n23:59:11 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 24\u001b[0m\n23:59:11 | saving model checkpoint: /tmp/model1.checkpoint\n23:59:26 | time:613s total_exs:32940 total_steps:1647 epochs:164.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9882 9.882e-10               .9877                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9757            .9886              .9774   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  10.8 .3684   256 966.3       0          0 75.49  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9882             32768  .1402    .1192 5.974 .01729 1.249e-05 119.5   451   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1647 375.5 1417 3.783        .9882\n\n23:59:31 | time:618s total_exs:33320 total_steps:1666 epochs:166.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9974 9.974e-10               .9975                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9950            .9972              .9944   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.42 .2632 268.4  1046       0          0 77.98  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9974             32768 .08434    .1192 6.058 .008757 1.249e-05 121.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   472.4       0          0                 1666 389.5 1519 3.917        .9974\n\n23:59:31 | running eval: valid\n23:59:31 | eval completed in 0.23s\n23:59:31 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1513       0          0 112.4   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 1.723 1.249e-05    72 674.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1666 233.5 2187        .7913\n\u001b[0m\n23:59:31 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 25\u001b[0m\n23:59:31 | saving model checkpoint: /tmp/model1.checkpoint\n23:59:46 | time:633s total_exs:34100 total_steps:1705 epochs:170.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9936 9.936e-10               .9934                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9869            .9937              .9876   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.18 .2051 263.5  1003       0          0 76.11  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9936             32768 .08005    .1192 5.982 .01059 1.249e-05 119.6 455.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1705 383.2 1458 3.814        .9936\n\n23:59:52 | time:638s total_exs:34500 total_steps:1725 epochs:172.50\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9950 9.95e-10               .9951                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9902            .9949              .9899   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.34 .3500 266.9 991.7       0          0 74.32  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9950             32768 .09908    .1192  6.02 .0109 1.249e-05 120.4 447.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1725 387.2 1439 3.732        .9950\n\n23:59:52 | running eval: valid\n23:59:52 | eval completed in 0.21s\n23:59:52 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1737       0          0   129   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 1.719 1.249e-05    72 774.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1725 233.5 2511        .7913\n\u001b[0m\nEpoch 00013: reducing learning rate of group 0 to 6.2438e-06.\n23:59:52 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 26\u001b[0m\n23:59:52 | saving model checkpoint: /tmp/model1.checkpoint\n00:00:07 | time:653s total_exs:35280 total_steps:1764 epochs:176.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9949 9.949e-10               .9946                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9892            .9951              .9903   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.29 .3333 265.8  1013       0          0 76.21  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9949             32768 .09824    .1192 5.949 .0119 6.244e-06   119 453.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1764 384.8 1466 3.819        .9949\n\n00:00:12 | time:658s total_exs:35660 total_steps:1783 epochs:178.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9947 9.947e-10               .9948                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9896            .9947              .9894   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.95 .1579 259.1  1003       0          0 77.46  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9947             32768 .06547    .1192 6.016 .008611 6.244e-06 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     466       0          0                 1783 379.4 1469 3.891        .9947\n\n00:00:12 | running eval: valid\n00:00:12 | eval completed in 0.20s\n00:00:12 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1755       0          0 130.4   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 1.722 6.244e-06    72 782.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1783 233.5 2537        .7913\n\u001b[0m\n00:00:12 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 27\u001b[0m\n00:00:12 | saving model checkpoint: /tmp/model1.checkpoint\n00:00:27 | time:673s total_exs:36420 total_steps:1821 epochs:182.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9947 9.947e-10               .9943                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9887            .9951              .9903   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.08 .3158 261.6 977.9       0          0 74.77  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9947             32768 .09119    .1192 5.929 .0123 6.244e-06 118.6 443.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1821 380.1 1421 3.747        .9947\n\n00:00:32 | time:679s total_exs:36840 total_steps:1842 epochs:184.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9857 9.857e-10               .9848                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9700            .9865              .9735   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.93 .5238 258.5 995.7       0          0 77.03  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9857             32768  .1957    .1193 5.952 .02712 6.244e-06   119 458.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1842 377.6 1454 3.867        .9857\n\n00:00:32 | running eval: valid\n00:00:32 | eval completed in 0.20s\n00:00:32 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1780       0          0 132.3   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 1.725 6.244e-06    72 793.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1842 233.5 2574        .7913\n\u001b[0m\n00:00:32 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 28\u001b[0m\n00:00:32 | saving model checkpoint: /tmp/model1.checkpoint\n00:00:47 | time:693s total_exs:37620 total_steps:1881 epochs:188.10\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9910 9.91e-10               .9912                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9825            .9909              .9820   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.27 .2564 265.4  1014       0          0 76.39  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9910             32768  .1077    .1193 6.023 .01606 6.244e-06 120.5 460.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1881 385.8 1474 3.828        .9910\n\n00:00:52 | time:699s total_exs:38020 total_steps:1901 epochs:190.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9875 9.875e-10               .9877                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9757            .9873              .9749   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.29 .5500 265.9 955.9       0          0  71.9  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9875             32768  .1750    .1193  6.03 .02419 6.244e-06 120.6 433.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1901 386.5 1389 3.61        .9875\n\n00:00:52 | running eval: valid\n00:00:53 | eval completed in 0.20s\n00:00:53 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7500                 .7500   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .7500              .7500   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.46 161.5  1747       0          0 129.8   24 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08122     6 1.805 6.244e-06    72   779       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1901 233.5 2526        .7500\n\u001b[0m\n00:00:53 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 29\u001b[0m\n00:00:53 | saving model checkpoint: /tmp/model1.checkpoint\n00:01:07 | time:714s total_exs:38800 total_steps:1940 epochs:194.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9897 9.897e-10               .9889                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9781            .9905              .9811   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.12 .3077 262.4   999       0          0 76.15  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9897             32768  .1398    .1193 5.936 .01865 6.244e-06 118.7   452   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1940 381.1 1451 3.816        .9897\n\n00:01:13 | time:719s total_exs:39200 total_steps:1960 epochs:196.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9975 9.975e-10               .9973                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9947            .9977              .9953   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.57 .4000 251.4 946.4       0          0 75.29  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9975             32768 .07993    .1193 5.935 .008328 6.244e-06 118.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   446.9       0          0                 1960 370.1 1393 3.781        .9975\n\n00:01:13 | running eval: valid\n00:01:13 | eval completed in 0.20s\n00:01:13 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7500                 .7500   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .7500              .7500   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.46 161.5  1788       0          0 132.8   24 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08123     6 1.811 6.244e-06    72   797       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1960 233.5 2585        .7500\n\u001b[0m\nEpoch 00017: reducing learning rate of group 0 to 3.1219e-06.\n00:01:13 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 30\u001b[0m\n00:01:13 | saving model checkpoint: /tmp/model1.checkpoint\n00:01:17 | ran out of patience! stopping training.\n00:01:18 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n00:01:18 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n00:01:18 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run1/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n00:01:18 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n00:01:18 | Using CUDA\n00:01:18 | loading dictionary from /tmp/model1.dict\n00:01:18 | num words = 54944\n00:01:23 | Loading existing model parameters from /tmp/model1\n00:01:31 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:01:32 | creating task(s): fromfile:parlaiformat\n00:01:32 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run1/data_valid.txt\n00:01:32 | running eval: valid\n00:01:32 | eval completed in 0.24s\n00:01:32 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1511       0          0 112.2   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298     6 .4019 1.01e-05    72 673.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    202 233.5 2184        .8322\n\u001b[0m\n00:01:32 | creating task(s): fromfile:parlaiformat\n00:01:32 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run1/data_test.txt\n00:01:32 | running eval: test\n00:01:37 | eval completed in 5.03s\n00:01:37 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8990 8.99e-10               .6576                 .4974   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9700            .9408              .9963   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8911 12.07 281.4  2809       0          0 199.6 1000 .8990   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298   5.2 .2605 1.01e-05   104  1038       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    202 385.4 3847        .9124\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type2/run1/data_test.txt -m transformer/classifier -mf /tmp/model1 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:01:39.740580Z","iopub.execute_input":"2022-12-04T00:01:39.741344Z","iopub.status.idle":"2022-12-04T00:02:10.060329Z","shell.execute_reply.started":"2022-12-04T00:01:39.741296Z","shell.execute_reply":"2022-12-04T00:02:10.059118Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"00:01:48 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr2type2/run1/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr2type2/run1/data)\u001b[0m\n00:01:48 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n00:01:48 | Using CUDA\n00:01:48 | loading dictionary from /tmp/model1.dict\n00:01:48 | num words = 54944\n00:01:52 | Loading existing model parameters from /tmp/model1\n00:01:58 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:02:00 | Opt:\n00:02:00 |     activation: gelu\n00:02:00 |     adafactor_eps: '[1e-30, 0.001]'\n00:02:00 |     adam_eps: 1e-08\n00:02:00 |     add_p1_after_newln: False\n00:02:00 |     aggregate_micro: False\n00:02:00 |     allow_missing_init_opts: False\n00:02:00 |     area_under_curve_class: None\n00:02:00 |     area_under_curve_digits: -1\n00:02:00 |     attention_dropout: 0.1\n00:02:00 |     batchsize: 40\n00:02:00 |     betas: '[0.9, 0.999]'\n00:02:00 |     bpe_add_prefix_space: None\n00:02:00 |     bpe_debug: False\n00:02:00 |     bpe_dropout: None\n00:02:00 |     bpe_merge: None\n00:02:00 |     bpe_vocab: None\n00:02:00 |     candidates: inline\n00:02:00 |     cap_num_predictions: 100\n00:02:00 |     checkpoint_activations: False\n00:02:00 |     class_weights: None\n00:02:00 |     classes: \"['__notok__', '__ok__']\"\n00:02:00 |     classes_from_file: None\n00:02:00 |     data_parallel: True\n00:02:00 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n00:02:00 |     datatype: train\n00:02:00 |     delimiter: '\\n'\n00:02:00 |     dict_class: parlai.core.dict:DictionaryAgent\n00:02:00 |     dict_endtoken: __start__\n00:02:00 |     dict_file: /tmp/model1.dict\n00:02:00 |     dict_include_test: False\n00:02:00 |     dict_include_valid: False\n00:02:00 |     dict_initpath: None\n00:02:00 |     dict_language: english\n00:02:00 |     dict_loaded: True\n00:02:00 |     dict_lower: True\n00:02:00 |     dict_max_ngram_size: -1\n00:02:00 |     dict_maxexs: -1\n00:02:00 |     dict_maxtokens: -1\n00:02:00 |     dict_minfreq: 0\n00:02:00 |     dict_nulltoken: __null__\n00:02:00 |     dict_starttoken: __start__\n00:02:00 |     dict_textfields: text,labels\n00:02:00 |     dict_tokenizer: bpe\n00:02:00 |     dict_unktoken: __unk__\n00:02:00 |     display_examples: False\n00:02:00 |     download_path: None\n00:02:00 |     dropout: 0.1\n00:02:00 |     dynamic_batching: None\n00:02:00 |     embedding_projection: random\n00:02:00 |     embedding_size: 768\n00:02:00 |     embedding_type: random\n00:02:00 |     embeddings_scale: False\n00:02:00 |     encode_candidate_vecs: True\n00:02:00 |     encode_candidate_vecs_batchsize: 256\n00:02:00 |     eval_batchsize: None\n00:02:00 |     eval_candidates: inline\n00:02:00 |     eval_dynamic_batching: None\n00:02:00 |     evaltask: None\n00:02:00 |     ffn_size: 3072\n00:02:00 |     final_extra_opt: \n00:02:00 |     fixed_candidate_vecs: reuse\n00:02:00 |     fixed_candidates_path: None\n00:02:00 |     force_fp16_tokens: True\n00:02:00 |     fp16: True\n00:02:00 |     fp16_impl: safe\n00:02:00 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run1/data_test.txt\n00:02:00 |     fromfile_datatype_extension: True\n00:02:00 |     gpu: -1\n00:02:00 |     gradient_clip: 0.1\n00:02:00 |     hide_labels: False\n00:02:00 |     history_add_global_end_token: None\n00:02:00 |     history_reversed: False\n00:02:00 |     history_size: 20\n00:02:00 |     ignore_bad_candidates: False\n00:02:00 |     ignore_labels: None\n00:02:00 |     image_cropsize: 224\n00:02:00 |     image_mode: raw\n00:02:00 |     image_size: 256\n00:02:00 |     inference: max\n00:02:00 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:02:00 |     init_opt: None\n00:02:00 |     interactive_candidates: fixed\n00:02:00 |     interactive_mode: False\n00:02:00 |     invsqrt_lr_decay_gamma: -1\n00:02:00 |     is_debug: False\n00:02:00 |     label_truncate: 72\n00:02:00 |     learn_embeddings: True\n00:02:00 |     learn_positional_embeddings: True\n00:02:00 |     learningrate: 5e-05\n00:02:00 |     load_from_pretrained_ranker: True\n00:02:00 |     log_every_n_secs: 10.0\n00:02:00 |     log_every_n_steps: 50\n00:02:00 |     log_keep_fields: all\n00:02:00 |     loglevel: info\n00:02:00 |     lr_scheduler: reduceonplateau\n00:02:00 |     lr_scheduler_decay: 0.5\n00:02:00 |     lr_scheduler_patience: 3\n00:02:00 |     max_train_steps: -1\n00:02:00 |     max_train_time: 7200.0\n00:02:00 |     memory_attention: sqrt\n00:02:00 |     metrics: default\n00:02:00 |     model: transformer/classifier\n00:02:00 |     model_file: /tmp/model1\n00:02:00 |     model_parallel: False\n00:02:00 |     momentum: 0\n00:02:00 |     multitask_weights: [1]\n00:02:00 |     mutators: None\n00:02:00 |     n_decoder_layers: -1\n00:02:00 |     n_encoder_layers: -1\n00:02:00 |     n_heads: 12\n00:02:00 |     n_layers: 12\n00:02:00 |     n_positions: 1024\n00:02:00 |     n_segments: 2\n00:02:00 |     nesterov: True\n00:02:00 |     no_cuda: False\n00:02:00 |     normalize_sent_emb: False\n00:02:00 |     num_epochs: -1\n00:02:00 |     num_examples: -1\n00:02:00 |     num_workers: 0\n00:02:00 |     nus: [0.7]\n00:02:00 |     optimizer: adamax\n00:02:00 |     output_scaling: 0.06\n00:02:00 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type2/run1/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model1', 'batchsize': 40}\"\n00:02:00 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n00:02:00 |     person_tokens: False\n00:02:00 |     print_scores: False\n00:02:00 |     rank_candidates: False\n00:02:00 |     rank_top_k: -1\n00:02:00 |     reduction_type: mean\n00:02:00 |     ref_class: None\n00:02:00 |     relu_dropout: 0.0\n00:02:00 |     repeat_blocking_heuristic: True\n00:02:00 |     report_filename: \n00:02:00 |     return_cand_scores: False\n00:02:00 |     save_after_valid: True\n00:02:00 |     save_every_n_secs: -1\n00:02:00 |     save_format: conversations\n00:02:00 |     share_encoders: False\n00:02:00 |     share_word_embeddings: False\n00:02:00 |     short_final_eval: False\n00:02:00 |     special_tok_lst: None\n00:02:00 |     split_lines: False\n00:02:00 |     starttime: Dec03_23-48\n00:02:00 |     task: fromfile:parlaiformat\n00:02:00 |     tensorboard_log: False\n00:02:00 |     tensorboard_logdir: None\n00:02:00 |     text_truncate: 360\n00:02:00 |     threshold: 0.5\n00:02:00 |     topk: 5\n00:02:00 |     train_predict: False\n00:02:00 |     truncate: 1024\n00:02:00 |     update_classifier_head_only: False\n00:02:00 |     update_freq: 1\n00:02:00 |     use_memories: False\n00:02:00 |     use_reply: none\n00:02:00 |     validation_cutoff: 1.0\n00:02:00 |     validation_every_n_epochs: -1\n00:02:00 |     validation_every_n_secs: 20.0\n00:02:00 |     validation_every_n_steps: -1\n00:02:00 |     validation_max_exs: -1\n00:02:00 |     validation_metric: accuracy\n00:02:00 |     validation_metric_mode: max\n00:02:00 |     validation_patience: 30\n00:02:00 |     validation_share_agent: False\n00:02:00 |     variant: xlm\n00:02:00 |     verbose: False\n00:02:00 |     wandb_entity: None\n00:02:00 |     wandb_log: False\n00:02:00 |     wandb_name: None\n00:02:00 |     wandb_project: None\n00:02:00 |     warmup_rate: 0.0001\n00:02:00 |     warmup_updates: 1000\n00:02:00 |     weight_decay: None\n00:02:00 |     world_logs: \n00:02:00 |     wrap_memory_encoder: False\n00:02:00 | Evaluating task fromfile:parlaiformat using datatype valid.\n00:02:00 | creating task(s): fromfile:parlaiformat\n00:02:00 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n00:02:00 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run1/data_test.txt\n00:02:08 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8990 8.99e-10               .6576                 .4974   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9700            .9408              .9963   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8911 12.07 562.9  1878       0          0 133.5 1000 .8990   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2605 1.01e-05   208   694       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    202 770.9 2572        .9124\u001b[0m\n00:02:08 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8990 8.99e-10               .6576                 .4974   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9700            .9408              .9963   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8911 12.07 562.9  1878       0          0 133.5 1000 .8990   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2605 1.01e-05   208   694       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    202 770.9 2572        .9124\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model1*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:02:10.062742Z","iopub.execute_input":"2022-12-04T00:02:10.063501Z","iopub.status.idle":"2022-12-04T00:02:11.281907Z","shell.execute_reply.started":"2022-12-04T00:02:10.063455Z","shell.execute_reply":"2022-12-04T00:02:11.280384Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"run 2","metadata":{}},{"cell_type":"code","source":"# run 2 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type2/run2/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model2","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:02:11.284469Z","iopub.execute_input":"2022-12-04T00:02:11.284947Z","iopub.status.idle":"2022-12-04T00:14:58.908424Z","shell.execute_reply.started":"2022-12-04T00:02:11.284875Z","shell.execute_reply":"2022-12-04T00:14:58.907274Z"},"scrolled":true,"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"00:02:18 | building dictionary first...\n00:02:18 | No model with opt yet at: /tmp/model2(.opt)\n00:02:18 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run2/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n00:02:18 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n00:02:18 | Using CUDA\n00:02:18 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n00:02:18 | num words = 54944\n00:02:23 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:02:33 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:02:33 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n00:02:33 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n00:02:33 | Opt:\n00:02:33 |     activation: gelu\n00:02:33 |     adafactor_eps: '(1e-30, 0.001)'\n00:02:33 |     adam_eps: 1e-08\n00:02:33 |     add_p1_after_newln: False\n00:02:33 |     aggregate_micro: False\n00:02:33 |     allow_missing_init_opts: False\n00:02:33 |     attention_dropout: 0.1\n00:02:33 |     batchsize: 20\n00:02:33 |     betas: '(0.9, 0.999)'\n00:02:33 |     bpe_add_prefix_space: None\n00:02:33 |     bpe_debug: False\n00:02:33 |     bpe_dropout: None\n00:02:33 |     bpe_merge: None\n00:02:33 |     bpe_vocab: None\n00:02:33 |     candidates: inline\n00:02:33 |     cap_num_predictions: 100\n00:02:33 |     checkpoint_activations: False\n00:02:33 |     class_weights: None\n00:02:33 |     classes: \"['__notok__', '__ok__']\"\n00:02:33 |     classes_from_file: None\n00:02:33 |     data_parallel: True\n00:02:33 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n00:02:33 |     datatype: train\n00:02:33 |     delimiter: '\\n'\n00:02:33 |     dict_class: parlai.core.dict:DictionaryAgent\n00:02:33 |     dict_endtoken: __start__\n00:02:33 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n00:02:33 |     dict_include_test: False\n00:02:33 |     dict_include_valid: False\n00:02:33 |     dict_initpath: None\n00:02:33 |     dict_language: english\n00:02:33 |     dict_loaded: True\n00:02:33 |     dict_lower: True\n00:02:33 |     dict_max_ngram_size: -1\n00:02:33 |     dict_maxexs: -1\n00:02:33 |     dict_maxtokens: -1\n00:02:33 |     dict_minfreq: 0\n00:02:33 |     dict_nulltoken: __null__\n00:02:33 |     dict_starttoken: __start__\n00:02:33 |     dict_textfields: text,labels\n00:02:33 |     dict_tokenizer: bpe\n00:02:33 |     dict_unktoken: __unk__\n00:02:33 |     display_examples: False\n00:02:33 |     download_path: None\n00:02:33 |     dropout: 0.1\n00:02:33 |     dynamic_batching: None\n00:02:33 |     embedding_projection: random\n00:02:33 |     embedding_size: 768\n00:02:33 |     embedding_type: random\n00:02:33 |     embeddings_scale: False\n00:02:33 |     encode_candidate_vecs: True\n00:02:33 |     encode_candidate_vecs_batchsize: 256\n00:02:33 |     eval_batchsize: None\n00:02:33 |     eval_candidates: inline\n00:02:33 |     eval_dynamic_batching: None\n00:02:33 |     evaltask: None\n00:02:33 |     ffn_size: 3072\n00:02:33 |     final_extra_opt: \n00:02:33 |     fixed_candidate_vecs: reuse\n00:02:33 |     fixed_candidates_path: None\n00:02:33 |     force_fp16_tokens: False\n00:02:33 |     fp16: True\n00:02:33 |     fp16_impl: safe\n00:02:33 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run2/data\n00:02:33 |     fromfile_datatype_extension: True\n00:02:33 |     gpu: -1\n00:02:33 |     gradient_clip: 0.1\n00:02:33 |     hide_labels: False\n00:02:33 |     history_add_global_end_token: None\n00:02:33 |     history_reversed: False\n00:02:33 |     history_size: 20\n00:02:33 |     ignore_bad_candidates: False\n00:02:33 |     ignore_labels: None\n00:02:33 |     image_cropsize: 224\n00:02:33 |     image_mode: raw\n00:02:33 |     image_size: 256\n00:02:33 |     inference: max\n00:02:33 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:02:33 |     init_opt: None\n00:02:33 |     interactive_candidates: fixed\n00:02:33 |     interactive_mode: False\n00:02:33 |     invsqrt_lr_decay_gamma: -1\n00:02:33 |     is_debug: False\n00:02:33 |     label_truncate: 72\n00:02:33 |     learn_embeddings: True\n00:02:33 |     learn_positional_embeddings: True\n00:02:33 |     learningrate: 5e-05\n00:02:33 |     load_from_checkpoint: False\n00:02:33 |     load_from_pretrained_ranker: True\n00:02:33 |     log_every_n_secs: 10.0\n00:02:33 |     log_every_n_steps: 50\n00:02:33 |     log_keep_fields: all\n00:02:33 |     loglevel: info\n00:02:33 |     lr_scheduler: reduceonplateau\n00:02:33 |     lr_scheduler_decay: 0.5\n00:02:33 |     lr_scheduler_patience: 3\n00:02:33 |     max_train_steps: -1\n00:02:33 |     max_train_time: 7200.0\n00:02:33 |     memory_attention: sqrt\n00:02:33 |     metrics: default\n00:02:33 |     model: transformer/classifier\n00:02:33 |     model_file: /tmp/model2\n00:02:33 |     model_parallel: False\n00:02:33 |     momentum: 0\n00:02:33 |     multitask_weights: [1]\n00:02:33 |     mutators: None\n00:02:33 |     n_decoder_layers: -1\n00:02:33 |     n_encoder_layers: -1\n00:02:33 |     n_heads: 12\n00:02:33 |     n_layers: 12\n00:02:33 |     n_positions: 1024\n00:02:33 |     n_segments: 2\n00:02:33 |     nesterov: True\n00:02:33 |     no_cuda: False\n00:02:33 |     normalize_sent_emb: False\n00:02:33 |     num_epochs: -1\n00:02:33 |     num_workers: 0\n00:02:33 |     nus: (0.7,)\n00:02:33 |     optimizer: adamax\n00:02:33 |     output_scaling: 0.06\n00:02:33 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type2/run2/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model2'}\"\n00:02:33 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n00:02:33 |     person_tokens: False\n00:02:33 |     print_scores: False\n00:02:33 |     rank_candidates: False\n00:02:33 |     rank_top_k: -1\n00:02:33 |     reduction_type: mean\n00:02:33 |     ref_class: None\n00:02:33 |     relu_dropout: 0.0\n00:02:33 |     repeat_blocking_heuristic: True\n00:02:33 |     return_cand_scores: False\n00:02:33 |     save_after_valid: True\n00:02:33 |     save_every_n_secs: -1\n00:02:33 |     save_format: conversations\n00:02:33 |     share_encoders: False\n00:02:33 |     share_word_embeddings: False\n00:02:33 |     short_final_eval: False\n00:02:33 |     special_tok_lst: None\n00:02:33 |     split_lines: False\n00:02:33 |     starttime: Dec04_00-02\n00:02:33 |     task: fromfile:parlaiformat\n00:02:33 |     tensorboard_log: False\n00:02:33 |     tensorboard_logdir: None\n00:02:33 |     text_truncate: 360\n00:02:33 |     threshold: 0.5\n00:02:33 |     topk: 5\n00:02:33 |     train_predict: False\n00:02:33 |     truncate: 1024\n00:02:33 |     update_classifier_head_only: False\n00:02:33 |     update_freq: 1\n00:02:33 |     use_memories: False\n00:02:33 |     use_reply: none\n00:02:33 |     validation_cutoff: 1.0\n00:02:33 |     validation_every_n_epochs: -1\n00:02:33 |     validation_every_n_secs: 20.0\n00:02:33 |     validation_every_n_steps: -1\n00:02:33 |     validation_max_exs: -1\n00:02:33 |     validation_metric: accuracy\n00:02:33 |     validation_metric_mode: max\n00:02:33 |     validation_patience: 30\n00:02:33 |     validation_share_agent: False\n00:02:33 |     variant: xlm\n00:02:33 |     verbose: False\n00:02:33 |     wandb_entity: None\n00:02:33 |     wandb_log: False\n00:02:33 |     wandb_name: None\n00:02:33 |     wandb_project: None\n00:02:33 |     warmup_rate: 0.0001\n00:02:33 |     warmup_updates: 1000\n00:02:33 |     weight_decay: None\n00:02:33 |     world_logs: \n00:02:33 |     wrap_memory_encoder: False\n00:02:33 | creating task(s): fromfile:parlaiformat\n00:02:33 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run2/data_train.txt\n00:02:34 | training...\n00:02:44 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .4675 4.675e-10               .5943                 .4845   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7685            .2255              .3974   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .1574 11.54     1 270.9 541.7       0          0 39.99  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .4675             32768  2.454    .1206 6.015 .7015 1.005e-06 120.3 240.6   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 391.2 782.3 2.004        .4126\n\n00:02:54 | time:20s total_exs:1160 total_steps:58 epochs:5.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5829 5.829e-10               .6694                 .5544   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8447            .4349              .6740   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .3211 11.58     1 271.6  1040       0          0 76.59  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5829             32768  2.427    .1207     6 .6772 2.905e-06   120 459.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   58 391.6 1500 3.838        .5522\n\n00:02:54 | creating task(s): fromfile:parlaiformat\n00:02:54 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run2/data_valid.txt\n00:02:54 | running eval: valid\n00:02:54 | eval completed in 0.20s\n00:02:54 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5833 5.833e-10               .6667                 .5556   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .4444              .6667   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .3333    11   156  1704       0          0   131   24 .5833   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6761 2.905e-06    72 786.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                     58  228 2490        .5556\n\u001b[0m\n00:02:54 | \u001b[1;32mnew best accuracy: 0.5833\u001b[0m\n00:02:54 | saving best valid model: /tmp/model2\n00:02:54 | Saving dictionary to /tmp/model2.dict\n00:02:58 | saving model checkpoint: /tmp/model2.checkpoint\n00:02:58 | Saving dictionary to /tmp/model2.checkpoint.dict\n00:03:15 | time:42s total_exs:1880 total_steps:94 epochs:9.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7847 7.847e-10               .8153                 .7566   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8837            .7421              .8321   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6697 11.67     1 273.3 975.6       0          0 71.38  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7847             32768  2.576    .1207 6.075 .6346 4.705e-06 121.5 433.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   94 394.8 1409 3.577        .7814\n\n00:03:19 | time:45s total_exs:2140 total_steps:107 epochs:10.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8346 8.346e-10               .8502                 .7531   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9760            .8155              .9694   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7037 11.35     1   267  1037       0          0 77.67  260   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8346             32768  3.043    .1207 5.962 .5812 5.354e-06 119.2   463   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  107 386.2 1500 3.91        .8321\n\n00:03:19 | running eval: valid\n00:03:19 | eval completed in 0.20s\n00:03:19 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8148                 .7333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .7619              .8889   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .6667    11   156  1698       0          0 130.6   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5997 5.354e-06    72 783.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    107  228 2481        .7884\n\u001b[0m\n00:03:19 | \u001b[1;32mnew best accuracy: 0.7917 (previous best was 0.5833)\u001b[0m\n00:03:19 | saving best valid model: /tmp/model2\n00:03:28 | saving model checkpoint: /tmp/model2.checkpoint\n00:03:43 | time:70s total_exs:2900 total_steps:145 epochs:14.50\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8784                 .8596   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8979            .8714              .8920   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8519 11.81     1 276.2  1048       0          0  75.9  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8750             32768  3.569    .1207 6.005 .4976 7.254e-06 120.1 455.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  145 396.3 1504 3.804        .8749\n\n00:03:48 | time:75s total_exs:3260 total_steps:163 epochs:16.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9139 9.139e-10               .9146                 .9022   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9274            .9132              .9261   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9006  11.8     1   276  1044       0          0 75.65  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9139             32768  4.493    .1207 5.994 .3324 8.154e-06 119.9 453.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  163 395.9 1497  3.8        .9139\n\n00:03:48 | running eval: valid\n00:03:48 | eval completed in 0.20s\n00:03:48 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8462                 .7857   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8182              .9000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1715       0          0 131.9   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .3664 8.154e-06    72 791.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    163  228 2507        .8322\n\u001b[0m\n00:03:48 | \u001b[1;32mnew best accuracy: 0.8333 (previous best was 0.7917)\u001b[0m\n00:03:48 | saving best valid model: /tmp/model2\n00:03:53 | saving model checkpoint: /tmp/model2.checkpoint\n00:04:13 | time:99s total_exs:4020 total_steps:201 epochs:20.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9276 9.276e-10               .9318                 .9082   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9567            .9229              .9509   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8965 11.73     1 274.6  1040       0          0 75.74  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9276             32768  5.687    .1207 6.034 .2520 1.005e-05 120.7 457.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  201 395.3 1497 3.796        .9275\n\n00:04:13 | time:100s total_exs:4060 total_steps:203 epochs:20.30\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9750 9.75e-10               .9744                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9756              .9524   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.38     1 267.5  1055       0          0  78.9   40   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9750             32768  6.575    .1207     6 .1019 1.015e-05   120 473.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  203 387.5 1529 4.129        .9750\n\n00:04:13 | running eval: valid\n00:04:14 | eval completed in 0.20s\n00:04:14 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1699       0          0 130.7   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .2753 1.015e-05    72 784.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    203  228 2483        .8748\n\u001b[0m\n00:04:14 | \u001b[1;32mnew best accuracy: 0.875 (previous best was 0.8333)\u001b[0m\n00:04:14 | saving best valid model: /tmp/model2\n00:04:23 | saving model checkpoint: /tmp/model2.checkpoint\n00:04:38 | time:125s total_exs:4820 total_steps:241 epochs:24.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9408 9.408e-10               .9406                 .9295   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9519            .9410              .9523   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9301 11.89     1 277.8  1030       0          0 74.16  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9408             32768  6.107    .1207 5.984 .1805 1.205e-05 119.7 443.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  241 397.4 1474 3.716        .9408\n\n00:04:43 | time:130s total_exs:5180 total_steps:259 epochs:25.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9444 9.444e-10               .9342                 .9281   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9404            .9519              .9565   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9474 11.51     1 270.2  1022       0          0 75.64  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9444             32768  13.04    .1207 5.839 .1647 1.295e-05 116.8 441.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  259 386.9 1463  3.8        .9445\n\n00:04:43 | running eval: valid\n00:04:43 | eval completed in 0.20s\n00:04:43 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1674       0          0 128.7   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .3493 1.295e-05    72 772.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    259  228 2447        .8748\n\u001b[0m\n00:04:43 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 1\u001b[0m\n00:04:43 | saving model checkpoint: /tmp/model2.checkpoint\n00:04:59 | time:145s total_exs:5940 total_steps:297 epochs:29.70\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9750 9.75e-10               .9741                 .9755   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9728            .9758              .9746   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9770 11.64     1 272.8  1020       0          0 74.78  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9750             32768  8.571    .1207 5.968 .08299 1.485e-05 119.4 446.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  297 392.2 1466 3.747        .9750\n\n00:05:04 | time:150s total_exs:6300 total_steps:315 epochs:31.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9778 9.778e-10               .9766                 .9709   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9824            .9788              .9840   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9737 11.16     1 263.2 994.1       0          0 75.55  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9778             32768  7.571    .1207 5.944 .07153 1.575e-05 118.9 449.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  315 382.1 1443 3.795        .9778\n\n00:05:04 | running eval: valid\n00:05:04 | eval completed in 0.21s\n00:05:04 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8462                 .7857   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8182              .9000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1646       0          0 126.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .6389 1.575e-05    72 759.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    315  228 2405        .8322\n\u001b[0m\n00:05:04 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 2\u001b[0m\n00:05:04 | saving model checkpoint: /tmp/model2.checkpoint\n00:05:19 | time:165s total_exs:7060 total_steps:353 epochs:35.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9855 9.855e-10               .9858                 .9948   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9770            .9852              .9760   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9946 11.69 .5789 273.8  1038       0          0 75.82  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9855             32768  6.032    .1207 6.032 .0687 1.765e-05 120.6 457.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  353 394.4 1495  3.8        .9855\n\n00:05:24 | time:170s total_exs:7460 total_steps:373 epochs:37.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9800 9.8e-10               .9803                 .9851   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9755            .9797              .9747   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9847 11.74 .5500 274.9  1043       0          0 75.87  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9800             32768  20.34    .1207  6.02 .07544 1.865e-05 120.4 456.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  373 395.2 1499 3.809        .9800\n\n00:05:24 | running eval: valid\n00:05:24 | eval completed in 0.23s\n00:05:24 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8000                 .7692   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7826              .8182   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1559       0          0 119.9   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08095     6 1.098 1.865e-05    72 719.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    373  228 2278        .7913\n\u001b[0m\n00:05:24 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 3\u001b[0m\n00:05:24 | saving model checkpoint: /tmp/model2.checkpoint\n00:05:39 | time:185s total_exs:8220 total_steps:411 epochs:41.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9961 9.961e-10               .9956                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9913            .9964              .9929   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.67 .1316 273.4  1017       0          0 74.39  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9961             32768  .3641    .1207 5.903 .01284 2.055e-05 118.1 439.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  411 391.5 1456 3.728        .9961\n\n00:05:44 | time:191s total_exs:8640 total_steps:432 epochs:43.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9952 9.952e-10               .9954                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9908            .9951              .9902   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.62 .2381 272.4  1031       0          0 75.69  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9952             32768  .7229    .1207 6.038 .02999 2.16e-05 120.8   457   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  432 393.1 1488  3.8        .9952\n\n00:05:44 | running eval: valid\n00:05:44 | eval completed in 0.20s\n00:05:44 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8462                 .7857   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8182              .9000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1698       0          0 130.6   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 1.129 2.16e-05    72 783.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    432  228 2482        .8322\n\u001b[0m\n00:05:44 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 4\u001b[0m\n00:05:44 | saving model checkpoint: /tmp/model2.checkpoint\n00:05:59 | time:205s total_exs:9400 total_steps:470 epochs:47.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9961 9.961e-10               .9958                 .9972   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9944            .9963              .9951   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9975  11.8 .2632 276.1  1039       0          0 75.26  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9961             32768  1.938    .1207 5.934 .0260 2.35e-05 118.7 446.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  470 394.7 1485 3.771        .9961\n\n00:06:05 | time:211s total_exs:9840 total_steps:492 epochs:49.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9909 9.909e-10               .9913                 .9913   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9913            .9905              .9905   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9905    12 .1818   280  1076       0          0 76.82  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9909             32768  11.21    .1207 6.041 .02396 2.46e-05 120.8   464   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  492 400.9 1540 3.856        .9909\n\n00:06:05 | running eval: valid\n00:06:05 | eval completed in 0.20s\n00:06:05 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8462                 .7857   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8182              .9000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1686       0          0 129.6   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 .9962 2.46e-05    72   778       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    492  228 2464        .8322\n\u001b[0m\n00:06:05 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 5\u001b[0m\n00:06:05 | saving model checkpoint: /tmp/model2.checkpoint\n00:06:20 | time:226s total_exs:10600 total_steps:530 epochs:53.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9974 9.974e-10               .9974                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9949            .9973              .9946   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71 .1842 274.1  1041       0          0 75.94  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9974             32768  .4117    .1207 6.029 .01501 2.65e-05 120.6 457.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  530 394.7 1499 3.806        .9974\n\n00:06:25 | time:232s total_exs:11000 total_steps:550 epochs:55.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.66     0 273.2  1048       0          0 76.71  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .01381    .1207  6.02 .000959 2.75e-05 120.4 461.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  550 393.6 1510 3.852            1\n\n00:06:25 | running eval: valid\n00:06:25 | eval completed in 0.20s\n00:06:25 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8000                 .7692   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7826              .8182   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1727       0          0 132.8   24 .7917   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 1.083 2.75e-05    72   797       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    550  228 2524        .7913\n\u001b[0m\n00:06:25 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 6\u001b[0m\n00:06:25 | saving model checkpoint: /tmp/model2.checkpoint\n00:06:41 | time:247s total_exs:11760 total_steps:588 epochs:58.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9947 9.947e-10               .9949                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9899            .9945              .9891   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.7 .1316 274.1  1041       0          0 75.97  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9947             32768  .4193    .1208 6.042 .02703 2.94e-05 120.8   459   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  588 394.9 1500 3.807        .9947\n\n00:06:45 | time:252s total_exs:12100 total_steps:605 epochs:60.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9882 9.882e-10               .9866                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9735            .9895              .9793   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.81 .3529 276.2   968       0          0  70.1  340   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9882             32768  1.117    .1208 5.888 .02243 3.025e-05 117.8 412.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  605 393.9 1381 3.522        .9882\n\n00:06:45 | running eval: valid\n00:06:46 | eval completed in 0.21s\n00:06:46 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1666       0          0 128.1   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 .8782 3.025e-05    72   769       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    605  228 2435        .8748\n\u001b[0m\n00:06:46 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 7\u001b[0m\n00:06:46 | saving model checkpoint: /tmp/model2.checkpoint\n00:07:00 | time:266s total_exs:12860 total_steps:643 epochs:64.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9961 9.961e-10               .9959                 .9919   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9962                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9923 11.83 .1053 276.6  1045       0          0 75.56  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9961             32768  .2267    .1208 5.968 .01914 3.215e-05 119.4 450.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  643 395.9 1496 3.786        .9961\n\n00:07:06 | time:272s total_exs:13300 total_steps:665 epochs:66.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9932 9.932e-10               .9931                 .9864   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9932                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9865 11.58 .1818 271.7  1026       0          0 75.54  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9932             32768  .3175    .1208 5.986 .01854 3.325e-05 119.7 452.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  665 391.4 1478 3.791        .9932\n\n00:07:06 | running eval: valid\n00:07:06 | eval completed in 0.20s\n00:07:06 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1731       0          0 133.1   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 1.179 3.325e-05    72 798.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    665  228 2530        .7913\n\u001b[0m\n00:07:06 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 8\u001b[0m\n00:07:06 | saving model checkpoint: /tmp/model2.checkpoint\n00:07:21 | time:287s total_exs:14060 total_steps:703 epochs:70.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9934 9.934e-10               .9935                 .9948   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9922            .9934              .9921   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9947 11.77 .1842 275.4  1023       0          0 74.33  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9934             32768  .2097    .1208 6.008 .0112 3.515e-05 120.2 446.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  703 395.5 1470 3.725        .9934\n\n00:07:26 | time:293s total_exs:14480 total_steps:724 epochs:72.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9929 9.929e-10               .9930                 .9953   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9907            .9927              .9903   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9951 11.79 .1905 275.7  1036       0          0 75.14  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9929             32768  11.54    .1208 6.024 .02139 3.62e-05 120.5 452.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  724 396.2 1489 3.772        .9929\n\n00:07:26 | running eval: valid\n00:07:26 | eval completed in 0.20s\n00:07:26 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1704       0          0   131   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 1.217 3.62e-05    72 786.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    724  228 2490        .8322\n\u001b[0m\n00:07:26 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 9\u001b[0m\n00:07:26 | saving model checkpoint: /tmp/model2.checkpoint\n00:07:41 | time:307s total_exs:15240 total_steps:762 epochs:76.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9947 9.947e-10               .9944                 .9944   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9944            .9951              .9951   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9951 11.61 .1579 272.2  1031       0          0 75.76  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9947             32768  .1234    .1208 5.934 .00832 3.81e-05 118.7 449.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  762 390.9 1481 3.797        .9947\n\n00:07:47 | time:313s total_exs:15660 total_steps:783 epochs:78.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9976 9.976e-10               .9977                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9953            .9976              .9952   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.76 .1905 275.2  1016       0          0 73.87  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9976             32768 .09676    .1208 6.019 .008447 3.915e-05 120.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   444.6       0          0                  783 395.6 1461 3.708        .9976\n\n00:07:47 | running eval: valid\n00:07:47 | eval completed in 0.22s\n00:07:47 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7826                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8000              .7692   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1586       0          0   122   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6  1.43 3.915e-05    72 731.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    783  228 2318        .7913\n\u001b[0m\n00:07:47 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 10\u001b[0m\n00:07:47 | saving model checkpoint: /tmp/model2.checkpoint\n00:08:01 | time:328s total_exs:16420 total_steps:821 epochs:82.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9987                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9974            .9987              .9973   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.76 .02632 275.2  1039       0          0  75.5   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    760 .9987             32768 .04026    .1208 6.018 .006545 4.105e-05 120.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   454.4       0          0                  821 395.6 1493 3.784        .9987\n\n00:08:07 | time:333s total_exs:16840 total_steps:842 epochs:84.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9952 9.952e-10               .9954                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9909            .9950              .9901   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.75 .09524 275.1  1064       0          0 77.36   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  \\\n    420 .9952             32768  .1106    .1208 6.043 .01853 4.21e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   467.5       0          0                  842  396 1532 3.884        .9952\n\n00:08:07 | running eval: valid\n00:08:07 | eval completed in 0.20s\n00:08:07 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1732       0          0 133.2   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 .9795 4.21e-05    72 799.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    842  228 2531        .8748\n\u001b[0m\n00:08:07 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 11\u001b[0m\n00:08:07 | saving model checkpoint: /tmp/model2.checkpoint\n00:08:22 | time:348s total_exs:17580 total_steps:879 epochs:87.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9986 9.986e-10               .9986                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9971            .9987              .9975   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.94 .02703 278.8  1032       0          0 74.02   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    740 .9986             32768 .03764    .1208 5.935 .004934 4.395e-05 118.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   439.3       0          0                  879 397.5 1471 3.709        .9986\n\n00:08:27 | time:354s total_exs:18000 total_steps:900 epochs:90.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9881 9.881e-10               .9881                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9765            .9881              .9764   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.74 .1905 274.9  1056       0          0 76.84  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss      lr  ltpb  ltps  \\\n   .9881             32768  .2261    .1208 6.014 .04096 4.5e-05 120.3 462.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  900 395.1 1518 3.858        .9881\n\n00:08:27 | running eval: valid\n00:08:27 | eval completed in 0.21s\n00:08:27 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1680       0          0 129.2   24 .8333   \n    gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6  1.17 4.5e-05    72 775.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    900  228 2456        .8333\n\u001b[0m\n00:08:27 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 12\u001b[0m\n00:08:27 | saving model checkpoint: /tmp/model2.checkpoint\n00:08:42 | time:368s total_exs:18780 total_steps:939 epochs:93.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9962 9.962e-10               .9958                 .9972   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9944            .9964              .9953   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9976 11.52 .1026 270.4  1033       0          0 76.37  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9962             32768   11.3    .1208 5.921 .02126 4.695e-05 118.4 452.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  939 388.8 1485 3.827        .9962\n\n00:08:47 | time:374s total_exs:19180 total_steps:959 epochs:95.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9975 9.975e-10               .9973                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9947            .9977              .9953   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.61 .0500 272.1  1036       0          0 76.13  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9975             32768 .04948    .1208 5.935 .01039 4.795e-05 118.7 451.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  959 390.9 1488 3.824        .9975\n\n00:08:47 | running eval: valid\n00:08:48 | eval completed in 0.23s\n00:08:48 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1500       0          0 115.4   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6 1.269 4.795e-05    72 692.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    959  228 2193        .8333\n\u001b[0m\n00:08:48 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 13\u001b[0m\n00:08:48 | saving model checkpoint: /tmp/model2.checkpoint\n00:09:02 | time:389s total_exs:19940 total_steps:997 epochs:99.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9974 9.974e-10               .9973                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9946            .9974              .9949   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.72 .05263 274.4  1039       0          0 75.69   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    760 .9974             32768 .05879    .1208 5.982 .008665 4.985e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   452.7       0          0                  997 394.1 1491 3.793        .9974\n\n00:09:08 | time:394s total_exs:20360 total_steps:1018 epochs:101.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9952 9.952e-10               .9950                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9901            .9954              .9909   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.55 .2381 271.1  1018       0          0 75.13  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9952             32768  .1293    .1208 5.967 .01381 4.995e-05 119.3 448.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1018 390.4 1467 3.772        .9952\n\n00:09:08 | running eval: valid\n00:09:08 | eval completed in 0.20s\n00:09:08 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1701       0          0 130.8   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 1.205 4.995e-05    72 784.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1018  228 2486        .8322\n\u001b[0m\n00:09:08 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 14\u001b[0m\n00:09:08 | saving model checkpoint: /tmp/model2.checkpoint\n00:09:22 | time:409s total_exs:21100 total_steps:1055 epochs:105.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9946 9.946e-10               .9944                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9889            .9948              .9896   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.71 .08108 274.2  1011       0          0 73.72   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  \\\n    740 .9946             32768  .1149    .1208 5.976 .01607 4.995e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   440.5       0          0                 1055 393.7 1451 3.694        .9946\n\n00:09:28 | time:414s total_exs:21520 total_steps:1076 epochs:107.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9905 9.905e-10               .9911                 .9955   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9867            .9898              .9848   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9949 11.45 .1905   269  1012       0          0 75.25  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9905             32768  .4058    .1208 6.071 .01914 4.995e-05 121.4 456.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1076 390.4 1469 3.778        .9905\n\n00:09:28 | running eval: valid\n00:09:28 | eval completed in 0.20s\n00:09:28 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1678       0          0   129   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 1.305 4.995e-05    72 774.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1076  228 2452        .8322\n\u001b[0m\n00:09:28 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 15\u001b[0m\n00:09:28 | saving model checkpoint: /tmp/model2.checkpoint\n00:09:43 | time:429s total_exs:22280 total_steps:1114 epochs:111.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9868 9.868e-10               .9868                 .9947   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9790            .9869              .9792   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9947 11.93 .3158 278.6  1046       0          0  75.1  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9868             32768  26.11    .1209 6.003 .0477 4.995e-05 120.1 450.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1114 398.7 1497 3.763        .9868\n\n00:09:48 | time:435s total_exs:22720 total_steps:1136 epochs:113.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9955 9.955e-10               .9954                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9908            .9955              .9911   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.43 .1818 268.6  1020       0          0 75.97  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9955             32768  .1188    .1209 5.986 .01086 4.995e-05 119.7 454.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1136 388.4 1475 3.813        .9955\n\n00:09:48 | running eval: valid\n00:09:49 | eval completed in 0.21s\n00:09:49 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1669       0          0 128.3   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 1.277 4.995e-05    72 770.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1136  228 2440        .8333\n\u001b[0m\n00:09:49 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 16\u001b[0m\n00:09:49 | saving model checkpoint: /tmp/model2.checkpoint\n00:10:03 | time:450s total_exs:23480 total_steps:1174 epochs:117.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9986                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9973            .9987              .9974   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.69 .07895 273.9  1034       0          0  75.5   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  \\\n    760 .9987             32768 .03699    .1209 5.971 .00311 4.995e-05 119.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   450.8       0          0                 1174 393.3 1485 3.784        .9987\n\n00:10:09 | time:455s total_exs:23900 total_steps:1195 epochs:119.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9976 9.976e-10               .9975                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9951            .9977              .9954   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.82 .09524 276.5  1070       0          0 77.43   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    420 .9976             32768 .05138    .1209 5.967 .005948 4.995e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     462       0          0                 1195 395.8 1532 3.888        .9976\n\n00:10:09 | running eval: valid\n00:10:09 | eval completed in 0.20s\n00:10:09 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1698       0          0 130.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6 1.374 4.995e-05    72 783.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1195  228 2482        .8333\n\u001b[0m\n00:10:09 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 17\u001b[0m\n00:10:09 | saving model checkpoint: /tmp/model2.checkpoint\n00:10:28 | time:475s total_exs:24640 total_steps:1232 epochs:123.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9946 9.946e-10               .9945                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9891            .9947              .9894   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.96 .1622 279.1  1031       0          0 73.89  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9946             32768  .1100    .1209 5.992 .01464 4.995e-05 119.8 442.7   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1232  399 1474 3.703        .9946\n\n00:10:29 | time:476s total_exs:24700 total_steps:1235 epochs:123.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.53     0 290.7  1116       0          0 76.75   60   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003992    .1209 5.967 .0003279 4.995e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n     458       0          0                 1235  410 1574 3.953            1\n\n00:10:29 | running eval: valid\n00:10:29 | eval completed in 0.21s\n00:10:29 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1644       0          0 126.4   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6  1.36 4.995e-05    72 758.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1235  228 2403        .8333\n\u001b[0m\nEpoch 00005: reducing learning rate of group 0 to 2.4975e-05.\n00:10:29 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 18\u001b[0m\n00:10:29 | saving model checkpoint: /tmp/model2.checkpoint\n00:10:44 | time:490s total_exs:25460 total_steps:1273 epochs:127.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9908 9.908e-10               .9910                 .9923   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9897            .9906              .9892   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9919 11.81 .2105 276.1  1042       0          0 75.48  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9908             32768  16.29    .1209 6.026 .02128 2.498e-05 120.5 454.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1273 396.7 1497 3.783        .9908\n\n00:10:49 | time:496s total_exs:25880 total_steps:1294 epochs:129.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9952 9.952e-10               .9950                 .9901   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9954                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9909 11.75 .1905 274.9  1057       0          0  76.9  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9952             32768  .1014    .1209 5.952 .007432 2.498e-05   119   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   457.8       0          0                 1294  394 1515 3.861        .9952\n\n00:10:49 | running eval: valid\n00:10:50 | eval completed in 0.21s\n00:10:50 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1662       0          0 127.8   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 1.372 2.498e-05    72 766.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1294  228 2429        .8333\n\u001b[0m\n00:10:50 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 19\u001b[0m\n00:10:50 | saving model checkpoint: /tmp/model2.checkpoint\n00:11:05 | time:511s total_exs:26640 total_steps:1332 epochs:133.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9987                 .9973   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9987                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9974 11.53 .1842 270.7  1016       0          0  75.1  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9987             32768 .06604    .1209 5.987 .004499 2.498e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.6       0          0                 1332 390.4 1466 3.767        .9987\n\n00:11:10 | time:516s total_exs:27020 total_steps:1351 epochs:135.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9921 9.921e-10               .9925                 .9851   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9917                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9835  11.8 .2105 275.9  1047       0          0 75.91  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9921             32768  .1907    .1209 6.042 .02083 2.498e-05 120.8 458.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1351 396.8 1506 3.813        .9921\n\n00:11:10 | running eval: valid\n00:11:10 | eval completed in 0.20s\n00:11:10 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1682       0          0 129.3   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 1.386 2.498e-05    72 776.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1351  228 2458        .8333\n\u001b[0m\n00:11:10 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 20\u001b[0m\n00:11:10 | saving model checkpoint: /tmp/model2.checkpoint\n00:11:25 | time:531s total_exs:27780 total_steps:1389 epochs:138.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9961 9.961e-10               .9961                 .9923   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9960                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9920 11.82 .1053 276.3  1039       0          0 75.19  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9961             32768 .07825    .1209 6.016 .007908 2.498e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   452.3       0          0                 1389 396.7 1491 3.768        .9961\n\n00:11:30 | time:536s total_exs:28140 total_steps:1407 epochs:140.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.38 .05556 267.6 947.8       0          0 70.85   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    360   1             32768 .01899    .1209 6.067 .001229 2.498e-05 121.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   429.8       0          0                 1407 388.9 1378 3.559            1\n\n00:11:30 | running eval: valid\n00:11:30 | eval completed in 0.21s\n00:11:30 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1641       0          0 126.2   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6 1.387 2.498e-05    72 757.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1407  228 2398        .8333\n\u001b[0m\n00:11:30 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 21\u001b[0m\n00:11:30 | saving model checkpoint: /tmp/model2.checkpoint\n00:11:45 | time:551s total_exs:28900 total_steps:1445 epochs:144.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9895 9.895e-10               .9893                 .9840   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9946            .9896              .9948   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9845 11.77 .2632 275.5  1034       0          0 75.06  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9895             32768  .1451    .1209 5.979 .01371 2.498e-05 119.6 448.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1445 395.1 1483 3.762        .9895\n\n00:11:50 | time:557s total_exs:29320 total_steps:1466 epochs:146.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9929 9.929e-10               .9926                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9854            .9931              .9862   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.86 .2857 277.2  1035       0          0 74.67  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9929             32768  .1348    .1209 5.976 .0108 2.498e-05 119.5 446.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1466 396.8 1481 3.749        .9929\n\n00:11:50 | running eval: valid\n00:11:51 | eval completed in 0.20s\n00:11:51 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1700       0          0 130.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 1.396 2.498e-05    72 784.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1466  228 2484        .8333\n\u001b[0m\nEpoch 00009: reducing learning rate of group 0 to 1.2488e-05.\n00:11:51 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 22\u001b[0m\n00:11:51 | saving model checkpoint: /tmp/model2.checkpoint\n00:12:05 | time:572s total_exs:30080 total_steps:1504 epochs:150.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9974 9.974e-10               .9972                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9944            .9975              .9951   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.57 .2105 271.4  1009       0          0 74.33  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9974             32768 .09126    .1209 5.934 .006914 1.249e-05 118.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   441.1       0          0                 1504 390.1 1450 3.725        .9974\n\n00:12:11 | time:577s total_exs:30500 total_steps:1525 epochs:152.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.5 .1429 270.1  1035       0          0 76.64  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .03121    .1209  6.01 .002009 1.249e-05 120.2 460.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1525 390.3 1496 3.848            1\n\n00:12:11 | running eval: valid\n00:12:11 | eval completed in 0.24s\n00:12:11 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1449       0          0 111.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 1.381 1.249e-05    72 668.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1525  228 2118        .8333\n\u001b[0m\n00:12:11 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 23\u001b[0m\n00:12:11 | saving model checkpoint: /tmp/model2.checkpoint\n00:12:25 | time:592s total_exs:31260 total_steps:1563 epochs:156.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9921 9.921e-10               .9922                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9845            .9920              .9842   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.47 .1842 269.5  1015       0          0 75.35  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9921             32768  .1514    .1209 6.016 .02108 1.249e-05 120.3 453.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1563 389.8 1469 3.776        .9921\n\n00:12:31 | time:598s total_exs:31680 total_steps:1584 epochs:158.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9881 9.881e-10               .9873                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9750            .9888              .9778   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.63 .2857 272.5  1002       0          0 73.54  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9881             32768  .2035    .1209 5.952 .02739 1.249e-05   119 437.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1584 391.6 1440 3.692        .9881\n\n00:12:31 | running eval: valid\n00:12:31 | eval completed in 0.21s\n00:12:31 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1588       0          0 122.1   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 1.368 1.249e-05    72 732.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1584  228 2321        .8333\n\u001b[0m\n00:12:31 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 24\u001b[0m\n00:12:31 | saving model checkpoint: /tmp/model2.checkpoint\n00:12:46 | time:612s total_exs:32440 total_steps:1622 epochs:162.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9947 9.947e-10               .9946                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9893            .9948              .9897   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.84 .2632 276.8  1050       0          0 75.86  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9947             32768  .1037    .1210 5.987 .0118 1.249e-05 119.7 454.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1622 396.6 1504 3.802        .9947\n\n00:12:51 | time:618s total_exs:32860 total_steps:1643 epochs:164.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9952 9.952e-10               .9948                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9896            .9956              .9913   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.86 .1429 277.2  1072       0          0 77.35  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9952             32768 .08276    .1210 5.914 .01075 1.249e-05 118.3 457.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1643 395.5 1529 3.884        .9952\n\n00:12:51 | running eval: valid\n00:12:52 | eval completed in 0.20s\n00:12:52 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1704       0          0   131   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 1.371 1.249e-05    72 786.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1643  228 2490        .8333\n\u001b[0m\n00:12:52 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 25\u001b[0m\n00:12:52 | saving model checkpoint: /tmp/model2.checkpoint\n00:13:06 | time:633s total_exs:33620 total_steps:1681 epochs:168.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9947 9.947e-10               .9945                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9890            .9950              .9900   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.9 .2105   278  1041       0          0 74.93  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9947             32768 .09115    .1210 5.955 .01143 1.249e-05 119.1 446.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1681 397.1 1488 3.755        .9947\n\n00:13:12 | time:638s total_exs:34040 total_steps:1702 epochs:170.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.38 .1429 267.6  1021       0          0 76.33  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01951    .1210 6.033 .001307 1.249e-05 120.7 460.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1702 388.3 1482 3.832            1\n\n00:13:12 | running eval: valid\n00:13:12 | eval completed in 0.20s\n00:13:12 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1678       0          0   129   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 1.404 1.249e-05    72 774.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1702  228 2452        .8333\n\u001b[0m\nEpoch 00013: reducing learning rate of group 0 to 6.2438e-06.\n00:13:12 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 26\u001b[0m\n00:13:12 | saving model checkpoint: /tmp/model2.checkpoint\n00:13:26 | time:653s total_exs:34800 total_steps:1740 epochs:174.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9986                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9973            .9987              .9974   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.61 .02632 272.2  1031       0          0 75.79   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    760 .9987             32768 .02869    .1210 5.971 .003705 6.244e-06 119.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   452.5       0          0                 1740 391.6 1484 3.798        .9987\n\n00:13:32 | time:658s total_exs:35220 total_steps:1761 epochs:176.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9929 9.929e-10               .9925                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9851            .9932              .9865   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.48 .1429 269.6  1010       0          0  74.9  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9929             32768  .1190    .1210 5.957 .01732 6.244e-06 119.1 446.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1761 388.8 1456 3.761        .9929\n\n00:13:32 | running eval: valid\n00:13:32 | eval completed in 0.25s\n00:13:32 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1467       0          0 112.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 1.408 6.244e-06    72 676.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1761  228 2144        .8333\n\u001b[0m\n00:13:32 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 27\u001b[0m\n00:13:32 | saving model checkpoint: /tmp/model2.checkpoint\n00:13:47 | time:673s total_exs:35980 total_steps:1799 epochs:179.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9947 9.947e-10               .9945                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9891            .9949              .9899   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.91 .07895 278.2  1056       0          0 75.93   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  \\\n    760 .9947             32768  .0886    .1210 5.963 .01306 6.244e-06 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   452.8       0          0                 1799 397.4 1509 3.805        .9947\n\n00:13:52 | time:679s total_exs:36400 total_steps:1820 epochs:182.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9952 9.952e-10               .9953                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9906            .9952              .9904   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 12.11 .04762 282.3  1066       0          0  75.5   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  \\\n    420 .9952             32768 .09138    .1210 6.014 .01235 6.244e-06 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   454.1       0          0                 1820 402.6 1520 3.79        .9952\n\n00:13:52 | running eval: valid\n00:13:53 | eval completed in 0.20s\n00:13:53 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1700       0          0 130.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08122     6 1.411 6.244e-06    72 784.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1820  228 2484        .8333\n\u001b[0m\n00:13:53 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 28\u001b[0m\n00:13:53 | saving model checkpoint: /tmp/model2.checkpoint\n00:14:07 | time:694s total_exs:37140 total_steps:1857 epochs:185.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9946 9.946e-10               .9946                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9893            .9946              .9892   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.48 .1081 269.5   991       0          0 73.54  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9946             32768 .09816    .1210 6.008 .01423 6.244e-06 120.2 441.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1857 389.7 1433 3.685        .9946\n\n00:14:13 | time:699s total_exs:37540 total_steps:1877 epochs:187.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.1  1035       0          0  75.5  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01331    .1210  5.96 .0008362 6.244e-06 119.2   450   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1877 393.3 1485 3.791            1\n\n00:14:13 | running eval: valid\n00:14:13 | eval completed in 0.20s\n00:14:13 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1707       0          0 131.3   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08124     6 1.405 6.244e-06    72 787.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1877  228 2495        .8333\n\u001b[0m\n00:14:13 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 29\u001b[0m\n00:14:13 | saving model checkpoint: /tmp/model2.checkpoint\n00:14:28 | time:714s total_exs:38320 total_steps:1916 epochs:191.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9974 9.974e-10               .9974                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9948            .9975              .9949   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1  11.6 .05128   272  1037       0          0 76.24   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    780 .9974             32768 .04992    .1210 5.995 .007501 6.244e-06 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   457.1       0          0                 1916 391.9 1494 3.82        .9974\n\n00:14:33 | time:720s total_exs:38740 total_steps:1937 epochs:193.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9976 9.976e-10               .9977                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9954            .9975              .9951   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.45 .09524 268.9  1038       0          0 77.22   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    420 .9976             32768   4.78    .1210 6.033 .007404 6.244e-06 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   465.9       0          0                 1937 389.6 1504 3.877        .9976\n\n00:14:33 | running eval: valid\n00:14:33 | eval completed in 0.22s\n00:14:33 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1582       0          0 121.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08125     6 1.421 6.244e-06    72 730.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1937  228 2312        .8333\n\u001b[0m\nEpoch 00017: reducing learning rate of group 0 to 3.1219e-06.\n00:14:33 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 30\u001b[0m\n00:14:33 | saving model checkpoint: /tmp/model2.checkpoint\n00:14:38 | ran out of patience! stopping training.\n00:14:38 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n00:14:38 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n00:14:38 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run2/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n00:14:38 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n00:14:38 | Using CUDA\n00:14:38 | loading dictionary from /tmp/model2.dict\n00:14:38 | num words = 54944\n00:14:43 | Loading existing model parameters from /tmp/model2\n00:14:50 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:14:51 | creating task(s): fromfile:parlaiformat\n00:14:51 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run2/data_valid.txt\n00:14:51 | running eval: valid\n00:14:52 | eval completed in 0.21s\n00:14:52 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1646       0          0 126.6   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298     6 .2753 1.015e-05    72 759.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    203  228 2406        .8748\n\u001b[0m\n00:14:52 | creating task(s): fromfile:parlaiformat\n00:14:52 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run2/data_test.txt\n00:14:52 | running eval: test\n00:14:57 | eval completed in 5.13s\n00:14:57 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8950 8.95e-10               .6512                 .4876   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9800            .9382              .9975   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8856 12.07 281.4  2757       0          0 195.9 1000 .8950   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298   5.2 .2571 1.015e-05   104  1019       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    203 385.4 3775        .9095\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type2/run2/data_test.txt -m transformer/classifier -mf /tmp/model2 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:14:58.913017Z","iopub.execute_input":"2022-12-04T00:14:58.913784Z","iopub.status.idle":"2022-12-04T00:15:30.003145Z","shell.execute_reply.started":"2022-12-04T00:14:58.913720Z","shell.execute_reply":"2022-12-04T00:15:30.001935Z"},"scrolled":true,"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"00:15:07 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr2type2/run2/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr2type2/run2/data)\u001b[0m\n00:15:07 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n00:15:07 | Using CUDA\n00:15:07 | loading dictionary from /tmp/model2.dict\n00:15:08 | num words = 54944\n00:15:12 | Loading existing model parameters from /tmp/model2\n00:15:18 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:15:19 | Opt:\n00:15:19 |     activation: gelu\n00:15:19 |     adafactor_eps: '[1e-30, 0.001]'\n00:15:19 |     adam_eps: 1e-08\n00:15:19 |     add_p1_after_newln: False\n00:15:19 |     aggregate_micro: False\n00:15:19 |     allow_missing_init_opts: False\n00:15:19 |     area_under_curve_class: None\n00:15:19 |     area_under_curve_digits: -1\n00:15:19 |     attention_dropout: 0.1\n00:15:19 |     batchsize: 40\n00:15:19 |     betas: '[0.9, 0.999]'\n00:15:19 |     bpe_add_prefix_space: None\n00:15:19 |     bpe_debug: False\n00:15:19 |     bpe_dropout: None\n00:15:19 |     bpe_merge: None\n00:15:19 |     bpe_vocab: None\n00:15:19 |     candidates: inline\n00:15:19 |     cap_num_predictions: 100\n00:15:19 |     checkpoint_activations: False\n00:15:19 |     class_weights: None\n00:15:19 |     classes: \"['__notok__', '__ok__']\"\n00:15:19 |     classes_from_file: None\n00:15:19 |     data_parallel: True\n00:15:19 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n00:15:19 |     datatype: train\n00:15:19 |     delimiter: '\\n'\n00:15:19 |     dict_class: parlai.core.dict:DictionaryAgent\n00:15:19 |     dict_endtoken: __start__\n00:15:19 |     dict_file: /tmp/model2.dict\n00:15:19 |     dict_include_test: False\n00:15:19 |     dict_include_valid: False\n00:15:19 |     dict_initpath: None\n00:15:19 |     dict_language: english\n00:15:19 |     dict_loaded: True\n00:15:19 |     dict_lower: True\n00:15:19 |     dict_max_ngram_size: -1\n00:15:19 |     dict_maxexs: -1\n00:15:19 |     dict_maxtokens: -1\n00:15:19 |     dict_minfreq: 0\n00:15:19 |     dict_nulltoken: __null__\n00:15:19 |     dict_starttoken: __start__\n00:15:19 |     dict_textfields: text,labels\n00:15:19 |     dict_tokenizer: bpe\n00:15:19 |     dict_unktoken: __unk__\n00:15:19 |     display_examples: False\n00:15:19 |     download_path: None\n00:15:19 |     dropout: 0.1\n00:15:19 |     dynamic_batching: None\n00:15:19 |     embedding_projection: random\n00:15:19 |     embedding_size: 768\n00:15:19 |     embedding_type: random\n00:15:19 |     embeddings_scale: False\n00:15:19 |     encode_candidate_vecs: True\n00:15:19 |     encode_candidate_vecs_batchsize: 256\n00:15:19 |     eval_batchsize: None\n00:15:19 |     eval_candidates: inline\n00:15:19 |     eval_dynamic_batching: None\n00:15:19 |     evaltask: None\n00:15:19 |     ffn_size: 3072\n00:15:19 |     final_extra_opt: \n00:15:19 |     fixed_candidate_vecs: reuse\n00:15:19 |     fixed_candidates_path: None\n00:15:19 |     force_fp16_tokens: True\n00:15:19 |     fp16: True\n00:15:19 |     fp16_impl: safe\n00:15:19 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run2/data_test.txt\n00:15:19 |     fromfile_datatype_extension: True\n00:15:19 |     gpu: -1\n00:15:19 |     gradient_clip: 0.1\n00:15:19 |     hide_labels: False\n00:15:19 |     history_add_global_end_token: None\n00:15:19 |     history_reversed: False\n00:15:19 |     history_size: 20\n00:15:19 |     ignore_bad_candidates: False\n00:15:19 |     ignore_labels: None\n00:15:19 |     image_cropsize: 224\n00:15:19 |     image_mode: raw\n00:15:19 |     image_size: 256\n00:15:19 |     inference: max\n00:15:19 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:15:19 |     init_opt: None\n00:15:19 |     interactive_candidates: fixed\n00:15:19 |     interactive_mode: False\n00:15:19 |     invsqrt_lr_decay_gamma: -1\n00:15:19 |     is_debug: False\n00:15:19 |     label_truncate: 72\n00:15:19 |     learn_embeddings: True\n00:15:19 |     learn_positional_embeddings: True\n00:15:19 |     learningrate: 5e-05\n00:15:19 |     load_from_pretrained_ranker: True\n00:15:19 |     log_every_n_secs: 10.0\n00:15:19 |     log_every_n_steps: 50\n00:15:19 |     log_keep_fields: all\n00:15:19 |     loglevel: info\n00:15:19 |     lr_scheduler: reduceonplateau\n00:15:19 |     lr_scheduler_decay: 0.5\n00:15:19 |     lr_scheduler_patience: 3\n00:15:19 |     max_train_steps: -1\n00:15:19 |     max_train_time: 7200.0\n00:15:19 |     memory_attention: sqrt\n00:15:19 |     metrics: default\n00:15:19 |     model: transformer/classifier\n00:15:19 |     model_file: /tmp/model2\n00:15:19 |     model_parallel: False\n00:15:19 |     momentum: 0\n00:15:19 |     multitask_weights: [1]\n00:15:19 |     mutators: None\n00:15:19 |     n_decoder_layers: -1\n00:15:19 |     n_encoder_layers: -1\n00:15:19 |     n_heads: 12\n00:15:19 |     n_layers: 12\n00:15:19 |     n_positions: 1024\n00:15:19 |     n_segments: 2\n00:15:19 |     nesterov: True\n00:15:19 |     no_cuda: False\n00:15:19 |     normalize_sent_emb: False\n00:15:19 |     num_epochs: -1\n00:15:19 |     num_examples: -1\n00:15:19 |     num_workers: 0\n00:15:19 |     nus: [0.7]\n00:15:19 |     optimizer: adamax\n00:15:19 |     output_scaling: 0.06\n00:15:19 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type2/run2/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model2', 'batchsize': 40}\"\n00:15:19 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n00:15:19 |     person_tokens: False\n00:15:19 |     print_scores: False\n00:15:19 |     rank_candidates: False\n00:15:19 |     rank_top_k: -1\n00:15:19 |     reduction_type: mean\n00:15:19 |     ref_class: None\n00:15:19 |     relu_dropout: 0.0\n00:15:19 |     repeat_blocking_heuristic: True\n00:15:19 |     report_filename: \n00:15:19 |     return_cand_scores: False\n00:15:19 |     save_after_valid: True\n00:15:19 |     save_every_n_secs: -1\n00:15:19 |     save_format: conversations\n00:15:19 |     share_encoders: False\n00:15:19 |     share_word_embeddings: False\n00:15:19 |     short_final_eval: False\n00:15:19 |     special_tok_lst: None\n00:15:19 |     split_lines: False\n00:15:19 |     starttime: Dec04_00-02\n00:15:19 |     task: fromfile:parlaiformat\n00:15:19 |     tensorboard_log: False\n00:15:19 |     tensorboard_logdir: None\n00:15:19 |     text_truncate: 360\n00:15:19 |     threshold: 0.5\n00:15:19 |     topk: 5\n00:15:19 |     train_predict: False\n00:15:19 |     truncate: 1024\n00:15:19 |     update_classifier_head_only: False\n00:15:19 |     update_freq: 1\n00:15:19 |     use_memories: False\n00:15:19 |     use_reply: none\n00:15:19 |     validation_cutoff: 1.0\n00:15:19 |     validation_every_n_epochs: -1\n00:15:19 |     validation_every_n_secs: 20.0\n00:15:19 |     validation_every_n_steps: -1\n00:15:19 |     validation_max_exs: -1\n00:15:19 |     validation_metric: accuracy\n00:15:19 |     validation_metric_mode: max\n00:15:19 |     validation_patience: 30\n00:15:19 |     validation_share_agent: False\n00:15:19 |     variant: xlm\n00:15:19 |     verbose: False\n00:15:19 |     wandb_entity: None\n00:15:19 |     wandb_log: False\n00:15:19 |     wandb_name: None\n00:15:19 |     wandb_project: None\n00:15:19 |     warmup_rate: 0.0001\n00:15:19 |     warmup_updates: 1000\n00:15:19 |     weight_decay: None\n00:15:19 |     world_logs: \n00:15:19 |     wrap_memory_encoder: False\n00:15:20 | Evaluating task fromfile:parlaiformat using datatype valid.\n00:15:20 | creating task(s): fromfile:parlaiformat\n00:15:20 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n00:15:20 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run2/data_test.txt\n00:15:28 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8950 8.95e-10               .6512                 .4876   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9800            .9382              .9975   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8856 12.07 562.9  1922       0          0 136.6 1000 .8950   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2571 1.015e-05   208 710.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    203 770.9 2633        .9095\u001b[0m\n00:15:28 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8950 8.95e-10               .6512                 .4876   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9800            .9382              .9975   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8856 12.07 562.9  1922       0          0 136.6 1000 .8950   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2571 1.015e-05   208 710.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    203 770.9 2633        .9095\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model2*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:15:30.005251Z","iopub.execute_input":"2022-12-04T00:15:30.005644Z","iopub.status.idle":"2022-12-04T00:15:31.268964Z","shell.execute_reply.started":"2022-12-04T00:15:30.005602Z","shell.execute_reply":"2022-12-04T00:15:31.267571Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"run 3","metadata":{}},{"cell_type":"code","source":"# run 3 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type2/run3/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model3","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:15:31.270570Z","iopub.execute_input":"2022-12-04T00:15:31.270960Z","iopub.status.idle":"2022-12-04T00:17:31.970902Z","shell.execute_reply.started":"2022-12-04T00:15:31.270917Z","shell.execute_reply":"2022-12-04T00:17:31.969614Z"},"scrolled":true,"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"00:15:38 | building dictionary first...\n00:15:38 | No model with opt yet at: /tmp/model3(.opt)\n00:15:38 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run3/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n00:15:38 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n00:15:38 | Using CUDA\n00:15:38 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n00:15:38 | num words = 54944\n00:15:43 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:15:53 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:15:53 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n00:15:53 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n00:15:53 | Opt:\n00:15:53 |     activation: gelu\n00:15:53 |     adafactor_eps: '(1e-30, 0.001)'\n00:15:53 |     adam_eps: 1e-08\n00:15:53 |     add_p1_after_newln: False\n00:15:53 |     aggregate_micro: False\n00:15:53 |     allow_missing_init_opts: False\n00:15:53 |     attention_dropout: 0.1\n00:15:53 |     batchsize: 20\n00:15:53 |     betas: '(0.9, 0.999)'\n00:15:53 |     bpe_add_prefix_space: None\n00:15:53 |     bpe_debug: False\n00:15:53 |     bpe_dropout: None\n00:15:53 |     bpe_merge: None\n00:15:53 |     bpe_vocab: None\n00:15:53 |     candidates: inline\n00:15:53 |     cap_num_predictions: 100\n00:15:53 |     checkpoint_activations: False\n00:15:53 |     class_weights: None\n00:15:53 |     classes: \"['__notok__', '__ok__']\"\n00:15:53 |     classes_from_file: None\n00:15:53 |     data_parallel: True\n00:15:53 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n00:15:53 |     datatype: train\n00:15:53 |     delimiter: '\\n'\n00:15:53 |     dict_class: parlai.core.dict:DictionaryAgent\n00:15:53 |     dict_endtoken: __start__\n00:15:53 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n00:15:53 |     dict_include_test: False\n00:15:53 |     dict_include_valid: False\n00:15:53 |     dict_initpath: None\n00:15:53 |     dict_language: english\n00:15:53 |     dict_loaded: True\n00:15:53 |     dict_lower: True\n00:15:53 |     dict_max_ngram_size: -1\n00:15:53 |     dict_maxexs: -1\n00:15:53 |     dict_maxtokens: -1\n00:15:53 |     dict_minfreq: 0\n00:15:53 |     dict_nulltoken: __null__\n00:15:53 |     dict_starttoken: __start__\n00:15:53 |     dict_textfields: text,labels\n00:15:53 |     dict_tokenizer: bpe\n00:15:53 |     dict_unktoken: __unk__\n00:15:53 |     display_examples: False\n00:15:53 |     download_path: None\n00:15:53 |     dropout: 0.1\n00:15:53 |     dynamic_batching: None\n00:15:53 |     embedding_projection: random\n00:15:53 |     embedding_size: 768\n00:15:53 |     embedding_type: random\n00:15:53 |     embeddings_scale: False\n00:15:53 |     encode_candidate_vecs: True\n00:15:53 |     encode_candidate_vecs_batchsize: 256\n00:15:53 |     eval_batchsize: None\n00:15:53 |     eval_candidates: inline\n00:15:53 |     eval_dynamic_batching: None\n00:15:53 |     evaltask: None\n00:15:53 |     ffn_size: 3072\n00:15:53 |     final_extra_opt: \n00:15:53 |     fixed_candidate_vecs: reuse\n00:15:53 |     fixed_candidates_path: None\n00:15:53 |     force_fp16_tokens: False\n00:15:53 |     fp16: True\n00:15:53 |     fp16_impl: safe\n00:15:53 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run3/data\n00:15:53 |     fromfile_datatype_extension: True\n00:15:53 |     gpu: -1\n00:15:53 |     gradient_clip: 0.1\n00:15:53 |     hide_labels: False\n00:15:53 |     history_add_global_end_token: None\n00:15:53 |     history_reversed: False\n00:15:53 |     history_size: 20\n00:15:53 |     ignore_bad_candidates: False\n00:15:53 |     ignore_labels: None\n00:15:53 |     image_cropsize: 224\n00:15:53 |     image_mode: raw\n00:15:53 |     image_size: 256\n00:15:53 |     inference: max\n00:15:53 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:15:53 |     init_opt: None\n00:15:53 |     interactive_candidates: fixed\n00:15:53 |     interactive_mode: False\n00:15:53 |     invsqrt_lr_decay_gamma: -1\n00:15:53 |     is_debug: False\n00:15:53 |     label_truncate: 72\n00:15:53 |     learn_embeddings: True\n00:15:53 |     learn_positional_embeddings: True\n00:15:53 |     learningrate: 5e-05\n00:15:53 |     load_from_checkpoint: False\n00:15:53 |     load_from_pretrained_ranker: True\n00:15:53 |     log_every_n_secs: 10.0\n00:15:53 |     log_every_n_steps: 50\n00:15:53 |     log_keep_fields: all\n00:15:53 |     loglevel: info\n00:15:53 |     lr_scheduler: reduceonplateau\n00:15:53 |     lr_scheduler_decay: 0.5\n00:15:53 |     lr_scheduler_patience: 3\n00:15:53 |     max_train_steps: -1\n00:15:53 |     max_train_time: 7200.0\n00:15:53 |     memory_attention: sqrt\n00:15:53 |     metrics: default\n00:15:53 |     model: transformer/classifier\n00:15:53 |     model_file: /tmp/model3\n00:15:53 |     model_parallel: False\n00:15:53 |     momentum: 0\n00:15:53 |     multitask_weights: [1]\n00:15:53 |     mutators: None\n00:15:53 |     n_decoder_layers: -1\n00:15:53 |     n_encoder_layers: -1\n00:15:53 |     n_heads: 12\n00:15:53 |     n_layers: 12\n00:15:53 |     n_positions: 1024\n00:15:53 |     n_segments: 2\n00:15:53 |     nesterov: True\n00:15:53 |     no_cuda: False\n00:15:53 |     normalize_sent_emb: False\n00:15:53 |     num_epochs: -1\n00:15:53 |     num_workers: 0\n00:15:53 |     nus: (0.7,)\n00:15:53 |     optimizer: adamax\n00:15:53 |     output_scaling: 0.06\n00:15:53 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type2/run3/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model3'}\"\n00:15:53 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n00:15:53 |     person_tokens: False\n00:15:53 |     print_scores: False\n00:15:53 |     rank_candidates: False\n00:15:53 |     rank_top_k: -1\n00:15:53 |     reduction_type: mean\n00:15:53 |     ref_class: None\n00:15:53 |     relu_dropout: 0.0\n00:15:53 |     repeat_blocking_heuristic: True\n00:15:53 |     return_cand_scores: False\n00:15:53 |     save_after_valid: True\n00:15:53 |     save_every_n_secs: -1\n00:15:53 |     save_format: conversations\n00:15:53 |     share_encoders: False\n00:15:53 |     share_word_embeddings: False\n00:15:53 |     short_final_eval: False\n00:15:53 |     special_tok_lst: None\n00:15:53 |     split_lines: False\n00:15:53 |     starttime: Dec04_00-15\n00:15:53 |     task: fromfile:parlaiformat\n00:15:53 |     tensorboard_log: False\n00:15:53 |     tensorboard_logdir: None\n00:15:53 |     text_truncate: 360\n00:15:53 |     threshold: 0.5\n00:15:53 |     topk: 5\n00:15:53 |     train_predict: False\n00:15:53 |     truncate: 1024\n00:15:53 |     update_classifier_head_only: False\n00:15:53 |     update_freq: 1\n00:15:53 |     use_memories: False\n00:15:53 |     use_reply: none\n00:15:53 |     validation_cutoff: 1.0\n00:15:53 |     validation_every_n_epochs: -1\n00:15:53 |     validation_every_n_secs: 20.0\n00:15:53 |     validation_every_n_steps: -1\n00:15:53 |     validation_max_exs: -1\n00:15:53 |     validation_metric: accuracy\n00:15:53 |     validation_metric_mode: max\n00:15:53 |     validation_patience: 30\n00:15:53 |     validation_share_agent: False\n00:15:53 |     variant: xlm\n00:15:53 |     verbose: False\n00:15:53 |     wandb_entity: None\n00:15:53 |     wandb_log: False\n00:15:53 |     wandb_name: None\n00:15:53 |     wandb_project: None\n00:15:53 |     warmup_rate: 0.0001\n00:15:53 |     warmup_updates: 1000\n00:15:53 |     weight_decay: None\n00:15:53 |     world_logs: \n00:15:53 |     wrap_memory_encoder: False\n00:15:54 | creating task(s): fromfile:parlaiformat\n00:15:54 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run3/data_train.txt\n00:15:54 | training...\n00:16:04 | time:10s total_exs:420 total_steps:21 epochs:2.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .4262 4.262e-10               .4248                 .4279   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .4218            .4276              .4245   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .4306  11.6     1   272 564.9       0          0 41.53  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .4262             32768  2.503    .1206 6.005 .7071 1.055e-06 120.1 249.4   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   21 392.1 814.3 2.081        .4262\n\n00:16:14 | time:20s total_exs:1180 total_steps:59 epochs:5.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5197 5.197e-10               .4288                 .5000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .3753            .5857              .5309   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6532 11.45     1   269  1036       0          0    77  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5197             32768  2.478    .1207 5.961 .6862 2.955e-06 119.2   459   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   59 388.2 1495 3.859        .5103\n\n00:16:14 | creating task(s): fromfile:parlaiformat\n00:16:14 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run3/data_valid.txt\n00:16:14 | running eval: valid\n00:16:14 | eval completed in 0.19s\n00:16:14 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7273                 .8000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .7692              .7143   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.71 164.5  1908       0          0 139.2   24 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6657 2.955e-06    72 835.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     59 236.5 2744        .7483\n\u001b[0m\n00:16:14 | \u001b[1;32mnew best accuracy: 0.75\u001b[0m\n00:16:14 | saving best valid model: /tmp/model3\n00:16:14 | Saving dictionary to /tmp/model3.dict\n00:16:18 | saving model checkpoint: /tmp/model3.checkpoint\n00:16:18 | Saving dictionary to /tmp/model3.checkpoint.dict\n00:16:34 | time:40s total_exs:1900 total_steps:95 epochs:9.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7722 7.722e-10               .7405                 .8097   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6822            .7970              .7471   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8541 11.53     1 270.5 967.8       0          0 71.55  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7722             32768  2.282    .1207 5.953 .6395 4.755e-06 119.1 425.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   95 389.6 1394 3.586        .7701\n\n00:16:38 | time:44s total_exs:2200 total_steps:110 epochs:11.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8267 8.267e-10               .8207                 .9015   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7532            .8323              .7679   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9085 11.47     1 269.3  1031       0          0 76.57  300   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8267             32768  2.479    .1207 6.053 .5885 5.504e-06 121.1 463.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  110 390.4 1495 3.851        .8262\n\n00:16:38 | running eval: valid\n00:16:38 | eval completed in 0.19s\n00:16:38 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8462                 .7857   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8182              .9000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.71 164.5  1965       0          0 143.3   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5538 5.504e-06    72   860       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    110 236.5 2825        .8322\n\u001b[0m\n00:16:38 | \u001b[1;32mnew best accuracy: 0.8333 (previous best was 0.75)\u001b[0m\n00:16:38 | saving best valid model: /tmp/model3\n00:16:47 | saving model checkpoint: /tmp/model3.checkpoint\n00:17:02 | time:69s total_exs:3000 total_steps:150 epochs:15.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8588 8.587e-10               .8653                 .8383   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8941            .8515              .8828   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8223 11.63     1 272.7  1070       0          0 78.47  800   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8588             32768  3.072    .1207 6.015 .5174 7.504e-06 120.3   472   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  150  393 1542 3.932        .8585\n\n00:17:07 | time:74s total_exs:3380 total_steps:169 epochs:16.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8711 8.711e-10               .8759                 .8607   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8918            .8658              .8827   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8495 11.39     1 267.9  1063       0          0 79.34  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8711             32768  4.142    .1207 6.021 .4140 8.454e-06 120.4 477.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  169 388.3 1540 3.986        .8710\n\n00:17:07 | running eval: valid\n00:17:07 | eval completed in 0.20s\n00:17:07 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 11.71 164.5  1800       0          0 131.2   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .3021 8.454e-06    72 787.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    169 236.5 2588            1\n\u001b[0m\n00:17:07 | \u001b[1;32mnew best accuracy: 1 (previous best was 0.8333)\u001b[0m\n00:17:07 | saving best valid model: /tmp/model3\n00:17:17 | task solved! stopping.\n00:17:17 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n00:17:17 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n00:17:17 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run3/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n00:17:17 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n00:17:17 | Using CUDA\n00:17:17 | loading dictionary from /tmp/model3.dict\n00:17:17 | num words = 54944\n00:17:22 | Loading existing model parameters from /tmp/model3\n00:17:23 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:17:25 | creating task(s): fromfile:parlaiformat\n00:17:25 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run3/data_valid.txt\n00:17:25 | running eval: valid\n00:17:25 | eval completed in 0.20s\n00:17:25 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 11.71 164.5  1857       0          0 135.4   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294     6 .3021 8.454e-06    72 812.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    169 236.5 2670            1\n\u001b[0m\n00:17:25 | creating task(s): fromfile:parlaiformat\n00:17:25 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run3/data_test.txt\n00:17:25 | running eval: test\n00:17:30 | eval completed in 4.74s\n00:17:30 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9250 9.25e-10               .7273                 .5714   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.07 281.4  2988       0          0 212.3 1000 .9250   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294   5.2 .3419 8.454e-06   104  1104       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    169 385.4 4092        .9336\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type2/run3/data_test.txt -m transformer/classifier -mf /tmp/model3 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:17:31.974768Z","iopub.execute_input":"2022-12-04T00:17:31.975201Z","iopub.status.idle":"2022-12-04T00:18:02.106481Z","shell.execute_reply.started":"2022-12-04T00:17:31.975161Z","shell.execute_reply":"2022-12-04T00:18:02.105261Z"},"scrolled":true,"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"00:17:40 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr2type2/run3/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr2type2/run3/data)\u001b[0m\n00:17:40 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n00:17:40 | Using CUDA\n00:17:40 | loading dictionary from /tmp/model3.dict\n00:17:40 | num words = 54944\n00:17:45 | Loading existing model parameters from /tmp/model3\n00:17:51 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:17:52 | Opt:\n00:17:52 |     activation: gelu\n00:17:52 |     adafactor_eps: '[1e-30, 0.001]'\n00:17:52 |     adam_eps: 1e-08\n00:17:52 |     add_p1_after_newln: False\n00:17:52 |     aggregate_micro: False\n00:17:52 |     allow_missing_init_opts: False\n00:17:52 |     area_under_curve_class: None\n00:17:52 |     area_under_curve_digits: -1\n00:17:52 |     attention_dropout: 0.1\n00:17:52 |     batchsize: 40\n00:17:52 |     betas: '[0.9, 0.999]'\n00:17:52 |     bpe_add_prefix_space: None\n00:17:52 |     bpe_debug: False\n00:17:52 |     bpe_dropout: None\n00:17:52 |     bpe_merge: None\n00:17:52 |     bpe_vocab: None\n00:17:52 |     candidates: inline\n00:17:52 |     cap_num_predictions: 100\n00:17:52 |     checkpoint_activations: False\n00:17:52 |     class_weights: None\n00:17:52 |     classes: \"['__notok__', '__ok__']\"\n00:17:52 |     classes_from_file: None\n00:17:52 |     data_parallel: True\n00:17:52 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n00:17:52 |     datatype: train\n00:17:52 |     delimiter: '\\n'\n00:17:52 |     dict_class: parlai.core.dict:DictionaryAgent\n00:17:52 |     dict_endtoken: __start__\n00:17:52 |     dict_file: /tmp/model3.dict\n00:17:52 |     dict_include_test: False\n00:17:52 |     dict_include_valid: False\n00:17:52 |     dict_initpath: None\n00:17:52 |     dict_language: english\n00:17:52 |     dict_loaded: True\n00:17:52 |     dict_lower: True\n00:17:52 |     dict_max_ngram_size: -1\n00:17:52 |     dict_maxexs: -1\n00:17:52 |     dict_maxtokens: -1\n00:17:52 |     dict_minfreq: 0\n00:17:52 |     dict_nulltoken: __null__\n00:17:52 |     dict_starttoken: __start__\n00:17:52 |     dict_textfields: text,labels\n00:17:52 |     dict_tokenizer: bpe\n00:17:52 |     dict_unktoken: __unk__\n00:17:52 |     display_examples: False\n00:17:52 |     download_path: None\n00:17:52 |     dropout: 0.1\n00:17:52 |     dynamic_batching: None\n00:17:52 |     embedding_projection: random\n00:17:52 |     embedding_size: 768\n00:17:52 |     embedding_type: random\n00:17:52 |     embeddings_scale: False\n00:17:52 |     encode_candidate_vecs: True\n00:17:52 |     encode_candidate_vecs_batchsize: 256\n00:17:52 |     eval_batchsize: None\n00:17:52 |     eval_candidates: inline\n00:17:52 |     eval_dynamic_batching: None\n00:17:52 |     evaltask: None\n00:17:52 |     ffn_size: 3072\n00:17:52 |     final_extra_opt: \n00:17:52 |     fixed_candidate_vecs: reuse\n00:17:52 |     fixed_candidates_path: None\n00:17:52 |     force_fp16_tokens: True\n00:17:52 |     fp16: True\n00:17:52 |     fp16_impl: safe\n00:17:52 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run3/data_test.txt\n00:17:52 |     fromfile_datatype_extension: True\n00:17:52 |     gpu: -1\n00:17:52 |     gradient_clip: 0.1\n00:17:52 |     hide_labels: False\n00:17:52 |     history_add_global_end_token: None\n00:17:52 |     history_reversed: False\n00:17:52 |     history_size: 20\n00:17:52 |     ignore_bad_candidates: False\n00:17:52 |     ignore_labels: None\n00:17:52 |     image_cropsize: 224\n00:17:52 |     image_mode: raw\n00:17:52 |     image_size: 256\n00:17:52 |     inference: max\n00:17:52 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:17:52 |     init_opt: None\n00:17:52 |     interactive_candidates: fixed\n00:17:52 |     interactive_mode: False\n00:17:52 |     invsqrt_lr_decay_gamma: -1\n00:17:52 |     is_debug: False\n00:17:52 |     label_truncate: 72\n00:17:52 |     learn_embeddings: True\n00:17:52 |     learn_positional_embeddings: True\n00:17:52 |     learningrate: 5e-05\n00:17:52 |     load_from_pretrained_ranker: True\n00:17:52 |     log_every_n_secs: 10.0\n00:17:52 |     log_every_n_steps: 50\n00:17:52 |     log_keep_fields: all\n00:17:52 |     loglevel: info\n00:17:52 |     lr_scheduler: reduceonplateau\n00:17:52 |     lr_scheduler_decay: 0.5\n00:17:52 |     lr_scheduler_patience: 3\n00:17:52 |     max_train_steps: -1\n00:17:52 |     max_train_time: 7200.0\n00:17:52 |     memory_attention: sqrt\n00:17:52 |     metrics: default\n00:17:52 |     model: transformer/classifier\n00:17:52 |     model_file: /tmp/model3\n00:17:52 |     model_parallel: False\n00:17:52 |     momentum: 0\n00:17:52 |     multitask_weights: [1]\n00:17:52 |     mutators: None\n00:17:52 |     n_decoder_layers: -1\n00:17:52 |     n_encoder_layers: -1\n00:17:52 |     n_heads: 12\n00:17:52 |     n_layers: 12\n00:17:52 |     n_positions: 1024\n00:17:52 |     n_segments: 2\n00:17:52 |     nesterov: True\n00:17:52 |     no_cuda: False\n00:17:52 |     normalize_sent_emb: False\n00:17:52 |     num_epochs: -1\n00:17:52 |     num_examples: -1\n00:17:52 |     num_workers: 0\n00:17:52 |     nus: [0.7]\n00:17:52 |     optimizer: adamax\n00:17:52 |     output_scaling: 0.06\n00:17:52 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type2/run3/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model3', 'batchsize': 40}\"\n00:17:52 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n00:17:52 |     person_tokens: False\n00:17:52 |     print_scores: False\n00:17:52 |     rank_candidates: False\n00:17:52 |     rank_top_k: -1\n00:17:52 |     reduction_type: mean\n00:17:52 |     ref_class: None\n00:17:52 |     relu_dropout: 0.0\n00:17:52 |     repeat_blocking_heuristic: True\n00:17:52 |     report_filename: \n00:17:52 |     return_cand_scores: False\n00:17:52 |     save_after_valid: True\n00:17:52 |     save_every_n_secs: -1\n00:17:52 |     save_format: conversations\n00:17:52 |     share_encoders: False\n00:17:52 |     share_word_embeddings: False\n00:17:52 |     short_final_eval: False\n00:17:52 |     special_tok_lst: None\n00:17:52 |     split_lines: False\n00:17:52 |     starttime: Dec04_00-15\n00:17:52 |     task: fromfile:parlaiformat\n00:17:52 |     tensorboard_log: False\n00:17:52 |     tensorboard_logdir: None\n00:17:52 |     text_truncate: 360\n00:17:52 |     threshold: 0.5\n00:17:52 |     topk: 5\n00:17:52 |     train_predict: False\n00:17:52 |     truncate: 1024\n00:17:52 |     update_classifier_head_only: False\n00:17:52 |     update_freq: 1\n00:17:52 |     use_memories: False\n00:17:52 |     use_reply: none\n00:17:52 |     validation_cutoff: 1.0\n00:17:52 |     validation_every_n_epochs: -1\n00:17:52 |     validation_every_n_secs: 20.0\n00:17:52 |     validation_every_n_steps: -1\n00:17:52 |     validation_max_exs: -1\n00:17:52 |     validation_metric: accuracy\n00:17:52 |     validation_metric_mode: max\n00:17:52 |     validation_patience: 30\n00:17:52 |     validation_share_agent: False\n00:17:52 |     variant: xlm\n00:17:52 |     verbose: False\n00:17:52 |     wandb_entity: None\n00:17:52 |     wandb_log: False\n00:17:52 |     wandb_name: None\n00:17:52 |     wandb_project: None\n00:17:52 |     warmup_rate: 0.0001\n00:17:52 |     warmup_updates: 1000\n00:17:52 |     weight_decay: None\n00:17:52 |     world_logs: \n00:17:52 |     wrap_memory_encoder: False\n00:17:52 | Evaluating task fromfile:parlaiformat using datatype valid.\n00:17:52 | creating task(s): fromfile:parlaiformat\n00:17:52 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n00:17:52 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run3/data_test.txt\n00:18:00 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9250 9.25e-10               .7273                 .5714   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.07 562.9  1940       0          0 137.9 1000 .9250   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .3419 8.454e-06   208 716.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    169 770.9 2657        .9336\u001b[0m\n00:18:00 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9250 9.25e-10               .7273                 .5714   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.07 562.9  1940       0          0 137.9 1000 .9250   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .3419 8.454e-06   208 716.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    169 770.9 2657        .9336\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model3*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:18:02.109573Z","iopub.execute_input":"2022-12-04T00:18:02.110009Z","iopub.status.idle":"2022-12-04T00:18:03.433908Z","shell.execute_reply.started":"2022-12-04T00:18:02.109965Z","shell.execute_reply":"2022-12-04T00:18:03.432033Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"run 4","metadata":{}},{"cell_type":"code","source":"# run 4 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type2/run4/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model4","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:18:03.439183Z","iopub.execute_input":"2022-12-04T00:18:03.441528Z","iopub.status.idle":"2022-12-04T00:20:27.094681Z","shell.execute_reply.started":"2022-12-04T00:18:03.441480Z","shell.execute_reply":"2022-12-04T00:20:27.093480Z"},"scrolled":true,"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"00:18:10 | building dictionary first...\n00:18:10 | No model with opt yet at: /tmp/model4(.opt)\n00:18:10 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run4/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n00:18:10 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n00:18:10 | Using CUDA\n00:18:10 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n00:18:10 | num words = 54944\n00:18:15 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:18:25 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:18:25 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n00:18:25 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n00:18:25 | Opt:\n00:18:25 |     activation: gelu\n00:18:25 |     adafactor_eps: '(1e-30, 0.001)'\n00:18:25 |     adam_eps: 1e-08\n00:18:25 |     add_p1_after_newln: False\n00:18:25 |     aggregate_micro: False\n00:18:25 |     allow_missing_init_opts: False\n00:18:25 |     attention_dropout: 0.1\n00:18:25 |     batchsize: 20\n00:18:25 |     betas: '(0.9, 0.999)'\n00:18:25 |     bpe_add_prefix_space: None\n00:18:25 |     bpe_debug: False\n00:18:25 |     bpe_dropout: None\n00:18:25 |     bpe_merge: None\n00:18:25 |     bpe_vocab: None\n00:18:25 |     candidates: inline\n00:18:25 |     cap_num_predictions: 100\n00:18:25 |     checkpoint_activations: False\n00:18:25 |     class_weights: None\n00:18:25 |     classes: \"['__notok__', '__ok__']\"\n00:18:25 |     classes_from_file: None\n00:18:25 |     data_parallel: True\n00:18:25 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n00:18:25 |     datatype: train\n00:18:25 |     delimiter: '\\n'\n00:18:25 |     dict_class: parlai.core.dict:DictionaryAgent\n00:18:25 |     dict_endtoken: __start__\n00:18:25 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n00:18:25 |     dict_include_test: False\n00:18:25 |     dict_include_valid: False\n00:18:25 |     dict_initpath: None\n00:18:25 |     dict_language: english\n00:18:25 |     dict_loaded: True\n00:18:25 |     dict_lower: True\n00:18:25 |     dict_max_ngram_size: -1\n00:18:25 |     dict_maxexs: -1\n00:18:25 |     dict_maxtokens: -1\n00:18:25 |     dict_minfreq: 0\n00:18:25 |     dict_nulltoken: __null__\n00:18:25 |     dict_starttoken: __start__\n00:18:25 |     dict_textfields: text,labels\n00:18:25 |     dict_tokenizer: bpe\n00:18:25 |     dict_unktoken: __unk__\n00:18:25 |     display_examples: False\n00:18:25 |     download_path: None\n00:18:25 |     dropout: 0.1\n00:18:25 |     dynamic_batching: None\n00:18:25 |     embedding_projection: random\n00:18:25 |     embedding_size: 768\n00:18:25 |     embedding_type: random\n00:18:25 |     embeddings_scale: False\n00:18:25 |     encode_candidate_vecs: True\n00:18:25 |     encode_candidate_vecs_batchsize: 256\n00:18:25 |     eval_batchsize: None\n00:18:25 |     eval_candidates: inline\n00:18:25 |     eval_dynamic_batching: None\n00:18:25 |     evaltask: None\n00:18:25 |     ffn_size: 3072\n00:18:25 |     final_extra_opt: \n00:18:25 |     fixed_candidate_vecs: reuse\n00:18:25 |     fixed_candidates_path: None\n00:18:25 |     force_fp16_tokens: False\n00:18:25 |     fp16: True\n00:18:25 |     fp16_impl: safe\n00:18:25 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run4/data\n00:18:25 |     fromfile_datatype_extension: True\n00:18:25 |     gpu: -1\n00:18:25 |     gradient_clip: 0.1\n00:18:25 |     hide_labels: False\n00:18:25 |     history_add_global_end_token: None\n00:18:25 |     history_reversed: False\n00:18:25 |     history_size: 20\n00:18:25 |     ignore_bad_candidates: False\n00:18:25 |     ignore_labels: None\n00:18:25 |     image_cropsize: 224\n00:18:25 |     image_mode: raw\n00:18:25 |     image_size: 256\n00:18:25 |     inference: max\n00:18:25 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:18:25 |     init_opt: None\n00:18:25 |     interactive_candidates: fixed\n00:18:25 |     interactive_mode: False\n00:18:25 |     invsqrt_lr_decay_gamma: -1\n00:18:25 |     is_debug: False\n00:18:25 |     label_truncate: 72\n00:18:25 |     learn_embeddings: True\n00:18:25 |     learn_positional_embeddings: True\n00:18:25 |     learningrate: 5e-05\n00:18:25 |     load_from_checkpoint: False\n00:18:25 |     load_from_pretrained_ranker: True\n00:18:25 |     log_every_n_secs: 10.0\n00:18:25 |     log_every_n_steps: 50\n00:18:25 |     log_keep_fields: all\n00:18:25 |     loglevel: info\n00:18:25 |     lr_scheduler: reduceonplateau\n00:18:25 |     lr_scheduler_decay: 0.5\n00:18:25 |     lr_scheduler_patience: 3\n00:18:25 |     max_train_steps: -1\n00:18:25 |     max_train_time: 7200.0\n00:18:25 |     memory_attention: sqrt\n00:18:25 |     metrics: default\n00:18:25 |     model: transformer/classifier\n00:18:25 |     model_file: /tmp/model4\n00:18:25 |     model_parallel: False\n00:18:25 |     momentum: 0\n00:18:25 |     multitask_weights: [1]\n00:18:25 |     mutators: None\n00:18:25 |     n_decoder_layers: -1\n00:18:25 |     n_encoder_layers: -1\n00:18:25 |     n_heads: 12\n00:18:25 |     n_layers: 12\n00:18:25 |     n_positions: 1024\n00:18:25 |     n_segments: 2\n00:18:25 |     nesterov: True\n00:18:25 |     no_cuda: False\n00:18:25 |     normalize_sent_emb: False\n00:18:25 |     num_epochs: -1\n00:18:25 |     num_workers: 0\n00:18:25 |     nus: (0.7,)\n00:18:25 |     optimizer: adamax\n00:18:25 |     output_scaling: 0.06\n00:18:25 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type2/run4/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model4'}\"\n00:18:25 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n00:18:25 |     person_tokens: False\n00:18:25 |     print_scores: False\n00:18:25 |     rank_candidates: False\n00:18:25 |     rank_top_k: -1\n00:18:25 |     reduction_type: mean\n00:18:25 |     ref_class: None\n00:18:25 |     relu_dropout: 0.0\n00:18:25 |     repeat_blocking_heuristic: True\n00:18:25 |     return_cand_scores: False\n00:18:25 |     save_after_valid: True\n00:18:25 |     save_every_n_secs: -1\n00:18:25 |     save_format: conversations\n00:18:25 |     share_encoders: False\n00:18:25 |     share_word_embeddings: False\n00:18:25 |     short_final_eval: False\n00:18:25 |     special_tok_lst: None\n00:18:25 |     split_lines: False\n00:18:25 |     starttime: Dec04_00-18\n00:18:25 |     task: fromfile:parlaiformat\n00:18:25 |     tensorboard_log: False\n00:18:25 |     tensorboard_logdir: None\n00:18:25 |     text_truncate: 360\n00:18:25 |     threshold: 0.5\n00:18:25 |     topk: 5\n00:18:25 |     train_predict: False\n00:18:25 |     truncate: 1024\n00:18:25 |     update_classifier_head_only: False\n00:18:25 |     update_freq: 1\n00:18:25 |     use_memories: False\n00:18:25 |     use_reply: none\n00:18:25 |     validation_cutoff: 1.0\n00:18:25 |     validation_every_n_epochs: -1\n00:18:25 |     validation_every_n_secs: 20.0\n00:18:25 |     validation_every_n_steps: -1\n00:18:25 |     validation_max_exs: -1\n00:18:25 |     validation_metric: accuracy\n00:18:25 |     validation_metric_mode: max\n00:18:25 |     validation_patience: 30\n00:18:25 |     validation_share_agent: False\n00:18:25 |     variant: xlm\n00:18:25 |     verbose: False\n00:18:25 |     wandb_entity: None\n00:18:25 |     wandb_log: False\n00:18:25 |     wandb_name: None\n00:18:25 |     wandb_project: None\n00:18:25 |     warmup_rate: 0.0001\n00:18:25 |     warmup_updates: 1000\n00:18:25 |     weight_decay: None\n00:18:25 |     world_logs: \n00:18:25 |     wrap_memory_encoder: False\n00:18:25 | creating task(s): fromfile:parlaiformat\n00:18:25 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run4/data_train.txt\n00:18:25 | training...\n00:18:35 | time:10s total_exs:420 total_steps:21 epochs:2.10\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .3810 3.81e-10               .3839                 .3403   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .4402            .3780              .4341   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .3347 11.54     1 270.8 569.4       0          0 42.06  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .3810             32768  2.946    .1245 5.876 .7063 1.055e-06 117.5 247.2   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   21 388.3 816.6 2.108        .3806\n\n00:18:45 | time:20s total_exs:1200 total_steps:60 epochs:6.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .4897 4.897e-10               .4006                 .4389   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .3684            .5558              .5220   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .5943 11.42     1 268.5  1048       0          0 78.05  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .4897             32768  2.653    .1245 5.926 .6881 3.005e-06 118.5 462.5   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                   60  387 1510 3.911        .4840\n\n00:18:45 | creating task(s): fromfile:parlaiformat\n00:18:45 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run4/data_valid.txt\n00:18:45 | running eval: valid\n00:18:46 | eval completed in 0.20s\n00:18:46 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .6250 6.25e-10               .5714                 .6667   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5000            .6667              .6000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 12.04 168.5  1886       0          0 134.2   24 .6250   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6683 3.005e-06    72 805.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     60 240.5 2691        .6190\n\u001b[0m\n00:18:46 | \u001b[1;32mnew best accuracy: 0.625\u001b[0m\n00:18:46 | saving best valid model: /tmp/model4\n00:18:46 | Saving dictionary to /tmp/model4.dict\n00:18:51 | saving model checkpoint: /tmp/model4.checkpoint\n00:18:51 | Saving dictionary to /tmp/model4.checkpoint.dict\n00:19:06 | time:41s total_exs:1940 total_steps:97 epochs:9.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6892 6.892e-10               .6179                 .7750   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5138            .7380              .6480   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8571 11.64     1 272.8 985.6       0          0 72.27  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6892             32768  2.822    .1245 5.978 .6462 4.855e-06 119.6   432   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   97 392.3 1418 3.621        .6793\n\n00:19:11 | time:46s total_exs:2300 total_steps:115 epochs:11.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .8000   8e-10               .7447                 .7895   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7047            .8356              .8062   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8673 11.83     1 276.6  1060       0          0 76.64  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8000             32768   3.31    .1245 5.828 .5941 5.754e-06 116.6 446.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  115 393.2 1507 3.85        .7980\n\n00:19:11 | running eval: valid\n00:19:11 | eval completed in 0.20s\n00:19:11 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7368                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5833            .8276              .7059   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 12.04 168.5  1871       0          0 133.2   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .5628 5.754e-06    72 799.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    115 240.5 2670        .7822\n\u001b[0m\n00:19:11 | \u001b[1;32mnew best accuracy: 0.7917 (previous best was 0.625)\u001b[0m\n00:19:11 | saving best valid model: /tmp/model4\n00:19:16 | saving model checkpoint: /tmp/model4.checkpoint\n00:19:36 | time:70s total_exs:3080 total_steps:154 epochs:15.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8154 8.154e-10               .7743                 .8488   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7118            .8438              .7955   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8984 11.83     1 276.7  1074       0          0 77.61  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8154             32768  3.463    .1245  5.89 .5299 7.704e-06 117.8 457.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  154 394.5 1531 3.889        .8129\n\n00:19:36 | time:71s total_exs:3140 total_steps:157 epochs:15.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8833 8.833e-10               .8814                 .8966   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8667            .8852              .8710   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9000 10.65     1   253  1011       0          0 79.94   60   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8833             32768  3.779    .1189     6 .4339 7.854e-06   120 479.6   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps  ups  weighted_f1  \n         0          0                  157  373 1491 4.12        .8833\n\n00:19:36 | running eval: valid\n00:19:37 | eval completed in 0.20s\n00:19:37 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 12.04 168.5  1896       0          0   135   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .3888 7.854e-06    72 810.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    157 240.5 2706        .9583\n\u001b[0m\n00:19:37 | \u001b[1;32mnew best accuracy: 0.9583 (previous best was 0.7917)\u001b[0m\n00:19:37 | saving best valid model: /tmp/model4\n00:19:46 | saving model checkpoint: /tmp/model4.checkpoint\n00:20:02 | time:97s total_exs:3920 total_steps:196 epochs:19.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8744 8.744e-10               .8635                 .8683   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8587            .8836              .8794   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8878 11.49     1 269.8  1037       0          0 76.86  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8744             32768  4.582    .1245 5.926 .3695 9.804e-06 118.5 455.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  196 388.4 1493 3.852        .8743\n\n00:20:06 | time:101s total_exs:4260 total_steps:213 epochs:21.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9147 9.147e-10               .9129                 .8941   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9325            .9164              .9353   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8983 11.34     1 266.9  1033       0          0 77.38  340   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9147             32768  5.446    .1245 5.959 .2634 1.065e-05 119.2 461.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  213 386.1 1494 3.888        .9147\n\n00:20:06 | running eval: valid\n00:20:06 | eval completed in 0.20s\n00:20:06 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 12.04 168.5  1896       0          0   135   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .1659 1.065e-05    72 810.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    213 240.5 2706            1\n\u001b[0m\n00:20:06 | \u001b[1;32mnew best accuracy: 1 (previous best was 0.9583)\u001b[0m\n00:20:06 | saving best valid model: /tmp/model4\n00:20:11 | task solved! stopping.\n00:20:11 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n00:20:11 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n00:20:11 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run4/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n00:20:11 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n00:20:11 | Using CUDA\n00:20:11 | loading dictionary from /tmp/model4.dict\n00:20:11 | num words = 54944\n00:20:16 | Loading existing model parameters from /tmp/model4\n00:20:18 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:20:19 | creating task(s): fromfile:parlaiformat\n00:20:19 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run4/data_valid.txt\n00:20:19 | running eval: valid\n00:20:19 | eval completed in 0.20s\n00:20:19 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 12.04 168.5  1886       0          0 134.2   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294     6 .1659 1.065e-05    72 805.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    213 240.5 2692            1\n\u001b[0m\n00:20:19 | creating task(s): fromfile:parlaiformat\n00:20:19 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run4/data_test.txt\n00:20:19 | running eval: test\n00:20:25 | eval completed in 5.32s\n00:20:25 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9440 9.44e-10               .7647                 .6594   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9100            .9682              .9896   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9478 12.07 281.4  2655       0          0 188.7 1000 .9440   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294   5.2 .1952 1.065e-05   104   981       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    213 385.4 3636        .9479\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type2/run4/data_test.txt -m transformer/classifier -mf /tmp/model4 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:20:27.098594Z","iopub.execute_input":"2022-12-04T00:20:27.099085Z","iopub.status.idle":"2022-12-04T00:20:57.159393Z","shell.execute_reply.started":"2022-12-04T00:20:27.099033Z","shell.execute_reply":"2022-12-04T00:20:57.158203Z"},"scrolled":true,"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"00:20:35 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr2type2/run4/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr2type2/run4/data)\u001b[0m\n00:20:35 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n00:20:35 | Using CUDA\n00:20:35 | loading dictionary from /tmp/model4.dict\n00:20:35 | num words = 54944\n00:20:39 | Loading existing model parameters from /tmp/model4\n00:20:45 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:20:46 | Opt:\n00:20:46 |     activation: gelu\n00:20:46 |     adafactor_eps: '[1e-30, 0.001]'\n00:20:46 |     adam_eps: 1e-08\n00:20:46 |     add_p1_after_newln: False\n00:20:46 |     aggregate_micro: False\n00:20:46 |     allow_missing_init_opts: False\n00:20:46 |     area_under_curve_class: None\n00:20:46 |     area_under_curve_digits: -1\n00:20:46 |     attention_dropout: 0.1\n00:20:46 |     batchsize: 40\n00:20:46 |     betas: '[0.9, 0.999]'\n00:20:46 |     bpe_add_prefix_space: None\n00:20:46 |     bpe_debug: False\n00:20:46 |     bpe_dropout: None\n00:20:46 |     bpe_merge: None\n00:20:46 |     bpe_vocab: None\n00:20:46 |     candidates: inline\n00:20:46 |     cap_num_predictions: 100\n00:20:46 |     checkpoint_activations: False\n00:20:46 |     class_weights: None\n00:20:46 |     classes: \"['__notok__', '__ok__']\"\n00:20:46 |     classes_from_file: None\n00:20:46 |     data_parallel: True\n00:20:46 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n00:20:46 |     datatype: train\n00:20:46 |     delimiter: '\\n'\n00:20:46 |     dict_class: parlai.core.dict:DictionaryAgent\n00:20:46 |     dict_endtoken: __start__\n00:20:46 |     dict_file: /tmp/model4.dict\n00:20:46 |     dict_include_test: False\n00:20:46 |     dict_include_valid: False\n00:20:46 |     dict_initpath: None\n00:20:46 |     dict_language: english\n00:20:46 |     dict_loaded: True\n00:20:46 |     dict_lower: True\n00:20:46 |     dict_max_ngram_size: -1\n00:20:46 |     dict_maxexs: -1\n00:20:46 |     dict_maxtokens: -1\n00:20:46 |     dict_minfreq: 0\n00:20:46 |     dict_nulltoken: __null__\n00:20:46 |     dict_starttoken: __start__\n00:20:46 |     dict_textfields: text,labels\n00:20:46 |     dict_tokenizer: bpe\n00:20:46 |     dict_unktoken: __unk__\n00:20:46 |     display_examples: False\n00:20:46 |     download_path: None\n00:20:46 |     dropout: 0.1\n00:20:46 |     dynamic_batching: None\n00:20:46 |     embedding_projection: random\n00:20:46 |     embedding_size: 768\n00:20:46 |     embedding_type: random\n00:20:46 |     embeddings_scale: False\n00:20:46 |     encode_candidate_vecs: True\n00:20:46 |     encode_candidate_vecs_batchsize: 256\n00:20:46 |     eval_batchsize: None\n00:20:46 |     eval_candidates: inline\n00:20:46 |     eval_dynamic_batching: None\n00:20:46 |     evaltask: None\n00:20:46 |     ffn_size: 3072\n00:20:46 |     final_extra_opt: \n00:20:46 |     fixed_candidate_vecs: reuse\n00:20:46 |     fixed_candidates_path: None\n00:20:46 |     force_fp16_tokens: True\n00:20:46 |     fp16: True\n00:20:46 |     fp16_impl: safe\n00:20:46 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run4/data_test.txt\n00:20:46 |     fromfile_datatype_extension: True\n00:20:46 |     gpu: -1\n00:20:46 |     gradient_clip: 0.1\n00:20:46 |     hide_labels: False\n00:20:46 |     history_add_global_end_token: None\n00:20:46 |     history_reversed: False\n00:20:46 |     history_size: 20\n00:20:46 |     ignore_bad_candidates: False\n00:20:46 |     ignore_labels: None\n00:20:46 |     image_cropsize: 224\n00:20:46 |     image_mode: raw\n00:20:46 |     image_size: 256\n00:20:46 |     inference: max\n00:20:46 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:20:46 |     init_opt: None\n00:20:46 |     interactive_candidates: fixed\n00:20:46 |     interactive_mode: False\n00:20:46 |     invsqrt_lr_decay_gamma: -1\n00:20:46 |     is_debug: False\n00:20:46 |     label_truncate: 72\n00:20:46 |     learn_embeddings: True\n00:20:46 |     learn_positional_embeddings: True\n00:20:46 |     learningrate: 5e-05\n00:20:46 |     load_from_pretrained_ranker: True\n00:20:46 |     log_every_n_secs: 10.0\n00:20:46 |     log_every_n_steps: 50\n00:20:46 |     log_keep_fields: all\n00:20:46 |     loglevel: info\n00:20:46 |     lr_scheduler: reduceonplateau\n00:20:46 |     lr_scheduler_decay: 0.5\n00:20:46 |     lr_scheduler_patience: 3\n00:20:46 |     max_train_steps: -1\n00:20:46 |     max_train_time: 7200.0\n00:20:46 |     memory_attention: sqrt\n00:20:46 |     metrics: default\n00:20:46 |     model: transformer/classifier\n00:20:46 |     model_file: /tmp/model4\n00:20:46 |     model_parallel: False\n00:20:46 |     momentum: 0\n00:20:46 |     multitask_weights: [1]\n00:20:46 |     mutators: None\n00:20:46 |     n_decoder_layers: -1\n00:20:46 |     n_encoder_layers: -1\n00:20:46 |     n_heads: 12\n00:20:46 |     n_layers: 12\n00:20:46 |     n_positions: 1024\n00:20:46 |     n_segments: 2\n00:20:46 |     nesterov: True\n00:20:46 |     no_cuda: False\n00:20:46 |     normalize_sent_emb: False\n00:20:46 |     num_epochs: -1\n00:20:46 |     num_examples: -1\n00:20:46 |     num_workers: 0\n00:20:46 |     nus: [0.7]\n00:20:46 |     optimizer: adamax\n00:20:46 |     output_scaling: 0.06\n00:20:46 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type2/run4/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model4', 'batchsize': 40}\"\n00:20:46 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n00:20:46 |     person_tokens: False\n00:20:46 |     print_scores: False\n00:20:46 |     rank_candidates: False\n00:20:46 |     rank_top_k: -1\n00:20:46 |     reduction_type: mean\n00:20:46 |     ref_class: None\n00:20:46 |     relu_dropout: 0.0\n00:20:46 |     repeat_blocking_heuristic: True\n00:20:46 |     report_filename: \n00:20:46 |     return_cand_scores: False\n00:20:46 |     save_after_valid: True\n00:20:46 |     save_every_n_secs: -1\n00:20:46 |     save_format: conversations\n00:20:46 |     share_encoders: False\n00:20:46 |     share_word_embeddings: False\n00:20:46 |     short_final_eval: False\n00:20:46 |     special_tok_lst: None\n00:20:46 |     split_lines: False\n00:20:46 |     starttime: Dec04_00-18\n00:20:46 |     task: fromfile:parlaiformat\n00:20:46 |     tensorboard_log: False\n00:20:46 |     tensorboard_logdir: None\n00:20:46 |     text_truncate: 360\n00:20:46 |     threshold: 0.5\n00:20:46 |     topk: 5\n00:20:46 |     train_predict: False\n00:20:46 |     truncate: 1024\n00:20:46 |     update_classifier_head_only: False\n00:20:46 |     update_freq: 1\n00:20:46 |     use_memories: False\n00:20:46 |     use_reply: none\n00:20:46 |     validation_cutoff: 1.0\n00:20:46 |     validation_every_n_epochs: -1\n00:20:46 |     validation_every_n_secs: 20.0\n00:20:46 |     validation_every_n_steps: -1\n00:20:46 |     validation_max_exs: -1\n00:20:46 |     validation_metric: accuracy\n00:20:46 |     validation_metric_mode: max\n00:20:46 |     validation_patience: 30\n00:20:46 |     validation_share_agent: False\n00:20:46 |     variant: xlm\n00:20:46 |     verbose: False\n00:20:46 |     wandb_entity: None\n00:20:46 |     wandb_log: False\n00:20:46 |     wandb_name: None\n00:20:46 |     wandb_project: None\n00:20:46 |     warmup_rate: 0.0001\n00:20:46 |     warmup_updates: 1000\n00:20:46 |     weight_decay: None\n00:20:46 |     world_logs: \n00:20:46 |     wrap_memory_encoder: False\n00:20:47 | Evaluating task fromfile:parlaiformat using datatype valid.\n00:20:47 | creating task(s): fromfile:parlaiformat\n00:20:47 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n00:20:47 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run4/data_test.txt\n00:20:55 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9440 9.44e-10               .7647                 .6594   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9100            .9682              .9896   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9478 12.07 562.9  1843       0          0 130.9 1000 .9440   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .1952 1.065e-05   208 680.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    213 770.9 2524        .9479\u001b[0m\n00:20:55 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9440 9.44e-10               .7647                 .6594   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9100            .9682              .9896   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9478 12.07 562.9  1843       0          0 130.9 1000 .9440   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .1952 1.065e-05   208 680.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    213 770.9 2524        .9479\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model4*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:20:57.162272Z","iopub.execute_input":"2022-12-04T00:20:57.162589Z","iopub.status.idle":"2022-12-04T00:20:58.408929Z","shell.execute_reply.started":"2022-12-04T00:20:57.162557Z","shell.execute_reply":"2022-12-04T00:20:58.407633Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"run 5","metadata":{}},{"cell_type":"code","source":"# run 5 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type2/run5/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model5","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:20:58.411934Z","iopub.execute_input":"2022-12-04T00:20:58.412391Z","iopub.status.idle":"2022-12-04T00:34:03.589099Z","shell.execute_reply.started":"2022-12-04T00:20:58.412348Z","shell.execute_reply":"2022-12-04T00:34:03.587856Z"},"scrolled":true,"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"00:21:05 | building dictionary first...\n00:21:05 | No model with opt yet at: /tmp/model5(.opt)\n00:21:05 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run5/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n00:21:05 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n00:21:05 | Using CUDA\n00:21:05 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n00:21:05 | num words = 54944\n00:21:09 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:21:19 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:21:19 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n00:21:19 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n00:21:19 | Opt:\n00:21:19 |     activation: gelu\n00:21:19 |     adafactor_eps: '(1e-30, 0.001)'\n00:21:19 |     adam_eps: 1e-08\n00:21:19 |     add_p1_after_newln: False\n00:21:19 |     aggregate_micro: False\n00:21:19 |     allow_missing_init_opts: False\n00:21:19 |     attention_dropout: 0.1\n00:21:19 |     batchsize: 20\n00:21:19 |     betas: '(0.9, 0.999)'\n00:21:19 |     bpe_add_prefix_space: None\n00:21:19 |     bpe_debug: False\n00:21:19 |     bpe_dropout: None\n00:21:19 |     bpe_merge: None\n00:21:19 |     bpe_vocab: None\n00:21:19 |     candidates: inline\n00:21:19 |     cap_num_predictions: 100\n00:21:19 |     checkpoint_activations: False\n00:21:19 |     class_weights: None\n00:21:19 |     classes: \"['__notok__', '__ok__']\"\n00:21:19 |     classes_from_file: None\n00:21:19 |     data_parallel: True\n00:21:19 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n00:21:19 |     datatype: train\n00:21:19 |     delimiter: '\\n'\n00:21:19 |     dict_class: parlai.core.dict:DictionaryAgent\n00:21:19 |     dict_endtoken: __start__\n00:21:19 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n00:21:19 |     dict_include_test: False\n00:21:19 |     dict_include_valid: False\n00:21:19 |     dict_initpath: None\n00:21:19 |     dict_language: english\n00:21:19 |     dict_loaded: True\n00:21:19 |     dict_lower: True\n00:21:19 |     dict_max_ngram_size: -1\n00:21:19 |     dict_maxexs: -1\n00:21:19 |     dict_maxtokens: -1\n00:21:19 |     dict_minfreq: 0\n00:21:19 |     dict_nulltoken: __null__\n00:21:19 |     dict_starttoken: __start__\n00:21:19 |     dict_textfields: text,labels\n00:21:19 |     dict_tokenizer: bpe\n00:21:19 |     dict_unktoken: __unk__\n00:21:19 |     display_examples: False\n00:21:19 |     download_path: None\n00:21:19 |     dropout: 0.1\n00:21:19 |     dynamic_batching: None\n00:21:19 |     embedding_projection: random\n00:21:19 |     embedding_size: 768\n00:21:19 |     embedding_type: random\n00:21:19 |     embeddings_scale: False\n00:21:19 |     encode_candidate_vecs: True\n00:21:19 |     encode_candidate_vecs_batchsize: 256\n00:21:19 |     eval_batchsize: None\n00:21:19 |     eval_candidates: inline\n00:21:19 |     eval_dynamic_batching: None\n00:21:19 |     evaltask: None\n00:21:19 |     ffn_size: 3072\n00:21:19 |     final_extra_opt: \n00:21:19 |     fixed_candidate_vecs: reuse\n00:21:19 |     fixed_candidates_path: None\n00:21:19 |     force_fp16_tokens: False\n00:21:19 |     fp16: True\n00:21:19 |     fp16_impl: safe\n00:21:19 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run5/data\n00:21:19 |     fromfile_datatype_extension: True\n00:21:19 |     gpu: -1\n00:21:19 |     gradient_clip: 0.1\n00:21:19 |     hide_labels: False\n00:21:19 |     history_add_global_end_token: None\n00:21:19 |     history_reversed: False\n00:21:19 |     history_size: 20\n00:21:19 |     ignore_bad_candidates: False\n00:21:19 |     ignore_labels: None\n00:21:19 |     image_cropsize: 224\n00:21:19 |     image_mode: raw\n00:21:19 |     image_size: 256\n00:21:19 |     inference: max\n00:21:19 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:21:19 |     init_opt: None\n00:21:19 |     interactive_candidates: fixed\n00:21:19 |     interactive_mode: False\n00:21:19 |     invsqrt_lr_decay_gamma: -1\n00:21:19 |     is_debug: False\n00:21:19 |     label_truncate: 72\n00:21:19 |     learn_embeddings: True\n00:21:19 |     learn_positional_embeddings: True\n00:21:19 |     learningrate: 5e-05\n00:21:19 |     load_from_checkpoint: False\n00:21:19 |     load_from_pretrained_ranker: True\n00:21:19 |     log_every_n_secs: 10.0\n00:21:19 |     log_every_n_steps: 50\n00:21:19 |     log_keep_fields: all\n00:21:19 |     loglevel: info\n00:21:19 |     lr_scheduler: reduceonplateau\n00:21:19 |     lr_scheduler_decay: 0.5\n00:21:19 |     lr_scheduler_patience: 3\n00:21:19 |     max_train_steps: -1\n00:21:19 |     max_train_time: 7200.0\n00:21:19 |     memory_attention: sqrt\n00:21:19 |     metrics: default\n00:21:19 |     model: transformer/classifier\n00:21:19 |     model_file: /tmp/model5\n00:21:19 |     model_parallel: False\n00:21:19 |     momentum: 0\n00:21:19 |     multitask_weights: [1]\n00:21:19 |     mutators: None\n00:21:19 |     n_decoder_layers: -1\n00:21:19 |     n_encoder_layers: -1\n00:21:19 |     n_heads: 12\n00:21:19 |     n_layers: 12\n00:21:19 |     n_positions: 1024\n00:21:19 |     n_segments: 2\n00:21:19 |     nesterov: True\n00:21:19 |     no_cuda: False\n00:21:19 |     normalize_sent_emb: False\n00:21:19 |     num_epochs: -1\n00:21:19 |     num_workers: 0\n00:21:19 |     nus: (0.7,)\n00:21:19 |     optimizer: adamax\n00:21:19 |     output_scaling: 0.06\n00:21:19 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type2/run5/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model5'}\"\n00:21:19 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n00:21:19 |     person_tokens: False\n00:21:19 |     print_scores: False\n00:21:19 |     rank_candidates: False\n00:21:19 |     rank_top_k: -1\n00:21:19 |     reduction_type: mean\n00:21:19 |     ref_class: None\n00:21:19 |     relu_dropout: 0.0\n00:21:19 |     repeat_blocking_heuristic: True\n00:21:19 |     return_cand_scores: False\n00:21:19 |     save_after_valid: True\n00:21:19 |     save_every_n_secs: -1\n00:21:19 |     save_format: conversations\n00:21:19 |     share_encoders: False\n00:21:19 |     share_word_embeddings: False\n00:21:19 |     short_final_eval: False\n00:21:19 |     special_tok_lst: None\n00:21:19 |     split_lines: False\n00:21:19 |     starttime: Dec04_00-21\n00:21:19 |     task: fromfile:parlaiformat\n00:21:19 |     tensorboard_log: False\n00:21:19 |     tensorboard_logdir: None\n00:21:19 |     text_truncate: 360\n00:21:19 |     threshold: 0.5\n00:21:19 |     topk: 5\n00:21:19 |     train_predict: False\n00:21:19 |     truncate: 1024\n00:21:19 |     update_classifier_head_only: False\n00:21:19 |     update_freq: 1\n00:21:19 |     use_memories: False\n00:21:19 |     use_reply: none\n00:21:19 |     validation_cutoff: 1.0\n00:21:19 |     validation_every_n_epochs: -1\n00:21:19 |     validation_every_n_secs: 20.0\n00:21:19 |     validation_every_n_steps: -1\n00:21:19 |     validation_max_exs: -1\n00:21:19 |     validation_metric: accuracy\n00:21:19 |     validation_metric_mode: max\n00:21:19 |     validation_patience: 30\n00:21:19 |     validation_share_agent: False\n00:21:19 |     variant: xlm\n00:21:19 |     verbose: False\n00:21:19 |     wandb_entity: None\n00:21:19 |     wandb_log: False\n00:21:19 |     wandb_name: None\n00:21:19 |     wandb_project: None\n00:21:19 |     warmup_rate: 0.0001\n00:21:19 |     warmup_updates: 1000\n00:21:19 |     weight_decay: None\n00:21:19 |     world_logs: \n00:21:19 |     wrap_memory_encoder: False\n00:21:20 | creating task(s): fromfile:parlaiformat\n00:21:20 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run5/data_train.txt\n00:21:20 | training...\n00:21:30 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .4675 4.675e-10               .4662                 .4973   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .4387            .4688              .4413   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .5000 11.93     1 278.5 552.8       0          0 39.69  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .4675             32768   2.51    .1206  6.06 .6958 1.005e-06 121.2 240.6   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 399.7 793.3 1.989        .4674\n\n00:21:40 | time:20s total_exs:1180 total_steps:59 epochs:5.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6231 6.231e-10               .6886                 .6214   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7720            .5227              .6265   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .4485  11.9     1 278.1  1101       0          0 79.19  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6231             32768  2.527    .1207 6.079 .6737 2.955e-06 121.6 481.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   59 399.6 1582 3.969        .6122\n\n00:21:40 | creating task(s): fromfile:parlaiformat\n00:21:40 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run5/data_valid.txt\n00:21:40 | running eval: valid\n00:21:40 | eval completed in 0.19s\n00:21:40 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5833 5.833e-10               .6667                 .5556   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .4444              .6667   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .3333 10.67   152  1805       0          0 142.4   24 .5833   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6643 2.955e-06    72 854.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                     59  224 2660        .5556\n\u001b[0m\n00:21:40 | \u001b[1;32mnew best accuracy: 0.5833\u001b[0m\n00:21:40 | saving best valid model: /tmp/model5\n00:21:40 | Saving dictionary to /tmp/model5.dict\n00:21:45 | saving model checkpoint: /tmp/model5.checkpoint\n00:21:45 | Saving dictionary to /tmp/model5.checkpoint.dict\n00:22:01 | time:42s total_exs:1900 total_steps:95 epochs:9.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7847 7.847e-10               .8126                 .7134   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9438            .7471              .9197   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6291 11.71     1 274.2 970.3       0          0 70.76  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7847             32768  2.681    .1207 5.989 .6210 4.755e-06 119.8 423.8   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                   95  394 1394 3.546        .7795\n\n00:22:05 | time:45s total_exs:2160 total_steps:108 epochs:10.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8846 8.846e-10               .8819                 .8960   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8682            .8872              .8741   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9008 12.35     1 287.1  1135       0          0 79.05  260   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8846             32768  3.237    .1207 5.992 .5667 5.404e-06 119.8 473.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  108 406.9 1608 3.98        .8846\n\n00:22:05 | running eval: valid\n00:22:05 | eval completed in 0.22s\n00:22:05 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1599       0          0 126.2   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5409 5.404e-06    72 757.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    108  224 2357        .8748\n\u001b[0m\n00:22:05 | \u001b[1;32mnew best accuracy: 0.875 (previous best was 0.5833)\u001b[0m\n00:22:05 | saving best valid model: /tmp/model5\n00:22:14 | saving model checkpoint: /tmp/model5.checkpoint\n00:22:30 | time:70s total_exs:2960 total_steps:148 epochs:14.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9062 9.062e-10               .9042                 .9054   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9031            .9082              .9071   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9093 11.73     1 274.5  1069       0          0 77.91  800   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9062             32768  3.816    .1207  5.98 .4521 7.404e-06 119.6 465.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  148 394.1 1535 3.903        .9062\n\n00:22:35 | time:75s total_exs:3320 total_steps:166 epochs:16.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9500 9.5e-10               .9497                 .9551   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9444            .9503              .9451   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9556 11.79     1 275.8  1075       0          0 77.99  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9500             32768  5.177    .1189     6 .2873 8.304e-06   120   468   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  166 395.8 1543 3.919        .9500\n\n00:22:35 | running eval: valid\n00:22:35 | eval completed in 0.19s\n00:22:35 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1768       0          0 139.5   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .2752 8.304e-06    72 837.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    166  224 2605        .9167\n\u001b[0m\n00:22:35 | \u001b[1;32mnew best accuracy: 0.9167 (previous best was 0.875)\u001b[0m\n00:22:35 | saving best valid model: /tmp/model5\n00:22:45 | saving model checkpoint: /tmp/model5.checkpoint\n00:23:00 | time:101s total_exs:4120 total_steps:206 epochs:20.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9525 9.525e-10               .9530                 .9625   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9436            .9520              .9425   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9617 11.88     1 277.5  1086       0          0 78.28  800   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9525             32768  5.541    .1207  6.02 .1947 1.03e-05 120.4 471.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  206 397.9 1557 3.923        .9525\n\n00:23:05 | time:105s total_exs:4480 total_steps:224 epochs:22.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9444 9.444e-10               .9422                 .9477   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9368            .9465              .9415   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9516  11.6     1   272  1047       0          0 76.99  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9444             32768  5.072    .1207 5.967 .1881 1.12e-05 119.3 459.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  224 391.3 1506 3.868        .9444\n\n00:23:05 | running eval: valid\n00:23:05 | eval completed in 0.19s\n00:23:05 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1810       0          0 142.9   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .2439 1.12e-05    72 857.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    224  224 2668        .9167\n\u001b[0m\n00:23:05 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 1\u001b[0m\n00:23:05 | saving model checkpoint: /tmp/model5.checkpoint\n00:23:21 | time:121s total_exs:5260 total_steps:263 epochs:26.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9769 9.769e-10               .9767                 .9793   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9742            .9771              .9746   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9796 11.81     1 276.2  1071       0          0 77.53  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9769             32768  3.661    .1207 5.995 .08771 1.315e-05 119.9 464.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  263 396.1 1536 3.886        .9769\n\n00:23:25 | time:126s total_exs:5640 total_steps:282 epochs:28.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9842 9.842e-10               .9841                 .9789   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9894            .9843              .9895   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9792 11.69     1 273.9  1073       0          0 78.37  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9842             32768  9.655    .1207 5.989 .06469 1.41e-05 119.8 469.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  282 393.7 1543 3.937        .9842\n\n00:23:25 | running eval: valid\n00:23:26 | eval completed in 0.19s\n00:23:26 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1784       0          0 140.8   24 .9583   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .2554 1.41e-05    72 844.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    282  224 2629        .9583\n\u001b[0m\n00:23:26 | \u001b[1;32mnew best accuracy: 0.9583 (previous best was 0.9167)\u001b[0m\n00:23:26 | saving best valid model: /tmp/model5\n00:23:30 | saving model checkpoint: /tmp/model5.checkpoint\n00:23:48 | time:148s total_exs:6420 total_steps:321 epochs:32.10\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9910 9.91e-10               .9915                 .9878   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9951            .9906              .9946   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9866 11.73 .4359 274.7  1062       0          0 77.29  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9910             32768  4.252    .1207 6.046 .04071 1.605e-05 120.9 467.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  321 395.6 1529 3.873        .9910\n\n00:23:50 | time:150s total_exs:6560 total_steps:328 epochs:32.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.49 .4286 269.9  1075       0          0 79.67  140   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768  2.313    .1190   5.9 .003546 1.64e-05   118   470   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  328 387.9 1545 4.036            1\n\n00:23:50 | running eval: valid\n00:23:50 | eval completed in 0.19s\n00:23:50 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1814       0          0 143.2   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 .5243 1.64e-05    72 859.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    328  224 2673        .9161\n\u001b[0m\n00:23:50 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 1\u001b[0m\n00:23:50 | saving model checkpoint: /tmp/model5.checkpoint\n00:24:09 | time:170s total_exs:7340 total_steps:367 epochs:36.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9987                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9974            .9987              .9975   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.74 .1538 274.8  1057       0          0 76.89  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9987             32768  1.029    .1207 5.982 .009246 1.835e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     460       0          0                  367 394.5 1517 3.853        .9987\n\n00:24:10 | time:170s total_exs:7380 total_steps:369 epochs:36.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.25     0   285  1149       0          0 80.62   40   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01835    .1207  6.05 .001566 1.845e-05   121 487.8   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  369  406 1637 4.221            1\n\n00:24:10 | running eval: valid\n00:24:10 | eval completed in 0.19s\n00:24:10 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1779       0          0 140.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 .5779 1.845e-05    72 842.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    369  224 2621        .8748\n\u001b[0m\n00:24:10 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 2\u001b[0m\n00:24:10 | saving model checkpoint: /tmp/model5.checkpoint\n00:24:25 | time:185s total_exs:8180 total_steps:409 epochs:40.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.88     0 277.6  1087       0          0 78.27  800   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01847    .1207  6.03 .001409 2.045e-05 120.6   472   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  409 398.2 1559 3.922            1\n\n00:24:30 | time:190s total_exs:8600 total_steps:430 epochs:43.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.83 .04762 276.5  1088       0          0 78.67   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  \\\n    420   1             32768 .02518    .1207 6.105 .00125 2.15e-05 122.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   480.3       0          0                  430 398.6 1568 3.95            1\n\n00:24:30 | running eval: valid\n00:24:30 | eval completed in 0.19s\n00:24:30 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1796       0          0 141.8   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08095     6 .6413 2.15e-05    72 850.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    430  224 2647        .8748\n\u001b[0m\n00:24:30 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 3\u001b[0m\n00:24:30 | saving model checkpoint: /tmp/model5.checkpoint\n00:24:45 | time:205s total_exs:9360 total_steps:468 epochs:46.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1  11.7 .02632 273.9  1036       0          0 75.63   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  \\\n    760   1             32768  .0180    .1207 6.008 .001126 2.34e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   454.4       0          0                  468 394.1 1490 3.79            1\n\n00:24:50 | time:211s total_exs:9800 total_steps:490 epochs:49.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.94     0 278.7  1098       0          0 78.76  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .01412    .1207 5.995 .001035 2.45e-05 119.9 472.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  490 398.6 1570 3.954            1\n\n00:24:50 | running eval: valid\n00:24:51 | eval completed in 0.19s\n00:24:51 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1788       0          0 141.1   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 .5783 2.45e-05    72 846.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    490  224 2635        .9161\n\u001b[0m\n00:24:51 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 4\u001b[0m\n00:24:51 | saving model checkpoint: /tmp/model5.checkpoint\n00:25:05 | time:225s total_exs:10580 total_steps:529 epochs:52.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.53     0 270.5  1056       0          0 78.05  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01202    .1207 6.028 .0009615 2.645e-05 120.6 470.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  529 391.1 1526 3.911            1\n\n00:25:11 | time:231s total_exs:11040 total_steps:552 epochs:55.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.64     0 272.8  1058       0          0 77.54  460   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .01043    .1207 6.004 .0008911 2.76e-05 120.1 465.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  552 392.9 1523 3.892            1\n\n00:25:11 | running eval: valid\n00:25:11 | eval completed in 0.19s\n00:25:11 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1777       0          0 140.2   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 .5906 2.76e-05    72 841.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    552  224 2619        .9161\n\u001b[0m\n00:25:11 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 5\u001b[0m\n00:25:11 | saving model checkpoint: /tmp/model5.checkpoint\n00:25:25 | time:246s total_exs:11820 total_steps:591 epochs:59.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.92     0 278.5  1087       0          0 78.06  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .009842    .1207 6.005 .000833 2.955e-05 120.1 468.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  591 398.6 1556 3.912            1\n\n00:25:31 | time:251s total_exs:12260 total_steps:613 epochs:61.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.92     0 278.4  1112       0          0 79.88  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .009107    .1190 5.991 .0007775 3.065e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   478.5       0          0                  613 398.2 1590 4.01            1\n\n00:25:31 | running eval: valid\n00:25:31 | eval completed in 0.19s\n00:25:31 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1768       0          0 139.5   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 .6122 3.065e-05    72 837.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    613  224 2605        .9161\n\u001b[0m\n00:25:31 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 6\u001b[0m\n00:25:31 | saving model checkpoint: /tmp/model5.checkpoint\n00:25:46 | time:266s total_exs:13020 total_steps:651 epochs:65.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.73     0 274.6  1040       0          0 75.79  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .008638    .1208 6.084 .0007323 3.255e-05 121.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.1       0          0                  651 396.2 1502 3.798            1\n\n00:25:51 | time:272s total_exs:13480 total_steps:674 epochs:67.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0 275.9  1099       0          0 79.66  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .008219    .1208 6.013 .0006836 3.37e-05 120.3   479   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  674 396.2 1578 3.998            1\n\n00:25:51 | running eval: valid\n00:25:52 | eval completed in 0.19s\n00:25:52 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1781       0          0 140.6   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 .6228 3.37e-05    72 843.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    674  224 2625        .9161\n\u001b[0m\n00:25:52 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 7\u001b[0m\n00:25:52 | saving model checkpoint: /tmp/model5.checkpoint\n00:26:06 | time:286s total_exs:14280 total_steps:714 epochs:71.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8 .0250 275.9  1088       0          0 78.84  800   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768   3.39    .1190 5.997 .001033 3.57e-05   120 472.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  714 395.9 1561 3.951            1\n\n00:26:12 | time:292s total_exs:14700 total_steps:735 epochs:73.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.7     0   274  1044       0          0 76.19  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .007033    .1208 6.024 .0006019 3.675e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.9       0          0                  735 394.5 1503 3.825            1\n\n00:26:12 | running eval: valid\n00:26:12 | eval completed in 0.22s\n00:26:12 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1544       0          0 121.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 .6214 3.675e-05    72 731.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    735  224 2276        .9161\n\u001b[0m\n00:26:12 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 8\u001b[0m\n00:26:12 | saving model checkpoint: /tmp/model5.checkpoint\n00:26:26 | time:307s total_exs:15500 total_steps:775 epochs:77.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.72     0 274.4  1071       0          0 78.09  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006611    .1208 6.005 .0005623 3.875e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   468.9       0          0                  775 394.4 1540 3.913            1\n\n00:26:32 | time:312s total_exs:15940 total_steps:797 epochs:79.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.89     0 277.8  1091       0          0 78.54  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006178    .1191 6.036 .0005272 3.985e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   474.1       0          0                  797 398.5 1565 3.943            1\n\n00:26:32 | running eval: valid\n00:26:32 | eval completed in 0.19s\n00:26:32 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1747       0          0 137.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 .6277 3.985e-05    72 827.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    797  224 2575        .9161\n\u001b[0m\n00:26:32 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 9\u001b[0m\n00:26:32 | saving model checkpoint: /tmp/model5.checkpoint\n00:26:47 | time:327s total_exs:16700 total_steps:835 epochs:83.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.57 .02632 271.4  1020       0          0 75.17   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n    760   1             32768 .03334    .1208  6.05 .0005019 4.175e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   454.8       0          0                  835 392.4 1475 3.767            1\n\n00:26:52 | time:333s total_exs:17140 total_steps:857 epochs:85.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9977 9.977e-10               .9978                 .9955   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9977                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                  .9954 11.72 .04545 274.4  1070       0          0 77.99   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  \\\n    440 .9977             32768  16.34    .1191 6.014 .01132 4.285e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     469       0          0                  857 394.6 1539 3.915        .9977\n\n00:26:52 | running eval: valid\n00:26:53 | eval completed in 0.19s\n00:26:53 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1766       0          0 139.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 .9946 4.285e-05    72 836.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    857  224 2603        .8730\n\u001b[0m\n00:26:53 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 10\u001b[0m\n00:26:53 | saving model checkpoint: /tmp/model5.checkpoint\n00:27:07 | time:347s total_exs:17940 total_steps:897 epochs:89.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.86 .0250 277.1  1086       0          0 78.37  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .007942    .1208 6.018 .000438 4.485e-05 120.3 471.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  897 397.5 1558 3.927            1\n\n00:27:13 | time:353s total_exs:18380 total_steps:919 epochs:91.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.14     0 282.8  1121       0          0 79.28  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004766    .1208 5.914 .0004066 4.595e-05 118.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   468.8       0          0                  919 401.1 1590 3.982            1\n\n00:27:13 | running eval: valid\n00:27:13 | eval completed in 0.22s\n00:27:13 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1609       0          0 126.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 .4008 4.595e-05    72 761.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    919  224 2370        .9161\n\u001b[0m\n00:27:13 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 11\u001b[0m\n00:27:13 | saving model checkpoint: /tmp/model5.checkpoint\n00:27:28 | time:368s total_exs:19180 total_steps:959 epochs:95.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.51     0 270.1  1056       0          0 78.21  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004463    .1208 5.973 .0003811 4.795e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   467.1       0          0                  959 389.6 1523 3.919            1\n\n00:27:33 | time:373s total_exs:19600 total_steps:980 epochs:98.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.75     0   275  1103       0          0 80.22  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss      lr  ltpb  ltps  \\\n     1             32768 .006311    .1208 5.957 .0003592 4.9e-05 119.1 477.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  980 394.2 1581 4.029            1\n\n00:27:33 | running eval: valid\n00:27:33 | eval completed in 0.19s\n00:27:33 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 10.67   152  1782       0          0 140.6   24 .8750   \n    gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6 .9984 4.9e-05    72   844       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    980  224 2627        .8748\n\u001b[0m\n00:27:33 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 12\u001b[0m\n00:27:33 | saving model checkpoint: /tmp/model5.checkpoint\n00:27:48 | time:388s total_exs:20360 total_steps:1018 epochs:101.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.93     0 278.6  1052       0          0 75.51  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003942    .1208 6.047 .0003359 4.995e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.6       0          0                 1018 399.6 1509 3.784            1\n\n00:27:53 | time:394s total_exs:20800 total_steps:1040 epochs:104.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.02     0 280.4  1118       0          0 79.76  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003708    .1208 6.041 .0003159 4.995e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   481.9       0          0                 1040 401.2 1600 4.005            1\n\n00:27:53 | running eval: valid\n00:27:54 | eval completed in 0.19s\n00:27:54 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1772       0          0 139.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 .6870 4.995e-05    72 839.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1040  224 2612        .9161\n\u001b[0m\n00:27:54 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 13\u001b[0m\n00:27:54 | saving model checkpoint: /tmp/model5.checkpoint\n00:28:08 | time:408s total_exs:21600 total_steps:1080 epochs:108.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.72     0 274.5  1076       0          0 78.38  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003472    .1208 5.985 .0002961 4.995e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   469.1       0          0                 1080 394.2 1545 3.928            1\n\n00:28:14 | time:414s total_exs:22040 total_steps:1102 epochs:110.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  12.2     0 284.1  1139       0          0 80.17  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .003274    .1208 6.055 .000279 4.995e-05 121.1 485.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1102 405.2 1624 4.025            1\n\n00:28:14 | running eval: valid\n00:28:14 | eval completed in 0.19s\n00:28:14 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1795       0          0 141.6   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 .7075 4.995e-05    72 849.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1102  224 2645        .9161\n\u001b[0m\n00:28:14 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 14\u001b[0m\n00:28:14 | saving model checkpoint: /tmp/model5.checkpoint\n00:28:28 | time:429s total_exs:22820 total_steps:1141 epochs:114.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.86     0 277.2  1059       0          0 76.39  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .003091    .1208 5.992 .000263 4.995e-05 119.8 457.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1141 397.1 1517 3.828            1\n\n00:28:34 | time:434s total_exs:23240 total_steps:1162 epochs:116.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.99     0 279.8  1098       0          0 78.45  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002925    .1191 6.086 .0002492 4.995e-05 121.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   477.4       0          0                 1162 401.5 1575 3.939            1\n\n00:28:34 | running eval: valid\n00:28:34 | eval completed in 0.19s\n00:28:34 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1772       0          0 139.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 .7149 4.995e-05    72 839.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1162  224 2612        .9161\n\u001b[0m\n00:28:34 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 15\u001b[0m\n00:28:34 | saving model checkpoint: /tmp/model5.checkpoint\n00:28:48 | time:449s total_exs:24020 total_steps:1201 epochs:120.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.86     0 277.1  1077       0          0 77.72  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002766    .1209 5.987 .0002356 4.995e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   465.4       0          0                 1201 396.9 1542 3.895            1\n\n00:28:54 | time:454s total_exs:24460 total_steps:1223 epochs:122.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.69     0 273.9  1039       0          0 75.84  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002643    .1209 6.114 .0002239 4.995e-05 122.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.7       0          0                 1223 396.1 1502 3.807            1\n\n00:28:54 | running eval: valid\n00:28:54 | eval completed in 0.19s\n00:28:54 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1741       0          0 137.4   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6 .7235 4.995e-05    72 824.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1223  224 2566        .9161\n\u001b[0m\n00:28:54 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 16\u001b[0m\n00:28:54 | saving model checkpoint: /tmp/model5.checkpoint\n00:29:09 | time:469s total_exs:25260 total_steps:1263 epochs:126.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.75     0   275  1076       0          0 78.24  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .002492    .1209 6.062 .000212 4.995e-05 121.2 474.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1263 396.3 1550 3.921            1\n\n00:29:14 | time:475s total_exs:25700 total_steps:1285 epochs:128.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.93     0 278.5  1093       0          0 78.49  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00236    .1209 6.014 .0002009 4.995e-05 120.3   472   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1285 398.8 1565 3.941            1\n\n00:29:14 | running eval: valid\n00:29:15 | eval completed in 0.19s\n00:29:15 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1776       0          0 140.2   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 .7317 4.995e-05    72 841.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1285  224 2618        .9161\n\u001b[0m\nEpoch 00005: reducing learning rate of group 0 to 2.4975e-05.\n00:29:15 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 17\u001b[0m\n00:29:15 | saving model checkpoint: /tmp/model5.checkpoint\n00:29:29 | time:489s total_exs:26460 total_steps:1323 epochs:132.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.57     0 271.5  1031       0          0 75.96  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002282    .1209 5.989 .0001941 2.498e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     455       0          0                 1323 391.3 1486 3.807            1\n\n00:29:35 | time:495s total_exs:26920 total_steps:1346 epochs:134.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.7     0   274  1099       0          0 80.21  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002263    .1209 6.065 .0001895 2.498e-05 121.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   486.5       0          0                 1346 395.3 1585 4.026            1\n\n00:29:35 | running eval: valid\n00:29:35 | eval completed in 0.19s\n00:29:35 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1763       0          0 139.1   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 .7348 2.498e-05    72 834.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1346  224 2597        .9161\n\u001b[0m\n00:29:35 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 18\u001b[0m\n00:29:35 | saving model checkpoint: /tmp/model5.checkpoint\n00:29:49 | time:510s total_exs:27700 total_steps:1385 epochs:138.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.79     0 275.8  1075       0          0 77.97  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002169    .1209 6.069 .0001845 2.498e-05 121.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   473.2       0          0                 1385 397.2 1549 3.907            1\n\n00:29:55 | time:515s total_exs:28140 total_steps:1407 epochs:140.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.99     0 279.8  1079       0          0 77.14  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002112    .1209 5.986 .0001797 2.498e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.8       0          0                 1407 399.5 1541 3.873            1\n\n00:29:55 | running eval: valid\n00:29:55 | eval completed in 0.19s\n00:29:55 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1727       0          0 136.3   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 .7404 2.498e-05    72 818.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1407  224 2545        .9161\n\u001b[0m\n00:29:55 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 19\u001b[0m\n00:29:55 | saving model checkpoint: /tmp/model5.checkpoint\n00:30:10 | time:530s total_exs:28940 total_steps:1447 epochs:144.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.79     0 275.8  1082       0          0 78.46  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002059    .1209 6.018 .0001751 2.498e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   472.1       0          0                 1447 396.1 1554 3.932            1\n\n00:30:15 | time:536s total_exs:29380 total_steps:1469 epochs:146.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.1  1102       0          0 80.42  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002007    .1192 6.055 .0001708 2.498e-05 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   486.9       0          0                 1469 395.2 1589 4.038            1\n\n00:30:15 | running eval: valid\n00:30:16 | eval completed in 0.19s\n00:30:16 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1818       0          0 143.4   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6 .7461 2.498e-05    72   861       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1469  224 2679        .9161\n\u001b[0m\n00:30:16 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 20\u001b[0m\n00:30:16 | saving model checkpoint: /tmp/model5.checkpoint\n00:30:30 | time:550s total_exs:30160 total_steps:1508 epochs:150.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.64     0 272.7  1053       0          0 77.25  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001957    .1209 6.044 .0001663 2.498e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   466.9       0          0                 1508 393.6 1520 3.871            1\n\n00:30:36 | time:556s total_exs:30600 total_steps:1530 epochs:153.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0   276  1078       0          0 78.11  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001906    .1209 6.036 .0001621 2.498e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   471.5       0          0                 1530 396.7 1549 3.921            1\n\n00:30:36 | running eval: valid\n00:30:36 | eval completed in 0.19s\n00:30:36 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1800       0          0 142.1   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 .7512 2.498e-05    72 852.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1530  224 2653        .9161\n\u001b[0m\nEpoch 00009: reducing learning rate of group 0 to 1.2488e-05.\n00:30:36 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 21\u001b[0m\n00:30:36 | saving model checkpoint: /tmp/model5.checkpoint\n00:30:50 | time:571s total_exs:31400 total_steps:1570 epochs:157.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.57     0 271.5  1063       0          0 78.32  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001871    .1209  6.06 .0001591 1.249e-05 121.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   474.6       0          0                 1570 392.7 1538 3.925            1\n\n00:30:56 | time:576s total_exs:31840 total_steps:1592 epochs:159.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.91     0 278.1  1091       0          0 78.48  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001844    .1209 6.036 .0001568 1.249e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   473.8       0          0                 1592 398.9 1565 3.94            1\n\n00:30:56 | running eval: valid\n00:30:56 | eval completed in 0.23s\n00:30:56 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1557       0          0 122.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 .7536 1.249e-05    72 737.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1592  224 2295        .9161\n\u001b[0m\n00:30:56 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 22\u001b[0m\n00:30:56 | saving model checkpoint: /tmp/model5.checkpoint\n00:31:11 | time:591s total_exs:32620 total_steps:1631 epochs:163.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.44     0 268.8  1044       0          0 77.69  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001823    .1209 6.036 .000155 1.249e-05 120.7 468.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1631 389.5 1513 3.893            1\n\n00:31:16 | time:596s total_exs:33040 total_steps:1652 epochs:165.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.09     0 281.8  1104       0          0 78.35  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001807    .1209 6.138 .0001529 1.249e-05 122.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   480.9       0          0                 1652 404.5 1585 3.934            1\n\n00:31:16 | running eval: valid\n00:31:16 | eval completed in 0.19s\n00:31:16 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1731       0          0 136.6   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 .7551 1.249e-05    72 819.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1652  224 2550        .9161\n\u001b[0m\n00:31:16 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 23\u001b[0m\n00:31:16 | saving model checkpoint: /tmp/model5.checkpoint\n00:31:31 | time:611s total_exs:33800 total_steps:1690 epochs:169.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.67     0 273.4  1037       0          0 75.86  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001773    .1210 6.045 .0001507 1.249e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.6       0          0                 1690 394.3 1496 3.802            1\n\n00:31:36 | time:617s total_exs:34260 total_steps:1713 epochs:171.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.87     0 277.5  1108       0          0 79.83  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001748    .1210 6.096 .0001486 1.249e-05 121.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   486.6       0          0                 1713 399.4 1594 4.007            1\n\n00:31:36 | running eval: valid\n00:31:37 | eval completed in 0.21s\n00:31:37 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1562       0          0 123.3   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 .7573 1.249e-05    72 739.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1713  224 2301        .9161\n\u001b[0m\n00:31:37 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 24\u001b[0m\n00:31:37 | saving model checkpoint: /tmp/model5.checkpoint\n00:31:51 | time:631s total_exs:35060 total_steps:1753 epochs:175.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.82     0 276.4  1086       0          0 78.56  800   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00172    .1210  5.98 .0001462 1.249e-05 119.6 469.8   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1753  396 1555 3.937            1\n\n00:31:57 | time:637s total_exs:35520 total_steps:1776 epochs:177.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.91     0 278.3  1114       0          0  80.1  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002471    .1210 6.078 .0001447 1.249e-05 121.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   486.8       0          0                 1776 399.8 1601 4.02            1\n\n00:31:57 | running eval: valid\n00:31:57 | eval completed in 0.19s\n00:31:57 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1805       0          0 142.4   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 .7648 1.249e-05    72 854.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1776  224 2660        .9161\n\u001b[0m\nEpoch 00013: reducing learning rate of group 0 to 6.2438e-06.\n00:31:57 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 25\u001b[0m\n00:31:57 | saving model checkpoint: /tmp/model5.checkpoint\n00:32:12 | time:652s total_exs:36320 total_steps:1816 epochs:181.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.85     0 277.1  1094       0          0 79.01  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001682    .1210     6 .0001426 6.244e-06   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   474.1       0          0                 1816 397.1 1569 3.959            1\n\n00:32:17 | time:657s total_exs:36720 total_steps:1836 epochs:183.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.2  1100       0          0 80.23  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00167    .1210 6.055 .0001417 6.244e-06 121.1 485.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1836 395.4 1586 4.03            1\n\n00:32:17 | running eval: valid\n00:32:17 | eval completed in 0.19s\n00:32:17 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1760       0          0 138.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 .7657 6.244e-06    72 833.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1836  224 2593        .9161\n\u001b[0m\n00:32:17 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 26\u001b[0m\n00:32:17 | saving model checkpoint: /tmp/model5.checkpoint\n00:32:32 | time:672s total_exs:37520 total_steps:1876 epochs:187.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.66     0 273.2  1067       0          0 78.08  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001655    .1210 6.027 .0001405 6.244e-06 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   470.7       0          0                 1876 393.8 1537 3.906            1\n\n00:32:38 | time:678s total_exs:37940 total_steps:1897 epochs:189.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.5     0 270.1  1034       0          0 76.58  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001648    .1210  6.09 .0001397 6.244e-06 121.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   466.4       0          0                 1897 391.9 1501 3.845            1\n\n00:32:38 | running eval: valid\n00:32:38 | eval completed in 0.19s\n00:32:38 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1746       0          0 137.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08122     6 .7666 6.244e-06    72 826.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1897  224 2573        .9161\n\u001b[0m\n00:32:38 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 27\u001b[0m\n00:32:38 | saving model checkpoint: /tmp/model5.checkpoint\n00:32:52 | time:693s total_exs:38740 total_steps:1937 epochs:193.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.9     0   278  1094       0          0 78.71  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001627    .1210 6.055 .0001382 6.244e-06 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   476.6       0          0                 1937 399.1 1571 3.944            1\n\n00:32:58 | time:698s total_exs:39180 total_steps:1959 epochs:195.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  12.1     0 281.9  1102       0          0 78.19  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00161    .1210 6.005 .0001368 6.244e-06 120.1 469.5   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1959  402 1572 3.925            1\n\n00:32:58 | running eval: valid\n00:32:58 | eval completed in 0.19s\n00:32:58 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1810       0          0 142.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08124     6 .7677 6.244e-06    72 857.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1959  224 2668        .9161\n\u001b[0m\n00:32:58 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 28\u001b[0m\n00:32:58 | saving model checkpoint: /tmp/model5.checkpoint\n00:33:12 | time:713s total_exs:39960 total_steps:1998 epochs:199.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0 275.9  1066       0          0 77.29  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001603    .1210 6.079 .000136 6.244e-06 121.6 469.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1998 397.5 1536 3.873            1\n\n00:33:18 | time:719s total_exs:40420 total_steps:2021 epochs:202.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.89     0 277.8  1089       0          0 78.42  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             64111 .001588    .1210 6.043 .0001347 6.244e-06 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   473.9       0          0                 2021 398.7 1563 3.936            1\n\n00:33:18 | running eval: valid\n00:33:19 | eval completed in 0.19s\n00:33:19 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1746       0          0 137.8   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08125     6 .7687 6.244e-06    72 826.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   2021  224 2573        .9161\n\u001b[0m\nEpoch 00017: reducing learning rate of group 0 to 3.1219e-06.\n00:33:19 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 29\u001b[0m\n00:33:19 | saving model checkpoint: /tmp/model5.checkpoint\n00:33:33 | time:733s total_exs:41220 total_steps:2061 epochs:206.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.54     0 270.8  1063       0          0 78.52  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             65536 .001577    .1210 6.075 .0001339 3.122e-06 121.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     477       0          0                 2061 392.3 1540 3.935            1\n\n00:33:39 | time:739s total_exs:41640 total_steps:2082 epochs:208.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.72 .04762 274.3  1040       0          0  75.8   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n    420   1             65536  .0219    .1210 6.014 .0001374 3.122e-06 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   455.9       0          0                 2082 394.6 1496 3.805            1\n\n00:33:39 | running eval: valid\n00:33:39 | eval completed in 0.19s\n00:33:39 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1814       0          0 143.2   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08126     6 .7671 3.122e-06    72 859.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   2082  224 2674        .9161\n\u001b[0m\n00:33:39 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 30\u001b[0m\n00:33:39 | saving model checkpoint: /tmp/model5.checkpoint\n00:33:43 | ran out of patience! stopping training.\n00:33:43 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n00:33:43 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n00:33:43 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run5/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n00:33:43 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n00:33:43 | Using CUDA\n00:33:43 | loading dictionary from /tmp/model5.dict\n00:33:43 | num words = 54944\n00:33:48 | Loading existing model parameters from /tmp/model5\n00:33:55 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:33:56 | creating task(s): fromfile:parlaiformat\n00:33:56 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run5/data_valid.txt\n00:33:56 | running eval: valid\n00:33:57 | eval completed in 0.29s\n00:33:57 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1201       0          0 94.73   24 .9583   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298     6 .2554 1.41e-05    72 568.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    282  224 1770        .9583\n\u001b[0m\n00:33:57 | creating task(s): fromfile:parlaiformat\n00:33:57 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run5/data_test.txt\n00:33:57 | running eval: test\n00:34:01 | eval completed in 4.79s\n00:34:01 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9190 9.19e-10               .7011                 .5556   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9532              .9940   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9156 12.07 281.4  2952       0          0 209.7 1000 .9190   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298   5.2 .3024 1.41e-05   104  1091       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    282 385.4 4042        .9279\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev1corr2type2/run5/data_test.txt -m transformer/classifier -mf /tmp/model5 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:34:03.593445Z","iopub.execute_input":"2022-12-04T00:34:03.593856Z","iopub.status.idle":"2022-12-04T00:34:33.697735Z","shell.execute_reply.started":"2022-12-04T00:34:03.593812Z","shell.execute_reply":"2022-12-04T00:34:33.696534Z"},"scrolled":true,"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"00:34:12 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev1corr2type2/run5/data_test.txt (previously: ../input/comp599projproposed/proposed/prev1corr2type2/run5/data)\u001b[0m\n00:34:12 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n00:34:12 | Using CUDA\n00:34:12 | loading dictionary from /tmp/model5.dict\n00:34:12 | num words = 54944\n00:34:16 | Loading existing model parameters from /tmp/model5\n00:34:22 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:34:23 | Opt:\n00:34:23 |     activation: gelu\n00:34:23 |     adafactor_eps: '[1e-30, 0.001]'\n00:34:23 |     adam_eps: 1e-08\n00:34:23 |     add_p1_after_newln: False\n00:34:23 |     aggregate_micro: False\n00:34:23 |     allow_missing_init_opts: False\n00:34:23 |     area_under_curve_class: None\n00:34:23 |     area_under_curve_digits: -1\n00:34:23 |     attention_dropout: 0.1\n00:34:23 |     batchsize: 40\n00:34:23 |     betas: '[0.9, 0.999]'\n00:34:23 |     bpe_add_prefix_space: None\n00:34:23 |     bpe_debug: False\n00:34:23 |     bpe_dropout: None\n00:34:23 |     bpe_merge: None\n00:34:23 |     bpe_vocab: None\n00:34:23 |     candidates: inline\n00:34:23 |     cap_num_predictions: 100\n00:34:23 |     checkpoint_activations: False\n00:34:23 |     class_weights: None\n00:34:23 |     classes: \"['__notok__', '__ok__']\"\n00:34:23 |     classes_from_file: None\n00:34:23 |     data_parallel: True\n00:34:23 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n00:34:23 |     datatype: train\n00:34:23 |     delimiter: '\\n'\n00:34:23 |     dict_class: parlai.core.dict:DictionaryAgent\n00:34:23 |     dict_endtoken: __start__\n00:34:23 |     dict_file: /tmp/model5.dict\n00:34:23 |     dict_include_test: False\n00:34:23 |     dict_include_valid: False\n00:34:23 |     dict_initpath: None\n00:34:23 |     dict_language: english\n00:34:23 |     dict_loaded: True\n00:34:23 |     dict_lower: True\n00:34:23 |     dict_max_ngram_size: -1\n00:34:23 |     dict_maxexs: -1\n00:34:23 |     dict_maxtokens: -1\n00:34:23 |     dict_minfreq: 0\n00:34:23 |     dict_nulltoken: __null__\n00:34:23 |     dict_starttoken: __start__\n00:34:23 |     dict_textfields: text,labels\n00:34:23 |     dict_tokenizer: bpe\n00:34:23 |     dict_unktoken: __unk__\n00:34:23 |     display_examples: False\n00:34:23 |     download_path: None\n00:34:23 |     dropout: 0.1\n00:34:23 |     dynamic_batching: None\n00:34:23 |     embedding_projection: random\n00:34:23 |     embedding_size: 768\n00:34:23 |     embedding_type: random\n00:34:23 |     embeddings_scale: False\n00:34:23 |     encode_candidate_vecs: True\n00:34:23 |     encode_candidate_vecs_batchsize: 256\n00:34:23 |     eval_batchsize: None\n00:34:23 |     eval_candidates: inline\n00:34:23 |     eval_dynamic_batching: None\n00:34:23 |     evaltask: None\n00:34:23 |     ffn_size: 3072\n00:34:23 |     final_extra_opt: \n00:34:23 |     fixed_candidate_vecs: reuse\n00:34:23 |     fixed_candidates_path: None\n00:34:23 |     force_fp16_tokens: True\n00:34:23 |     fp16: True\n00:34:23 |     fp16_impl: safe\n00:34:23 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev1corr2type2/run5/data_test.txt\n00:34:23 |     fromfile_datatype_extension: True\n00:34:23 |     gpu: -1\n00:34:23 |     gradient_clip: 0.1\n00:34:23 |     hide_labels: False\n00:34:23 |     history_add_global_end_token: None\n00:34:23 |     history_reversed: False\n00:34:23 |     history_size: 20\n00:34:23 |     ignore_bad_candidates: False\n00:34:23 |     ignore_labels: None\n00:34:23 |     image_cropsize: 224\n00:34:23 |     image_mode: raw\n00:34:23 |     image_size: 256\n00:34:23 |     inference: max\n00:34:23 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:34:23 |     init_opt: None\n00:34:23 |     interactive_candidates: fixed\n00:34:23 |     interactive_mode: False\n00:34:23 |     invsqrt_lr_decay_gamma: -1\n00:34:23 |     is_debug: False\n00:34:23 |     label_truncate: 72\n00:34:23 |     learn_embeddings: True\n00:34:23 |     learn_positional_embeddings: True\n00:34:23 |     learningrate: 5e-05\n00:34:23 |     load_from_pretrained_ranker: True\n00:34:23 |     log_every_n_secs: 10.0\n00:34:23 |     log_every_n_steps: 50\n00:34:23 |     log_keep_fields: all\n00:34:23 |     loglevel: info\n00:34:23 |     lr_scheduler: reduceonplateau\n00:34:23 |     lr_scheduler_decay: 0.5\n00:34:23 |     lr_scheduler_patience: 3\n00:34:23 |     max_train_steps: -1\n00:34:23 |     max_train_time: 7200.0\n00:34:23 |     memory_attention: sqrt\n00:34:23 |     metrics: default\n00:34:23 |     model: transformer/classifier\n00:34:23 |     model_file: /tmp/model5\n00:34:23 |     model_parallel: False\n00:34:23 |     momentum: 0\n00:34:23 |     multitask_weights: [1]\n00:34:23 |     mutators: None\n00:34:23 |     n_decoder_layers: -1\n00:34:23 |     n_encoder_layers: -1\n00:34:23 |     n_heads: 12\n00:34:23 |     n_layers: 12\n00:34:23 |     n_positions: 1024\n00:34:23 |     n_segments: 2\n00:34:23 |     nesterov: True\n00:34:23 |     no_cuda: False\n00:34:23 |     normalize_sent_emb: False\n00:34:23 |     num_epochs: -1\n00:34:23 |     num_examples: -1\n00:34:23 |     num_workers: 0\n00:34:23 |     nus: [0.7]\n00:34:23 |     optimizer: adamax\n00:34:23 |     output_scaling: 0.06\n00:34:23 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev1corr2type2/run5/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model5', 'batchsize': 40}\"\n00:34:23 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n00:34:23 |     person_tokens: False\n00:34:23 |     print_scores: False\n00:34:23 |     rank_candidates: False\n00:34:23 |     rank_top_k: -1\n00:34:23 |     reduction_type: mean\n00:34:23 |     ref_class: None\n00:34:23 |     relu_dropout: 0.0\n00:34:23 |     repeat_blocking_heuristic: True\n00:34:23 |     report_filename: \n00:34:23 |     return_cand_scores: False\n00:34:23 |     save_after_valid: True\n00:34:23 |     save_every_n_secs: -1\n00:34:23 |     save_format: conversations\n00:34:23 |     share_encoders: False\n00:34:23 |     share_word_embeddings: False\n00:34:23 |     short_final_eval: False\n00:34:23 |     special_tok_lst: None\n00:34:23 |     split_lines: False\n00:34:23 |     starttime: Dec04_00-21\n00:34:23 |     task: fromfile:parlaiformat\n00:34:23 |     tensorboard_log: False\n00:34:23 |     tensorboard_logdir: None\n00:34:23 |     text_truncate: 360\n00:34:23 |     threshold: 0.5\n00:34:23 |     topk: 5\n00:34:23 |     train_predict: False\n00:34:23 |     truncate: 1024\n00:34:23 |     update_classifier_head_only: False\n00:34:23 |     update_freq: 1\n00:34:23 |     use_memories: False\n00:34:23 |     use_reply: none\n00:34:23 |     validation_cutoff: 1.0\n00:34:23 |     validation_every_n_epochs: -1\n00:34:23 |     validation_every_n_secs: 20.0\n00:34:23 |     validation_every_n_steps: -1\n00:34:23 |     validation_max_exs: -1\n00:34:23 |     validation_metric: accuracy\n00:34:23 |     validation_metric_mode: max\n00:34:23 |     validation_patience: 30\n00:34:23 |     validation_share_agent: False\n00:34:23 |     variant: xlm\n00:34:23 |     verbose: False\n00:34:23 |     wandb_entity: None\n00:34:23 |     wandb_log: False\n00:34:23 |     wandb_name: None\n00:34:23 |     wandb_project: None\n00:34:23 |     warmup_rate: 0.0001\n00:34:23 |     warmup_updates: 1000\n00:34:23 |     weight_decay: None\n00:34:23 |     world_logs: \n00:34:23 |     wrap_memory_encoder: False\n00:34:24 | Evaluating task fromfile:parlaiformat using datatype valid.\n00:34:24 | creating task(s): fromfile:parlaiformat\n00:34:24 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n00:34:24 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev1corr2type2/run5/data_test.txt\n00:34:32 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9190 9.19e-10               .7011                 .5556   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9532              .9940   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9156 12.07 562.9  1925       0          0 136.8 1000 .9190   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .3024 1.41e-05   208 711.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    282 770.9 2636        .9279\u001b[0m\n00:34:32 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9190 9.19e-10               .7011                 .5556   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9532              .9940   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9156 12.07 562.9  1925       0          0 136.8 1000 .9190   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .3024 1.41e-05   208 711.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    282 770.9 2636        .9279\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model5*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:34:33.703113Z","iopub.execute_input":"2022-12-04T00:34:33.705293Z","iopub.status.idle":"2022-12-04T00:34:34.975867Z","shell.execute_reply.started":"2022-12-04T00:34:33.705249Z","shell.execute_reply":"2022-12-04T00:34:34.974352Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"# Actual code prev2corr1type1","metadata":{}},{"cell_type":"markdown","source":"run 1","metadata":{}},{"cell_type":"code","source":"# run 1 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type1/run1/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model1","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:34:34.977722Z","iopub.execute_input":"2022-12-04T00:34:34.978620Z","iopub.status.idle":"2022-12-04T00:46:27.962544Z","shell.execute_reply.started":"2022-12-04T00:34:34.978568Z","shell.execute_reply":"2022-12-04T00:46:27.961380Z"},"scrolled":true,"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"00:34:42 | building dictionary first...\n00:34:42 | No model with opt yet at: /tmp/model1(.opt)\n00:34:42 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run1/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n00:34:42 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n00:34:42 | Using CUDA\n00:34:42 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n00:34:42 | num words = 54944\n00:34:46 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:34:57 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:34:57 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n00:34:57 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n00:34:57 | Opt:\n00:34:57 |     activation: gelu\n00:34:57 |     adafactor_eps: '(1e-30, 0.001)'\n00:34:57 |     adam_eps: 1e-08\n00:34:57 |     add_p1_after_newln: False\n00:34:57 |     aggregate_micro: False\n00:34:57 |     allow_missing_init_opts: False\n00:34:57 |     attention_dropout: 0.1\n00:34:57 |     batchsize: 20\n00:34:57 |     betas: '(0.9, 0.999)'\n00:34:57 |     bpe_add_prefix_space: None\n00:34:57 |     bpe_debug: False\n00:34:57 |     bpe_dropout: None\n00:34:57 |     bpe_merge: None\n00:34:57 |     bpe_vocab: None\n00:34:57 |     candidates: inline\n00:34:57 |     cap_num_predictions: 100\n00:34:57 |     checkpoint_activations: False\n00:34:57 |     class_weights: None\n00:34:57 |     classes: \"['__notok__', '__ok__']\"\n00:34:57 |     classes_from_file: None\n00:34:57 |     data_parallel: True\n00:34:57 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n00:34:57 |     datatype: train\n00:34:57 |     delimiter: '\\n'\n00:34:57 |     dict_class: parlai.core.dict:DictionaryAgent\n00:34:57 |     dict_endtoken: __start__\n00:34:57 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n00:34:57 |     dict_include_test: False\n00:34:57 |     dict_include_valid: False\n00:34:57 |     dict_initpath: None\n00:34:57 |     dict_language: english\n00:34:57 |     dict_loaded: True\n00:34:57 |     dict_lower: True\n00:34:57 |     dict_max_ngram_size: -1\n00:34:57 |     dict_maxexs: -1\n00:34:57 |     dict_maxtokens: -1\n00:34:57 |     dict_minfreq: 0\n00:34:57 |     dict_nulltoken: __null__\n00:34:57 |     dict_starttoken: __start__\n00:34:57 |     dict_textfields: text,labels\n00:34:57 |     dict_tokenizer: bpe\n00:34:57 |     dict_unktoken: __unk__\n00:34:57 |     display_examples: False\n00:34:57 |     download_path: None\n00:34:57 |     dropout: 0.1\n00:34:57 |     dynamic_batching: None\n00:34:57 |     embedding_projection: random\n00:34:57 |     embedding_size: 768\n00:34:57 |     embedding_type: random\n00:34:57 |     embeddings_scale: False\n00:34:57 |     encode_candidate_vecs: True\n00:34:57 |     encode_candidate_vecs_batchsize: 256\n00:34:57 |     eval_batchsize: None\n00:34:57 |     eval_candidates: inline\n00:34:57 |     eval_dynamic_batching: None\n00:34:57 |     evaltask: None\n00:34:57 |     ffn_size: 3072\n00:34:57 |     final_extra_opt: \n00:34:57 |     fixed_candidate_vecs: reuse\n00:34:57 |     fixed_candidates_path: None\n00:34:57 |     force_fp16_tokens: False\n00:34:57 |     fp16: True\n00:34:57 |     fp16_impl: safe\n00:34:57 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run1/data\n00:34:57 |     fromfile_datatype_extension: True\n00:34:57 |     gpu: -1\n00:34:57 |     gradient_clip: 0.1\n00:34:57 |     hide_labels: False\n00:34:57 |     history_add_global_end_token: None\n00:34:57 |     history_reversed: False\n00:34:57 |     history_size: 20\n00:34:57 |     ignore_bad_candidates: False\n00:34:57 |     ignore_labels: None\n00:34:57 |     image_cropsize: 224\n00:34:57 |     image_mode: raw\n00:34:57 |     image_size: 256\n00:34:57 |     inference: max\n00:34:57 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:34:57 |     init_opt: None\n00:34:57 |     interactive_candidates: fixed\n00:34:57 |     interactive_mode: False\n00:34:57 |     invsqrt_lr_decay_gamma: -1\n00:34:57 |     is_debug: False\n00:34:57 |     label_truncate: 72\n00:34:57 |     learn_embeddings: True\n00:34:57 |     learn_positional_embeddings: True\n00:34:57 |     learningrate: 5e-05\n00:34:57 |     load_from_checkpoint: False\n00:34:57 |     load_from_pretrained_ranker: True\n00:34:57 |     log_every_n_secs: 10.0\n00:34:57 |     log_every_n_steps: 50\n00:34:57 |     log_keep_fields: all\n00:34:57 |     loglevel: info\n00:34:57 |     lr_scheduler: reduceonplateau\n00:34:57 |     lr_scheduler_decay: 0.5\n00:34:57 |     lr_scheduler_patience: 3\n00:34:57 |     max_train_steps: -1\n00:34:57 |     max_train_time: 7200.0\n00:34:57 |     memory_attention: sqrt\n00:34:57 |     metrics: default\n00:34:57 |     model: transformer/classifier\n00:34:57 |     model_file: /tmp/model1\n00:34:57 |     model_parallel: False\n00:34:57 |     momentum: 0\n00:34:57 |     multitask_weights: [1]\n00:34:57 |     mutators: None\n00:34:57 |     n_decoder_layers: -1\n00:34:57 |     n_encoder_layers: -1\n00:34:57 |     n_heads: 12\n00:34:57 |     n_layers: 12\n00:34:57 |     n_positions: 1024\n00:34:57 |     n_segments: 2\n00:34:57 |     nesterov: True\n00:34:57 |     no_cuda: False\n00:34:57 |     normalize_sent_emb: False\n00:34:57 |     num_epochs: -1\n00:34:57 |     num_workers: 0\n00:34:57 |     nus: (0.7,)\n00:34:57 |     optimizer: adamax\n00:34:57 |     output_scaling: 0.06\n00:34:57 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type1/run1/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model1'}\"\n00:34:57 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n00:34:57 |     person_tokens: False\n00:34:57 |     print_scores: False\n00:34:57 |     rank_candidates: False\n00:34:57 |     rank_top_k: -1\n00:34:57 |     reduction_type: mean\n00:34:57 |     ref_class: None\n00:34:57 |     relu_dropout: 0.0\n00:34:57 |     repeat_blocking_heuristic: True\n00:34:57 |     return_cand_scores: False\n00:34:57 |     save_after_valid: True\n00:34:57 |     save_every_n_secs: -1\n00:34:57 |     save_format: conversations\n00:34:57 |     share_encoders: False\n00:34:57 |     share_word_embeddings: False\n00:34:57 |     short_final_eval: False\n00:34:57 |     special_tok_lst: None\n00:34:57 |     split_lines: False\n00:34:57 |     starttime: Dec04_00-34\n00:34:57 |     task: fromfile:parlaiformat\n00:34:57 |     tensorboard_log: False\n00:34:57 |     tensorboard_logdir: None\n00:34:57 |     text_truncate: 360\n00:34:57 |     threshold: 0.5\n00:34:57 |     topk: 5\n00:34:57 |     train_predict: False\n00:34:57 |     truncate: 1024\n00:34:57 |     update_classifier_head_only: False\n00:34:57 |     update_freq: 1\n00:34:57 |     use_memories: False\n00:34:57 |     use_reply: none\n00:34:57 |     validation_cutoff: 1.0\n00:34:57 |     validation_every_n_epochs: -1\n00:34:57 |     validation_every_n_secs: 20.0\n00:34:57 |     validation_every_n_steps: -1\n00:34:57 |     validation_max_exs: -1\n00:34:57 |     validation_metric: accuracy\n00:34:57 |     validation_metric_mode: max\n00:34:57 |     validation_patience: 30\n00:34:57 |     validation_share_agent: False\n00:34:57 |     variant: xlm\n00:34:57 |     verbose: False\n00:34:57 |     wandb_entity: None\n00:34:57 |     wandb_log: False\n00:34:57 |     wandb_name: None\n00:34:57 |     wandb_project: None\n00:34:57 |     warmup_rate: 0.0001\n00:34:57 |     warmup_updates: 1000\n00:34:57 |     weight_decay: None\n00:34:57 |     world_logs: \n00:34:57 |     wrap_memory_encoder: False\n00:34:57 | creating task(s): fromfile:parlaiformat\n00:34:57 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run1/data_train.txt\n00:34:57 | training...\n00:35:08 | time:10s total_exs:420 total_steps:21 epochs:2.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .4357 4.357e-10               .5325                 .4561   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6398            .2883              .3871   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .2297  11.2     1   264   547       0          0 41.43  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .4357             32768  2.813    .1189 6.005 .7073 1.055e-06 120.1 248.8   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   21 384.1 795.7 2.076        .4110\n\n00:35:18 | time:20s total_exs:1180 total_steps:59 epochs:5.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5592 5.592e-10               .6355                 .5562   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7411            .4426              .5660   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .3634 11.19     1 263.8  1024       0          0 77.62  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5592             32768  2.754    .1189 6.037 .6879 2.955e-06 120.7 468.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                   59 384.5 1492 3.89        .5426\n\n00:35:18 | creating task(s): fromfile:parlaiformat\n00:35:18 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run1/data_valid.txt\n00:35:18 | running eval: valid\n00:35:18 | eval completed in 0.19s\n00:35:18 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8148                 .7333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .7619              .8889   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .6667 11.46 161.5  1913       0          0 142.1   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6663 2.955e-06    72 852.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     59 233.5 2766        .7884\n\u001b[0m\n00:35:18 | \u001b[1;32mnew best accuracy: 0.7917\u001b[0m\n00:35:18 | saving best valid model: /tmp/model1\n00:35:18 | Saving dictionary to /tmp/model1.dict\n00:35:21 | saving model checkpoint: /tmp/model1.checkpoint\n00:35:21 | Saving dictionary to /tmp/model1.checkpoint.dict\n00:35:38 | time:40s total_exs:1900 total_steps:95 epochs:9.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7806 7.806e-10               .8167                 .7154   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9514            .7266              .9211   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6000 11.37     1 267.4 944.9       0          0 70.67  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7806             32768  2.805    .1189 6.028 .6174 4.755e-06 120.6   426   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                   95  388 1371 3.541        .7729\n\n00:35:41 | time:44s total_exs:2180 total_steps:109 epochs:10.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9000   9e-10               .9054                 .8933   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9178            .8939              .9077   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8806 11.17     1 263.4  1012       0          0  76.8  280   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9000             32768  3.201    .1189 6.043 .5294 5.454e-06 120.9 464.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  109 384.3 1476 3.864        .8999\n\n00:35:41 | running eval: valid\n00:35:42 | eval completed in 0.23s\n00:35:42 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1596       0          0 118.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5506 5.454e-06    72 711.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    109 233.5 2307        .8748\n\u001b[0m\n00:35:42 | \u001b[1;32mnew best accuracy: 0.875 (previous best was 0.7917)\u001b[0m\n00:35:42 | saving best valid model: /tmp/model1\n00:35:51 | saving model checkpoint: /tmp/model1.checkpoint\n00:36:07 | time:69s total_exs:2980 total_steps:149 epochs:14.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9575 9.575e-10               .9582                 .9582   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9582            .9567              .9567   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9567 11.15     1 262.9  1039       0          0 79.04  800   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9575             32768  3.818    .1189 6.018 .3636 7.454e-06 120.3 475.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  149 383.3 1515 3.961        .9575\n\n00:36:11 | time:74s total_exs:3360 total_steps:168 epochs:16.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9684 9.684e-10               .9649                 .9706   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9593            .9713              .9667   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9760 10.82     1 256.4  1025       0          0 79.94  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9684             32768  4.731    .1189 5.905 .1686 8.404e-06 118.1   472   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  168 374.5 1497 4.016        .9684\n\n00:36:11 | running eval: valid\n00:36:12 | eval completed in 0.19s\n00:36:12 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1852       0          0 137.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .3391 8.404e-06    72 825.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    168 233.5 2678        .8322\n\u001b[0m\n00:36:12 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 1\u001b[0m\n00:36:12 | saving model checkpoint: /tmp/model1.checkpoint\n00:36:31 | time:94s total_exs:4140 total_steps:207 epochs:20.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9859 9.859e-10               .9863                 .9851   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9876            .9854              .9867   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9841 11.21     1 264.1  1027       0          0 77.77  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9859             32768  4.008    .1190 6.031 .07203 1.035e-05 120.6   469   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  207 384.7 1496 3.897        .9859\n\n00:36:32 | time:94s total_exs:4160 total_steps:208 epochs:20.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  10.5     1   250  1026       0          0 82.03   20   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n     1             32768  .2417    .1190   6.2 .01709 1.04e-05   124 508.6   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  208  374 1534 4.518            1\n\n00:36:32 | running eval: valid\n00:36:32 | eval completed in 0.19s\n00:36:32 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 11.46 161.5  1842       0          0 136.8   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .4198 1.04e-05    72 821.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    208 233.5 2663        .8730\n\u001b[0m\n00:36:32 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 2\u001b[0m\n00:36:32 | saving model checkpoint: /tmp/model1.checkpoint\n00:36:47 | time:109s total_exs:4940 total_steps:247 epochs:24.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9962 9.962e-10               .9962                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9924            .9961              .9922   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.35 .5641   267  1012       0          0 75.78  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9962             32768  1.021    .1190 6.015 .02443 1.235e-05 120.3 455.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  247 387.3 1467 3.798        .9962\n\n00:36:52 | time:115s total_exs:5360 total_steps:268 epochs:26.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 10.78 .04762 255.5  1007       0          0 78.83   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  \\\n    420   1             32768  .1565    .1190 6.029 .002719 1.34e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   475.3       0          0                  268 376.1 1482 3.959            1\n\n00:36:52 | running eval: valid\n00:36:52 | eval completed in 0.19s\n00:36:52 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1912       0          0   142   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .7349 1.34e-05    72 852.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    268 233.5 2765        .8322\n\u001b[0m\n00:36:52 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 3\u001b[0m\n00:36:52 | saving model checkpoint: /tmp/model1.checkpoint\n00:37:07 | time:129s total_exs:6140 total_steps:307 epochs:30.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.47     0 269.4  1047       0          0  77.7  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .02092    .1190 6.062 .001763 1.535e-05 121.2   471   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  307 390.7 1518 3.894            1\n\n00:37:12 | time:135s total_exs:6580 total_steps:329 epochs:32.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.51     0 270.2  1049       0          0 77.62  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01685    .1190 6.045 .001391 1.645e-05 120.9 469.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  329 391.1 1518 3.896            1\n\n00:37:12 | running eval: valid\n00:37:12 | eval completed in 0.20s\n00:37:12 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1821       0          0 135.3   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .8989 1.645e-05    72 811.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    329 233.5 2633        .8322\n\u001b[0m\n00:37:12 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 4\u001b[0m\n00:37:12 | saving model checkpoint: /tmp/model1.checkpoint\n00:37:27 | time:150s total_exs:7360 total_steps:368 epochs:36.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.05 .02564 261.1  1006       0          0 77.04   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  \\\n    780   1             32768 .08013    .1190 6.044 .001224 1.84e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   465.6       0          0                  368 381.9 1471 3.861            1\n\n00:37:32 | time:155s total_exs:7780 total_steps:389 epochs:38.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.99     0 259.9  1008       0          0 77.55  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01301    .1190 6.076 .001087 1.945e-05 121.5 471.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  389 381.4 1479 3.894            1\n\n00:37:32 | running eval: valid\n00:37:33 | eval completed in 0.19s\n00:37:33 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8000                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8571              .7500   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 11.46 161.5  1915       0          0 142.2   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 .9488 1.945e-05    72 853.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    389 233.5 2769        .8286\n\u001b[0m\n00:37:33 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 5\u001b[0m\n00:37:33 | saving model checkpoint: /tmp/model1.checkpoint\n00:37:47 | time:170s total_exs:8580 total_steps:429 epochs:42.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.97     0 259.4  1014       0          0 78.16  800   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01605    .1190 6.008 .001004 2.145e-05 120.2 469.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  429 379.6 1483 3.917            1\n\n00:37:53 | time:175s total_exs:9000 total_steps:450 epochs:45.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 10.91 .04762 258.2 959.1       0          0 74.29   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  \\\n    420   1             32768  5.036    .1190 6.067 .001522 2.25e-05 121.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   450.7       0          0                  450 379.5 1410 3.73            1\n\n00:37:53 | running eval: valid\n00:37:53 | eval completed in 0.20s\n00:37:53 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1862       0          0 138.3   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 1.034 2.25e-05    72 829.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    450 233.5 2692        .8322\n\u001b[0m\n00:37:53 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 6\u001b[0m\n00:37:53 | saving model checkpoint: /tmp/model1.checkpoint\n00:38:07 | time:190s total_exs:9780 total_steps:489 epochs:48.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9987                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9973            .9988              .9975   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.29 .05128 265.8  1034       0          0 77.83   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    780 .9987             32768  .6057    .1190 5.964 .009456 2.445e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   464.2       0          0                  489 385.1 1499  3.9        .9987\n\n00:38:13 | time:196s total_exs:10240 total_steps:512 epochs:51.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.18     0 263.6  1049       0          0 79.59  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .009632    .1190  6.03 .0008243 2.56e-05 120.6   480   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  512 384.2 1529 3.995            1\n\n00:38:13 | running eval: valid\n00:38:13 | eval completed in 0.19s\n00:38:13 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1839       0          0 136.6   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 1.145 2.56e-05    72   820       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    512 233.5 2660        .8322\n\u001b[0m\n00:38:13 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 7\u001b[0m\n00:38:13 | saving model checkpoint: /tmp/model1.checkpoint\n00:38:28 | time:210s total_exs:11000 total_steps:550 epochs:55.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.2     0   264 998.6       0          0 75.64  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .009063    .1190 6.032 .0007755 2.75e-05 120.6 456.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  550 384.7 1455 3.791            1\n\n00:38:33 | time:216s total_exs:11440 total_steps:572 epochs:57.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.28     0 265.5  1035       0          0 77.94  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .008675    .1190 6.036 .0007316 2.86e-05 120.7 470.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  572 386.2 1505 3.912            1\n\n00:38:33 | running eval: valid\n00:38:34 | eval completed in 0.19s\n00:38:34 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1866       0          0 138.6   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 1.208 2.86e-05    72 831.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    572 233.5 2698        .8322\n\u001b[0m\n00:38:34 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 8\u001b[0m\n00:38:34 | saving model checkpoint: /tmp/model1.checkpoint\n00:38:48 | time:231s total_exs:12220 total_steps:611 epochs:61.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.31     0 266.3  1034       0          0 77.69  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .008066    .1190     6 .0006888 3.055e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   466.1       0          0                  611 386.3 1500 3.893            1\n\n00:38:54 | time:236s total_exs:12660 total_steps:633 epochs:63.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.15     0   263  1018       0          0 77.43  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .007625    .1190 6.014 .0006503 3.165e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   465.7       0          0                  633 383.2 1484 3.887            1\n\n00:38:54 | running eval: valid\n00:38:54 | eval completed in 0.19s\n00:38:54 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1868       0          0 138.8   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 1.237 3.165e-05    72 832.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    633 233.5 2701        .8322\n\u001b[0m\n00:38:54 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 9\u001b[0m\n00:38:54 | saving model checkpoint: /tmp/model1.checkpoint\n00:39:08 | time:251s total_exs:13440 total_steps:672 epochs:67.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.03     0 260.6  1016       0          0    78  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .007179    .1190 6.013 .000613 3.36e-05 120.3   469   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  672 380.8 1485 3.909            1\n\n00:39:14 | time:257s total_exs:13900 total_steps:695 epochs:69.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.95     0   259  1015       0          0 78.41  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006768    .1190 6.026 .0005769 3.475e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   472.5       0          0                  695 379.5 1488 3.936            1\n\n00:39:14 | running eval: valid\n00:39:14 | eval completed in 0.19s\n00:39:14 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1905       0          0 141.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6  1.26 3.475e-05    72 849.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    695 233.5 2755        .8322\n\u001b[0m\n00:39:14 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 10\u001b[0m\n00:39:14 | saving model checkpoint: /tmp/model1.checkpoint\n00:39:29 | time:271s total_exs:14680 total_steps:734 epochs:73.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.04     0 260.9  1004       0          0 76.96  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .006355    .1190 5.992 .0005419 3.67e-05 119.8 461.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  734 380.7 1465 3.857            1\n\n00:39:35 | time:277s total_exs:15120 total_steps:756 epochs:75.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.34     0 266.7  1025       0          0 76.89  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .005991    .1191 5.941 .0005106 3.78e-05 118.8 456.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  756 385.5 1482 3.86            1\n\n00:39:35 | running eval: valid\n00:39:35 | eval completed in 0.19s\n00:39:35 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1883       0          0 139.9   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 1.282 3.78e-05    72 839.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    756 233.5 2723        .8322\n\u001b[0m\n00:39:35 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 11\u001b[0m\n00:39:35 | saving model checkpoint: /tmp/model1.checkpoint\n00:39:49 | time:292s total_exs:15920 total_steps:796 epochs:79.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.12     0 262.4  1033       0          0 78.72  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .005634    .1191 6.035 .0004799 3.98e-05 120.7 475.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  796 383.1 1508 3.945            1\n\n00:39:55 | time:297s total_exs:16360 total_steps:818 epochs:81.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.45     0   269  1041       0          0 77.42  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .005303    .1191 5.995 .0004511 4.09e-05 119.9 464.1   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  818  389 1506 3.887            1\n\n00:39:55 | running eval: valid\n00:39:55 | eval completed in 0.23s\n00:39:55 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1618       0          0 120.2   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 1.307 4.09e-05    72 721.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    818 233.5 2339        .8322\n\u001b[0m\n00:39:55 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 12\u001b[0m\n00:39:55 | saving model checkpoint: /tmp/model1.checkpoint\n00:40:10 | time:312s total_exs:17140 total_steps:857 epochs:85.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.21     0 264.2  1028       0          0  77.8  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004988    .1191 5.985 .0004243 4.285e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   465.6       0          0                  857 383.9 1493 3.899            1\n\n00:40:15 | time:318s total_exs:17580 total_steps:879 epochs:87.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.19     0 263.8  1047       0          0 79.42  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004703    .1191     6 .0003996 4.395e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   476.5       0          0                  879 383.8 1524 3.987            1\n\n00:40:15 | running eval: valid\n00:40:15 | eval completed in 0.22s\n00:40:15 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1692       0          0 125.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 1.329 4.395e-05    72 754.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    879 233.5 2446        .8322\n\u001b[0m\n00:40:15 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 13\u001b[0m\n00:40:15 | saving model checkpoint: /tmp/model1.checkpoint\n00:40:30 | time:332s total_exs:18340 total_steps:917 epochs:91.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.93     0 258.7 970.6       0          0 75.05  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00443    .1191 6.071 .0003759 4.585e-05 121.4 455.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  917 380.1 1426 3.761            1\n\n00:40:35 | time:338s total_exs:18780 total_steps:939 epochs:93.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.52     0 270.3  1073       0          0 79.41  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .004168    .1191 5.955 .000354 4.695e-05 119.1 472.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  939 389.4 1546 3.986            1\n\n00:40:35 | running eval: valid\n00:40:36 | eval completed in 0.19s\n00:40:36 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1917       0          0 142.4   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 1.355 4.695e-05    72 854.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    939 233.5 2771        .8322\n\u001b[0m\n00:40:36 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 14\u001b[0m\n00:40:36 | saving model checkpoint: /tmp/model1.checkpoint\n00:40:50 | time:353s total_exs:19560 total_steps:978 epochs:97.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.98     0 259.6  1013       0          0 78.06  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .003946    .1191 6.021 .0003332 4.89e-05 120.4   470   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  978 380.1 1483 3.912            1\n\n00:40:56 | time:358s total_exs:20020 total_steps:1001 epochs:100.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.85     0 256.9  1023       0          0 79.67  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003692    .1191 5.991 .0003135 4.995e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   477.3       0          0                 1001 376.7 1501 3.999            1\n\n00:40:56 | running eval: valid\n00:40:56 | eval completed in 0.19s\n00:40:56 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1921       0          0 142.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6 1.377 4.995e-05    72 856.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1001 233.5 2778        .8322\n\u001b[0m\n00:40:56 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 15\u001b[0m\n00:40:56 | saving model checkpoint: /tmp/model1.checkpoint\n00:41:11 | time:374s total_exs:20800 total_steps:1040 epochs:104.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.99     0 259.7  1009       0          0 77.69  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003471    .1191 6.036 .0002941 4.995e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   468.9       0          0                 1040 380.5 1478 3.893            1\n\n00:41:16 | time:379s total_exs:21220 total_steps:1061 epochs:106.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.42     0 268.4  1063       0          0 79.22  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003272    .1191 6.019 .0002773 4.995e-05 120.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   476.8       0          0                 1061 388.8 1540 3.978            1\n\n00:41:16 | running eval: valid\n00:41:16 | eval completed in 0.19s\n00:41:16 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1876       0          0 139.3   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 1.398 4.995e-05    72 836.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1061 233.5 2712        .8322\n\u001b[0m\n00:41:16 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 16\u001b[0m\n00:41:16 | saving model checkpoint: /tmp/model1.checkpoint\n00:41:32 | time:394s total_exs:22000 total_steps:1100 epochs:110.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.05     0 261.1 994.3       0          0 76.18  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003092    .1191 6.033 .0002622 4.995e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.6       0          0                 1100 381.7 1454 3.817            1\n\n00:41:37 | time:399s total_exs:22380 total_steps:1119 epochs:111.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.92     0 258.4 982.2       0          0 76.01  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002944    .1191 6.005 .0002486 4.995e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.5       0          0                 1119 378.5 1439 3.818            1\n\n00:41:37 | running eval: valid\n00:41:37 | eval completed in 0.19s\n00:41:37 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1873       0          0 139.1   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 1.417 4.995e-05    72 834.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1119 233.5 2708        .8322\n\u001b[0m\n00:41:37 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 17\u001b[0m\n00:41:37 | saving model checkpoint: /tmp/model1.checkpoint\n00:41:51 | time:414s total_exs:23160 total_steps:1158 epochs:115.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.07     0 261.4  1010       0          0  77.3  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002788    .1191 5.997 .0002362 4.995e-05 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.6       0          0                 1158 381.4 1474 3.874            1\n\n00:41:57 | time:420s total_exs:23600 total_steps:1180 epochs:118.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.64     0 272.9  1068       0          0 78.26  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002648    .1191 6.009 .0002233 4.995e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   470.3       0          0                 1180  393 1538 3.929            1\n\n00:41:57 | running eval: valid\n00:41:57 | eval completed in 0.19s\n00:41:57 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1903       0          0 141.4   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 1.435 4.995e-05    72 848.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1180 233.5 2751        .8322\n\u001b[0m\n00:41:57 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 18\u001b[0m\n00:41:57 | saving model checkpoint: /tmp/model1.checkpoint\n00:42:12 | time:434s total_exs:24380 total_steps:1219 epochs:121.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.15     0   263  1002       0          0 76.19  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .002504    .1191 6.005 .000212 4.995e-05 120.1 457.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1219 383.1 1459 3.818            1\n\n00:42:17 | time:440s total_exs:24820 total_steps:1241 epochs:124.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1    11     0   260  1006       0          0 77.42  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002386    .1191 5.986 .0002019 4.995e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.5       0          0                 1241 379.7 1470 3.886            1\n\n00:42:17 | running eval: valid\n00:42:18 | eval completed in 0.19s\n00:42:18 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1876       0          0 139.4   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6 1.454 4.995e-05    72 836.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1241 233.5 2712        .8322\n\u001b[0m\nEpoch 00005: reducing learning rate of group 0 to 2.4975e-05.\n00:42:18 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 19\u001b[0m\n00:42:18 | saving model checkpoint: /tmp/model1.checkpoint\n00:42:32 | time:455s total_exs:25620 total_steps:1281 epochs:128.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.21     0 264.2  1032       0          0  78.1  800   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768  .0023    .1191 6.032 .0001945 2.498e-05 120.7 471.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1281 384.9 1503 3.914            1\n\n00:42:38 | time:460s total_exs:26020 total_steps:1301 epochs:130.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.42     0 268.4  1003       0          0 74.73  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002244    .1192 6.025 .0001899 2.498e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   450.2       0          0                 1301 388.9 1453 3.752            1\n\n00:42:38 | running eval: valid\n00:42:38 | eval completed in 0.20s\n00:42:38 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1792       0          0   133   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 1.462 2.498e-05    72 798.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1301 233.5 2591        .8322\n\u001b[0m\n00:42:38 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 20\u001b[0m\n00:42:38 | saving model checkpoint: /tmp/model1.checkpoint\n00:42:52 | time:475s total_exs:26800 total_steps:1340 epochs:134.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.42     0 268.5  1047       0          0 77.96  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002285    .1192 6.059 .0001851 2.498e-05 121.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   472.4       0          0                 1340 389.7 1519 3.907            1\n\n00:42:58 | time:480s total_exs:27240 total_steps:1362 epochs:136.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.24     0 264.8  1050       0          0  79.3  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002136    .1192 6.027 .0001807 2.498e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     478       0          0                 1362 385.3 1528 3.981            1\n\n00:42:58 | running eval: valid\n00:42:58 | eval completed in 0.19s\n00:42:58 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1925       0          0   143   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 1.471 2.498e-05    72 858.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1362 233.5 2784        .8322\n\u001b[0m\n00:42:58 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 21\u001b[0m\n00:42:58 | saving model checkpoint: /tmp/model1.checkpoint\n00:43:13 | time:495s total_exs:28020 total_steps:1401 epochs:140.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.12     0 262.3  1002       0          0 76.36  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .002081    .1192 6.054 .000176 2.498e-05 121.1 462.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1401 383.4 1464 3.827            1\n\n00:43:18 | time:501s total_exs:28460 total_steps:1423 epochs:142.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.07     0 261.4  1032       0          0 78.95  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002034    .1192 5.964 .0001719 2.498e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   470.8       0          0                 1423 380.7 1503 3.963            1\n\n00:43:18 | running eval: valid\n00:43:19 | eval completed in 0.19s\n00:43:19 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1852       0          0 137.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 1.481 2.498e-05    72 825.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1423 233.5 2678        .8322\n\u001b[0m\n00:43:19 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 22\u001b[0m\n00:43:19 | saving model checkpoint: /tmp/model1.checkpoint\n00:43:34 | time:516s total_exs:29240 total_steps:1462 epochs:146.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.13     0 262.7  1025       0          0 78.05  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001981    .1192 5.949 .0001675 2.498e-05   119   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   464.3       0          0                 1462 381.7 1489 3.911            1\n\n00:43:39 | time:521s total_exs:29620 total_steps:1481 epochs:148.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.24     0 264.8 994.4       0          0 75.09  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001929    .1192 6.111 .000163 2.498e-05 122.2 458.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1481 387.1 1453 3.771            1\n\n00:43:39 | running eval: valid\n00:43:39 | eval completed in 0.19s\n00:43:39 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1860       0          0 138.1   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6 1.491 2.498e-05    72 828.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1481 233.5 2689        .8322\n\u001b[0m\nEpoch 00009: reducing learning rate of group 0 to 1.2488e-05.\n00:43:39 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 23\u001b[0m\n00:43:39 | saving model checkpoint: /tmp/model1.checkpoint\n00:43:54 | time:536s total_exs:30420 total_steps:1521 epochs:152.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.95     0 259.1  1017       0          0 78.53  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001895    .1192  6.12 .0001601 1.249e-05 122.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   480.6       0          0                 1521 381.5 1498 3.935            1\n\n00:43:59 | time:542s total_exs:30820 total_steps:1541 epochs:154.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.23     0 264.6  1026       0          0 77.54  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001873    .1192  6.02 .0001584 1.249e-05 120.4   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   466.8       0          0                 1541  385 1493 3.894            1\n\n00:43:59 | running eval: valid\n00:43:59 | eval completed in 0.19s\n00:43:59 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1885       0          0 139.9   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6 1.496 1.249e-05    72   840       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1541 233.5 2725        .8322\n\u001b[0m\n00:43:59 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 24\u001b[0m\n00:43:59 | saving model checkpoint: /tmp/model1.checkpoint\n00:44:14 | time:556s total_exs:31580 total_steps:1579 epochs:157.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.15     0   263 999.8       0          0 76.02  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00185    .1192 6.037 .0001563 1.249e-05 120.7 458.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1579 383.8 1459 3.81            1\n\n00:44:19 | time:562s total_exs:32020 total_steps:1601 epochs:160.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.97     0 259.3  1012       0          0 78.03  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001824    .1192  6.05 .0001541 1.249e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   472.1       0          0                 1601 380.3 1484 3.917            1\n\n00:44:19 | running eval: valid\n00:44:19 | eval completed in 0.19s\n00:44:19 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1835       0          0 136.3   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6   1.5 1.249e-05    72 817.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1601 233.5 2653        .8322\n\u001b[0m\n00:44:19 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 25\u001b[0m\n00:44:19 | saving model checkpoint: /tmp/model1.checkpoint\n00:44:34 | time:576s total_exs:32820 total_steps:1641 epochs:164.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.06     0 261.2  1025       0          0 78.48  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001803    .1192 6.022 .0001522 1.249e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   472.7       0          0                 1641 381.7 1498 3.933            1\n\n00:44:39 | time:582s total_exs:33260 total_steps:1663 epochs:166.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.26     0 265.2  1054       0          0 79.47  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001778    .1192 5.968 .0001502 1.249e-05 119.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   474.3       0          0                 1663 384.5 1528 3.99            1\n\n00:44:39 | running eval: valid\n00:44:40 | eval completed in 0.23s\n00:44:40 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1623       0          0 120.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 1.505 1.249e-05    72 723.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1663 233.5 2347        .8322\n\u001b[0m\n00:44:40 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 26\u001b[0m\n00:44:40 | saving model checkpoint: /tmp/model1.checkpoint\n00:44:55 | time:597s total_exs:34060 total_steps:1703 epochs:170.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.98     0 259.6  1020       0          0 78.63  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001747    .1192  6.03 .0001476 1.249e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   474.1       0          0                 1703 380.1 1495 3.94            1\n\n00:45:00 | time:602s total_exs:34480 total_steps:1724 epochs:172.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.2     0   264  1050       0          0 79.56  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001724    .1192 6.067 .0001456 1.249e-05 121.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   482.7       0          0                 1724 385.4 1533 3.995            1\n\n00:45:00 | running eval: valid\n00:45:00 | eval completed in 0.18s\n00:45:00 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1945       0          0 144.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 1.511 1.249e-05    72 867.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1724 233.5 2812        .8322\n\u001b[0m\nEpoch 00013: reducing learning rate of group 0 to 6.2438e-06.\n00:45:00 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 27\u001b[0m\n00:45:00 | saving model checkpoint: /tmp/model1.checkpoint\n00:45:15 | time:617s total_exs:35240 total_steps:1762 epochs:176.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.24     0 264.8 995.6       0          0 75.21  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001707    .1192 6.029 .0001442 6.244e-06 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   453.4       0          0                 1762 385.3 1449 3.769            1\n\n00:45:20 | time:623s total_exs:35680 total_steps:1784 epochs:178.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.46     0 269.2  1073       0          0  79.7  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001692    .1192  6.05 .0001429 6.244e-06   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   482.2       0          0                 1784 390.2 1555 4.001            1\n\n00:45:20 | running eval: valid\n00:45:20 | eval completed in 0.19s\n00:45:20 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1925       0          0   143   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 1.513 6.244e-06    72   858       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1784 233.5 2782        .8322\n\u001b[0m\n00:45:20 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 28\u001b[0m\n00:45:20 | saving model checkpoint: /tmp/model1.checkpoint\n00:45:35 | time:637s total_exs:36480 total_steps:1824 epochs:182.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.44     0 268.8  1055       0          0 78.52  800   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00168    .1192  6.05 .0001418 6.244e-06   121   475   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1824 389.8 1530 3.935            1\n\n00:45:40 | time:643s total_exs:36920 total_steps:1846 epochs:184.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.23     0 264.6  1049       0          0 79.31  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001665    .1193  6.05 .0001407 6.244e-06   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   479.8       0          0                 1846 385.6 1529 3.982            1\n\n00:45:40 | running eval: valid\n00:45:41 | eval completed in 0.22s\n00:45:41 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1680       0          0 124.8   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 1.516 6.244e-06    72 749.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1846 233.5 2429        .8322\n\u001b[0m\n00:45:41 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 29\u001b[0m\n00:45:41 | saving model checkpoint: /tmp/model1.checkpoint\n00:45:55 | time:658s total_exs:37700 total_steps:1885 epochs:188.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.05     0   261  1019       0          0 78.05  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001653    .1193 6.054 .0001396 6.244e-06 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   472.5       0          0                 1885 382.1 1491 3.912            1\n\n00:46:01 | time:663s total_exs:38140 total_steps:1907 epochs:190.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.98     0 259.5  1021       0          0 78.68  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001642    .1193 6.009 .0001387 6.244e-06 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   472.8       0          0                 1907 379.7 1494 3.95            1\n\n00:46:01 | running eval: valid\n00:46:01 | eval completed in 0.19s\n00:46:01 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1893       0          0 140.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08122     6 1.519 6.244e-06    72 843.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1907 233.5 2737        .8322\n\u001b[0m\n00:46:01 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 30\u001b[0m\n00:46:01 | saving model checkpoint: /tmp/model1.checkpoint\n00:46:06 | ran out of patience! stopping training.\n00:46:06 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n00:46:06 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n00:46:06 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run1/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n00:46:06 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n00:46:06 | Using CUDA\n00:46:06 | loading dictionary from /tmp/model1.dict\n00:46:06 | num words = 54944\n00:46:10 | Loading existing model parameters from /tmp/model1\n00:46:19 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:46:21 | creating task(s): fromfile:parlaiformat\n00:46:21 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run1/data_valid.txt\n00:46:21 | running eval: valid\n00:46:21 | eval completed in 0.21s\n00:46:21 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1764       0          0   131   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297     6 .5506 5.454e-06    72 786.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    109 233.5 2551        .8748\n\u001b[0m\n00:46:21 | creating task(s): fromfile:parlaiformat\n00:46:21 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run1/data_test.txt\n00:46:21 | running eval: test\n00:46:26 | eval completed in 4.74s\n00:46:26 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8860 8.86e-10               .6225                 .4653   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9400            .9329              .9925   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8800 12.07 281.4  2986       0          0 212.2 1000 .8860   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298   5.2 .5243 5.454e-06   104  1104       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    109 385.4 4090        .9018\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type1/run1/data_test.txt -m transformer/classifier -mf /tmp/model1 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:46:27.966733Z","iopub.execute_input":"2022-12-04T00:46:27.967138Z","iopub.status.idle":"2022-12-04T00:46:58.610128Z","shell.execute_reply.started":"2022-12-04T00:46:27.967096Z","shell.execute_reply":"2022-12-04T00:46:58.608953Z"},"scrolled":true,"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"00:46:36 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr1type1/run1/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr1type1/run1/data)\u001b[0m\n00:46:36 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n00:46:36 | Using CUDA\n00:46:36 | loading dictionary from /tmp/model1.dict\n00:46:36 | num words = 54944\n00:46:41 | Loading existing model parameters from /tmp/model1\n00:46:46 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:46:48 | Opt:\n00:46:48 |     activation: gelu\n00:46:48 |     adafactor_eps: '[1e-30, 0.001]'\n00:46:48 |     adam_eps: 1e-08\n00:46:48 |     add_p1_after_newln: False\n00:46:48 |     aggregate_micro: False\n00:46:48 |     allow_missing_init_opts: False\n00:46:48 |     area_under_curve_class: None\n00:46:48 |     area_under_curve_digits: -1\n00:46:48 |     attention_dropout: 0.1\n00:46:48 |     batchsize: 40\n00:46:48 |     betas: '[0.9, 0.999]'\n00:46:48 |     bpe_add_prefix_space: None\n00:46:48 |     bpe_debug: False\n00:46:48 |     bpe_dropout: None\n00:46:48 |     bpe_merge: None\n00:46:48 |     bpe_vocab: None\n00:46:48 |     candidates: inline\n00:46:48 |     cap_num_predictions: 100\n00:46:48 |     checkpoint_activations: False\n00:46:48 |     class_weights: None\n00:46:48 |     classes: \"['__notok__', '__ok__']\"\n00:46:48 |     classes_from_file: None\n00:46:48 |     data_parallel: True\n00:46:48 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n00:46:48 |     datatype: train\n00:46:48 |     delimiter: '\\n'\n00:46:48 |     dict_class: parlai.core.dict:DictionaryAgent\n00:46:48 |     dict_endtoken: __start__\n00:46:48 |     dict_file: /tmp/model1.dict\n00:46:48 |     dict_include_test: False\n00:46:48 |     dict_include_valid: False\n00:46:48 |     dict_initpath: None\n00:46:48 |     dict_language: english\n00:46:48 |     dict_loaded: True\n00:46:48 |     dict_lower: True\n00:46:48 |     dict_max_ngram_size: -1\n00:46:48 |     dict_maxexs: -1\n00:46:48 |     dict_maxtokens: -1\n00:46:48 |     dict_minfreq: 0\n00:46:48 |     dict_nulltoken: __null__\n00:46:48 |     dict_starttoken: __start__\n00:46:48 |     dict_textfields: text,labels\n00:46:48 |     dict_tokenizer: bpe\n00:46:48 |     dict_unktoken: __unk__\n00:46:48 |     display_examples: False\n00:46:48 |     download_path: None\n00:46:48 |     dropout: 0.1\n00:46:48 |     dynamic_batching: None\n00:46:48 |     embedding_projection: random\n00:46:48 |     embedding_size: 768\n00:46:48 |     embedding_type: random\n00:46:48 |     embeddings_scale: False\n00:46:48 |     encode_candidate_vecs: True\n00:46:48 |     encode_candidate_vecs_batchsize: 256\n00:46:48 |     eval_batchsize: None\n00:46:48 |     eval_candidates: inline\n00:46:48 |     eval_dynamic_batching: None\n00:46:48 |     evaltask: None\n00:46:48 |     ffn_size: 3072\n00:46:48 |     final_extra_opt: \n00:46:48 |     fixed_candidate_vecs: reuse\n00:46:48 |     fixed_candidates_path: None\n00:46:48 |     force_fp16_tokens: True\n00:46:48 |     fp16: True\n00:46:48 |     fp16_impl: safe\n00:46:48 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run1/data_test.txt\n00:46:48 |     fromfile_datatype_extension: True\n00:46:48 |     gpu: -1\n00:46:48 |     gradient_clip: 0.1\n00:46:48 |     hide_labels: False\n00:46:48 |     history_add_global_end_token: None\n00:46:48 |     history_reversed: False\n00:46:48 |     history_size: 20\n00:46:48 |     ignore_bad_candidates: False\n00:46:48 |     ignore_labels: None\n00:46:48 |     image_cropsize: 224\n00:46:48 |     image_mode: raw\n00:46:48 |     image_size: 256\n00:46:48 |     inference: max\n00:46:48 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:46:48 |     init_opt: None\n00:46:48 |     interactive_candidates: fixed\n00:46:48 |     interactive_mode: False\n00:46:48 |     invsqrt_lr_decay_gamma: -1\n00:46:48 |     is_debug: False\n00:46:48 |     label_truncate: 72\n00:46:48 |     learn_embeddings: True\n00:46:48 |     learn_positional_embeddings: True\n00:46:48 |     learningrate: 5e-05\n00:46:48 |     load_from_pretrained_ranker: True\n00:46:48 |     log_every_n_secs: 10.0\n00:46:48 |     log_every_n_steps: 50\n00:46:48 |     log_keep_fields: all\n00:46:48 |     loglevel: info\n00:46:48 |     lr_scheduler: reduceonplateau\n00:46:48 |     lr_scheduler_decay: 0.5\n00:46:48 |     lr_scheduler_patience: 3\n00:46:48 |     max_train_steps: -1\n00:46:48 |     max_train_time: 7200.0\n00:46:48 |     memory_attention: sqrt\n00:46:48 |     metrics: default\n00:46:48 |     model: transformer/classifier\n00:46:48 |     model_file: /tmp/model1\n00:46:48 |     model_parallel: False\n00:46:48 |     momentum: 0\n00:46:48 |     multitask_weights: [1]\n00:46:48 |     mutators: None\n00:46:48 |     n_decoder_layers: -1\n00:46:48 |     n_encoder_layers: -1\n00:46:48 |     n_heads: 12\n00:46:48 |     n_layers: 12\n00:46:48 |     n_positions: 1024\n00:46:48 |     n_segments: 2\n00:46:48 |     nesterov: True\n00:46:48 |     no_cuda: False\n00:46:48 |     normalize_sent_emb: False\n00:46:48 |     num_epochs: -1\n00:46:48 |     num_examples: -1\n00:46:48 |     num_workers: 0\n00:46:48 |     nus: [0.7]\n00:46:48 |     optimizer: adamax\n00:46:48 |     output_scaling: 0.06\n00:46:48 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type1/run1/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model1', 'batchsize': 40}\"\n00:46:48 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n00:46:48 |     person_tokens: False\n00:46:48 |     print_scores: False\n00:46:48 |     rank_candidates: False\n00:46:48 |     rank_top_k: -1\n00:46:48 |     reduction_type: mean\n00:46:48 |     ref_class: None\n00:46:48 |     relu_dropout: 0.0\n00:46:48 |     repeat_blocking_heuristic: True\n00:46:48 |     report_filename: \n00:46:48 |     return_cand_scores: False\n00:46:48 |     save_after_valid: True\n00:46:48 |     save_every_n_secs: -1\n00:46:48 |     save_format: conversations\n00:46:48 |     share_encoders: False\n00:46:48 |     share_word_embeddings: False\n00:46:48 |     short_final_eval: False\n00:46:48 |     special_tok_lst: None\n00:46:48 |     split_lines: False\n00:46:48 |     starttime: Dec04_00-34\n00:46:48 |     task: fromfile:parlaiformat\n00:46:48 |     tensorboard_log: False\n00:46:48 |     tensorboard_logdir: None\n00:46:48 |     text_truncate: 360\n00:46:48 |     threshold: 0.5\n00:46:48 |     topk: 5\n00:46:48 |     train_predict: False\n00:46:48 |     truncate: 1024\n00:46:48 |     update_classifier_head_only: False\n00:46:48 |     update_freq: 1\n00:46:48 |     use_memories: False\n00:46:48 |     use_reply: none\n00:46:48 |     validation_cutoff: 1.0\n00:46:48 |     validation_every_n_epochs: -1\n00:46:48 |     validation_every_n_secs: 20.0\n00:46:48 |     validation_every_n_steps: -1\n00:46:48 |     validation_max_exs: -1\n00:46:48 |     validation_metric: accuracy\n00:46:48 |     validation_metric_mode: max\n00:46:48 |     validation_patience: 30\n00:46:48 |     validation_share_agent: False\n00:46:48 |     variant: xlm\n00:46:48 |     verbose: False\n00:46:48 |     wandb_entity: None\n00:46:48 |     wandb_log: False\n00:46:48 |     wandb_name: None\n00:46:48 |     wandb_project: None\n00:46:48 |     warmup_rate: 0.0001\n00:46:48 |     warmup_updates: 1000\n00:46:48 |     weight_decay: None\n00:46:48 |     world_logs: \n00:46:48 |     wrap_memory_encoder: False\n00:46:49 | Evaluating task fromfile:parlaiformat using datatype valid.\n00:46:49 | creating task(s): fromfile:parlaiformat\n00:46:49 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n00:46:49 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run1/data_test.txt\n00:46:57 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8860 8.86e-10               .6225                 .4653   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9400            .9329              .9925   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8800 12.07 562.9  1871       0          0 132.9 1000 .8860   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5243 5.454e-06   208 691.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    109 770.9 2562        .9018\u001b[0m\n00:46:57 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8860 8.86e-10               .6225                 .4653   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9400            .9329              .9925   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8800 12.07 562.9  1871       0          0 132.9 1000 .8860   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5243 5.454e-06   208 691.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    109 770.9 2562        .9018\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model1*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:46:58.612135Z","iopub.execute_input":"2022-12-04T00:46:58.612509Z","iopub.status.idle":"2022-12-04T00:46:59.956052Z","shell.execute_reply.started":"2022-12-04T00:46:58.612474Z","shell.execute_reply":"2022-12-04T00:46:59.954444Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"run 2","metadata":{}},{"cell_type":"code","source":"# run 2 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type1/run2/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model2","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:46:59.957824Z","iopub.execute_input":"2022-12-04T00:46:59.958253Z","iopub.status.idle":"2022-12-04T00:58:53.238092Z","shell.execute_reply.started":"2022-12-04T00:46:59.958210Z","shell.execute_reply":"2022-12-04T00:58:53.236831Z"},"scrolled":true,"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"00:47:07 | building dictionary first...\n00:47:07 | No model with opt yet at: /tmp/model2(.opt)\n00:47:07 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run2/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n00:47:07 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n00:47:07 | Using CUDA\n00:47:07 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n00:47:07 | num words = 54944\n00:47:11 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:47:22 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:47:22 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n00:47:22 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n00:47:22 | Opt:\n00:47:22 |     activation: gelu\n00:47:22 |     adafactor_eps: '(1e-30, 0.001)'\n00:47:22 |     adam_eps: 1e-08\n00:47:22 |     add_p1_after_newln: False\n00:47:22 |     aggregate_micro: False\n00:47:22 |     allow_missing_init_opts: False\n00:47:22 |     attention_dropout: 0.1\n00:47:22 |     batchsize: 20\n00:47:22 |     betas: '(0.9, 0.999)'\n00:47:22 |     bpe_add_prefix_space: None\n00:47:22 |     bpe_debug: False\n00:47:22 |     bpe_dropout: None\n00:47:22 |     bpe_merge: None\n00:47:22 |     bpe_vocab: None\n00:47:22 |     candidates: inline\n00:47:22 |     cap_num_predictions: 100\n00:47:22 |     checkpoint_activations: False\n00:47:22 |     class_weights: None\n00:47:22 |     classes: \"['__notok__', '__ok__']\"\n00:47:22 |     classes_from_file: None\n00:47:22 |     data_parallel: True\n00:47:22 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n00:47:22 |     datatype: train\n00:47:22 |     delimiter: '\\n'\n00:47:22 |     dict_class: parlai.core.dict:DictionaryAgent\n00:47:22 |     dict_endtoken: __start__\n00:47:22 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n00:47:22 |     dict_include_test: False\n00:47:22 |     dict_include_valid: False\n00:47:22 |     dict_initpath: None\n00:47:22 |     dict_language: english\n00:47:22 |     dict_loaded: True\n00:47:22 |     dict_lower: True\n00:47:22 |     dict_max_ngram_size: -1\n00:47:22 |     dict_maxexs: -1\n00:47:22 |     dict_maxtokens: -1\n00:47:22 |     dict_minfreq: 0\n00:47:22 |     dict_nulltoken: __null__\n00:47:22 |     dict_starttoken: __start__\n00:47:22 |     dict_textfields: text,labels\n00:47:22 |     dict_tokenizer: bpe\n00:47:22 |     dict_unktoken: __unk__\n00:47:22 |     display_examples: False\n00:47:22 |     download_path: None\n00:47:22 |     dropout: 0.1\n00:47:22 |     dynamic_batching: None\n00:47:22 |     embedding_projection: random\n00:47:22 |     embedding_size: 768\n00:47:22 |     embedding_type: random\n00:47:22 |     embeddings_scale: False\n00:47:22 |     encode_candidate_vecs: True\n00:47:22 |     encode_candidate_vecs_batchsize: 256\n00:47:22 |     eval_batchsize: None\n00:47:22 |     eval_candidates: inline\n00:47:22 |     eval_dynamic_batching: None\n00:47:22 |     evaltask: None\n00:47:22 |     ffn_size: 3072\n00:47:22 |     final_extra_opt: \n00:47:22 |     fixed_candidate_vecs: reuse\n00:47:22 |     fixed_candidates_path: None\n00:47:22 |     force_fp16_tokens: False\n00:47:22 |     fp16: True\n00:47:22 |     fp16_impl: safe\n00:47:22 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run2/data\n00:47:22 |     fromfile_datatype_extension: True\n00:47:22 |     gpu: -1\n00:47:22 |     gradient_clip: 0.1\n00:47:22 |     hide_labels: False\n00:47:22 |     history_add_global_end_token: None\n00:47:22 |     history_reversed: False\n00:47:22 |     history_size: 20\n00:47:22 |     ignore_bad_candidates: False\n00:47:22 |     ignore_labels: None\n00:47:22 |     image_cropsize: 224\n00:47:22 |     image_mode: raw\n00:47:22 |     image_size: 256\n00:47:22 |     inference: max\n00:47:22 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:47:22 |     init_opt: None\n00:47:22 |     interactive_candidates: fixed\n00:47:22 |     interactive_mode: False\n00:47:22 |     invsqrt_lr_decay_gamma: -1\n00:47:22 |     is_debug: False\n00:47:22 |     label_truncate: 72\n00:47:22 |     learn_embeddings: True\n00:47:22 |     learn_positional_embeddings: True\n00:47:22 |     learningrate: 5e-05\n00:47:22 |     load_from_checkpoint: False\n00:47:22 |     load_from_pretrained_ranker: True\n00:47:22 |     log_every_n_secs: 10.0\n00:47:22 |     log_every_n_steps: 50\n00:47:22 |     log_keep_fields: all\n00:47:22 |     loglevel: info\n00:47:22 |     lr_scheduler: reduceonplateau\n00:47:22 |     lr_scheduler_decay: 0.5\n00:47:22 |     lr_scheduler_patience: 3\n00:47:22 |     max_train_steps: -1\n00:47:22 |     max_train_time: 7200.0\n00:47:22 |     memory_attention: sqrt\n00:47:22 |     metrics: default\n00:47:22 |     model: transformer/classifier\n00:47:22 |     model_file: /tmp/model2\n00:47:22 |     model_parallel: False\n00:47:22 |     momentum: 0\n00:47:22 |     multitask_weights: [1]\n00:47:22 |     mutators: None\n00:47:22 |     n_decoder_layers: -1\n00:47:22 |     n_encoder_layers: -1\n00:47:22 |     n_heads: 12\n00:47:22 |     n_layers: 12\n00:47:22 |     n_positions: 1024\n00:47:22 |     n_segments: 2\n00:47:22 |     nesterov: True\n00:47:22 |     no_cuda: False\n00:47:22 |     normalize_sent_emb: False\n00:47:22 |     num_epochs: -1\n00:47:22 |     num_workers: 0\n00:47:22 |     nus: (0.7,)\n00:47:22 |     optimizer: adamax\n00:47:22 |     output_scaling: 0.06\n00:47:22 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type1/run2/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model2'}\"\n00:47:22 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n00:47:22 |     person_tokens: False\n00:47:22 |     print_scores: False\n00:47:22 |     rank_candidates: False\n00:47:22 |     rank_top_k: -1\n00:47:22 |     reduction_type: mean\n00:47:22 |     ref_class: None\n00:47:22 |     relu_dropout: 0.0\n00:47:22 |     repeat_blocking_heuristic: True\n00:47:22 |     return_cand_scores: False\n00:47:22 |     save_after_valid: True\n00:47:22 |     save_every_n_secs: -1\n00:47:22 |     save_format: conversations\n00:47:22 |     share_encoders: False\n00:47:22 |     share_word_embeddings: False\n00:47:22 |     short_final_eval: False\n00:47:22 |     special_tok_lst: None\n00:47:22 |     split_lines: False\n00:47:22 |     starttime: Dec04_00-47\n00:47:22 |     task: fromfile:parlaiformat\n00:47:22 |     tensorboard_log: False\n00:47:22 |     tensorboard_logdir: None\n00:47:22 |     text_truncate: 360\n00:47:22 |     threshold: 0.5\n00:47:22 |     topk: 5\n00:47:22 |     train_predict: False\n00:47:22 |     truncate: 1024\n00:47:22 |     update_classifier_head_only: False\n00:47:22 |     update_freq: 1\n00:47:22 |     use_memories: False\n00:47:22 |     use_reply: none\n00:47:22 |     validation_cutoff: 1.0\n00:47:22 |     validation_every_n_epochs: -1\n00:47:22 |     validation_every_n_secs: 20.0\n00:47:22 |     validation_every_n_steps: -1\n00:47:22 |     validation_max_exs: -1\n00:47:22 |     validation_metric: accuracy\n00:47:22 |     validation_metric_mode: max\n00:47:22 |     validation_patience: 30\n00:47:22 |     validation_share_agent: False\n00:47:22 |     variant: xlm\n00:47:22 |     verbose: False\n00:47:22 |     wandb_entity: None\n00:47:22 |     wandb_log: False\n00:47:22 |     wandb_name: None\n00:47:22 |     wandb_project: None\n00:47:22 |     warmup_rate: 0.0001\n00:47:22 |     warmup_updates: 1000\n00:47:22 |     weight_decay: None\n00:47:22 |     world_logs: \n00:47:22 |     wrap_memory_encoder: False\n00:47:22 | creating task(s): fromfile:parlaiformat\n00:47:22 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run2/data_train.txt\n00:47:22 | training...\n00:47:32 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .6450 6.45e-10               .6263                 .6134   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6398            .6619              .6748   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6495 11.95     1 279.1 557.8       0          0 39.97  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6450             32768  2.336    .1206  5.93 .6770 1.005e-06 118.6 237.1   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 397.6 794.8 2.003        .6454\n\n00:47:42 | time:20s total_exs:1160 total_steps:58 epochs:5.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6803 6.803e-10               .7111                 .7069   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7153            .6421              .6469   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6374 11.91     1 278.3  1070       0          0 76.91  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6803             32768  2.647    .1207   6.1 .6627 2.905e-06   122 469.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   58 400.3 1539 3.854        .6800\n\n00:47:42 | creating task(s): fromfile:parlaiformat\n00:47:42 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run2/data_valid.txt\n00:47:42 | running eval: valid\n00:47:43 | eval completed in 0.20s\n00:47:43 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5833 5.833e-10               .6429                 .5625   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .5000              .6250   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .4167    11   156  1721       0          0 132.4   24 .5833   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6626 2.905e-06    72 794.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                     58  228 2515        .5714\n\u001b[0m\n00:47:43 | \u001b[1;32mnew best accuracy: 0.5833\u001b[0m\n00:47:43 | saving best valid model: /tmp/model2\n00:47:43 | Saving dictionary to /tmp/model2.dict\n00:47:46 | saving model checkpoint: /tmp/model2.checkpoint\n00:47:46 | Saving dictionary to /tmp/model2.checkpoint.dict\n00:48:02 | time:40s total_exs:1860 total_steps:93 epochs:9.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8857 8.857e-10               .8892                 .8295   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9582            .8820              .9553   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8192 11.84     1 276.9 958.5       0          0 69.24  700   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8857             32768  2.667    .1207 5.957 .6008 4.655e-06 119.1 412.5   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps  ups  weighted_f1  \n         0          0                   93  396 1371 3.47        .8854\n\n00:48:06 | time:44s total_exs:2200 total_steps:110 epochs:11.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9471 9.471e-10               .9486                 .9486   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9486            .9455              .9455   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9455  11.8     1   276  1074       0          0  77.8  340   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9471             32768  3.156    .1207 6.029 .5171 5.504e-06 120.6 469.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  110 396.6 1543 3.91        .9471\n\n00:48:06 | running eval: valid\n00:48:07 | eval completed in 0.20s\n00:48:07 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1731       0          0 133.1   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .5459 5.504e-06    72 798.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    110  228 2530        .9167\n\u001b[0m\n00:48:07 | \u001b[1;32mnew best accuracy: 0.9167 (previous best was 0.5833)\u001b[0m\n00:48:07 | saving best valid model: /tmp/model2\n00:48:16 | saving model checkpoint: /tmp/model2.checkpoint\n00:48:31 | time:69s total_exs:2960 total_steps:148 epochs:14.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9421 9.421e-10               .9462                 .9439   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9485            .9373              .9400   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9347 11.91     1 278.1  1048       0          0 75.38  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9421             32768   3.77    .1207 6.074 .3872 7.404e-06 121.5 457.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  148 399.6 1506 3.777        .9421\n\n00:48:36 | time:74s total_exs:3340 total_steps:167 epochs:16.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9579 9.579e-10               .9628                 .9810   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9452            .9515              .9290   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9752 11.85     1   277  1066       0          0 76.98  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9579             32768  5.233    .1207 6.153 .2359 8.354e-06 123.1 473.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  167 400.1 1540 3.867        .9580\n\n00:48:36 | running eval: valid\n00:48:36 | eval completed in 0.20s\n00:48:36 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1687       0          0 129.7   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .3133 8.354e-06    72 778.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    167  228 2466        .8748\n\u001b[0m\n00:48:36 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 1\u001b[0m\n00:48:36 | saving model checkpoint: /tmp/model2.checkpoint\n00:48:56 | time:94s total_exs:4080 total_steps:204 epochs:20.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9824 9.824e-10               .9836                 .9873   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9798            .9811              .9769   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9854  11.9     1   278  1025       0          0 73.78  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9824             32768  3.789    .1207 6.073 .1023 1.02e-05 121.5   448   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  204 399.5 1474 3.697        .9824\n\n00:48:56 | time:94s total_exs:4120 total_steps:206 epochs:20.60\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9750 9.75e-10               .9811                 .9630   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9630                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9286 11.75     1   275  1087       0          0 79.02   40   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9750             32768  22.21    .1207   6.3 .09224 1.03e-05   126 497.9   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  206  401 1585 4.136        .9748\n\n00:48:56 | running eval: valid\n00:48:57 | eval completed in 0.21s\n00:48:57 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1672       0          0 128.6   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .3191 1.03e-05    72 771.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    206  228 2444        .9167\n\u001b[0m\n00:48:57 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 2\u001b[0m\n00:48:57 | saving model checkpoint: /tmp/model2.checkpoint\n00:49:11 | time:109s total_exs:4900 total_steps:245 epochs:24.50\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9910 9.91e-10               .9908                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9818            .9912              .9826   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.87 .9487 277.4  1063       0          0  76.6  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9910             32768  1.624    .1207 5.987 .04472 1.225e-05 119.7 458.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  245 397.2 1521 3.839        .9910\n\n00:49:17 | time:115s total_exs:5320 total_steps:266 epochs:26.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9952 9.952e-10               .9956                 .9956   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9956            .9948              .9948   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9948  11.5 .3333   270  1027       0          0 76.06  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9952             32768  3.489    .1207  6.09 .02419 1.33e-05 121.8 463.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  266 391.8 1490 3.818        .9952\n\n00:49:17 | running eval: valid\n00:49:17 | eval completed in 0.20s\n00:49:17 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1734       0          0 133.4   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .4712 1.33e-05    72 800.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    266  228 2535        .9167\n\u001b[0m\n00:49:17 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 3\u001b[0m\n00:49:17 | saving model checkpoint: /tmp/model2.checkpoint\n00:49:31 | time:129s total_exs:6060 total_steps:303 epochs:30.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.47 .02703 269.4 995.8       0          0 73.92   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    740   1             32768 .04669    .1207 6.114 .002844 1.515e-05 122.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.9       0          0                  303 391.7 1448 3.705            1\n\n00:49:37 | time:135s total_exs:6500 total_steps:325 epochs:32.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.94     0 278.7  1067       0          0 76.56  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768  .0255    .1207 6.041 .002076 1.625e-05 120.8 462.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  325 399.5 1529 3.843            1\n\n00:49:37 | running eval: valid\n00:49:37 | eval completed in 0.20s\n00:49:37 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1731       0          0 133.1   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 .7307 1.625e-05    72 798.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    325  228 2529        .8748\n\u001b[0m\n00:49:37 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 4\u001b[0m\n00:49:37 | saving model checkpoint: /tmp/model2.checkpoint\n00:49:52 | time:150s total_exs:7280 total_steps:364 epochs:36.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.54     0 270.9  1036       0          0 76.49  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768  .0235    .1207 6.054 .001777 1.82e-05 121.1   463   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  364  392 1499 3.833            1\n\n00:49:57 | time:155s total_exs:7700 total_steps:385 epochs:38.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.69     0 273.7  1044       0          0 76.26  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01905    .1207 6.005 .001593 1.925e-05 120.1 457.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  385 393.8 1502 3.829            1\n\n00:49:57 | running eval: valid\n00:49:57 | eval completed in 0.24s\n00:49:57 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1461       0          0 112.3   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08095     6 .8015 1.925e-05    72 674.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    385  228 2135        .8748\n\u001b[0m\n00:49:57 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 5\u001b[0m\n00:49:57 | saving model checkpoint: /tmp/model2.checkpoint\n00:50:12 | time:170s total_exs:8460 total_steps:423 epochs:42.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0 276.1  1049       0          0 75.98  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01698    .1207 6.076 .001456 2.115e-05 121.5 461.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  423 397.6 1511 3.808            1\n\n00:50:18 | time:176s total_exs:8900 total_steps:445 epochs:44.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.76     0 275.1  1067       0          0 77.53  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n     1             32768  .0158    .1207 5.995 .00135 2.225e-05 119.9 464.8   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  445  395 1531 3.892            1\n\n00:50:18 | running eval: valid\n00:50:18 | eval completed in 0.20s\n00:50:18 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1736       0          0 133.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 .8478 2.225e-05    72 801.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    445  228 2537        .8748\n\u001b[0m\n00:50:18 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 6\u001b[0m\n00:50:18 | saving model checkpoint: /tmp/model2.checkpoint\n00:50:33 | time:190s total_exs:9660 total_steps:483 epochs:48.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.81 .02632 276.2  1024       0          0 74.16   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    760   1             32768  .0433    .1207 5.987 .001271 2.415e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     444       0          0                  483 395.9 1468 3.716            1\n\n00:50:38 | time:196s total_exs:10100 total_steps:505 epochs:50.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.17     0 283.3  1104       0          0 77.92  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01378    .1207 5.986 .001172 2.525e-05 119.7 466.5   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  505  403 1570 3.911            1\n\n00:50:38 | running eval: valid\n00:50:38 | eval completed in 0.20s\n00:50:38 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1710       0          0 131.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 .8688 2.525e-05    72   789       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    505  228 2499        .8748\n\u001b[0m\n00:50:38 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 7\u001b[0m\n00:50:38 | saving model checkpoint: /tmp/model2.checkpoint\n00:50:53 | time:211s total_exs:10880 total_steps:544 epochs:54.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.58     0 271.6  1040       0          0 76.58  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .01281    .1207 6.026 .001094 2.72e-05 120.5 461.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  544 392.1 1501 3.837            1\n\n00:50:58 | time:216s total_exs:11300 total_steps:565 epochs:56.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.65     0   273  1045       0          0 76.56  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01197    .1208 6.033 .001021 2.825e-05 120.7 461.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  565 393.6 1507 3.844            1\n\n00:50:58 | running eval: valid\n00:50:59 | eval completed in 0.20s\n00:50:59 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1683       0          0 129.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 .8906 2.825e-05    72 776.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    565  228 2459        .8748\n\u001b[0m\n00:50:59 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 8\u001b[0m\n00:50:59 | saving model checkpoint: /tmp/model2.checkpoint\n00:51:13 | time:231s total_exs:12080 total_steps:604 epochs:60.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.55     0 271.1  1039       0          0 76.67  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .01117    .1208 6.079 .0009545 3.02e-05 121.6 466.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  604 392.7 1505 3.842            1\n\n00:51:19 | time:237s total_exs:12480 total_steps:624 epochs:62.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.83     0 276.6  1051       0          0 76.01  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .01046    .1208 5.975 .0008922 3.12e-05 119.5 454.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  624 396.1 1506 3.817            1\n\n00:51:19 | running eval: valid\n00:51:19 | eval completed in 0.20s\n00:51:19 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1725       0          0 132.7   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 .9104 3.12e-05    72 796.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    624  228 2521        .8748\n\u001b[0m\n00:51:19 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 9\u001b[0m\n00:51:19 | saving model checkpoint: /tmp/model2.checkpoint\n00:51:33 | time:251s total_exs:13240 total_steps:662 epochs:66.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.2  1027       0          0 74.91  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .009778    .1208 6.005 .0008361 3.31e-05 120.1 449.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  662 394.3 1477 3.753            1\n\n00:51:39 | time:257s total_exs:13680 total_steps:684 epochs:68.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.49     0 269.7  1032       0          0 76.53  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .00915    .1208 5.991 .0007815 3.42e-05 119.8 458.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  684 389.5 1491 3.842            1\n\n00:51:39 | running eval: valid\n00:51:39 | eval completed in 0.20s\n00:51:39 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1734       0          0 133.4   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 .9321 3.42e-05    72 800.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    684  228 2535        .8748\n\u001b[0m\n00:51:39 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 10\u001b[0m\n00:51:39 | saving model checkpoint: /tmp/model2.checkpoint\n00:51:54 | time:271s total_exs:14440 total_steps:722 epochs:72.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.52     0 270.4  1027       0          0 75.92  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .00859    .1208 6.063 .0007294 3.61e-05 121.3 460.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  722 391.7 1487 3.805            1\n\n00:51:59 | time:277s total_exs:14880 total_steps:744 epochs:74.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.72     0 274.4  1060       0          0 77.27  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .008598    .1208 6.045 .0006819 3.72e-05 120.9 467.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  744 395.3 1527 3.879            1\n\n00:51:59 | running eval: valid\n00:52:00 | eval completed in 0.23s\n00:52:00 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1514       0          0 116.4   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 .9469 3.72e-05    72 698.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    744  228 2213        .8748\n\u001b[0m\n00:52:00 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 11\u001b[0m\n00:52:00 | saving model checkpoint: /tmp/model2.checkpoint\n00:52:14 | time:292s total_exs:15640 total_steps:782 epochs:78.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.77     0 275.4  1043       0          0 75.77  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .007452    .1208 6.082 .0006356 3.91e-05 121.6 460.8   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  782  397 1504 3.797            1\n\n00:52:20 | time:297s total_exs:16060 total_steps:803 epochs:80.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.41     0 268.2  1037       0          0  77.3  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006977    .1208 5.981 .0005954 4.015e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   462.3       0          0                  803 387.9 1499 3.881            1\n\n00:52:20 | running eval: valid\n00:52:20 | eval completed in 0.20s\n00:52:20 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1702       0          0 130.9   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 .9643 4.015e-05    72 785.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    803  228 2488        .8748\n\u001b[0m\n00:52:20 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 12\u001b[0m\n00:52:20 | saving model checkpoint: /tmp/model2.checkpoint\n00:52:34 | time:312s total_exs:16820 total_steps:841 epochs:84.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.55     0 270.9  1010       0          0 74.53  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006548    .1208 5.947 .0005575 4.205e-05 118.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   443.2       0          0                  841 389.9 1453 3.735            1\n\n00:52:40 | time:318s total_exs:17240 total_steps:862 epochs:86.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.18     0 283.7  1067       0          0 75.26  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .006114    .1208 6.043 .0005201 4.31e-05 120.9 454.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  862 404.5 1522 3.778            1\n\n00:52:40 | running eval: valid\n00:52:40 | eval completed in 0.20s\n00:52:40 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1734       0          0 133.3   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 .9814 4.31e-05    72 800.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    862  228 2534        .8748\n\u001b[0m\n00:52:40 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 13\u001b[0m\n00:52:40 | saving model checkpoint: /tmp/model2.checkpoint\n00:52:55 | time:333s total_exs:18020 total_steps:901 epochs:90.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.54 .02564 270.8  1030       0          0 76.05   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n    780   1             32768  .0104    .1208 6.062 .0004894 4.505e-05 121.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     461       0          0                  901 392.1 1491 3.812            1\n\n00:53:00 | time:338s total_exs:18440 total_steps:922 epochs:92.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.68 .04762 273.5  1064       0          0 77.76   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  \\\n    420   1             32768 .03235    .1208 6.029 .0004634 4.61e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   468.8       0          0                  922 394.1 1532 3.904            1\n\n00:53:00 | running eval: valid\n00:53:01 | eval completed in 0.20s\n00:53:01 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7857                 .6875   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .7000              .8750   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .5833    11   156  1732       0          0 133.2   24 .7500   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 1.996 4.61e-05    72 799.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    922  228 2531        .7429\n\u001b[0m\n00:53:01 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 14\u001b[0m\n00:53:01 | saving model checkpoint: /tmp/model2.checkpoint\n00:53:15 | time:353s total_exs:19200 total_steps:960 epochs:96.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.74     0 274.9  1033       0          0 75.18  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss      lr  ltpb  ltps  \\\n     1             32768 .005484    .1208     6 .0004283 4.8e-05   120 451.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  960 394.9 1484 3.768            1\n\n00:53:21 | time:359s total_exs:19640 total_steps:982 epochs:98.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.91     0 278.2  1060       0          0 76.24  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .004696    .1208 6.027 .0003992 4.91e-05 120.5 459.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  982 398.7 1520 3.827            1\n\n00:53:21 | running eval: valid\n00:53:21 | eval completed in 0.20s\n00:53:21 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1758       0          0 135.2   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6 1.004 4.91e-05    72 811.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    982  228 2570        .8748\n\u001b[0m\n00:53:21 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 15\u001b[0m\n00:53:21 | saving model checkpoint: /tmp/model2.checkpoint\n00:53:35 | time:373s total_exs:20420 total_steps:1021 epochs:102.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.58     0 271.6  1040       0          0 76.57  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00439    .1208 6.005 .0003733 4.995e-05 120.1 459.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1021 391.7 1500 3.837            1\n\n00:53:41 | time:379s total_exs:20840 total_steps:1042 epochs:104.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.94     0 278.8  1010       0          0 72.45  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004108    .1208 6.067 .0003492 4.995e-05 121.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   439.5       0          0                 1042 400.1 1449 3.636            1\n\n00:53:41 | running eval: valid\n00:53:41 | eval completed in 0.19s\n00:53:41 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1786       0          0 137.3   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6  1.02 4.995e-05    72 824.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1042  228 2611        .8748\n\u001b[0m\n00:53:41 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 16\u001b[0m\n00:53:41 | saving model checkpoint: /tmp/model2.checkpoint\n00:53:56 | time:393s total_exs:21600 total_steps:1080 epochs:108.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.91     0 278.1  1055       0          0 75.87  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003869    .1208 5.976 .0003285 4.995e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   453.4       0          0                 1080 397.6 1508 3.802            1\n\n00:54:01 | time:399s total_exs:22040 total_steps:1102 epochs:110.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.5     0   270  1027       0          0 76.03  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003635    .1209 6.073 .0003087 4.995e-05 121.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.7       0          0                 1102 391.5 1488 3.816            1\n\n00:54:01 | running eval: valid\n00:54:02 | eval completed in 0.21s\n00:54:02 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1611       0          0 123.9   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 1.037 4.995e-05    72 743.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1102  228 2355        .8748\n\u001b[0m\n00:54:02 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 17\u001b[0m\n00:54:02 | saving model checkpoint: /tmp/model2.checkpoint\n00:54:16 | time:414s total_exs:22800 total_steps:1140 epochs:114.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.62     0 272.4  1018       0          0  74.7  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003424    .1209 6.126 .0002907 4.995e-05 122.5   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   457.6       0          0                 1140  395 1475 3.743            1\n\n00:54:22 | time:420s total_exs:23240 total_steps:1162 epochs:116.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.59     0 271.8  1051       0          0 77.36  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00324    .1209 6.005 .0002749 4.995e-05 120.1 464.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1162 391.9 1516 3.884            1\n\n00:54:22 | running eval: valid\n00:54:22 | eval completed in 0.22s\n00:54:22 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1578       0          0 121.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6 1.053 4.995e-05    72 728.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1162  228 2307        .8748\n\u001b[0m\n00:54:22 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 18\u001b[0m\n00:54:22 | saving model checkpoint: /tmp/model2.checkpoint\n00:54:36 | time:434s total_exs:24000 total_steps:1200 epochs:120.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.9     0 278.1  1056       0          0 75.95  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003057    .1209 6.063 .0002594 4.995e-05 121.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.5       0          0                 1200 399.3 1516 3.806            1\n\n00:54:42 | time:440s total_exs:24440 total_steps:1222 epochs:122.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.07     0 281.3  1077       0          0 76.56  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002894    .1209 6.105 .0002454 4.995e-05 122.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   467.4       0          0                 1222 403.4 1544 3.841            1\n\n00:54:42 | running eval: valid\n00:54:42 | eval completed in 0.23s\n00:54:42 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1553       0          0 119.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 1.068 4.995e-05    72 716.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1222  228 2269        .8748\n\u001b[0m\n00:54:42 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 19\u001b[0m\n00:54:42 | saving model checkpoint: /tmp/model2.checkpoint\n00:54:57 | time:455s total_exs:25220 total_steps:1261 epochs:126.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.63     0 272.6  1038       0          0 76.15  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002749    .1209 6.023 .0002331 4.995e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.6       0          0                 1261 393.1 1497 3.816            1\n\n00:55:03 | time:460s total_exs:25640 total_steps:1282 epochs:128.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.72     0 274.3  1068       0          0 77.89  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002613    .1209  6.11 .0002208 4.995e-05 122.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   475.9       0          0                 1282 396.5 1544 3.911            1\n\n00:55:03 | running eval: valid\n00:55:03 | eval completed in 0.20s\n00:55:03 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1707       0          0 131.3   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 1.088 4.995e-05    72   788       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1282  228 2496        .8748\n\u001b[0m\nEpoch 00005: reducing learning rate of group 0 to 2.4975e-05.\n00:55:03 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 20\u001b[0m\n00:55:03 | saving model checkpoint: /tmp/model2.checkpoint\n00:55:18 | time:476s total_exs:26400 total_steps:1320 epochs:132.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.77     0 275.4  1026       0          0 74.51  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002518    .1209     6 .0002134 2.498e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   447.1       0          0                 1320 395.4 1473 3.734            1\n\n00:55:23 | time:481s total_exs:26780 total_steps:1339 epochs:133.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.6     0   272  1056       0          0 77.61  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002454    .1209 6.026 .0002081 2.498e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   467.7       0          0                 1339 392.5 1523 3.898            1\n\n00:55:23 | running eval: valid\n00:55:23 | eval completed in 0.20s\n00:55:23 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1730       0          0   133   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 1.089 2.498e-05    72 798.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1339  228 2528        .8748\n\u001b[0m\n00:55:23 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 21\u001b[0m\n00:55:23 | saving model checkpoint: /tmp/model2.checkpoint\n00:55:38 | time:495s total_exs:27560 total_steps:1378 epochs:137.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.65     0 273.1  1044       0          0 76.44  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .002396    .1209 6.059 .000203 2.498e-05 121.2 463.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1378 394.2 1507 3.831            1\n\n00:55:43 | time:501s total_exs:28000 total_steps:1400 epochs:140.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.55     0 271.1  1044       0          0 77.04  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002334    .1209 6.095 .0001978 2.498e-05 121.9   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   469.6       0          0                 1400  393 1514 3.867            1\n\n00:55:43 | running eval: valid\n00:55:44 | eval completed in 0.20s\n00:55:44 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1722       0          0 132.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6 1.096 2.498e-05    72 794.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1400  228 2517        .8748\n\u001b[0m\n00:55:44 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 22\u001b[0m\n00:55:44 | saving model checkpoint: /tmp/model2.checkpoint\n00:55:58 | time:516s total_exs:28780 total_steps:1439 epochs:143.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.77     0 275.5  1057       0          0 76.72  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002275    .1209 6.031 .0001927 2.498e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   462.7       0          0                 1439 396.1 1520 3.845            1\n\n00:56:04 | time:522s total_exs:29180 total_steps:1459 epochs:145.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.85     0 276.9  1050       0          0 75.83  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002219    .1209 6.025 .0001879 2.498e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.9       0          0                 1459 397.4 1507 3.808            1\n\n00:56:04 | running eval: valid\n00:56:04 | eval completed in 0.20s\n00:56:04 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1698       0          0 130.6   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 1.103 2.498e-05    72 783.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1459  228 2482        .8748\n\u001b[0m\n00:56:04 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 23\u001b[0m\n00:56:04 | saving model checkpoint: /tmp/model2.checkpoint\n00:56:18 | time:536s total_exs:29940 total_steps:1497 epochs:149.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.63     0 272.7  1021       0          0 74.87  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002159    .1209 6.068 .0001829 2.498e-05 121.4   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   454.4       0          0                 1497  394 1475 3.752            1\n\n00:56:24 | time:542s total_exs:30380 total_steps:1519 epochs:151.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.33     0 266.6  1008       0          0 75.59  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002129    .1209 5.995 .0001786 2.498e-05 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   453.2       0          0                 1519 386.5 1461 3.794            1\n\n00:56:24 | running eval: valid\n00:56:24 | eval completed in 0.20s\n00:56:24 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1748       0          0 134.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 1.111 2.498e-05    72 806.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1519  228 2554        .8748\n\u001b[0m\nEpoch 00009: reducing learning rate of group 0 to 1.2488e-05.\n00:56:24 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 24\u001b[0m\n00:56:24 | saving model checkpoint: /tmp/model2.checkpoint\n00:56:39 | time:557s total_exs:31160 total_steps:1558 epochs:155.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.65     0   273  1043       0          0 76.41  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .002067    .1209 6.021 .000175 1.249e-05 120.4 460.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1558 393.4 1503 3.829            1\n\n00:56:45 | time:562s total_exs:31600 total_steps:1580 epochs:158.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.85     0 277.1  1070       0          0 77.25  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002035    .1209 6.055 .0001723 1.249e-05 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   467.7       0          0                 1580 398.2 1538 3.878            1\n\n00:56:45 | running eval: valid\n00:56:45 | eval completed in 0.21s\n00:56:45 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1673       0          0 128.7   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 1.114 1.249e-05    72 772.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1580  228 2446        .8748\n\u001b[0m\n00:56:45 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 25\u001b[0m\n00:56:45 | saving model checkpoint: /tmp/model2.checkpoint\n00:56:59 | time:577s total_exs:32360 total_steps:1618 epochs:161.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.44     0 268.8  1020       0          0  75.9  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002066    .1210 6.034 .0001705 1.249e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     458       0          0                 1618 389.4 1478 3.803            1\n\n00:57:05 | time:583s total_exs:32800 total_steps:1640 epochs:164.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.5     0 270.1  1055       0          0 78.12  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001984    .1210 6.027 .000168 1.249e-05 120.5 470.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1640 390.6 1526 3.921            1\n\n00:57:05 | running eval: valid\n00:57:05 | eval completed in 0.20s\n00:57:05 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1697       0          0 130.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 1.118 1.249e-05    72 783.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1640  228 2481        .8748\n\u001b[0m\n00:57:05 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 26\u001b[0m\n00:57:05 | saving model checkpoint: /tmp/model2.checkpoint\n00:57:20 | time:597s total_exs:33580 total_steps:1679 epochs:167.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.84     0 276.9  1057       0          0 76.36  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001956    .1210  6.01 .0001656 1.249e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     459       0          0                 1679 397.1 1516 3.827            1\n\n00:57:25 | time:603s total_exs:34000 total_steps:1700 epochs:170.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0   276  1032       0          0 74.76  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001925    .1210 6.048 .000163 1.249e-05   121 452.1   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1700  397 1484 3.753            1\n\n00:57:25 | running eval: valid\n00:57:26 | eval completed in 0.20s\n00:57:26 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1736       0          0 133.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 1.121 1.249e-05    72 801.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1700  228 2538        .8748\n\u001b[0m\n00:57:26 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 27\u001b[0m\n00:57:26 | saving model checkpoint: /tmp/model2.checkpoint\n00:57:40 | time:618s total_exs:34780 total_steps:1739 epochs:173.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.76     0 275.2  1060       0          0 77.03  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001901    .1210 5.985 .000161 1.249e-05 119.7   461   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1739 394.9 1521 3.86            1\n\n00:57:46 | time:623s total_exs:35200 total_steps:1760 epochs:176.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.5     0   270  1029       0          0 76.25  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00187    .1210 6.038 .0001584 1.249e-05 120.8 460.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1760 390.7 1490 3.828            1\n\n00:57:46 | running eval: valid\n00:57:46 | eval completed in 0.21s\n00:57:46 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1645       0          0 126.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 1.125 1.249e-05    72 759.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1760  228 2405        .8748\n\u001b[0m\nEpoch 00013: reducing learning rate of group 0 to 6.2438e-06.\n00:57:46 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 28\u001b[0m\n00:57:46 | saving model checkpoint: /tmp/model2.checkpoint\n00:58:01 | time:639s total_exs:35960 total_steps:1798 epochs:179.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.65     0 273.1  1018       0          0 74.53  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001853    .1210 6.011 .0001568 6.244e-06 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     448       0          0                 1798 393.3 1466 3.735            1\n\n00:58:06 | time:644s total_exs:36360 total_steps:1818 epochs:181.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.9     0 278.1  1063       0          0 76.43  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00184    .1210 6.025 .0001557 6.244e-06 120.5 460.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1818 398.6 1523 3.838            1\n\n00:58:06 | running eval: valid\n00:58:06 | eval completed in 0.20s\n00:58:06 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1707       0          0 131.2   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08122     6 1.127 6.244e-06    72 787.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1818  228 2495        .8748\n\u001b[0m\n00:58:06 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 29\u001b[0m\n00:58:06 | saving model checkpoint: /tmp/model2.checkpoint\n00:58:21 | time:659s total_exs:37140 total_steps:1857 epochs:185.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.94     0 278.8  1069       0          0 76.72  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001823    .1210 6.103 .0001543 6.244e-06 122.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   468.2       0          0                 1857 400.8 1538 3.84            1\n\n00:58:26 | time:664s total_exs:37540 total_steps:1877 epochs:187.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.99     0 279.8  1025       0          0 73.24  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001813    .1210 5.965 .0001534 6.244e-06 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   436.9       0          0                 1877 399.1 1461 3.677            1\n\n00:58:26 | running eval: valid\n00:58:27 | eval completed in 0.20s\n00:58:27 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1724       0          0 132.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08124     6 1.129 6.244e-06    72 795.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1877  228 2519        .8748\n\u001b[0m\n00:58:27 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 30\u001b[0m\n00:58:27 | saving model checkpoint: /tmp/model2.checkpoint\n00:58:31 | ran out of patience! stopping training.\n00:58:31 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n00:58:31 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n00:58:31 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run2/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n00:58:31 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n00:58:31 | Using CUDA\n00:58:31 | loading dictionary from /tmp/model2.dict\n00:58:31 | num words = 54944\n00:58:35 | Loading existing model parameters from /tmp/model2\n00:58:44 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:58:45 | creating task(s): fromfile:parlaiformat\n00:58:45 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run2/data_valid.txt\n00:58:46 | running eval: valid\n00:58:46 | eval completed in 0.35s\n00:58:46 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156 988.4       0          0 75.98   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298     6 .5459 5.504e-06    72 456.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    110  228 1445        .9167\n\u001b[0m\n00:58:46 | creating task(s): fromfile:parlaiformat\n00:58:46 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run2/data_test.txt\n00:58:46 | running eval: test\n00:58:51 | eval completed in 4.98s\n00:58:51 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8820 8.82e-10               .6144                 .4563   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9400            .9303              .9924   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8756 12.07 281.4  2842       0          0   202 1000 .8820   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298   5.2 .5216 5.504e-06   104  1050       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    110 385.4 3893        .8987\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type1/run2/data_test.txt -m transformer/classifier -mf /tmp/model2 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:58:53.246943Z","iopub.execute_input":"2022-12-04T00:58:53.247352Z","iopub.status.idle":"2022-12-04T00:59:25.013305Z","shell.execute_reply.started":"2022-12-04T00:58:53.247309Z","shell.execute_reply":"2022-12-04T00:59:25.012094Z"},"scrolled":true,"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"00:59:03 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr1type1/run2/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr1type1/run2/data)\u001b[0m\n00:59:03 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n00:59:03 | Using CUDA\n00:59:03 | loading dictionary from /tmp/model2.dict\n00:59:03 | num words = 54944\n00:59:07 | Loading existing model parameters from /tmp/model2\n00:59:13 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:59:14 | Opt:\n00:59:14 |     activation: gelu\n00:59:14 |     adafactor_eps: '[1e-30, 0.001]'\n00:59:14 |     adam_eps: 1e-08\n00:59:14 |     add_p1_after_newln: False\n00:59:14 |     aggregate_micro: False\n00:59:14 |     allow_missing_init_opts: False\n00:59:14 |     area_under_curve_class: None\n00:59:14 |     area_under_curve_digits: -1\n00:59:14 |     attention_dropout: 0.1\n00:59:14 |     batchsize: 40\n00:59:14 |     betas: '[0.9, 0.999]'\n00:59:14 |     bpe_add_prefix_space: None\n00:59:14 |     bpe_debug: False\n00:59:14 |     bpe_dropout: None\n00:59:14 |     bpe_merge: None\n00:59:14 |     bpe_vocab: None\n00:59:14 |     candidates: inline\n00:59:14 |     cap_num_predictions: 100\n00:59:14 |     checkpoint_activations: False\n00:59:14 |     class_weights: None\n00:59:14 |     classes: \"['__notok__', '__ok__']\"\n00:59:14 |     classes_from_file: None\n00:59:14 |     data_parallel: True\n00:59:14 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n00:59:14 |     datatype: train\n00:59:14 |     delimiter: '\\n'\n00:59:14 |     dict_class: parlai.core.dict:DictionaryAgent\n00:59:14 |     dict_endtoken: __start__\n00:59:14 |     dict_file: /tmp/model2.dict\n00:59:14 |     dict_include_test: False\n00:59:14 |     dict_include_valid: False\n00:59:14 |     dict_initpath: None\n00:59:14 |     dict_language: english\n00:59:14 |     dict_loaded: True\n00:59:14 |     dict_lower: True\n00:59:14 |     dict_max_ngram_size: -1\n00:59:14 |     dict_maxexs: -1\n00:59:14 |     dict_maxtokens: -1\n00:59:14 |     dict_minfreq: 0\n00:59:14 |     dict_nulltoken: __null__\n00:59:14 |     dict_starttoken: __start__\n00:59:14 |     dict_textfields: text,labels\n00:59:14 |     dict_tokenizer: bpe\n00:59:14 |     dict_unktoken: __unk__\n00:59:14 |     display_examples: False\n00:59:14 |     download_path: None\n00:59:14 |     dropout: 0.1\n00:59:14 |     dynamic_batching: None\n00:59:14 |     embedding_projection: random\n00:59:14 |     embedding_size: 768\n00:59:14 |     embedding_type: random\n00:59:14 |     embeddings_scale: False\n00:59:14 |     encode_candidate_vecs: True\n00:59:14 |     encode_candidate_vecs_batchsize: 256\n00:59:14 |     eval_batchsize: None\n00:59:14 |     eval_candidates: inline\n00:59:14 |     eval_dynamic_batching: None\n00:59:14 |     evaltask: None\n00:59:14 |     ffn_size: 3072\n00:59:14 |     final_extra_opt: \n00:59:14 |     fixed_candidate_vecs: reuse\n00:59:14 |     fixed_candidates_path: None\n00:59:14 |     force_fp16_tokens: True\n00:59:14 |     fp16: True\n00:59:14 |     fp16_impl: safe\n00:59:14 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run2/data_test.txt\n00:59:14 |     fromfile_datatype_extension: True\n00:59:14 |     gpu: -1\n00:59:14 |     gradient_clip: 0.1\n00:59:14 |     hide_labels: False\n00:59:14 |     history_add_global_end_token: None\n00:59:14 |     history_reversed: False\n00:59:14 |     history_size: 20\n00:59:14 |     ignore_bad_candidates: False\n00:59:14 |     ignore_labels: None\n00:59:14 |     image_cropsize: 224\n00:59:14 |     image_mode: raw\n00:59:14 |     image_size: 256\n00:59:14 |     inference: max\n00:59:14 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:59:14 |     init_opt: None\n00:59:14 |     interactive_candidates: fixed\n00:59:14 |     interactive_mode: False\n00:59:14 |     invsqrt_lr_decay_gamma: -1\n00:59:14 |     is_debug: False\n00:59:14 |     label_truncate: 72\n00:59:14 |     learn_embeddings: True\n00:59:14 |     learn_positional_embeddings: True\n00:59:14 |     learningrate: 5e-05\n00:59:14 |     load_from_pretrained_ranker: True\n00:59:14 |     log_every_n_secs: 10.0\n00:59:14 |     log_every_n_steps: 50\n00:59:14 |     log_keep_fields: all\n00:59:14 |     loglevel: info\n00:59:14 |     lr_scheduler: reduceonplateau\n00:59:14 |     lr_scheduler_decay: 0.5\n00:59:14 |     lr_scheduler_patience: 3\n00:59:14 |     max_train_steps: -1\n00:59:14 |     max_train_time: 7200.0\n00:59:14 |     memory_attention: sqrt\n00:59:14 |     metrics: default\n00:59:14 |     model: transformer/classifier\n00:59:14 |     model_file: /tmp/model2\n00:59:14 |     model_parallel: False\n00:59:14 |     momentum: 0\n00:59:14 |     multitask_weights: [1]\n00:59:14 |     mutators: None\n00:59:14 |     n_decoder_layers: -1\n00:59:14 |     n_encoder_layers: -1\n00:59:14 |     n_heads: 12\n00:59:14 |     n_layers: 12\n00:59:14 |     n_positions: 1024\n00:59:14 |     n_segments: 2\n00:59:14 |     nesterov: True\n00:59:14 |     no_cuda: False\n00:59:14 |     normalize_sent_emb: False\n00:59:14 |     num_epochs: -1\n00:59:14 |     num_examples: -1\n00:59:14 |     num_workers: 0\n00:59:14 |     nus: [0.7]\n00:59:14 |     optimizer: adamax\n00:59:14 |     output_scaling: 0.06\n00:59:14 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type1/run2/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model2', 'batchsize': 40}\"\n00:59:14 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n00:59:14 |     person_tokens: False\n00:59:14 |     print_scores: False\n00:59:14 |     rank_candidates: False\n00:59:14 |     rank_top_k: -1\n00:59:14 |     reduction_type: mean\n00:59:14 |     ref_class: None\n00:59:14 |     relu_dropout: 0.0\n00:59:14 |     repeat_blocking_heuristic: True\n00:59:14 |     report_filename: \n00:59:14 |     return_cand_scores: False\n00:59:14 |     save_after_valid: True\n00:59:14 |     save_every_n_secs: -1\n00:59:14 |     save_format: conversations\n00:59:14 |     share_encoders: False\n00:59:14 |     share_word_embeddings: False\n00:59:14 |     short_final_eval: False\n00:59:14 |     special_tok_lst: None\n00:59:14 |     split_lines: False\n00:59:14 |     starttime: Dec04_00-47\n00:59:14 |     task: fromfile:parlaiformat\n00:59:14 |     tensorboard_log: False\n00:59:14 |     tensorboard_logdir: None\n00:59:14 |     text_truncate: 360\n00:59:14 |     threshold: 0.5\n00:59:14 |     topk: 5\n00:59:14 |     train_predict: False\n00:59:14 |     truncate: 1024\n00:59:14 |     update_classifier_head_only: False\n00:59:14 |     update_freq: 1\n00:59:14 |     use_memories: False\n00:59:14 |     use_reply: none\n00:59:14 |     validation_cutoff: 1.0\n00:59:14 |     validation_every_n_epochs: -1\n00:59:14 |     validation_every_n_secs: 20.0\n00:59:14 |     validation_every_n_steps: -1\n00:59:14 |     validation_max_exs: -1\n00:59:14 |     validation_metric: accuracy\n00:59:14 |     validation_metric_mode: max\n00:59:14 |     validation_patience: 30\n00:59:14 |     validation_share_agent: False\n00:59:14 |     variant: xlm\n00:59:14 |     verbose: False\n00:59:14 |     wandb_entity: None\n00:59:14 |     wandb_log: False\n00:59:14 |     wandb_name: None\n00:59:14 |     wandb_project: None\n00:59:14 |     warmup_rate: 0.0001\n00:59:14 |     warmup_updates: 1000\n00:59:14 |     weight_decay: None\n00:59:14 |     world_logs: \n00:59:14 |     wrap_memory_encoder: False\n00:59:15 | Evaluating task fromfile:parlaiformat using datatype valid.\n00:59:15 | creating task(s): fromfile:parlaiformat\n00:59:15 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n00:59:15 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run2/data_test.txt\n00:59:23 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8820 8.82e-10               .6144                 .4563   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9400            .9303              .9924   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8756 12.07 562.9  1845       0          0 131.1 1000 .8820   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5216 5.504e-06   208 681.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    110 770.9 2527        .8987\u001b[0m\n00:59:23 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8820 8.82e-10               .6144                 .4563   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9400            .9303              .9924   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8756 12.07 562.9  1845       0          0 131.1 1000 .8820   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5216 5.504e-06   208 681.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    110 770.9 2527        .8987\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model2*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:59:25.015385Z","iopub.execute_input":"2022-12-04T00:59:25.015850Z","iopub.status.idle":"2022-12-04T00:59:26.232742Z","shell.execute_reply.started":"2022-12-04T00:59:25.015804Z","shell.execute_reply":"2022-12-04T00:59:26.231432Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"run 3","metadata":{}},{"cell_type":"code","source":"# run 3 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type1/run3/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model3","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:59:26.234562Z","iopub.execute_input":"2022-12-04T00:59:26.235053Z","iopub.status.idle":"2022-12-04T01:01:22.626432Z","shell.execute_reply.started":"2022-12-04T00:59:26.235004Z","shell.execute_reply":"2022-12-04T01:01:22.625189Z"},"scrolled":true,"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"00:59:33 | building dictionary first...\n00:59:33 | No model with opt yet at: /tmp/model3(.opt)\n00:59:33 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run3/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n00:59:33 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n00:59:33 | Using CUDA\n00:59:33 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n00:59:33 | num words = 54944\n00:59:38 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:59:48 | Total parameters: 128,042,498 (128,042,498 trainable)\n00:59:48 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n00:59:48 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n00:59:48 | Opt:\n00:59:48 |     activation: gelu\n00:59:48 |     adafactor_eps: '(1e-30, 0.001)'\n00:59:48 |     adam_eps: 1e-08\n00:59:48 |     add_p1_after_newln: False\n00:59:48 |     aggregate_micro: False\n00:59:48 |     allow_missing_init_opts: False\n00:59:48 |     attention_dropout: 0.1\n00:59:48 |     batchsize: 20\n00:59:48 |     betas: '(0.9, 0.999)'\n00:59:48 |     bpe_add_prefix_space: None\n00:59:48 |     bpe_debug: False\n00:59:48 |     bpe_dropout: None\n00:59:48 |     bpe_merge: None\n00:59:48 |     bpe_vocab: None\n00:59:48 |     candidates: inline\n00:59:48 |     cap_num_predictions: 100\n00:59:48 |     checkpoint_activations: False\n00:59:48 |     class_weights: None\n00:59:48 |     classes: \"['__notok__', '__ok__']\"\n00:59:48 |     classes_from_file: None\n00:59:48 |     data_parallel: True\n00:59:48 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n00:59:48 |     datatype: train\n00:59:48 |     delimiter: '\\n'\n00:59:48 |     dict_class: parlai.core.dict:DictionaryAgent\n00:59:48 |     dict_endtoken: __start__\n00:59:48 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n00:59:48 |     dict_include_test: False\n00:59:48 |     dict_include_valid: False\n00:59:48 |     dict_initpath: None\n00:59:48 |     dict_language: english\n00:59:48 |     dict_loaded: True\n00:59:48 |     dict_lower: True\n00:59:48 |     dict_max_ngram_size: -1\n00:59:48 |     dict_maxexs: -1\n00:59:48 |     dict_maxtokens: -1\n00:59:48 |     dict_minfreq: 0\n00:59:48 |     dict_nulltoken: __null__\n00:59:48 |     dict_starttoken: __start__\n00:59:48 |     dict_textfields: text,labels\n00:59:48 |     dict_tokenizer: bpe\n00:59:48 |     dict_unktoken: __unk__\n00:59:48 |     display_examples: False\n00:59:48 |     download_path: None\n00:59:48 |     dropout: 0.1\n00:59:48 |     dynamic_batching: None\n00:59:48 |     embedding_projection: random\n00:59:48 |     embedding_size: 768\n00:59:48 |     embedding_type: random\n00:59:48 |     embeddings_scale: False\n00:59:48 |     encode_candidate_vecs: True\n00:59:48 |     encode_candidate_vecs_batchsize: 256\n00:59:48 |     eval_batchsize: None\n00:59:48 |     eval_candidates: inline\n00:59:48 |     eval_dynamic_batching: None\n00:59:48 |     evaltask: None\n00:59:48 |     ffn_size: 3072\n00:59:48 |     final_extra_opt: \n00:59:48 |     fixed_candidate_vecs: reuse\n00:59:48 |     fixed_candidates_path: None\n00:59:48 |     force_fp16_tokens: False\n00:59:48 |     fp16: True\n00:59:48 |     fp16_impl: safe\n00:59:48 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run3/data\n00:59:48 |     fromfile_datatype_extension: True\n00:59:48 |     gpu: -1\n00:59:48 |     gradient_clip: 0.1\n00:59:48 |     hide_labels: False\n00:59:48 |     history_add_global_end_token: None\n00:59:48 |     history_reversed: False\n00:59:48 |     history_size: 20\n00:59:48 |     ignore_bad_candidates: False\n00:59:48 |     ignore_labels: None\n00:59:48 |     image_cropsize: 224\n00:59:48 |     image_mode: raw\n00:59:48 |     image_size: 256\n00:59:48 |     inference: max\n00:59:48 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n00:59:48 |     init_opt: None\n00:59:48 |     interactive_candidates: fixed\n00:59:48 |     interactive_mode: False\n00:59:48 |     invsqrt_lr_decay_gamma: -1\n00:59:48 |     is_debug: False\n00:59:48 |     label_truncate: 72\n00:59:48 |     learn_embeddings: True\n00:59:48 |     learn_positional_embeddings: True\n00:59:48 |     learningrate: 5e-05\n00:59:48 |     load_from_checkpoint: False\n00:59:48 |     load_from_pretrained_ranker: True\n00:59:48 |     log_every_n_secs: 10.0\n00:59:48 |     log_every_n_steps: 50\n00:59:48 |     log_keep_fields: all\n00:59:48 |     loglevel: info\n00:59:48 |     lr_scheduler: reduceonplateau\n00:59:48 |     lr_scheduler_decay: 0.5\n00:59:48 |     lr_scheduler_patience: 3\n00:59:48 |     max_train_steps: -1\n00:59:48 |     max_train_time: 7200.0\n00:59:48 |     memory_attention: sqrt\n00:59:48 |     metrics: default\n00:59:48 |     model: transformer/classifier\n00:59:48 |     model_file: /tmp/model3\n00:59:48 |     model_parallel: False\n00:59:48 |     momentum: 0\n00:59:48 |     multitask_weights: [1]\n00:59:48 |     mutators: None\n00:59:48 |     n_decoder_layers: -1\n00:59:48 |     n_encoder_layers: -1\n00:59:48 |     n_heads: 12\n00:59:48 |     n_layers: 12\n00:59:48 |     n_positions: 1024\n00:59:48 |     n_segments: 2\n00:59:48 |     nesterov: True\n00:59:48 |     no_cuda: False\n00:59:48 |     normalize_sent_emb: False\n00:59:48 |     num_epochs: -1\n00:59:48 |     num_workers: 0\n00:59:48 |     nus: (0.7,)\n00:59:48 |     optimizer: adamax\n00:59:48 |     output_scaling: 0.06\n00:59:48 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type1/run3/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model3'}\"\n00:59:48 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n00:59:48 |     person_tokens: False\n00:59:48 |     print_scores: False\n00:59:48 |     rank_candidates: False\n00:59:48 |     rank_top_k: -1\n00:59:48 |     reduction_type: mean\n00:59:48 |     ref_class: None\n00:59:48 |     relu_dropout: 0.0\n00:59:48 |     repeat_blocking_heuristic: True\n00:59:48 |     return_cand_scores: False\n00:59:48 |     save_after_valid: True\n00:59:48 |     save_every_n_secs: -1\n00:59:48 |     save_format: conversations\n00:59:48 |     share_encoders: False\n00:59:48 |     share_word_embeddings: False\n00:59:48 |     short_final_eval: False\n00:59:48 |     special_tok_lst: None\n00:59:48 |     split_lines: False\n00:59:48 |     starttime: Dec04_00-59\n00:59:48 |     task: fromfile:parlaiformat\n00:59:48 |     tensorboard_log: False\n00:59:48 |     tensorboard_logdir: None\n00:59:48 |     text_truncate: 360\n00:59:48 |     threshold: 0.5\n00:59:48 |     topk: 5\n00:59:48 |     train_predict: False\n00:59:48 |     truncate: 1024\n00:59:48 |     update_classifier_head_only: False\n00:59:48 |     update_freq: 1\n00:59:48 |     use_memories: False\n00:59:48 |     use_reply: none\n00:59:48 |     validation_cutoff: 1.0\n00:59:48 |     validation_every_n_epochs: -1\n00:59:48 |     validation_every_n_secs: 20.0\n00:59:48 |     validation_every_n_steps: -1\n00:59:48 |     validation_max_exs: -1\n00:59:48 |     validation_metric: accuracy\n00:59:48 |     validation_metric_mode: max\n00:59:48 |     validation_patience: 30\n00:59:48 |     validation_share_agent: False\n00:59:48 |     variant: xlm\n00:59:48 |     verbose: False\n00:59:48 |     wandb_entity: None\n00:59:48 |     wandb_log: False\n00:59:48 |     wandb_name: None\n00:59:48 |     wandb_project: None\n00:59:48 |     warmup_rate: 0.0001\n00:59:48 |     warmup_updates: 1000\n00:59:48 |     weight_decay: None\n00:59:48 |     world_logs: \n00:59:48 |     wrap_memory_encoder: False\n00:59:49 | creating task(s): fromfile:parlaiformat\n00:59:49 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run3/data_train.txt\n00:59:49 | training...\n00:59:59 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5675 5.675e-10               .6263                 .5731   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6905            .4866              .5578   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .4316 11.16     1 263.2 516.9       0          0 39.28  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5675             32768  2.288    .1206  6.05 .6840 1.005e-06   121 237.6   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 384.2 754.5 1.968        .5600\n\n01:00:09 | time:20s total_exs:1140 total_steps:57 epochs:5.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6581 6.581e-10               .6911                 .6233   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7753            .6172              .7133   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .5440 11.41     1 268.2  1037       0          0 77.31  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6581             32768  2.499    .1207 5.986 .6662 2.855e-06 119.7 462.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   57 387.9 1499 3.875        .6537\n\n01:00:09 | creating task(s): fromfile:parlaiformat\n01:00:09 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run3/data_valid.txt\n01:00:09 | running eval: valid\n01:00:09 | eval completed in 0.20s\n01:00:09 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .7200                 .6923   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .6957              .7273   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .6667 11.71 164.5  1845       0          0 134.5   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6553 2.855e-06    72 807.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     57 236.5 2652        .7078\n\u001b[0m\n01:00:09 | \u001b[1;32mnew best accuracy: 0.7083\u001b[0m\n01:00:09 | saving best valid model: /tmp/model3\n01:00:09 | Saving dictionary to /tmp/model3.dict\n01:00:13 | saving model checkpoint: /tmp/model3.checkpoint\n01:00:13 | Saving dictionary to /tmp/model3.checkpoint.dict\n01:00:29 | time:40s total_exs:1860 total_steps:93 epochs:9.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8681 8.681e-10               .8536                 .9052   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8076            .8799              .8406   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9231 11.39     1 267.8 944.5       0          0 70.55  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8681             32768  3.156    .1207 5.953 .6019 4.655e-06 119.1   420   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   93 386.8 1364 3.535        .8674\n\n01:00:33 | time:44s total_exs:2100 total_steps:105 epochs:10.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9292 9.292e-10               .9244                 .9286   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9204            .9333              .9297   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9370 11.64     1 272.8  1011       0          0 74.12  240   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9292             32768  3.304    .1207 5.942 .5293 5.254e-06 118.8 440.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  105 391.7 1452 3.732        .9291\n\n01:00:33 | running eval: valid\n01:00:33 | eval completed in 0.19s\n01:00:33 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 11.71 164.5  1896       0          0 138.2   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5204 5.254e-06    72 829.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    105 236.5 2725        .9161\n\u001b[0m\n01:00:33 | \u001b[1;32mnew best accuracy: 0.9167 (previous best was 0.7083)\u001b[0m\n01:00:33 | saving best valid model: /tmp/model3\n01:00:42 | saving model checkpoint: /tmp/model3.checkpoint\n01:00:57 | time:68s total_exs:2880 total_steps:144 epochs:14.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9513 9.513e-10               .9499                 .9524   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9474            .9526              .9502   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9550 11.41     1 268.3  1023       0          0 76.25  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9513             32768  4.141    .1207 5.974 .3909 7.204e-06 119.5 455.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  144 387.8 1478 3.821        .9513\n\n01:01:02 | time:73s total_exs:3240 total_steps:162 epochs:16.20\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9750 9.75e-10               .9756                 .9890   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9626            .9744              .9607   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9884 11.55     1 271.1  1018       0          0 75.09  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9750             32768  5.154    .1207 6.039 .1956 8.104e-06 120.8 453.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  162 391.8 1471 3.772        .9750\n\n01:01:02 | running eval: valid\n01:01:02 | eval completed in 0.22s\n01:01:02 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 11.71 164.5  1712       0          0 124.9   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .1344 8.104e-06    72 749.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    162 236.5 2462            1\n\u001b[0m\n01:01:02 | \u001b[1;32mnew best accuracy: 1 (previous best was 0.9167)\u001b[0m\n01:01:02 | saving best valid model: /tmp/model3\n01:01:07 | task solved! stopping.\n01:01:07 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n01:01:07 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n01:01:07 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run3/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n01:01:07 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n01:01:07 | Using CUDA\n01:01:07 | loading dictionary from /tmp/model3.dict\n01:01:07 | num words = 54944\n01:01:12 | Loading existing model parameters from /tmp/model3\n01:01:14 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:01:15 | creating task(s): fromfile:parlaiformat\n01:01:15 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run3/data_valid.txt\n01:01:15 | running eval: valid\n01:01:15 | eval completed in 0.21s\n01:01:15 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 11.71 164.5  1765       0          0 128.7   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294     6 .1344 8.104e-06    72 772.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    162 236.5 2537            1\n\u001b[0m\n01:01:15 | creating task(s): fromfile:parlaiformat\n01:01:15 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run3/data_test.txt\n01:01:15 | running eval: test\n01:01:20 | eval completed in 5.15s\n01:01:20 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9360 9.36e-10               .7480                 .6169   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9633              .9941   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9344 12.07 281.4  2750       0          0 195.4 1000 .9360   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294   5.2 .2068 8.104e-06   104  1016       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    162 385.4 3766        .9418\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type1/run3/data_test.txt -m transformer/classifier -mf /tmp/model3 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:01:22.630009Z","iopub.execute_input":"2022-12-04T01:01:22.630746Z","iopub.status.idle":"2022-12-04T01:01:53.005206Z","shell.execute_reply.started":"2022-12-04T01:01:22.630701Z","shell.execute_reply":"2022-12-04T01:01:53.003955Z"},"scrolled":true,"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"01:01:31 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr1type1/run3/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr1type1/run3/data)\u001b[0m\n01:01:31 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n01:01:31 | Using CUDA\n01:01:31 | loading dictionary from /tmp/model3.dict\n01:01:31 | num words = 54944\n01:01:36 | Loading existing model parameters from /tmp/model3\n01:01:41 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:01:43 | Opt:\n01:01:43 |     activation: gelu\n01:01:43 |     adafactor_eps: '[1e-30, 0.001]'\n01:01:43 |     adam_eps: 1e-08\n01:01:43 |     add_p1_after_newln: False\n01:01:43 |     aggregate_micro: False\n01:01:43 |     allow_missing_init_opts: False\n01:01:43 |     area_under_curve_class: None\n01:01:43 |     area_under_curve_digits: -1\n01:01:43 |     attention_dropout: 0.1\n01:01:43 |     batchsize: 40\n01:01:43 |     betas: '[0.9, 0.999]'\n01:01:43 |     bpe_add_prefix_space: None\n01:01:43 |     bpe_debug: False\n01:01:43 |     bpe_dropout: None\n01:01:43 |     bpe_merge: None\n01:01:43 |     bpe_vocab: None\n01:01:43 |     candidates: inline\n01:01:43 |     cap_num_predictions: 100\n01:01:43 |     checkpoint_activations: False\n01:01:43 |     class_weights: None\n01:01:43 |     classes: \"['__notok__', '__ok__']\"\n01:01:43 |     classes_from_file: None\n01:01:43 |     data_parallel: True\n01:01:43 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n01:01:43 |     datatype: train\n01:01:43 |     delimiter: '\\n'\n01:01:43 |     dict_class: parlai.core.dict:DictionaryAgent\n01:01:43 |     dict_endtoken: __start__\n01:01:43 |     dict_file: /tmp/model3.dict\n01:01:43 |     dict_include_test: False\n01:01:43 |     dict_include_valid: False\n01:01:43 |     dict_initpath: None\n01:01:43 |     dict_language: english\n01:01:43 |     dict_loaded: True\n01:01:43 |     dict_lower: True\n01:01:43 |     dict_max_ngram_size: -1\n01:01:43 |     dict_maxexs: -1\n01:01:43 |     dict_maxtokens: -1\n01:01:43 |     dict_minfreq: 0\n01:01:43 |     dict_nulltoken: __null__\n01:01:43 |     dict_starttoken: __start__\n01:01:43 |     dict_textfields: text,labels\n01:01:43 |     dict_tokenizer: bpe\n01:01:43 |     dict_unktoken: __unk__\n01:01:43 |     display_examples: False\n01:01:43 |     download_path: None\n01:01:43 |     dropout: 0.1\n01:01:43 |     dynamic_batching: None\n01:01:43 |     embedding_projection: random\n01:01:43 |     embedding_size: 768\n01:01:43 |     embedding_type: random\n01:01:43 |     embeddings_scale: False\n01:01:43 |     encode_candidate_vecs: True\n01:01:43 |     encode_candidate_vecs_batchsize: 256\n01:01:43 |     eval_batchsize: None\n01:01:43 |     eval_candidates: inline\n01:01:43 |     eval_dynamic_batching: None\n01:01:43 |     evaltask: None\n01:01:43 |     ffn_size: 3072\n01:01:43 |     final_extra_opt: \n01:01:43 |     fixed_candidate_vecs: reuse\n01:01:43 |     fixed_candidates_path: None\n01:01:43 |     force_fp16_tokens: True\n01:01:43 |     fp16: True\n01:01:43 |     fp16_impl: safe\n01:01:43 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run3/data_test.txt\n01:01:43 |     fromfile_datatype_extension: True\n01:01:43 |     gpu: -1\n01:01:43 |     gradient_clip: 0.1\n01:01:43 |     hide_labels: False\n01:01:43 |     history_add_global_end_token: None\n01:01:43 |     history_reversed: False\n01:01:43 |     history_size: 20\n01:01:43 |     ignore_bad_candidates: False\n01:01:43 |     ignore_labels: None\n01:01:43 |     image_cropsize: 224\n01:01:43 |     image_mode: raw\n01:01:43 |     image_size: 256\n01:01:43 |     inference: max\n01:01:43 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:01:43 |     init_opt: None\n01:01:43 |     interactive_candidates: fixed\n01:01:43 |     interactive_mode: False\n01:01:43 |     invsqrt_lr_decay_gamma: -1\n01:01:43 |     is_debug: False\n01:01:43 |     label_truncate: 72\n01:01:43 |     learn_embeddings: True\n01:01:43 |     learn_positional_embeddings: True\n01:01:43 |     learningrate: 5e-05\n01:01:43 |     load_from_pretrained_ranker: True\n01:01:43 |     log_every_n_secs: 10.0\n01:01:43 |     log_every_n_steps: 50\n01:01:43 |     log_keep_fields: all\n01:01:43 |     loglevel: info\n01:01:43 |     lr_scheduler: reduceonplateau\n01:01:43 |     lr_scheduler_decay: 0.5\n01:01:43 |     lr_scheduler_patience: 3\n01:01:43 |     max_train_steps: -1\n01:01:43 |     max_train_time: 7200.0\n01:01:43 |     memory_attention: sqrt\n01:01:43 |     metrics: default\n01:01:43 |     model: transformer/classifier\n01:01:43 |     model_file: /tmp/model3\n01:01:43 |     model_parallel: False\n01:01:43 |     momentum: 0\n01:01:43 |     multitask_weights: [1]\n01:01:43 |     mutators: None\n01:01:43 |     n_decoder_layers: -1\n01:01:43 |     n_encoder_layers: -1\n01:01:43 |     n_heads: 12\n01:01:43 |     n_layers: 12\n01:01:43 |     n_positions: 1024\n01:01:43 |     n_segments: 2\n01:01:43 |     nesterov: True\n01:01:43 |     no_cuda: False\n01:01:43 |     normalize_sent_emb: False\n01:01:43 |     num_epochs: -1\n01:01:43 |     num_examples: -1\n01:01:43 |     num_workers: 0\n01:01:43 |     nus: [0.7]\n01:01:43 |     optimizer: adamax\n01:01:43 |     output_scaling: 0.06\n01:01:43 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type1/run3/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model3', 'batchsize': 40}\"\n01:01:43 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n01:01:43 |     person_tokens: False\n01:01:43 |     print_scores: False\n01:01:43 |     rank_candidates: False\n01:01:43 |     rank_top_k: -1\n01:01:43 |     reduction_type: mean\n01:01:43 |     ref_class: None\n01:01:43 |     relu_dropout: 0.0\n01:01:43 |     repeat_blocking_heuristic: True\n01:01:43 |     report_filename: \n01:01:43 |     return_cand_scores: False\n01:01:43 |     save_after_valid: True\n01:01:43 |     save_every_n_secs: -1\n01:01:43 |     save_format: conversations\n01:01:43 |     share_encoders: False\n01:01:43 |     share_word_embeddings: False\n01:01:43 |     short_final_eval: False\n01:01:43 |     special_tok_lst: None\n01:01:43 |     split_lines: False\n01:01:43 |     starttime: Dec04_00-59\n01:01:43 |     task: fromfile:parlaiformat\n01:01:43 |     tensorboard_log: False\n01:01:43 |     tensorboard_logdir: None\n01:01:43 |     text_truncate: 360\n01:01:43 |     threshold: 0.5\n01:01:43 |     topk: 5\n01:01:43 |     train_predict: False\n01:01:43 |     truncate: 1024\n01:01:43 |     update_classifier_head_only: False\n01:01:43 |     update_freq: 1\n01:01:43 |     use_memories: False\n01:01:43 |     use_reply: none\n01:01:43 |     validation_cutoff: 1.0\n01:01:43 |     validation_every_n_epochs: -1\n01:01:43 |     validation_every_n_secs: 20.0\n01:01:43 |     validation_every_n_steps: -1\n01:01:43 |     validation_max_exs: -1\n01:01:43 |     validation_metric: accuracy\n01:01:43 |     validation_metric_mode: max\n01:01:43 |     validation_patience: 30\n01:01:43 |     validation_share_agent: False\n01:01:43 |     variant: xlm\n01:01:43 |     verbose: False\n01:01:43 |     wandb_entity: None\n01:01:43 |     wandb_log: False\n01:01:43 |     wandb_name: None\n01:01:43 |     wandb_project: None\n01:01:43 |     warmup_rate: 0.0001\n01:01:43 |     warmup_updates: 1000\n01:01:43 |     weight_decay: None\n01:01:43 |     world_logs: \n01:01:43 |     wrap_memory_encoder: False\n01:01:43 | Evaluating task fromfile:parlaiformat using datatype valid.\n01:01:43 | creating task(s): fromfile:parlaiformat\n01:01:43 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n01:01:43 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run3/data_test.txt\n01:01:51 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9360 9.36e-10               .7480                 .6169   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9633              .9941   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9344 12.07 562.9  1906       0          0 135.4 1000 .9360   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2068 8.104e-06   208 704.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    162 770.9 2610        .9418\u001b[0m\n01:01:51 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9360 9.36e-10               .7480                 .6169   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9633              .9941   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9344 12.07 562.9  1906       0          0 135.4 1000 .9360   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2068 8.104e-06   208 704.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    162 770.9 2610        .9418\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model3*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:01:53.007171Z","iopub.execute_input":"2022-12-04T01:01:53.007583Z","iopub.status.idle":"2022-12-04T01:01:54.453759Z","shell.execute_reply.started":"2022-12-04T01:01:53.007540Z","shell.execute_reply":"2022-12-04T01:01:54.452146Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"run 4","metadata":{}},{"cell_type":"code","source":"# run 4 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type1/run4/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model4","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:01:54.456065Z","iopub.execute_input":"2022-12-04T01:01:54.456504Z","iopub.status.idle":"2022-12-04T01:03:56.495280Z","shell.execute_reply.started":"2022-12-04T01:01:54.456460Z","shell.execute_reply":"2022-12-04T01:03:56.493966Z"},"scrolled":true,"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"01:02:01 | building dictionary first...\n01:02:01 | No model with opt yet at: /tmp/model4(.opt)\n01:02:01 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run4/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n01:02:01 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n01:02:01 | Using CUDA\n01:02:01 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n01:02:01 | num words = 54944\n01:02:06 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:02:17 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:02:17 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n01:02:17 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n01:02:17 | Opt:\n01:02:17 |     activation: gelu\n01:02:17 |     adafactor_eps: '(1e-30, 0.001)'\n01:02:17 |     adam_eps: 1e-08\n01:02:17 |     add_p1_after_newln: False\n01:02:17 |     aggregate_micro: False\n01:02:17 |     allow_missing_init_opts: False\n01:02:17 |     attention_dropout: 0.1\n01:02:17 |     batchsize: 20\n01:02:17 |     betas: '(0.9, 0.999)'\n01:02:17 |     bpe_add_prefix_space: None\n01:02:17 |     bpe_debug: False\n01:02:17 |     bpe_dropout: None\n01:02:17 |     bpe_merge: None\n01:02:17 |     bpe_vocab: None\n01:02:17 |     candidates: inline\n01:02:17 |     cap_num_predictions: 100\n01:02:17 |     checkpoint_activations: False\n01:02:17 |     class_weights: None\n01:02:17 |     classes: \"['__notok__', '__ok__']\"\n01:02:17 |     classes_from_file: None\n01:02:17 |     data_parallel: True\n01:02:17 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n01:02:17 |     datatype: train\n01:02:17 |     delimiter: '\\n'\n01:02:17 |     dict_class: parlai.core.dict:DictionaryAgent\n01:02:17 |     dict_endtoken: __start__\n01:02:17 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n01:02:17 |     dict_include_test: False\n01:02:17 |     dict_include_valid: False\n01:02:17 |     dict_initpath: None\n01:02:17 |     dict_language: english\n01:02:17 |     dict_loaded: True\n01:02:17 |     dict_lower: True\n01:02:17 |     dict_max_ngram_size: -1\n01:02:17 |     dict_maxexs: -1\n01:02:17 |     dict_maxtokens: -1\n01:02:17 |     dict_minfreq: 0\n01:02:17 |     dict_nulltoken: __null__\n01:02:17 |     dict_starttoken: __start__\n01:02:17 |     dict_textfields: text,labels\n01:02:17 |     dict_tokenizer: bpe\n01:02:17 |     dict_unktoken: __unk__\n01:02:17 |     display_examples: False\n01:02:17 |     download_path: None\n01:02:17 |     dropout: 0.1\n01:02:17 |     dynamic_batching: None\n01:02:17 |     embedding_projection: random\n01:02:17 |     embedding_size: 768\n01:02:17 |     embedding_type: random\n01:02:17 |     embeddings_scale: False\n01:02:17 |     encode_candidate_vecs: True\n01:02:17 |     encode_candidate_vecs_batchsize: 256\n01:02:17 |     eval_batchsize: None\n01:02:17 |     eval_candidates: inline\n01:02:17 |     eval_dynamic_batching: None\n01:02:17 |     evaltask: None\n01:02:17 |     ffn_size: 3072\n01:02:17 |     final_extra_opt: \n01:02:17 |     fixed_candidate_vecs: reuse\n01:02:17 |     fixed_candidates_path: None\n01:02:17 |     force_fp16_tokens: False\n01:02:17 |     fp16: True\n01:02:17 |     fp16_impl: safe\n01:02:17 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run4/data\n01:02:17 |     fromfile_datatype_extension: True\n01:02:17 |     gpu: -1\n01:02:17 |     gradient_clip: 0.1\n01:02:17 |     hide_labels: False\n01:02:17 |     history_add_global_end_token: None\n01:02:17 |     history_reversed: False\n01:02:17 |     history_size: 20\n01:02:17 |     ignore_bad_candidates: False\n01:02:17 |     ignore_labels: None\n01:02:17 |     image_cropsize: 224\n01:02:17 |     image_mode: raw\n01:02:17 |     image_size: 256\n01:02:17 |     inference: max\n01:02:17 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:02:17 |     init_opt: None\n01:02:17 |     interactive_candidates: fixed\n01:02:17 |     interactive_mode: False\n01:02:17 |     invsqrt_lr_decay_gamma: -1\n01:02:17 |     is_debug: False\n01:02:17 |     label_truncate: 72\n01:02:17 |     learn_embeddings: True\n01:02:17 |     learn_positional_embeddings: True\n01:02:17 |     learningrate: 5e-05\n01:02:17 |     load_from_checkpoint: False\n01:02:17 |     load_from_pretrained_ranker: True\n01:02:17 |     log_every_n_secs: 10.0\n01:02:17 |     log_every_n_steps: 50\n01:02:17 |     log_keep_fields: all\n01:02:17 |     loglevel: info\n01:02:17 |     lr_scheduler: reduceonplateau\n01:02:17 |     lr_scheduler_decay: 0.5\n01:02:17 |     lr_scheduler_patience: 3\n01:02:17 |     max_train_steps: -1\n01:02:17 |     max_train_time: 7200.0\n01:02:17 |     memory_attention: sqrt\n01:02:17 |     metrics: default\n01:02:17 |     model: transformer/classifier\n01:02:17 |     model_file: /tmp/model4\n01:02:17 |     model_parallel: False\n01:02:17 |     momentum: 0\n01:02:17 |     multitask_weights: [1]\n01:02:17 |     mutators: None\n01:02:17 |     n_decoder_layers: -1\n01:02:17 |     n_encoder_layers: -1\n01:02:17 |     n_heads: 12\n01:02:17 |     n_layers: 12\n01:02:17 |     n_positions: 1024\n01:02:17 |     n_segments: 2\n01:02:17 |     nesterov: True\n01:02:17 |     no_cuda: False\n01:02:17 |     normalize_sent_emb: False\n01:02:17 |     num_epochs: -1\n01:02:17 |     num_workers: 0\n01:02:17 |     nus: (0.7,)\n01:02:17 |     optimizer: adamax\n01:02:17 |     output_scaling: 0.06\n01:02:17 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type1/run4/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model4'}\"\n01:02:17 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n01:02:17 |     person_tokens: False\n01:02:17 |     print_scores: False\n01:02:17 |     rank_candidates: False\n01:02:17 |     rank_top_k: -1\n01:02:17 |     reduction_type: mean\n01:02:17 |     ref_class: None\n01:02:17 |     relu_dropout: 0.0\n01:02:17 |     repeat_blocking_heuristic: True\n01:02:17 |     return_cand_scores: False\n01:02:17 |     save_after_valid: True\n01:02:17 |     save_every_n_secs: -1\n01:02:17 |     save_format: conversations\n01:02:17 |     share_encoders: False\n01:02:17 |     share_word_embeddings: False\n01:02:17 |     short_final_eval: False\n01:02:17 |     special_tok_lst: None\n01:02:17 |     split_lines: False\n01:02:17 |     starttime: Dec04_01-02\n01:02:17 |     task: fromfile:parlaiformat\n01:02:17 |     tensorboard_log: False\n01:02:17 |     tensorboard_logdir: None\n01:02:17 |     text_truncate: 360\n01:02:17 |     threshold: 0.5\n01:02:17 |     topk: 5\n01:02:17 |     train_predict: False\n01:02:17 |     truncate: 1024\n01:02:17 |     update_classifier_head_only: False\n01:02:17 |     update_freq: 1\n01:02:17 |     use_memories: False\n01:02:17 |     use_reply: none\n01:02:17 |     validation_cutoff: 1.0\n01:02:17 |     validation_every_n_epochs: -1\n01:02:17 |     validation_every_n_secs: 20.0\n01:02:17 |     validation_every_n_steps: -1\n01:02:17 |     validation_max_exs: -1\n01:02:17 |     validation_metric: accuracy\n01:02:17 |     validation_metric_mode: max\n01:02:17 |     validation_patience: 30\n01:02:17 |     validation_share_agent: False\n01:02:17 |     variant: xlm\n01:02:17 |     verbose: False\n01:02:17 |     wandb_entity: None\n01:02:17 |     wandb_log: False\n01:02:17 |     wandb_name: None\n01:02:17 |     wandb_project: None\n01:02:17 |     warmup_rate: 0.0001\n01:02:17 |     warmup_updates: 1000\n01:02:17 |     weight_decay: None\n01:02:17 |     world_logs: \n01:02:17 |     wrap_memory_encoder: False\n01:02:17 | creating task(s): fromfile:parlaiformat\n01:02:17 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run4/data_train.txt\n01:02:17 | training...\n01:02:27 | time:10s total_exs:420 total_steps:21 epochs:2.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .5500 5.5e-10               .6135                 .5435   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7042            .4615              .5625   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .3913 11.42     1 268.4 551.1       0          0 41.07  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5500             32768  2.556    .1246 6.014 .6791 1.055e-06 120.3   247   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   21 388.7 798.1 2.058        .5386\n\n01:02:37 | time:20s total_exs:1160 total_steps:58 epochs:5.80\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .7270 7.27e-10               .7537                 .7023   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8132            .6939              .7633   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6361  11.5     1   270  1033       0          0  76.5  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7270             32768  2.741    .1245 6.027 .6556 2.905e-06 120.5 461.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   58 390.5 1494 3.834        .7246\n\n01:02:37 | creating task(s): fromfile:parlaiformat\n01:02:37 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run4/data_valid.txt\n01:02:37 | running eval: valid\n01:02:37 | eval completed in 0.25s\n01:02:37 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7692                 .7143   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7273              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .6667 12.04 168.5  1594       0          0 113.5   24 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6480 2.905e-06    72 681.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     58 240.5 2275        .7483\n\u001b[0m\n01:02:37 | \u001b[1;32mnew best accuracy: 0.75\u001b[0m\n01:02:37 | saving best valid model: /tmp/model4\n01:02:37 | Saving dictionary to /tmp/model4.dict\n01:02:42 | saving model checkpoint: /tmp/model4.checkpoint\n01:02:42 | Saving dictionary to /tmp/model4.checkpoint.dict\n01:02:59 | time:42s total_exs:1880 total_steps:94 epochs:9.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8653 8.653e-10               .8780                 .8270   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9357            .8496              .9195   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7896  11.4     1   268 942.2       0          0 70.31  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8653             32768  3.328    .1245 6.036 .5881 4.705e-06 120.7 424.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   94 388.8 1367 3.523        .8643\n\n01:03:02 | time:45s total_exs:2100 total_steps:105 epochs:10.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9000   9e-10               .8911                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8824            .9076              .9000   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9153 11.67     1 273.4  1034       0          0 75.64  220   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9000             32768  3.381    .1246 5.927 .5144 5.254e-06 118.5 448.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  105 391.9 1482 3.811        .8999\n\n01:03:02 | running eval: valid\n01:03:02 | eval completed in 0.20s\n01:03:02 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.04 168.5  1858       0          0 132.3   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5090 5.254e-06    72 793.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    105 240.5 2652        .9583\n\u001b[0m\n01:03:02 | \u001b[1;32mnew best accuracy: 0.9583 (previous best was 0.75)\u001b[0m\n01:03:02 | saving best valid model: /tmp/model4\n01:03:12 | saving model checkpoint: /tmp/model4.checkpoint\n01:03:27 | time:70s total_exs:2880 total_steps:144 epochs:14.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9487 9.487e-10               .9476                 .9602   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9354            .9497              .9380   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9618 11.52     1 270.4  1029       0          0 76.14  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9487             32768  4.209    .1246 5.992 .3668 7.204e-06 119.8 456.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  144 390.2 1486 3.815        .9487\n\n01:03:32 | time:75s total_exs:3220 total_steps:161 epochs:16.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9529 9.529e-10               .9574                 .9524   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9626            .9474              .9536   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9412 11.77     1 275.4  1054       0          0 76.55  340   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9529             32768   6.41    .1246   6.1 .1989 8.054e-06   122   467   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  161 397.4 1521 3.847        .9529\n\n01:03:32 | running eval: valid\n01:03:32 | eval completed in 0.20s\n01:03:32 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 12.04 168.5  1878       0          0 133.7   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .1518 8.054e-06    72 802.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    161 240.5 2681            1\n\u001b[0m\n01:03:32 | \u001b[1;32mnew best accuracy: 1 (previous best was 0.9583)\u001b[0m\n01:03:32 | saving best valid model: /tmp/model4\n01:03:41 | task solved! stopping.\n01:03:41 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n01:03:41 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n01:03:41 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run4/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n01:03:41 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n01:03:41 | Using CUDA\n01:03:41 | loading dictionary from /tmp/model4.dict\n01:03:41 | num words = 54944\n01:03:46 | Loading existing model parameters from /tmp/model4\n01:03:48 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:03:49 | creating task(s): fromfile:parlaiformat\n01:03:49 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run4/data_valid.txt\n01:03:49 | running eval: valid\n01:03:49 | eval completed in 0.21s\n01:03:49 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 12.04 168.5  1815       0          0 129.2   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294     6 .1518 8.054e-06    72 775.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    161 240.5 2591            1\n\u001b[0m\n01:03:49 | creating task(s): fromfile:parlaiformat\n01:03:49 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run4/data_test.txt\n01:03:49 | running eval: test\n01:03:54 | eval completed in 5.00s\n01:03:54 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9130 9.13e-10               .6859                 .5367   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9495              .9939   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9089 12.07 281.4  2831       0          0 201.1 1000 .9130   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294   5.2 .2417 8.054e-06   104  1046       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    161 385.4 3877        .9231\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type1/run4/data_test.txt -m transformer/classifier -mf /tmp/model4 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:03:56.499461Z","iopub.execute_input":"2022-12-04T01:03:56.499886Z","iopub.status.idle":"2022-12-04T01:04:26.518452Z","shell.execute_reply.started":"2022-12-04T01:03:56.499843Z","shell.execute_reply":"2022-12-04T01:04:26.517277Z"},"scrolled":true,"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"01:04:04 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr1type1/run4/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr1type1/run4/data)\u001b[0m\n01:04:04 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n01:04:04 | Using CUDA\n01:04:04 | loading dictionary from /tmp/model4.dict\n01:04:05 | num words = 54944\n01:04:09 | Loading existing model parameters from /tmp/model4\n01:04:15 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:04:16 | Opt:\n01:04:16 |     activation: gelu\n01:04:16 |     adafactor_eps: '[1e-30, 0.001]'\n01:04:16 |     adam_eps: 1e-08\n01:04:16 |     add_p1_after_newln: False\n01:04:16 |     aggregate_micro: False\n01:04:16 |     allow_missing_init_opts: False\n01:04:16 |     area_under_curve_class: None\n01:04:16 |     area_under_curve_digits: -1\n01:04:16 |     attention_dropout: 0.1\n01:04:16 |     batchsize: 40\n01:04:16 |     betas: '[0.9, 0.999]'\n01:04:16 |     bpe_add_prefix_space: None\n01:04:16 |     bpe_debug: False\n01:04:16 |     bpe_dropout: None\n01:04:16 |     bpe_merge: None\n01:04:16 |     bpe_vocab: None\n01:04:16 |     candidates: inline\n01:04:16 |     cap_num_predictions: 100\n01:04:16 |     checkpoint_activations: False\n01:04:16 |     class_weights: None\n01:04:16 |     classes: \"['__notok__', '__ok__']\"\n01:04:16 |     classes_from_file: None\n01:04:16 |     data_parallel: True\n01:04:16 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n01:04:16 |     datatype: train\n01:04:16 |     delimiter: '\\n'\n01:04:16 |     dict_class: parlai.core.dict:DictionaryAgent\n01:04:16 |     dict_endtoken: __start__\n01:04:16 |     dict_file: /tmp/model4.dict\n01:04:16 |     dict_include_test: False\n01:04:16 |     dict_include_valid: False\n01:04:16 |     dict_initpath: None\n01:04:16 |     dict_language: english\n01:04:16 |     dict_loaded: True\n01:04:16 |     dict_lower: True\n01:04:16 |     dict_max_ngram_size: -1\n01:04:16 |     dict_maxexs: -1\n01:04:16 |     dict_maxtokens: -1\n01:04:16 |     dict_minfreq: 0\n01:04:16 |     dict_nulltoken: __null__\n01:04:16 |     dict_starttoken: __start__\n01:04:16 |     dict_textfields: text,labels\n01:04:16 |     dict_tokenizer: bpe\n01:04:16 |     dict_unktoken: __unk__\n01:04:16 |     display_examples: False\n01:04:16 |     download_path: None\n01:04:16 |     dropout: 0.1\n01:04:16 |     dynamic_batching: None\n01:04:16 |     embedding_projection: random\n01:04:16 |     embedding_size: 768\n01:04:16 |     embedding_type: random\n01:04:16 |     embeddings_scale: False\n01:04:16 |     encode_candidate_vecs: True\n01:04:16 |     encode_candidate_vecs_batchsize: 256\n01:04:16 |     eval_batchsize: None\n01:04:16 |     eval_candidates: inline\n01:04:16 |     eval_dynamic_batching: None\n01:04:16 |     evaltask: None\n01:04:16 |     ffn_size: 3072\n01:04:16 |     final_extra_opt: \n01:04:16 |     fixed_candidate_vecs: reuse\n01:04:16 |     fixed_candidates_path: None\n01:04:16 |     force_fp16_tokens: True\n01:04:16 |     fp16: True\n01:04:16 |     fp16_impl: safe\n01:04:16 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run4/data_test.txt\n01:04:16 |     fromfile_datatype_extension: True\n01:04:16 |     gpu: -1\n01:04:16 |     gradient_clip: 0.1\n01:04:16 |     hide_labels: False\n01:04:16 |     history_add_global_end_token: None\n01:04:16 |     history_reversed: False\n01:04:16 |     history_size: 20\n01:04:16 |     ignore_bad_candidates: False\n01:04:16 |     ignore_labels: None\n01:04:16 |     image_cropsize: 224\n01:04:16 |     image_mode: raw\n01:04:16 |     image_size: 256\n01:04:16 |     inference: max\n01:04:16 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:04:16 |     init_opt: None\n01:04:16 |     interactive_candidates: fixed\n01:04:16 |     interactive_mode: False\n01:04:16 |     invsqrt_lr_decay_gamma: -1\n01:04:16 |     is_debug: False\n01:04:16 |     label_truncate: 72\n01:04:16 |     learn_embeddings: True\n01:04:16 |     learn_positional_embeddings: True\n01:04:16 |     learningrate: 5e-05\n01:04:16 |     load_from_pretrained_ranker: True\n01:04:16 |     log_every_n_secs: 10.0\n01:04:16 |     log_every_n_steps: 50\n01:04:16 |     log_keep_fields: all\n01:04:16 |     loglevel: info\n01:04:16 |     lr_scheduler: reduceonplateau\n01:04:16 |     lr_scheduler_decay: 0.5\n01:04:16 |     lr_scheduler_patience: 3\n01:04:16 |     max_train_steps: -1\n01:04:16 |     max_train_time: 7200.0\n01:04:16 |     memory_attention: sqrt\n01:04:16 |     metrics: default\n01:04:16 |     model: transformer/classifier\n01:04:16 |     model_file: /tmp/model4\n01:04:16 |     model_parallel: False\n01:04:16 |     momentum: 0\n01:04:16 |     multitask_weights: [1]\n01:04:16 |     mutators: None\n01:04:16 |     n_decoder_layers: -1\n01:04:16 |     n_encoder_layers: -1\n01:04:16 |     n_heads: 12\n01:04:16 |     n_layers: 12\n01:04:16 |     n_positions: 1024\n01:04:16 |     n_segments: 2\n01:04:16 |     nesterov: True\n01:04:16 |     no_cuda: False\n01:04:16 |     normalize_sent_emb: False\n01:04:16 |     num_epochs: -1\n01:04:16 |     num_examples: -1\n01:04:16 |     num_workers: 0\n01:04:16 |     nus: [0.7]\n01:04:16 |     optimizer: adamax\n01:04:16 |     output_scaling: 0.06\n01:04:16 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type1/run4/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model4', 'batchsize': 40}\"\n01:04:16 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n01:04:16 |     person_tokens: False\n01:04:16 |     print_scores: False\n01:04:16 |     rank_candidates: False\n01:04:16 |     rank_top_k: -1\n01:04:16 |     reduction_type: mean\n01:04:16 |     ref_class: None\n01:04:16 |     relu_dropout: 0.0\n01:04:16 |     repeat_blocking_heuristic: True\n01:04:16 |     report_filename: \n01:04:16 |     return_cand_scores: False\n01:04:16 |     save_after_valid: True\n01:04:16 |     save_every_n_secs: -1\n01:04:16 |     save_format: conversations\n01:04:16 |     share_encoders: False\n01:04:16 |     share_word_embeddings: False\n01:04:16 |     short_final_eval: False\n01:04:16 |     special_tok_lst: None\n01:04:16 |     split_lines: False\n01:04:16 |     starttime: Dec04_01-02\n01:04:16 |     task: fromfile:parlaiformat\n01:04:16 |     tensorboard_log: False\n01:04:16 |     tensorboard_logdir: None\n01:04:16 |     text_truncate: 360\n01:04:16 |     threshold: 0.5\n01:04:16 |     topk: 5\n01:04:16 |     train_predict: False\n01:04:16 |     truncate: 1024\n01:04:16 |     update_classifier_head_only: False\n01:04:16 |     update_freq: 1\n01:04:16 |     use_memories: False\n01:04:16 |     use_reply: none\n01:04:16 |     validation_cutoff: 1.0\n01:04:16 |     validation_every_n_epochs: -1\n01:04:16 |     validation_every_n_secs: 20.0\n01:04:16 |     validation_every_n_steps: -1\n01:04:16 |     validation_max_exs: -1\n01:04:16 |     validation_metric: accuracy\n01:04:16 |     validation_metric_mode: max\n01:04:16 |     validation_patience: 30\n01:04:16 |     validation_share_agent: False\n01:04:16 |     variant: xlm\n01:04:16 |     verbose: False\n01:04:16 |     wandb_entity: None\n01:04:16 |     wandb_log: False\n01:04:16 |     wandb_name: None\n01:04:16 |     wandb_project: None\n01:04:16 |     warmup_rate: 0.0001\n01:04:16 |     warmup_updates: 1000\n01:04:16 |     weight_decay: None\n01:04:16 |     world_logs: \n01:04:16 |     wrap_memory_encoder: False\n01:04:17 | Evaluating task fromfile:parlaiformat using datatype valid.\n01:04:17 | creating task(s): fromfile:parlaiformat\n01:04:17 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n01:04:17 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run4/data_test.txt\n01:04:24 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9130 9.13e-10               .6859                 .5367   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9495              .9939   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9089 12.07 562.9  1938       0          0 137.7 1000 .9130   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2417 8.054e-06   208   716       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    161 770.9 2654        .9231\u001b[0m\n01:04:24 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9130 9.13e-10               .6859                 .5367   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9495              .9939   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9089 12.07 562.9  1938       0          0 137.7 1000 .9130   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2417 8.054e-06   208   716       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    161 770.9 2654        .9231\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model4*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:04:26.520250Z","iopub.execute_input":"2022-12-04T01:04:26.520652Z","iopub.status.idle":"2022-12-04T01:04:27.828502Z","shell.execute_reply.started":"2022-12-04T01:04:26.520609Z","shell.execute_reply":"2022-12-04T01:04:27.827111Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"run 5","metadata":{}},{"cell_type":"code","source":"# run 5 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type1/run5/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model5","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:04:27.830560Z","iopub.execute_input":"2022-12-04T01:04:27.830967Z","iopub.status.idle":"2022-12-04T01:16:14.649975Z","shell.execute_reply.started":"2022-12-04T01:04:27.830922Z","shell.execute_reply":"2022-12-04T01:16:14.648740Z"},"scrolled":true,"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"01:04:34 | building dictionary first...\n01:04:34 | No model with opt yet at: /tmp/model5(.opt)\n01:04:35 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run5/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n01:04:35 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n01:04:35 | Using CUDA\n01:04:35 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n01:04:35 | num words = 54944\n01:04:39 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:04:49 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:04:49 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n01:04:49 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n01:04:49 | Opt:\n01:04:49 |     activation: gelu\n01:04:49 |     adafactor_eps: '(1e-30, 0.001)'\n01:04:49 |     adam_eps: 1e-08\n01:04:49 |     add_p1_after_newln: False\n01:04:49 |     aggregate_micro: False\n01:04:49 |     allow_missing_init_opts: False\n01:04:49 |     attention_dropout: 0.1\n01:04:49 |     batchsize: 20\n01:04:49 |     betas: '(0.9, 0.999)'\n01:04:49 |     bpe_add_prefix_space: None\n01:04:49 |     bpe_debug: False\n01:04:49 |     bpe_dropout: None\n01:04:49 |     bpe_merge: None\n01:04:49 |     bpe_vocab: None\n01:04:49 |     candidates: inline\n01:04:49 |     cap_num_predictions: 100\n01:04:49 |     checkpoint_activations: False\n01:04:49 |     class_weights: None\n01:04:49 |     classes: \"['__notok__', '__ok__']\"\n01:04:49 |     classes_from_file: None\n01:04:49 |     data_parallel: True\n01:04:49 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n01:04:49 |     datatype: train\n01:04:49 |     delimiter: '\\n'\n01:04:49 |     dict_class: parlai.core.dict:DictionaryAgent\n01:04:49 |     dict_endtoken: __start__\n01:04:49 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n01:04:49 |     dict_include_test: False\n01:04:49 |     dict_include_valid: False\n01:04:49 |     dict_initpath: None\n01:04:49 |     dict_language: english\n01:04:49 |     dict_loaded: True\n01:04:49 |     dict_lower: True\n01:04:49 |     dict_max_ngram_size: -1\n01:04:49 |     dict_maxexs: -1\n01:04:49 |     dict_maxtokens: -1\n01:04:49 |     dict_minfreq: 0\n01:04:49 |     dict_nulltoken: __null__\n01:04:49 |     dict_starttoken: __start__\n01:04:49 |     dict_textfields: text,labels\n01:04:49 |     dict_tokenizer: bpe\n01:04:49 |     dict_unktoken: __unk__\n01:04:49 |     display_examples: False\n01:04:49 |     download_path: None\n01:04:49 |     dropout: 0.1\n01:04:49 |     dynamic_batching: None\n01:04:49 |     embedding_projection: random\n01:04:49 |     embedding_size: 768\n01:04:49 |     embedding_type: random\n01:04:49 |     embeddings_scale: False\n01:04:49 |     encode_candidate_vecs: True\n01:04:49 |     encode_candidate_vecs_batchsize: 256\n01:04:49 |     eval_batchsize: None\n01:04:49 |     eval_candidates: inline\n01:04:49 |     eval_dynamic_batching: None\n01:04:49 |     evaltask: None\n01:04:49 |     ffn_size: 3072\n01:04:49 |     final_extra_opt: \n01:04:49 |     fixed_candidate_vecs: reuse\n01:04:49 |     fixed_candidates_path: None\n01:04:49 |     force_fp16_tokens: False\n01:04:49 |     fp16: True\n01:04:49 |     fp16_impl: safe\n01:04:49 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run5/data\n01:04:49 |     fromfile_datatype_extension: True\n01:04:49 |     gpu: -1\n01:04:49 |     gradient_clip: 0.1\n01:04:49 |     hide_labels: False\n01:04:49 |     history_add_global_end_token: None\n01:04:49 |     history_reversed: False\n01:04:49 |     history_size: 20\n01:04:49 |     ignore_bad_candidates: False\n01:04:49 |     ignore_labels: None\n01:04:49 |     image_cropsize: 224\n01:04:49 |     image_mode: raw\n01:04:49 |     image_size: 256\n01:04:49 |     inference: max\n01:04:49 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:04:49 |     init_opt: None\n01:04:49 |     interactive_candidates: fixed\n01:04:49 |     interactive_mode: False\n01:04:49 |     invsqrt_lr_decay_gamma: -1\n01:04:49 |     is_debug: False\n01:04:49 |     label_truncate: 72\n01:04:49 |     learn_embeddings: True\n01:04:49 |     learn_positional_embeddings: True\n01:04:49 |     learningrate: 5e-05\n01:04:49 |     load_from_checkpoint: False\n01:04:49 |     load_from_pretrained_ranker: True\n01:04:49 |     log_every_n_secs: 10.0\n01:04:49 |     log_every_n_steps: 50\n01:04:49 |     log_keep_fields: all\n01:04:49 |     loglevel: info\n01:04:49 |     lr_scheduler: reduceonplateau\n01:04:49 |     lr_scheduler_decay: 0.5\n01:04:49 |     lr_scheduler_patience: 3\n01:04:49 |     max_train_steps: -1\n01:04:49 |     max_train_time: 7200.0\n01:04:49 |     memory_attention: sqrt\n01:04:49 |     metrics: default\n01:04:49 |     model: transformer/classifier\n01:04:49 |     model_file: /tmp/model5\n01:04:49 |     model_parallel: False\n01:04:49 |     momentum: 0\n01:04:49 |     multitask_weights: [1]\n01:04:49 |     mutators: None\n01:04:49 |     n_decoder_layers: -1\n01:04:49 |     n_encoder_layers: -1\n01:04:49 |     n_heads: 12\n01:04:49 |     n_layers: 12\n01:04:49 |     n_positions: 1024\n01:04:49 |     n_segments: 2\n01:04:49 |     nesterov: True\n01:04:49 |     no_cuda: False\n01:04:49 |     normalize_sent_emb: False\n01:04:49 |     num_epochs: -1\n01:04:49 |     num_workers: 0\n01:04:49 |     nus: (0.7,)\n01:04:49 |     optimizer: adamax\n01:04:49 |     output_scaling: 0.06\n01:04:49 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type1/run5/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model5'}\"\n01:04:49 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n01:04:49 |     person_tokens: False\n01:04:49 |     print_scores: False\n01:04:49 |     rank_candidates: False\n01:04:49 |     rank_top_k: -1\n01:04:49 |     reduction_type: mean\n01:04:49 |     ref_class: None\n01:04:49 |     relu_dropout: 0.0\n01:04:49 |     repeat_blocking_heuristic: True\n01:04:49 |     return_cand_scores: False\n01:04:49 |     save_after_valid: True\n01:04:49 |     save_every_n_secs: -1\n01:04:49 |     save_format: conversations\n01:04:49 |     share_encoders: False\n01:04:49 |     share_word_embeddings: False\n01:04:49 |     short_final_eval: False\n01:04:49 |     special_tok_lst: None\n01:04:49 |     split_lines: False\n01:04:49 |     starttime: Dec04_01-04\n01:04:49 |     task: fromfile:parlaiformat\n01:04:49 |     tensorboard_log: False\n01:04:49 |     tensorboard_logdir: None\n01:04:49 |     text_truncate: 360\n01:04:49 |     threshold: 0.5\n01:04:49 |     topk: 5\n01:04:49 |     train_predict: False\n01:04:49 |     truncate: 1024\n01:04:49 |     update_classifier_head_only: False\n01:04:49 |     update_freq: 1\n01:04:49 |     use_memories: False\n01:04:49 |     use_reply: none\n01:04:49 |     validation_cutoff: 1.0\n01:04:49 |     validation_every_n_epochs: -1\n01:04:49 |     validation_every_n_secs: 20.0\n01:04:49 |     validation_every_n_steps: -1\n01:04:49 |     validation_max_exs: -1\n01:04:49 |     validation_metric: accuracy\n01:04:49 |     validation_metric_mode: max\n01:04:49 |     validation_patience: 30\n01:04:49 |     validation_share_agent: False\n01:04:49 |     variant: xlm\n01:04:49 |     verbose: False\n01:04:49 |     wandb_entity: None\n01:04:49 |     wandb_log: False\n01:04:49 |     wandb_name: None\n01:04:49 |     wandb_project: None\n01:04:49 |     warmup_rate: 0.0001\n01:04:49 |     warmup_updates: 1000\n01:04:49 |     weight_decay: None\n01:04:49 |     world_logs: \n01:04:49 |     wrap_memory_encoder: False\n01:04:50 | creating task(s): fromfile:parlaiformat\n01:04:50 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run5/data_train.txt\n01:04:50 | training...\n01:05:00 | time:10s total_exs:420 total_steps:21 epochs:2.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .3048 3.048e-10               .4183                 .3750   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .4730            .1361              .1643   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .1162  12.2     1   284 594.5       0          0 41.86  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .3048             32768  2.605    .1206 6.057 .7251 1.055e-06 121.1 253.5   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   21 405.2 848.1 2.098        .2853\n\n01:05:10 | time:20s total_exs:1200 total_steps:60 epochs:6.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .4795 4.795e-10               .5634                 .4870   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6684            .3556              .4628   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .2887 11.74     1 274.8  1089       0          0 79.28  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .4795             32768  2.442    .1206 6.005 .7002 3.005e-06 120.1 476.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   60 394.9 1565 3.973        .4600\n\n01:05:10 | creating task(s): fromfile:parlaiformat\n01:05:10 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run5/data_valid.txt\n01:05:10 | running eval: valid\n01:05:10 | eval completed in 0.19s\n01:05:10 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5833 5.833e-10               .5833                 .5833   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5833            .5833              .5833   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .5833 10.67   152  1816       0          0 143.3   24 .5833   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6932 3.005e-06    72 860.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                     60  224 2676        .5833\n\u001b[0m\n01:05:10 | \u001b[1;32mnew best accuracy: 0.5833\u001b[0m\n01:05:10 | saving best valid model: /tmp/model5\n01:05:10 | Saving dictionary to /tmp/model5.dict\n01:05:15 | saving model checkpoint: /tmp/model5.checkpoint\n01:05:15 | Saving dictionary to /tmp/model5.checkpoint.dict\n01:05:32 | time:42s total_exs:1940 total_steps:97 epochs:9.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7973 7.973e-10               .7967                 .7903   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8033            .7978              .8043   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7914 12.05     1 281.1  1030       0          0 73.31  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7973             32768  2.561    .1207 5.989 .6385 4.855e-06 119.8 439.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   97 400.8 1469 3.674        .7973\n\n01:05:35 | time:46s total_exs:2180 total_steps:109 epochs:10.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8833 8.833e-10               .8923                 .8788   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9062            .8727              .8889   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8571 12.49     1 289.8  1124       0          0  77.6  240   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8833             32768  3.194    .1207 6.067 .5796 5.454e-06 121.3 470.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  109 411.1 1595 3.909        .8832\n\n01:05:35 | running eval: valid\n01:05:36 | eval completed in 0.19s\n01:05:36 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1824       0          0   144   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5765 5.454e-06    72 864.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    109  224 2689        .9161\n\u001b[0m\n01:05:36 | \u001b[1;32mnew best accuracy: 0.9167 (previous best was 0.5833)\u001b[0m\n01:05:36 | saving best valid model: /tmp/model5\n01:05:40 | saving model checkpoint: /tmp/model5.checkpoint\n01:06:00 | time:70s total_exs:2980 total_steps:149 epochs:14.90\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9450 9.45e-10               .9462                 .9348   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9579            .9437              .9560   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9318 11.87     1 277.4  1083       0          0  78.1  800   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9450             32768  3.835    .1207  6.01 .4412 7.454e-06 120.2 469.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  149 397.6 1553 3.914        .9450\n\n01:06:00 | time:71s total_exs:3040 total_steps:152 epochs:15.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9667 9.667e-10               .9643                 .9310   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9688                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9394 10.32     1 246.3 997.1       0          0 80.95   60   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9667             32768  4.355    .1189   5.9 .2965 7.604e-06   118 477.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  152 364.3 1475 4.174        .9667\n\n01:06:00 | running eval: valid\n01:06:01 | eval completed in 0.18s\n01:06:01 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1830       0          0 144.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .3272 7.604e-06    72 866.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    152  224 2696        .8748\n\u001b[0m\n01:06:01 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 1\u001b[0m\n01:06:01 | saving model checkpoint: /tmp/model5.checkpoint\n01:06:20 | time:91s total_exs:3820 total_steps:191 epochs:19.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9551 9.551e-10               .9545                 .9532   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9557            .9558              .9570   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9545 11.94     1 278.9  1066       0          0 76.43  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9551             32768   6.01    .1207 5.985 .1924 9.554e-06 119.7 457.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  191 398.6 1523 3.83        .9551\n\n01:06:21 | time:91s total_exs:3860 total_steps:193 epochs:19.30\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9750 9.75e-10               .9756                 .9524   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9744                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9500 11.43     1 268.5  1087       0          0 80.97   40   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9750             32768  9.923    .1190     6 .1057 9.654e-06   120 485.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  193 388.5 1573 4.244        .9750\n\n01:06:21 | running eval: valid\n01:06:21 | eval completed in 0.19s\n01:06:21 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1778       0          0 140.3   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .2149 9.654e-06    72 842.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    193  224 2621        .9167\n\u001b[0m\n01:06:21 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 2\u001b[0m\n01:06:21 | saving model checkpoint: /tmp/model5.checkpoint\n01:06:36 | time:106s total_exs:4640 total_steps:232 epochs:23.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9885 9.885e-10               .9890                 .9877   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9902            .9879              .9892   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9866 11.97     1 279.3  1078       0          0 77.18  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9885             32768  5.636    .1207 6.044 .06264 1.16e-05 120.9 466.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  232 400.2 1544 3.868        .9885\n\n01:06:41 | time:111s total_exs:5060 total_steps:253 epochs:25.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9976 9.976e-10               .9976                 .9952   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9977                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9953  11.8 .6190   276  1030       0          0 74.65  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9976             32768  .6739    .1207 5.981 .01784 1.265e-05 119.6 446.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  253 395.6 1476 3.747        .9976\n\n01:06:41 | running eval: valid\n01:06:41 | eval completed in 0.18s\n01:06:41 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1816       0          0 143.3   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .3625 1.265e-05    72 860.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    253  224 2676        .9167\n\u001b[0m\n01:06:41 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 3\u001b[0m\n01:06:41 | saving model checkpoint: /tmp/model5.checkpoint\n01:06:56 | time:126s total_exs:5840 total_steps:292 epochs:29.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9949 9.949e-10               .9949                 .9899   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9948                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9897 11.58 .1282 271.7  1040       0          0 76.55  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9949             32768  .2488    .1207 6.005 .0316 1.46e-05 120.1 459.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  292 391.8 1500 3.836        .9949\n\n01:07:02 | time:132s total_exs:6280 total_steps:314 epochs:31.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9977 9.977e-10               .9977                 .9955   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9977                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                  .9955 11.73 .04545 274.6  1075       0          0 78.31   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  \\\n    440 .9977             32768  .1432    .1190 5.995 .01496 1.57e-05 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   469.5       0          0                  314 394.5 1545 3.932        .9977\n\n01:07:02 | running eval: valid\n01:07:02 | eval completed in 0.21s\n01:07:02 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1622       0          0   128   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .4247 1.57e-05    72 768.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    314  224 2391        .9161\n\u001b[0m\n01:07:02 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 4\u001b[0m\n01:07:02 | saving model checkpoint: /tmp/model5.checkpoint\n01:07:16 | time:146s total_exs:7060 total_steps:353 epochs:35.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9949 9.949e-10               .9952                 .9904   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9945                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9891 11.96 .1026 279.3  1088       0          0 77.91  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9949             32768  .5882    .1207 6.059 .02513 1.765e-05 121.2 472.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  353 400.4 1560 3.905        .9949\n\n01:07:22 | time:152s total_exs:7500 total_steps:375 epochs:37.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9977 9.977e-10               .9978                 .9957   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9976                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9952 11.64 .1818 272.8  1039       0          0 76.17  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9977             32768  .5144    .1207 6.055 .007802 1.875e-05 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.2       0          0                  375 393.9 1500 3.823        .9977\n\n01:07:22 | running eval: valid\n01:07:22 | eval completed in 0.19s\n01:07:22 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1744       0          0 137.7   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 .5523 1.875e-05    72 826.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    375  224 2571        .8748\n\u001b[0m\n01:07:22 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 5\u001b[0m\n01:07:22 | saving model checkpoint: /tmp/model5.checkpoint\n01:07:37 | time:167s total_exs:8280 total_steps:414 epochs:41.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.84     0 276.8  1072       0          0 77.47  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .01395    .1207 6.013 .001119 2.07e-05 120.3 465.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  414 397.1 1538 3.882            1\n\n01:07:42 | time:172s total_exs:8720 total_steps:436 epochs:43.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.76 .04545 275.2  1101       0          0 80.02   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  \\\n    440   1             32768 .01805    .1207 5.991 .00101 2.18e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   479.4       0          0                  436  395 1581 4.018            1\n\n01:07:42 | running eval: valid\n01:07:42 | eval completed in 0.18s\n01:07:42 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1816       0          0 143.3   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08095     6 .7143 2.18e-05    72 860.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    436  224 2677        .8748\n\u001b[0m\n01:07:42 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 6\u001b[0m\n01:07:42 | saving model checkpoint: /tmp/model5.checkpoint\n01:07:58 | time:188s total_exs:9500 total_steps:475 epochs:47.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.91 .05128 278.2  1066       0          0 76.59   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    780   1             32768 .01775    .1207 6.023 .000934 2.375e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.3       0          0                  475 398.7 1527 3.838            1\n\n01:08:02 | time:193s total_exs:9860 total_steps:493 epochs:49.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.74     0 274.8  1074       0          0 78.18  360   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01013    .1207 6.039 .0008675 2.465e-05 120.8 472.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  493 395.6 1546 3.928            1\n\n01:08:02 | running eval: valid\n01:08:03 | eval completed in 0.19s\n01:08:03 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1792       0          0 141.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 .6385 2.465e-05    72 848.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    493  224 2641        .8748\n\u001b[0m\n01:08:03 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 7\u001b[0m\n01:08:03 | saving model checkpoint: /tmp/model5.checkpoint\n01:08:17 | time:208s total_exs:10660 total_steps:533 epochs:53.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.88     0 277.7  1089       0          0 78.44  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .009557    .1207  6.08 .000815 2.665e-05 121.6 476.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  533 399.3 1566 3.927            1\n\n01:08:23 | time:213s total_exs:11060 total_steps:553 epochs:55.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.61     0 272.2  1057       0          0 77.62  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .008934    .1190  5.98 .0007644 2.765e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   464.2       0          0                  553 391.9 1521 3.898            1\n\n01:08:23 | running eval: valid\n01:08:23 | eval completed in 0.19s\n01:08:23 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1755       0          0 138.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 .6113 2.765e-05    72 831.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    553  224 2587        .8748\n\u001b[0m\n01:08:23 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 8\u001b[0m\n01:08:23 | saving model checkpoint: /tmp/model5.checkpoint\n01:08:38 | time:228s total_exs:11840 total_steps:592 epochs:59.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.59     0 271.8  1055       0          0  77.6  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .008471    .1207 5.959 .0007205 2.96e-05 119.2 462.4   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  592  391 1517 3.889            1\n\n01:08:43 | time:233s total_exs:12220 total_steps:611 epochs:61.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.95     0 279.1  1088       0          0 77.98  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .007997    .1208 6.053 .0006801 3.055e-05 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     472       0          0                  611 400.1 1560 3.917            1\n\n01:08:43 | running eval: valid\n01:08:43 | eval completed in 0.21s\n01:08:43 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1666       0          0 131.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 .6874 3.055e-05    72 789.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    611  224 2456        .8730\n\u001b[0m\n01:08:43 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 9\u001b[0m\n01:08:43 | saving model checkpoint: /tmp/model5.checkpoint\n01:08:58 | time:249s total_exs:13000 total_steps:650 epochs:65.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.93     0 278.7  1067       0          0 76.56  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .007524    .1208 6.026 .0006418 3.25e-05 120.5 461.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  650 399.2 1528 3.837            1\n\n01:09:03 | time:254s total_exs:13380 total_steps:669 epochs:66.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.78     0 275.6  1051       0          0 76.24  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .007099    .1190 5.953 .0006063 3.345e-05 119.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   453.8       0          0                  669 394.7 1505 3.829            1\n\n01:09:03 | running eval: valid\n01:09:04 | eval completed in 0.19s\n01:09:04 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1759       0          0 138.8   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 .5986 3.345e-05    72   833       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    669  224 2592        .8748\n\u001b[0m\n01:09:04 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 10\u001b[0m\n01:09:04 | saving model checkpoint: /tmp/model5.checkpoint\n01:09:18 | time:268s total_exs:14160 total_steps:708 epochs:70.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.2  1070       0          0 78.06  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .006717    .1208 5.995 .0005731 3.54e-05 119.9   468   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  708 394.1 1538 3.912            1\n\n01:09:24 | time:274s total_exs:14600 total_steps:730 epochs:73.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.83     0 276.5  1100       0          0 79.57  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .006334    .1208 5.977 .000539 3.65e-05 119.5 475.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  730 396.1 1576 3.995            1\n\n01:09:24 | running eval: valid\n01:09:24 | eval completed in 0.23s\n01:09:24 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1477       0          0 116.6   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 .6054 3.65e-05    72 699.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    730  224 2177        .9161\n\u001b[0m\n01:09:24 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 11\u001b[0m\n01:09:24 | saving model checkpoint: /tmp/model5.checkpoint\n01:09:44 | time:294s total_exs:15340 total_steps:767 epochs:76.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.62     0 272.4  1059       0          0 77.73  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .005957    .1208 6.014 .0005081 3.835e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   467.4       0          0                  767 392.6 1526 3.895            1\n\n01:09:44 | running eval: valid\n01:09:44 | eval completed in 0.19s\n01:09:44 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1784       0          0 140.8   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 .7118 3.835e-05    72 845.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    767  224 2630        .8730\n\u001b[0m\n01:09:44 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 12\u001b[0m\n01:09:44 | saving model checkpoint: /tmp/model5.checkpoint\n01:10:00 | time:310s total_exs:16120 total_steps:806 epochs:80.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0 276.1  1054       0          0 76.35  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .005528    .1208 6.013 .0004716 4.03e-05 120.3 459.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  806 396.3 1513 3.826            1\n\n01:10:05 | time:315s total_exs:16500 total_steps:825 epochs:82.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.38     0 267.6  1023       0          0 76.42  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .005221    .1208     6 .0004456 4.125e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.5       0          0                  825 387.6 1481 3.839            1\n\n01:10:05 | running eval: valid\n01:10:05 | eval completed in 0.18s\n01:10:05 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1846       0          0 145.7   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 .7776 4.125e-05    72 874.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    825  224 2721        .8730\n\u001b[0m\n01:10:05 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 13\u001b[0m\n01:10:05 | saving model checkpoint: /tmp/model5.checkpoint\n01:10:20 | time:331s total_exs:17300 total_steps:865 epochs:86.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.72     0 274.5  1076       0          0 78.43  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004939    .1208 5.973 .0004201 4.325e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   468.4       0          0                  865 393.9 1545 3.93            1\n\n01:10:25 | time:335s total_exs:17680 total_steps:884 epochs:88.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.87     0 277.4  1107       0          0 79.81  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .004646    .1208 5.984 .0003959 4.42e-05 119.7 477.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  884 397.1 1585 4.01            1\n\n01:10:25 | running eval: valid\n01:10:25 | eval completed in 0.19s\n01:10:25 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1797       0          0 141.8   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 .8854 4.42e-05    72 851.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    884  224 2649        .8730\n\u001b[0m\n01:10:25 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 14\u001b[0m\n01:10:25 | saving model checkpoint: /tmp/model5.checkpoint\n01:10:40 | time:350s total_exs:18460 total_steps:923 epochs:92.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.85     0   277  1061       0          0 76.57  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004376    .1208     6 .0003729 4.615e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   459.4       0          0                  923  397 1520 3.834            1\n\n01:10:45 | time:356s total_exs:18860 total_steps:943 epochs:94.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.93     0 278.5  1088       0          0 78.11  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004142    .1208  6.05 .0003516 4.715e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   472.6       0          0                  943 399.5 1560 3.923            1\n\n01:10:45 | running eval: valid\n01:10:46 | eval completed in 0.19s\n01:10:46 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1800       0          0 142.1   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 .7061 4.715e-05    72 852.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    943  224 2653        .8730\n\u001b[0m\n01:10:46 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 15\u001b[0m\n01:10:46 | saving model checkpoint: /tmp/model5.checkpoint\n01:11:00 | time:371s total_exs:19660 total_steps:983 epochs:98.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.72     0 274.4  1071       0          0 78.08  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004072    .1208  6.03 .0003317 4.915e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   470.8       0          0                  983  395 1542 3.913            1\n\n01:11:06 | time:376s total_exs:20040 total_steps:1002 epochs:100.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.73     0 274.7  1005       0          0  73.2  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003678    .1208 5.963 .0003129 4.995e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   436.5       0          0                 1002 393.9 1442 3.676            1\n\n01:11:06 | running eval: valid\n01:11:06 | eval completed in 0.19s\n01:11:06 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1770       0          0 139.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6 .6669 4.995e-05    72 838.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1002  224 2609        .9167\n\u001b[0m\n01:11:06 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 16\u001b[0m\n01:11:06 | saving model checkpoint: /tmp/model5.checkpoint\n01:11:21 | time:391s total_exs:20820 total_steps:1041 epochs:104.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.82     0 276.4  1077       0          0 77.91  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003475    .1208 6.008 .0002951 4.995e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     468       0          0                 1041 396.6 1545 3.904            1\n\n01:11:26 | time:396s total_exs:21240 total_steps:1062 epochs:106.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.15     0   283  1099       0          0 77.64  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003284    .1208  6.01 .0002787 4.995e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   466.6       0          0                 1062 403.2 1565 3.898            1\n\n01:11:26 | running eval: valid\n01:11:26 | eval completed in 0.19s\n01:11:26 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1747       0          0 137.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 .6667 4.995e-05    72 827.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1062  224 2574        .9161\n\u001b[0m\n01:11:26 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 17\u001b[0m\n01:11:26 | saving model checkpoint: /tmp/model5.checkpoint\n01:11:41 | time:411s total_exs:22000 total_steps:1100 epochs:110.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.64     0 272.7  1022       0          0 74.96  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003106    .1208  6.05 .0002637 4.995e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   453.5       0          0                 1100 393.7 1476 3.757            1\n\n01:11:46 | time:416s total_exs:22400 total_steps:1120 epochs:112.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0 276.1  1087       0          0 78.77  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002941    .1208  6.05 .0002499 4.995e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   476.6       0          0                 1120 397.1 1564 3.956            1\n\n01:11:46 | running eval: valid\n01:11:46 | eval completed in 0.21s\n01:11:46 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1615       0          0 127.5   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 .6953 4.995e-05    72   765       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1120  224 2380        .9161\n\u001b[0m\n01:11:46 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 18\u001b[0m\n01:11:46 | saving model checkpoint: /tmp/model5.checkpoint\n01:12:01 | time:432s total_exs:23180 total_steps:1159 epochs:115.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.83     0 276.6  1076       0          0 77.78  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002793    .1209 5.987 .0002373 4.995e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   465.7       0          0                 1159 396.4 1542 3.898            1\n\n01:12:07 | time:437s total_exs:23580 total_steps:1179 epochs:117.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.48     0 269.7  1048       0          0 77.69  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002654    .1209  6.09 .0002253 4.995e-05 121.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   473.1       0          0                 1179 391.5 1521 3.902            1\n\n01:12:07 | running eval: valid\n01:12:07 | eval completed in 0.21s\n01:12:07 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1609       0          0   127   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 .6874 4.995e-05    72   762       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1179  224 2371        .9161\n\u001b[0m\n01:12:07 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 19\u001b[0m\n01:12:07 | saving model checkpoint: /tmp/model5.checkpoint\n01:12:21 | time:452s total_exs:24360 total_steps:1218 epochs:121.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.93     0 278.6  1076       0          0 77.21  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002521    .1209 6.054 .0002141 4.995e-05 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   467.5       0          0                 1218 399.7 1543 3.87            1\n\n01:12:27 | time:457s total_exs:24800 total_steps:1240 epochs:124.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.65     0   273  1089       0          0 79.77  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .002426    .1209 5.995 .000204 4.995e-05 119.9 478.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1240 392.9 1567 4.005            1\n\n01:12:27 | running eval: valid\n01:12:27 | eval completed in 0.19s\n01:12:27 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1786       0          0   141   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6 .6924 4.995e-05    72 846.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1240  224 2632        .9161\n\u001b[0m\n01:12:27 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 20\u001b[0m\n01:12:27 | saving model checkpoint: /tmp/model5.checkpoint\n01:12:42 | time:472s total_exs:25580 total_steps:1279 epochs:127.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.97     0 279.4  1069       0          0 76.52  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002284    .1209     6 .0001939 4.995e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.1       0          0                 1279 399.4 1528 3.835            1\n\n01:12:47 | time:478s total_exs:26020 total_steps:1301 epochs:130.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.58     0 271.6  1054       0          0 77.61  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002174    .1209 6.055 .0001845 4.995e-05 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   469.9       0          0                 1301 392.7 1524 3.896            1\n\n01:12:47 | running eval: valid\n01:12:48 | eval completed in 0.19s\n01:12:48 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1806       0          0 142.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 .7301 4.995e-05    72 855.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1301  224 2661        .8748\n\u001b[0m\nEpoch 00006: reducing learning rate of group 0 to 2.4975e-05.\n01:12:48 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 21\u001b[0m\n01:12:48 | saving model checkpoint: /tmp/model5.checkpoint\n01:13:02 | time:492s total_exs:26820 total_steps:1341 epochs:134.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.58     0 271.7  1064       0          0 78.29  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002109    .1209 6.013 .0001785 2.498e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   470.7       0          0                 1341 391.9 1534 3.924            1\n\n01:13:08 | time:498s total_exs:27260 total_steps:1363 epochs:136.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.63     0 272.5  1071       0          0 78.62  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .002052    .1209 6.082 .000174 2.498e-05 121.6 478.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1363 394.2 1550 3.947            1\n\n01:13:08 | running eval: valid\n01:13:08 | eval completed in 0.19s\n01:13:08 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1779       0          0 140.4   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 .7052 2.498e-05    72 842.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1363  224 2621        .9161\n\u001b[0m\n01:13:08 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 22\u001b[0m\n01:13:08 | saving model checkpoint: /tmp/model5.checkpoint\n01:13:23 | time:513s total_exs:28060 total_steps:1403 epochs:140.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.54     0 270.9  1062       0          0 78.38  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002004    .1209 6.103 .0001698 2.498e-05   122   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   478.3       0          0                 1403 392.9 1540 3.928            1\n\n01:13:28 | time:518s total_exs:28460 total_steps:1423 epochs:142.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.33     0 286.6  1116       0          0  77.9  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001954    .1209  6.03 .0001657 2.498e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   469.7       0          0                 1423 407.1 1586 3.912            1\n\n01:13:28 | running eval: valid\n01:13:28 | eval completed in 0.19s\n01:13:28 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1772       0          0 139.8   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6 .7086 2.498e-05    72 839.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1423  224 2611        .9161\n\u001b[0m\n01:13:28 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 23\u001b[0m\n01:13:28 | saving model checkpoint: /tmp/model5.checkpoint\n01:13:43 | time:533s total_exs:29240 total_steps:1462 epochs:146.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.01     0 280.2  1072       0          0 76.53  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .00191    .1209 5.977 .000162 2.498e-05 119.5 457.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1462 399.7 1529 3.835            1\n\n01:13:48 | time:538s total_exs:29640 total_steps:1482 epochs:148.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.11     0 282.1  1114       0          0 78.95  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001865    .1192 6.035 .000158 2.498e-05 120.7 476.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1482 402.9 1590 3.965            1\n\n01:13:48 | running eval: valid\n01:13:48 | eval completed in 0.22s\n01:13:48 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1514       0          0 119.5   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6 .7123 2.498e-05    72 717.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1482  224 2231        .9161\n\u001b[0m\n01:13:48 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 24\u001b[0m\n01:13:48 | saving model checkpoint: /tmp/model5.checkpoint\n01:14:04 | time:554s total_exs:30420 total_steps:1521 epochs:152.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.93     0 278.5  1074       0          0 77.11  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001822    .1209 6.005 .0001545 2.498e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     463       0          0                 1521 398.6 1537 3.864            1\n\n01:14:09 | time:559s total_exs:30800 total_steps:1540 epochs:154.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.04     0 280.8  1121       0          0 79.82  380   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00178    .1209 5.963 .0001509 2.498e-05 119.3   476   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1540 400.1 1597 4.01            1\n\n01:14:09 | running eval: valid\n01:14:09 | eval completed in 0.19s\n01:14:09 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1803       0          0 142.3   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 .7151 2.498e-05    72 854.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1540  224 2658        .9161\n\u001b[0m\nEpoch 00010: reducing learning rate of group 0 to 1.2488e-05.\n01:14:09 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 25\u001b[0m\n01:14:09 | saving model checkpoint: /tmp/model5.checkpoint\n01:14:24 | time:574s total_exs:31580 total_steps:1579 epochs:157.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1    12     0   280  1086       0          0 77.58  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00175    .1209 6.069 .0001483 1.249e-05 121.4 470.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1579 401.4 1557 3.888            1\n\n01:14:29 | time:579s total_exs:31980 total_steps:1599 epochs:159.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.61     0 272.2  1087       0          0 79.88  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001728    .1209 6.095 .0001463 1.249e-05 121.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   486.9       0          0                 1599 394.1 1574 4.012            1\n\n01:14:29 | running eval: valid\n01:14:29 | eval completed in 0.18s\n01:14:29 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1847       0          0 145.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 .7171 1.249e-05    72 874.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1599  224 2721        .9161\n\u001b[0m\n01:14:29 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 26\u001b[0m\n01:14:29 | saving model checkpoint: /tmp/model5.checkpoint\n01:14:44 | time:594s total_exs:32780 total_steps:1639 epochs:163.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.6     0   272  1067       0          0 78.45  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001713    .1209 6.043 .0001447 1.249e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     474       0          0                 1639 392.9 1541 3.931            1\n\n01:14:49 | time:600s total_exs:33180 total_steps:1659 epochs:165.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  12.3     0 286.1  1079       0          0 75.42  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001683    .1209  6.02 .0001427 1.249e-05 120.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     454       0          0                 1659 406.4 1533 3.787            1\n\n01:14:49 | running eval: valid\n01:14:50 | eval completed in 0.19s\n01:14:50 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1775       0          0 140.1   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 .7308 1.249e-05    72 840.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1659  224 2616        .9161\n\u001b[0m\n01:14:50 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 27\u001b[0m\n01:14:50 | saving model checkpoint: /tmp/model5.checkpoint\n01:15:05 | time:615s total_exs:33960 total_steps:1698 epochs:169.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.56     0 271.1  1056       0          0  77.9  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001666    .1210 6.013 .0001412 1.249e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   468.4       0          0                 1698 391.4 1524 3.904            1\n\n01:15:10 | time:620s total_exs:34340 total_steps:1717 epochs:171.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.5     0 270.1  1052       0          0 77.94  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001644    .1210 5.995 .0001394 1.249e-05 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   467.2       0          0                 1717 389.9 1520 3.915            1\n\n01:15:10 | running eval: valid\n01:15:10 | eval completed in 0.19s\n01:15:10 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1820       0          0 143.6   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 .7214 1.249e-05    72   862       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1717  224 2682        .9161\n\u001b[0m\n01:15:10 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 28\u001b[0m\n01:15:10 | saving model checkpoint: /tmp/model5.checkpoint\n01:15:25 | time:635s total_exs:35120 total_steps:1756 epochs:175.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.76     0 275.2  1050       0          0 76.31  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00162    .1210 6.054 .0001373 1.249e-05 121.1   462   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1756 396.3 1512 3.824            1\n\n01:15:30 | time:640s total_exs:35500 total_steps:1775 epochs:177.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.76     0 275.2  1073       0          0 77.96  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001599    .1210 6.026 .0001355 1.249e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   469.8       0          0                 1775 395.7 1542 3.916            1\n\n01:15:30 | running eval: valid\n01:15:30 | eval completed in 0.19s\n01:15:30 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1812       0          0   143   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 .7227 1.249e-05    72 858.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1775  224 2671        .9161\n\u001b[0m\nEpoch 00014: reducing learning rate of group 0 to 6.2438e-06.\n01:15:30 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 29\u001b[0m\n01:15:30 | saving model checkpoint: /tmp/model5.checkpoint\n01:15:45 | time:655s total_exs:36300 total_steps:1815 epochs:181.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.74     0 274.8  1076       0          0 78.32  800   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001586    .1210 5.985 .0001344 6.244e-06 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   468.8       0          0                 1815 394.5 1545 3.925            1\n\n01:15:50 | time:660s total_exs:36700 total_steps:1835 epochs:183.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.78     0 275.6  1027       0          0 74.51  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001575    .1210  6.03 .0001335 6.244e-06 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.3       0          0                 1835 396.2 1476 3.742            1\n\n01:15:50 | running eval: valid\n01:15:50 | eval completed in 0.19s\n01:15:50 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1763       0          0 139.1   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 .7237 6.244e-06    72 834.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1835  224 2599        .9161\n\u001b[0m\n01:15:50 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 30\u001b[0m\n01:15:50 | saving model checkpoint: /tmp/model5.checkpoint\n01:15:55 | ran out of patience! stopping training.\n01:15:55 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n01:15:55 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n01:15:55 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run5/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n01:15:55 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n01:15:55 | Using CUDA\n01:15:55 | loading dictionary from /tmp/model5.dict\n01:15:55 | num words = 54944\n01:15:59 | Loading existing model parameters from /tmp/model5\n01:16:06 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:16:07 | creating task(s): fromfile:parlaiformat\n01:16:07 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run5/data_valid.txt\n01:16:07 | running eval: valid\n01:16:08 | eval completed in 0.28s\n01:16:08 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1250       0          0 98.55   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297     6 .5765 5.454e-06    72 591.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    109  224 1842        .9161\n\u001b[0m\n01:16:08 | creating task(s): fromfile:parlaiformat\n01:16:08 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run5/data_test.txt\n01:16:08 | running eval: test\n01:16:12 | eval completed in 4.74s\n01:16:12 | \u001b[1mtest:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .8700 8.7e-10               .5860                 .4299   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9200            .9229              .9898   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8644 12.07 281.4  2981       0          0 211.8 1000 .8700   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297   5.2 .5613 5.454e-06   104  1101       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    109 385.4 4082        .8892\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type1/run5/data_test.txt -m transformer/classifier -mf /tmp/model5 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:16:14.654121Z","iopub.execute_input":"2022-12-04T01:16:14.654795Z","iopub.status.idle":"2022-12-04T01:16:45.868948Z","shell.execute_reply.started":"2022-12-04T01:16:14.654741Z","shell.execute_reply":"2022-12-04T01:16:45.867702Z"},"scrolled":true,"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"01:16:24 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr1type1/run5/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr1type1/run5/data)\u001b[0m\n01:16:24 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n01:16:24 | Using CUDA\n01:16:24 | loading dictionary from /tmp/model5.dict\n01:16:24 | num words = 54944\n01:16:28 | Loading existing model parameters from /tmp/model5\n01:16:34 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:16:35 | Opt:\n01:16:35 |     activation: gelu\n01:16:35 |     adafactor_eps: '[1e-30, 0.001]'\n01:16:35 |     adam_eps: 1e-08\n01:16:35 |     add_p1_after_newln: False\n01:16:35 |     aggregate_micro: False\n01:16:35 |     allow_missing_init_opts: False\n01:16:35 |     area_under_curve_class: None\n01:16:35 |     area_under_curve_digits: -1\n01:16:35 |     attention_dropout: 0.1\n01:16:35 |     batchsize: 40\n01:16:35 |     betas: '[0.9, 0.999]'\n01:16:35 |     bpe_add_prefix_space: None\n01:16:35 |     bpe_debug: False\n01:16:35 |     bpe_dropout: None\n01:16:35 |     bpe_merge: None\n01:16:35 |     bpe_vocab: None\n01:16:35 |     candidates: inline\n01:16:35 |     cap_num_predictions: 100\n01:16:35 |     checkpoint_activations: False\n01:16:35 |     class_weights: None\n01:16:35 |     classes: \"['__notok__', '__ok__']\"\n01:16:35 |     classes_from_file: None\n01:16:35 |     data_parallel: True\n01:16:35 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n01:16:35 |     datatype: train\n01:16:35 |     delimiter: '\\n'\n01:16:35 |     dict_class: parlai.core.dict:DictionaryAgent\n01:16:35 |     dict_endtoken: __start__\n01:16:35 |     dict_file: /tmp/model5.dict\n01:16:35 |     dict_include_test: False\n01:16:35 |     dict_include_valid: False\n01:16:35 |     dict_initpath: None\n01:16:35 |     dict_language: english\n01:16:35 |     dict_loaded: True\n01:16:35 |     dict_lower: True\n01:16:35 |     dict_max_ngram_size: -1\n01:16:35 |     dict_maxexs: -1\n01:16:35 |     dict_maxtokens: -1\n01:16:35 |     dict_minfreq: 0\n01:16:35 |     dict_nulltoken: __null__\n01:16:35 |     dict_starttoken: __start__\n01:16:35 |     dict_textfields: text,labels\n01:16:35 |     dict_tokenizer: bpe\n01:16:35 |     dict_unktoken: __unk__\n01:16:35 |     display_examples: False\n01:16:35 |     download_path: None\n01:16:35 |     dropout: 0.1\n01:16:35 |     dynamic_batching: None\n01:16:35 |     embedding_projection: random\n01:16:35 |     embedding_size: 768\n01:16:35 |     embedding_type: random\n01:16:35 |     embeddings_scale: False\n01:16:35 |     encode_candidate_vecs: True\n01:16:35 |     encode_candidate_vecs_batchsize: 256\n01:16:35 |     eval_batchsize: None\n01:16:35 |     eval_candidates: inline\n01:16:35 |     eval_dynamic_batching: None\n01:16:35 |     evaltask: None\n01:16:35 |     ffn_size: 3072\n01:16:35 |     final_extra_opt: \n01:16:35 |     fixed_candidate_vecs: reuse\n01:16:35 |     fixed_candidates_path: None\n01:16:35 |     force_fp16_tokens: True\n01:16:35 |     fp16: True\n01:16:35 |     fp16_impl: safe\n01:16:35 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type1/run5/data_test.txt\n01:16:35 |     fromfile_datatype_extension: True\n01:16:35 |     gpu: -1\n01:16:35 |     gradient_clip: 0.1\n01:16:35 |     hide_labels: False\n01:16:35 |     history_add_global_end_token: None\n01:16:35 |     history_reversed: False\n01:16:35 |     history_size: 20\n01:16:35 |     ignore_bad_candidates: False\n01:16:35 |     ignore_labels: None\n01:16:35 |     image_cropsize: 224\n01:16:35 |     image_mode: raw\n01:16:35 |     image_size: 256\n01:16:35 |     inference: max\n01:16:35 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:16:35 |     init_opt: None\n01:16:35 |     interactive_candidates: fixed\n01:16:35 |     interactive_mode: False\n01:16:35 |     invsqrt_lr_decay_gamma: -1\n01:16:35 |     is_debug: False\n01:16:35 |     label_truncate: 72\n01:16:35 |     learn_embeddings: True\n01:16:35 |     learn_positional_embeddings: True\n01:16:35 |     learningrate: 5e-05\n01:16:35 |     load_from_pretrained_ranker: True\n01:16:35 |     log_every_n_secs: 10.0\n01:16:35 |     log_every_n_steps: 50\n01:16:35 |     log_keep_fields: all\n01:16:35 |     loglevel: info\n01:16:35 |     lr_scheduler: reduceonplateau\n01:16:35 |     lr_scheduler_decay: 0.5\n01:16:35 |     lr_scheduler_patience: 3\n01:16:35 |     max_train_steps: -1\n01:16:35 |     max_train_time: 7200.0\n01:16:35 |     memory_attention: sqrt\n01:16:35 |     metrics: default\n01:16:35 |     model: transformer/classifier\n01:16:35 |     model_file: /tmp/model5\n01:16:35 |     model_parallel: False\n01:16:35 |     momentum: 0\n01:16:35 |     multitask_weights: [1]\n01:16:35 |     mutators: None\n01:16:35 |     n_decoder_layers: -1\n01:16:35 |     n_encoder_layers: -1\n01:16:35 |     n_heads: 12\n01:16:35 |     n_layers: 12\n01:16:35 |     n_positions: 1024\n01:16:35 |     n_segments: 2\n01:16:35 |     nesterov: True\n01:16:35 |     no_cuda: False\n01:16:35 |     normalize_sent_emb: False\n01:16:35 |     num_epochs: -1\n01:16:35 |     num_examples: -1\n01:16:35 |     num_workers: 0\n01:16:35 |     nus: [0.7]\n01:16:35 |     optimizer: adamax\n01:16:35 |     output_scaling: 0.06\n01:16:35 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type1/run5/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model5', 'batchsize': 40}\"\n01:16:35 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n01:16:35 |     person_tokens: False\n01:16:35 |     print_scores: False\n01:16:35 |     rank_candidates: False\n01:16:35 |     rank_top_k: -1\n01:16:35 |     reduction_type: mean\n01:16:35 |     ref_class: None\n01:16:35 |     relu_dropout: 0.0\n01:16:35 |     repeat_blocking_heuristic: True\n01:16:35 |     report_filename: \n01:16:35 |     return_cand_scores: False\n01:16:35 |     save_after_valid: True\n01:16:35 |     save_every_n_secs: -1\n01:16:35 |     save_format: conversations\n01:16:35 |     share_encoders: False\n01:16:35 |     share_word_embeddings: False\n01:16:35 |     short_final_eval: False\n01:16:35 |     special_tok_lst: None\n01:16:35 |     split_lines: False\n01:16:35 |     starttime: Dec04_01-04\n01:16:35 |     task: fromfile:parlaiformat\n01:16:35 |     tensorboard_log: False\n01:16:35 |     tensorboard_logdir: None\n01:16:35 |     text_truncate: 360\n01:16:35 |     threshold: 0.5\n01:16:35 |     topk: 5\n01:16:35 |     train_predict: False\n01:16:35 |     truncate: 1024\n01:16:35 |     update_classifier_head_only: False\n01:16:35 |     update_freq: 1\n01:16:35 |     use_memories: False\n01:16:35 |     use_reply: none\n01:16:35 |     validation_cutoff: 1.0\n01:16:35 |     validation_every_n_epochs: -1\n01:16:35 |     validation_every_n_secs: 20.0\n01:16:35 |     validation_every_n_steps: -1\n01:16:35 |     validation_max_exs: -1\n01:16:35 |     validation_metric: accuracy\n01:16:35 |     validation_metric_mode: max\n01:16:35 |     validation_patience: 30\n01:16:35 |     validation_share_agent: False\n01:16:35 |     variant: xlm\n01:16:35 |     verbose: False\n01:16:35 |     wandb_entity: None\n01:16:35 |     wandb_log: False\n01:16:35 |     wandb_name: None\n01:16:35 |     wandb_project: None\n01:16:35 |     warmup_rate: 0.0001\n01:16:35 |     warmup_updates: 1000\n01:16:35 |     weight_decay: None\n01:16:35 |     world_logs: \n01:16:35 |     wrap_memory_encoder: False\n01:16:36 | Evaluating task fromfile:parlaiformat using datatype valid.\n01:16:36 | creating task(s): fromfile:parlaiformat\n01:16:36 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n01:16:36 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type1/run5/data_test.txt\n01:16:44 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .8700 8.7e-10               .5860                 .4299   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9200            .9229              .9898   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8644 12.07 562.9  1893       0          0 134.5 1000 .8700   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5613 5.454e-06   208 699.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    109 770.9 2593        .8892\u001b[0m\n01:16:44 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .8700 8.7e-10               .5860                 .4299   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9200            .9229              .9898   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8644 12.07 562.9  1893       0          0 134.5 1000 .8700   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5613 5.454e-06   208 699.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    109 770.9 2593        .8892\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model5*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:16:45.870937Z","iopub.execute_input":"2022-12-04T01:16:45.871350Z","iopub.status.idle":"2022-12-04T01:16:47.210842Z","shell.execute_reply.started":"2022-12-04T01:16:45.871307Z","shell.execute_reply":"2022-12-04T01:16:47.209348Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":"# prev2corr1type2","metadata":{}},{"cell_type":"markdown","source":"run 1","metadata":{}},{"cell_type":"code","source":"# run 1 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type2/run1/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model1","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:16:47.214322Z","iopub.execute_input":"2022-12-04T01:16:47.214853Z","iopub.status.idle":"2022-12-04T01:31:04.925211Z","shell.execute_reply.started":"2022-12-04T01:16:47.214807Z","shell.execute_reply":"2022-12-04T01:31:04.923968Z"},"scrolled":true,"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"01:16:54 | building dictionary first...\n01:16:54 | No model with opt yet at: /tmp/model1(.opt)\n01:16:54 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run1/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n01:16:54 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n01:16:54 | Using CUDA\n01:16:54 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n01:16:54 | num words = 54944\n01:16:59 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:17:09 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:17:09 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n01:17:09 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n01:17:09 | Opt:\n01:17:09 |     activation: gelu\n01:17:09 |     adafactor_eps: '(1e-30, 0.001)'\n01:17:09 |     adam_eps: 1e-08\n01:17:09 |     add_p1_after_newln: False\n01:17:09 |     aggregate_micro: False\n01:17:09 |     allow_missing_init_opts: False\n01:17:09 |     attention_dropout: 0.1\n01:17:09 |     batchsize: 20\n01:17:09 |     betas: '(0.9, 0.999)'\n01:17:09 |     bpe_add_prefix_space: None\n01:17:09 |     bpe_debug: False\n01:17:09 |     bpe_dropout: None\n01:17:09 |     bpe_merge: None\n01:17:09 |     bpe_vocab: None\n01:17:09 |     candidates: inline\n01:17:09 |     cap_num_predictions: 100\n01:17:09 |     checkpoint_activations: False\n01:17:09 |     class_weights: None\n01:17:09 |     classes: \"['__notok__', '__ok__']\"\n01:17:09 |     classes_from_file: None\n01:17:09 |     data_parallel: True\n01:17:09 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n01:17:09 |     datatype: train\n01:17:09 |     delimiter: '\\n'\n01:17:09 |     dict_class: parlai.core.dict:DictionaryAgent\n01:17:09 |     dict_endtoken: __start__\n01:17:09 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n01:17:09 |     dict_include_test: False\n01:17:09 |     dict_include_valid: False\n01:17:09 |     dict_initpath: None\n01:17:09 |     dict_language: english\n01:17:09 |     dict_loaded: True\n01:17:09 |     dict_lower: True\n01:17:09 |     dict_max_ngram_size: -1\n01:17:09 |     dict_maxexs: -1\n01:17:09 |     dict_maxtokens: -1\n01:17:09 |     dict_minfreq: 0\n01:17:09 |     dict_nulltoken: __null__\n01:17:09 |     dict_starttoken: __start__\n01:17:09 |     dict_textfields: text,labels\n01:17:09 |     dict_tokenizer: bpe\n01:17:09 |     dict_unktoken: __unk__\n01:17:09 |     display_examples: False\n01:17:09 |     download_path: None\n01:17:09 |     dropout: 0.1\n01:17:09 |     dynamic_batching: None\n01:17:09 |     embedding_projection: random\n01:17:09 |     embedding_size: 768\n01:17:09 |     embedding_type: random\n01:17:09 |     embeddings_scale: False\n01:17:09 |     encode_candidate_vecs: True\n01:17:09 |     encode_candidate_vecs_batchsize: 256\n01:17:09 |     eval_batchsize: None\n01:17:09 |     eval_candidates: inline\n01:17:09 |     eval_dynamic_batching: None\n01:17:09 |     evaltask: None\n01:17:09 |     ffn_size: 3072\n01:17:09 |     final_extra_opt: \n01:17:09 |     fixed_candidate_vecs: reuse\n01:17:09 |     fixed_candidates_path: None\n01:17:09 |     force_fp16_tokens: False\n01:17:09 |     fp16: True\n01:17:09 |     fp16_impl: safe\n01:17:09 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run1/data\n01:17:09 |     fromfile_datatype_extension: True\n01:17:09 |     gpu: -1\n01:17:09 |     gradient_clip: 0.1\n01:17:09 |     hide_labels: False\n01:17:09 |     history_add_global_end_token: None\n01:17:09 |     history_reversed: False\n01:17:09 |     history_size: 20\n01:17:09 |     ignore_bad_candidates: False\n01:17:09 |     ignore_labels: None\n01:17:09 |     image_cropsize: 224\n01:17:09 |     image_mode: raw\n01:17:09 |     image_size: 256\n01:17:09 |     inference: max\n01:17:09 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:17:09 |     init_opt: None\n01:17:09 |     interactive_candidates: fixed\n01:17:09 |     interactive_mode: False\n01:17:09 |     invsqrt_lr_decay_gamma: -1\n01:17:09 |     is_debug: False\n01:17:09 |     label_truncate: 72\n01:17:09 |     learn_embeddings: True\n01:17:09 |     learn_positional_embeddings: True\n01:17:09 |     learningrate: 5e-05\n01:17:09 |     load_from_checkpoint: False\n01:17:09 |     load_from_pretrained_ranker: True\n01:17:09 |     log_every_n_secs: 10.0\n01:17:09 |     log_every_n_steps: 50\n01:17:09 |     log_keep_fields: all\n01:17:09 |     loglevel: info\n01:17:09 |     lr_scheduler: reduceonplateau\n01:17:09 |     lr_scheduler_decay: 0.5\n01:17:09 |     lr_scheduler_patience: 3\n01:17:09 |     max_train_steps: -1\n01:17:09 |     max_train_time: 7200.0\n01:17:09 |     memory_attention: sqrt\n01:17:09 |     metrics: default\n01:17:09 |     model: transformer/classifier\n01:17:09 |     model_file: /tmp/model1\n01:17:09 |     model_parallel: False\n01:17:09 |     momentum: 0\n01:17:09 |     multitask_weights: [1]\n01:17:09 |     mutators: None\n01:17:09 |     n_decoder_layers: -1\n01:17:09 |     n_encoder_layers: -1\n01:17:09 |     n_heads: 12\n01:17:09 |     n_layers: 12\n01:17:09 |     n_positions: 1024\n01:17:09 |     n_segments: 2\n01:17:09 |     nesterov: True\n01:17:09 |     no_cuda: False\n01:17:09 |     normalize_sent_emb: False\n01:17:09 |     num_epochs: -1\n01:17:09 |     num_workers: 0\n01:17:09 |     nus: (0.7,)\n01:17:09 |     optimizer: adamax\n01:17:09 |     output_scaling: 0.06\n01:17:09 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type2/run1/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model1'}\"\n01:17:09 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n01:17:09 |     person_tokens: False\n01:17:09 |     print_scores: False\n01:17:09 |     rank_candidates: False\n01:17:09 |     rank_top_k: -1\n01:17:09 |     reduction_type: mean\n01:17:09 |     ref_class: None\n01:17:09 |     relu_dropout: 0.0\n01:17:09 |     repeat_blocking_heuristic: True\n01:17:09 |     return_cand_scores: False\n01:17:09 |     save_after_valid: True\n01:17:09 |     save_every_n_secs: -1\n01:17:09 |     save_format: conversations\n01:17:09 |     share_encoders: False\n01:17:09 |     share_word_embeddings: False\n01:17:09 |     short_final_eval: False\n01:17:09 |     special_tok_lst: None\n01:17:09 |     split_lines: False\n01:17:09 |     starttime: Dec04_01-16\n01:17:09 |     task: fromfile:parlaiformat\n01:17:09 |     tensorboard_log: False\n01:17:09 |     tensorboard_logdir: None\n01:17:09 |     text_truncate: 360\n01:17:09 |     threshold: 0.5\n01:17:09 |     topk: 5\n01:17:09 |     train_predict: False\n01:17:09 |     truncate: 1024\n01:17:09 |     update_classifier_head_only: False\n01:17:09 |     update_freq: 1\n01:17:09 |     use_memories: False\n01:17:09 |     use_reply: none\n01:17:09 |     validation_cutoff: 1.0\n01:17:09 |     validation_every_n_epochs: -1\n01:17:09 |     validation_every_n_secs: 20.0\n01:17:09 |     validation_every_n_steps: -1\n01:17:09 |     validation_max_exs: -1\n01:17:09 |     validation_metric: accuracy\n01:17:09 |     validation_metric_mode: max\n01:17:09 |     validation_patience: 30\n01:17:09 |     validation_share_agent: False\n01:17:09 |     variant: xlm\n01:17:09 |     verbose: False\n01:17:09 |     wandb_entity: None\n01:17:09 |     wandb_log: False\n01:17:09 |     wandb_name: None\n01:17:09 |     wandb_project: None\n01:17:09 |     warmup_rate: 0.0001\n01:17:09 |     warmup_updates: 1000\n01:17:09 |     weight_decay: None\n01:17:09 |     world_logs: \n01:17:09 |     wrap_memory_encoder: False\n01:17:09 | creating task(s): fromfile:parlaiformat\n01:17:09 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run1/data_train.txt\n01:17:09 | training...\n01:17:20 | time:10s total_exs:420 total_steps:21 epochs:2.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .4952 4.952e-10               .4726                 .5220   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .4318            .5160              .4748   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .5650 11.13     1 262.6 539.5       0          0 41.08  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .4952             32768  2.603    .1189 6.048 .6984 1.055e-06   121 248.5   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   21 383.6 787.9 2.059        .4933\n\n01:17:30 | time:20s total_exs:1160 total_steps:58 epochs:5.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6257 6.257e-10               .6516                 .6137   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6944            .5956              .6415   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .5559 11.31     1 266.1  1002       0          0 75.31  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6257             32768  2.564    .1189 6.008 .6724 2.905e-06 120.2 452.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   58 386.3 1455 3.774        .6238\n\n01:17:30 | creating task(s): fromfile:parlaiformat\n01:17:30 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run1/data_valid.txt\n01:17:30 | running eval: valid\n01:17:30 | eval completed in 0.20s\n01:17:30 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .6667                 .7778   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5833            .7407              .6667   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1745       0          0 129.6   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6627 2.905e-06    72   778       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     58 233.5 2523        .7037\n\u001b[0m\n01:17:30 | \u001b[1;32mnew best accuracy: 0.7083\u001b[0m\n01:17:30 | saving best valid model: /tmp/model1\n01:17:30 | Saving dictionary to /tmp/model1.dict\n01:17:33 | saving model checkpoint: /tmp/model1.checkpoint\n01:17:33 | Saving dictionary to /tmp/model1.checkpoint.dict\n01:17:50 | time:41s total_exs:1860 total_steps:93 epochs:9.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8629 8.629e-10               .8648                 .8599   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8697            .8609              .8659   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8559 11.17     1 263.5 910.1       0          0 69.09  700   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8629             32768  2.855    .1189 6.009 .6060 4.655e-06 120.2 415.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   93 383.6 1325 3.462        .8628\n\n01:17:53 | time:44s total_exs:2100 total_steps:105 epochs:10.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9375 9.375e-10               .9383                 .9500   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9268            .9367              .9250   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9487 10.95     1 258.9 969.4       0          0 74.88  240   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9375             32768  3.176    .1189 6.025 .5218 5.254e-06 120.5 451.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  105 379.4 1421 3.77        .9375\n\n01:17:53 | running eval: valid\n01:17:54 | eval completed in 0.20s\n01:17:54 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1756       0          0 130.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5664 5.254e-06    72 782.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    105 233.5 2539        .8322\n\u001b[0m\n01:17:54 | \u001b[1;32mnew best accuracy: 0.8333 (previous best was 0.7083)\u001b[0m\n01:17:54 | saving best valid model: /tmp/model1\n01:18:03 | saving model checkpoint: /tmp/model1.checkpoint\n01:18:18 | time:68s total_exs:2860 total_steps:143 epochs:14.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9566 9.566e-10               .9572                 .9510   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9634            .9559              .9624   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9496 11.12     1 262.3 992.8       0          0 75.69  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9566             32768  3.629    .1189 6.008 .3884 7.154e-06 120.2 454.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  143 382.5 1448 3.793        .9566\n\n01:18:23 | time:74s total_exs:3260 total_steps:163 epochs:16.30\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9650 9.65e-10               .9660                 .9660   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9660            .9639              .9639   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9639 10.96     1 259.3  1003       0          0 77.38  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9650             32768  4.816    .1189  6.03 .1922 8.154e-06 120.6 466.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  163 379.9 1470 3.886        .9650\n\n01:18:23 | running eval: valid\n01:18:23 | eval completed in 0.23s\n01:18:23 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1504       0          0 111.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .3581 8.154e-06    72 670.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    163 233.5 2175        .8322\n\u001b[0m\n01:18:23 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 1\u001b[0m\n01:18:23 | saving model checkpoint: /tmp/model1.checkpoint\n01:18:43 | time:94s total_exs:4020 total_steps:201 epochs:20.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9855 9.855e-10               .9856                 .9818   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9895            .9854              .9894   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9815 11.07     1 261.4 987.6       0          0 75.56  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9855             32768   3.06    .1190 6.003 .09206 1.005e-05 120.1 453.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  201 381.5 1441 3.786        .9855\n\n01:18:43 | time:94s total_exs:4040 total_steps:202 epochs:20.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.25     1   265 951.3       0          0 71.78   20   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n     1             32768  16.92    .1190   6.2 .04379 1.01e-05   124 445.1   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  202  389 1396 3.903            1\n\n01:18:43 | running eval: valid\n01:18:43 | eval completed in 0.21s\n01:18:43 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8000                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8571              .7500   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 11.46 161.5  1659       0          0 123.2   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .5289 1.01e-05    72 739.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    202 233.5 2399        .8286\n\u001b[0m\n01:18:43 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 2\u001b[0m\n01:18:43 | saving model checkpoint: /tmp/model1.checkpoint\n01:18:58 | time:109s total_exs:4800 total_steps:240 epochs:24.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9961 9.961e-10               .9962                 .9924   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9959                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9919 11.18 .7632 263.7 992.9       0          0 75.32  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss      lr  ltpb  ltps  \\\n   .9961             32768  1.589    .1190 6.029 .01873 1.2e-05 120.6 454.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  240 384.2 1447 3.774        .9961\n\n01:19:04 | time:114s total_exs:5200 total_steps:260 epochs:26.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.07 .0500 261.4 974.9       0          0 74.57  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss      lr  ltpb  ltps  \\\n     1             32768 .06275    .1190 5.995 .003512 1.3e-05 119.9 447.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  260 381.4 1422 3.744            1\n\n01:19:04 | running eval: valid\n01:19:04 | eval completed in 0.21s\n01:19:04 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1748       0          0 129.9   24 .8333   \n    gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .7784 1.3e-05    72 779.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    260 233.5 2528        .8322\n\u001b[0m\n01:19:04 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 3\u001b[0m\n01:19:04 | saving model checkpoint: /tmp/model1.checkpoint\n01:19:18 | time:129s total_exs:5960 total_steps:298 epochs:29.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.1     0 261.9 995.9       0          0 76.04  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .02799    .1190 5.982 .002218 1.49e-05 119.6 454.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  298 381.6 1451 3.811            1\n\n01:19:24 | time:135s total_exs:6380 total_steps:319 epochs:31.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 10.91 .04762 258.2 978.7       0          0  75.8   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    420   1             32768 .03399    .1190 6.033 .001749 1.595e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.3       0          0                  319 378.9 1436 3.805            1\n\n01:19:24 | running eval: valid\n01:19:24 | eval completed in 0.20s\n01:19:24 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1774       0          0 131.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .9251 1.595e-05    72 790.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    319 233.5 2565        .8333\n\u001b[0m\n01:19:24 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 4\u001b[0m\n01:19:24 | saving model checkpoint: /tmp/model1.checkpoint\n01:19:38 | time:149s total_exs:7140 total_steps:357 epochs:35.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.52     0 270.4  1007       0          0 74.48  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768  .0177    .1190 5.942 .001497 1.785e-05 118.8 442.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  357 389.2 1449 3.732            1\n\n01:19:44 | time:155s total_exs:7560 total_steps:378 epochs:37.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.23 .04762 264.6 997.9       0          0 75.44   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  \\\n    420   1             32768  .4638    .1190 6.005 .00143 1.89e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     453       0          0                  378 384.7 1451 3.787            1\n\n01:19:44 | running eval: valid\n01:19:44 | eval completed in 0.20s\n01:19:44 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 11.46 161.5  1778       0          0 132.1   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 1.067 1.89e-05    72 792.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    378 233.5 2570        .8333\n\u001b[0m\n01:19:44 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 5\u001b[0m\n01:19:44 | saving model checkpoint: /tmp/model1.checkpoint\n01:19:59 | time:170s total_exs:8340 total_steps:417 epochs:41.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.14     0 262.7  1000       0          0 76.14  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n     1             32768 .01573    .1190 6.015 .00125 2.085e-05 120.3   458   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  417  383 1458 3.815            1\n\n01:20:04 | time:175s total_exs:8740 total_steps:437 epochs:43.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.28     0 265.5   950       0          0 71.56  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01349    .1190  6.05 .001158 2.185e-05   121   433   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  437 386.5 1383 3.593            1\n\n01:20:04 | running eval: valid\n01:20:05 | eval completed in 0.20s\n01:20:05 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1757       0          0 130.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08095     6 1.102 2.185e-05    72 783.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    437 233.5 2541        .8322\n\u001b[0m\n01:20:05 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 6\u001b[0m\n01:20:05 | saving model checkpoint: /tmp/model1.checkpoint\n01:20:19 | time:190s total_exs:9500 total_steps:475 epochs:47.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1    11     0   260 979.4       0          0 75.33  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01267    .1190 6.021 .001085 2.375e-05 120.4 453.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  475 380.4 1433 3.775            1\n\n01:20:25 | time:195s total_exs:9940 total_steps:497 epochs:49.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1  10.8 .04545 256.1 976.6       0          0 76.27   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    440   1             32768 .02691    .1190 6.036 .001031 2.485e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.4       0          0                  497 376.8 1437 3.829            1\n\n01:20:25 | running eval: valid\n01:20:25 | eval completed in 0.23s\n01:20:25 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1550       0          0 115.1   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 .9126 2.485e-05    72   691       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    497 233.5 2241        .8748\n\u001b[0m\n01:20:25 | \u001b[1;32mnew best accuracy: 0.875 (previous best was 0.8333)\u001b[0m\n01:20:25 | saving best valid model: /tmp/model1\n01:20:29 | saving model checkpoint: /tmp/model1.checkpoint\n01:20:48 | time:218s total_exs:10700 total_steps:535 epochs:53.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.09     0 261.8 989.9       0          0 75.61  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01111    .1190 5.979 .000953 2.675e-05 119.6 452.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  535 381.4 1442 3.789            1\n\n01:20:49 | time:220s total_exs:10820 total_steps:541 epochs:54.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.93     0 258.7 980.7       0          0 75.83  120   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01049    .1190 5.833 .0009018 2.705e-05 116.7 442.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  541 375.3 1423 3.846            1\n\n01:20:49 | running eval: valid\n01:20:49 | eval completed in 0.20s\n01:20:49 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1773       0          0 131.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 1.166 2.705e-05    72 790.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    541 233.5 2564        .8322\n\u001b[0m\n01:20:49 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 1\u001b[0m\n01:20:49 | saving model checkpoint: /tmp/model1.checkpoint\n01:21:04 | time:235s total_exs:11580 total_steps:579 epochs:57.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.32     0 266.3  1010       0          0 75.84  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01085    .1190 6.066 .0008715 2.895e-05 121.3   460   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  579 387.7 1470  3.8            1\n\n01:21:10 | time:240s total_exs:11960 total_steps:598 epochs:59.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.73     0 254.6   929       0          0 72.98  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .009583    .1190 6.042 .000821 2.99e-05 120.8   441   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  598 375.4 1370 3.665            1\n\n01:21:10 | running eval: valid\n01:21:10 | eval completed in 0.20s\n01:21:10 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1744       0          0 129.5   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 1.042 2.99e-05    72 777.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    598 233.5 2521        .8322\n\u001b[0m\n01:21:10 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 2\u001b[0m\n01:21:10 | saving model checkpoint: /tmp/model1.checkpoint\n01:21:24 | time:255s total_exs:12720 total_steps:636 epochs:63.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.89     0 257.9 974.9       0          0  75.6  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .009045    .1190 6.087 .0007741 3.18e-05 121.7 460.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  636 379.6 1435 3.789            1\n\n01:21:30 | time:261s total_exs:13160 total_steps:658 epochs:65.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.95     0   259 996.1       0          0 76.92  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .00844    .1190 5.991 .0007233 3.29e-05 119.8 460.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  658 378.8 1457 3.859            1\n\n01:21:30 | running eval: valid\n01:21:30 | eval completed in 0.20s\n01:21:30 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1764       0          0   131   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 1.209 3.29e-05    72 786.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    658 233.5 2550        .8322\n\u001b[0m\n01:21:30 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 3\u001b[0m\n01:21:30 | saving model checkpoint: /tmp/model1.checkpoint\n01:21:45 | time:276s total_exs:13920 total_steps:696 epochs:69.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.14     0 262.7   976       0          0  74.3  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .007928    .1190 6.018 .0006793 3.48e-05 120.4 447.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  696 383.1 1423 3.723            1\n\n01:21:50 | time:281s total_exs:14320 total_steps:716 epochs:71.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.93 .1000 258.5 995.9       0          0 77.05  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768  .5344    .1190  5.95 .0007014 3.58e-05   119 458.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  716 377.5 1454 3.869            1\n\n01:21:50 | running eval: valid\n01:21:50 | eval completed in 0.21s\n01:21:50 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8000                 .7692   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7826              .8182   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.46 161.5  1664       0          0 123.6   24 .7917   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 1.471 3.58e-05    72 741.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    716 233.5 2406        .7913\n\u001b[0m\n01:21:50 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 4\u001b[0m\n01:21:50 | saving model checkpoint: /tmp/model1.checkpoint\n01:22:05 | time:296s total_exs:15080 total_steps:754 epochs:75.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 10.93 .05263 258.6 978.1       0          0 75.66   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  \\\n    760   1             32768  .3207    .1191 6.005 .0006504 3.77e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   454.3       0          0                  754 378.7 1432 3.791            1\n\n01:22:11 | time:301s total_exs:15500 total_steps:775 epochs:77.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.54     0 250.7 938.2       0          0 74.84  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006694    .1191 6.033 .0005692 3.875e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.5       0          0                  775 371.4 1390 3.757            1\n\n01:22:11 | running eval: valid\n01:22:11 | eval completed in 0.20s\n01:22:11 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1794       0          0 133.3   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 1.292 3.875e-05    72 799.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    775 233.5 2594        .8322\n\u001b[0m\n01:22:11 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 5\u001b[0m\n01:22:11 | saving model checkpoint: /tmp/model1.checkpoint\n01:22:26 | time:316s total_exs:16280 total_steps:814 epochs:81.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9987                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9974            .9987              .9975   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.02 .02564 260.4 992.7       0          0 76.24   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  \\\n    780 .9987             32768  .8161    .1191 5.995 .009498 4.07e-05 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.1       0          0                  814 380.3 1450 3.821        .9987\n\n01:22:31 | time:322s total_exs:16700 total_steps:835 epochs:83.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.17     0 263.4  1009       0          0 76.62  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .005849    .1191 5.871 .0004995 4.175e-05 117.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.9       0          0                  835 380.9 1459 3.847            1\n\n01:22:31 | running eval: valid\n01:22:31 | eval completed in 0.20s\n01:22:31 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1794       0          0 133.3   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 1.108 4.175e-05    72 799.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    835 233.5 2594        .8322\n\u001b[0m\n01:22:31 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 6\u001b[0m\n01:22:31 | saving model checkpoint: /tmp/model1.checkpoint\n01:22:46 | time:336s total_exs:17460 total_steps:873 epochs:87.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.3     0 266.1 992.9       0          0 74.63  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n     1             32768 .005511    .1191 5.989 .00047 4.365e-05 119.8   447   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  873 385.9 1440 3.74            1\n\n01:22:51 | time:342s total_exs:17880 total_steps:894 epochs:89.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  10.8     0   256   969       0          0 75.71  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .005191    .1191   6.1 .0004431 4.47e-05   122 461.8   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  894  378 1431 3.801            1\n\n01:22:51 | running eval: valid\n01:22:51 | eval completed in 0.20s\n01:22:51 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1750       0          0   130   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 1.308 4.47e-05    72   780       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    894 233.5 2530        .8322\n\u001b[0m\n01:22:51 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 7\u001b[0m\n01:22:51 | saving model checkpoint: /tmp/model1.checkpoint\n01:23:06 | time:356s total_exs:18640 total_steps:932 epochs:93.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.12     0 262.4 996.9       0          0 75.97  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .004861    .1191 6.039 .0004148 4.66e-05 120.8 458.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  932 383.2 1456 3.807            1\n\n01:23:12 | time:362s total_exs:19080 total_steps:954 epochs:95.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.4     0 267.9  1014       0          0 75.67  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .004544    .1191 5.959 .0003876 4.77e-05 119.2 450.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  954 387.1 1464 3.789            1\n\n01:23:12 | running eval: valid\n01:23:12 | eval completed in 0.24s\n01:23:12 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1509       0          0   112   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 1.338 4.77e-05    72 672.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    954 233.5 2182        .8322\n\u001b[0m\n01:23:12 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 8\u001b[0m\n01:23:12 | saving model checkpoint: /tmp/model1.checkpoint\n01:23:26 | time:377s total_exs:19840 total_steps:992 epochs:99.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.23     0 264.6  1001       0          0 75.65  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .004274    .1191 6.013 .0003641 4.96e-05 120.3 454.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  992 384.9 1456 3.791            1\n\n01:23:32 | time:383s total_exs:20260 total_steps:1013 epochs:101.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.94     0 258.8 985.3       0          0 76.14  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .004013    .1191  6.01 .000342 4.995e-05 120.2 457.6   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1013  379 1443 3.822            1\n\n01:23:32 | running eval: valid\n01:23:32 | eval completed in 0.21s\n01:23:32 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1691       0          0 125.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6 1.366 4.995e-05    72 754.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1013 233.5 2446        .8322\n\u001b[0m\n01:23:32 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 9\u001b[0m\n01:23:32 | saving model checkpoint: /tmp/model1.checkpoint\n01:23:46 | time:397s total_exs:21000 total_steps:1050 epochs:105.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.23     0 264.6 979.6       0          0 74.03  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003778    .1191 6.027 .0003218 4.995e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   446.2       0          0                 1050 385.2 1426 3.71            1\n\n01:23:52 | time:403s total_exs:21440 total_steps:1072 epochs:107.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.99     0 259.9 996.9       0          0 76.72  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003552    .1191 5.964 .0003025 4.995e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.5       0          0                 1072 379.1 1454 3.852            1\n\n01:23:52 | running eval: valid\n01:23:52 | eval completed in 0.20s\n01:23:52 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1765       0          0 131.1   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 1.389 4.995e-05    72 786.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1072 233.5 2552        .8322\n\u001b[0m\n01:23:52 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 10\u001b[0m\n01:23:52 | saving model checkpoint: /tmp/model1.checkpoint\n01:24:07 | time:417s total_exs:22200 total_steps:1110 epochs:111.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.35     0 267.1  1013       0          0 75.84  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003357    .1191 6.029 .0002858 4.995e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.3       0          0                 1110 387.7 1470 3.801            1\n\n01:24:12 | time:423s total_exs:22640 total_steps:1132 epochs:113.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.77     0 255.5 994.3       0          0 77.85  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003444    .1191 5.991 .0002701 4.995e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   466.4       0          0                 1132 375.3 1461 3.908            1\n\n01:24:12 | running eval: valid\n01:24:13 | eval completed in 0.20s\n01:24:13 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1781       0          0 132.3   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 1.406 4.995e-05    72 793.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1132 233.5 2575        .8322\n\u001b[0m\n01:24:13 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 11\u001b[0m\n01:24:13 | saving model checkpoint: /tmp/model1.checkpoint\n01:24:28 | time:439s total_exs:23420 total_steps:1171 epochs:117.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.12     0 262.4 998.5       0          0 76.11  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002999    .1191 6.031 .0002551 4.995e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n     459       0          0                 1171  383 1457 3.814            1\n\n01:24:33 | time:443s total_exs:23800 total_steps:1190 epochs:119.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.09     0 261.9  1010       0          0 77.14  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002846    .1191 5.984 .0002418 4.995e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.7       0          0                 1190 381.6 1472 3.875            1\n\n01:24:33 | running eval: valid\n01:24:33 | eval completed in 0.22s\n01:24:33 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1650       0          0 122.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 1.362 4.995e-05    72 735.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1190 233.5 2386        .8322\n\u001b[0m\n01:24:33 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 12\u001b[0m\n01:24:33 | saving model checkpoint: /tmp/model1.checkpoint\n01:24:47 | time:458s total_exs:24560 total_steps:1228 epochs:122.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.23     0 264.6  1007       0          0 76.09  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002694    .1191 5.937 .0002292 4.995e-05 118.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.7       0          0                 1228 383.3 1458 3.813            1\n\n01:24:53 | time:464s total_exs:24980 total_steps:1249 epochs:124.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.16     0 263.2 970.2       0          0 73.71  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002668    .1191 6.052 .0002188 4.995e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   446.1       0          0                 1249 384.3 1416 3.701            1\n\n01:24:53 | running eval: valid\n01:24:53 | eval completed in 0.20s\n01:24:53 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1765       0          0 131.1   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6  1.44 4.995e-05    72 786.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1249 233.5 2552        .8322\n\u001b[0m\n01:24:53 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 13\u001b[0m\n01:24:53 | saving model checkpoint: /tmp/model1.checkpoint\n01:25:08 | time:478s total_exs:25740 total_steps:1287 epochs:128.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.91     0 258.3 982.3       0          0 76.06  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002438    .1191 5.974 .0002073 4.995e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   454.4       0          0                 1287 377.8 1437 3.812            1\n\n01:25:13 | time:484s total_exs:26180 total_steps:1309 epochs:130.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.15     0   263  1005       0          0 76.42  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002327    .1192 6.082 .0001977 4.995e-05 121.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   464.8       0          0                 1309 384.7 1470 3.837            1\n\n01:25:13 | running eval: valid\n01:25:14 | eval completed in 0.20s\n01:25:14 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1780       0          0 132.2   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 1.467 4.995e-05    72 793.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1309 233.5 2574        .8322\n\u001b[0m\n01:25:14 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 14\u001b[0m\n01:25:14 | saving model checkpoint: /tmp/model1.checkpoint\n01:25:28 | time:499s total_exs:26940 total_steps:1347 epochs:134.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.15     0 263.1 978.6       0          0 74.39  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002212    .1192 6.037 .0001879 4.995e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.1       0          0                 1347 383.8 1428 3.728            1\n\n01:25:34 | time:504s total_exs:27360 total_steps:1368 epochs:136.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.85     0   257 978.8       0          0 76.18  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002113    .1192 6.062 .0001794 4.995e-05 121.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.8       0          0                 1368 378.2 1441 3.825            1\n\n01:25:34 | running eval: valid\n01:25:34 | eval completed in 0.20s\n01:25:34 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1770       0          0 131.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 1.481 4.995e-05    72   789       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1368 233.5 2559        .8322\n\u001b[0m\n01:25:34 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 15\u001b[0m\n01:25:34 | saving model checkpoint: /tmp/model1.checkpoint\n01:25:48 | time:519s total_exs:28120 total_steps:1406 epochs:140.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.02     0 260.4 981.3       0          0 75.35  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002015    .1192  6.05 .0001711 4.995e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   455.9       0          0                 1406 381.4 1437 3.776            1\n\n01:25:54 | time:525s total_exs:28560 total_steps:1428 epochs:142.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.39     0 267.9 998.4       0          0 74.55  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001921    .1192 6.014 .0001631 4.995e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   448.3       0          0                 1428 388.1 1447 3.742            1\n\n01:25:54 | running eval: valid\n01:25:54 | eval completed in 0.21s\n01:25:54 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1720       0          0 127.8   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 1.499 4.995e-05    72   767       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1428 233.5 2487        .8322\n\u001b[0m\nEpoch 00008: reducing learning rate of group 0 to 2.4975e-05.\n01:25:54 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 16\u001b[0m\n01:25:54 | saving model checkpoint: /tmp/model1.checkpoint\n01:26:09 | time:539s total_exs:29320 total_steps:1466 epochs:146.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.35     0   267  1003       0          0 75.11  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001858    .1192 5.982 .0001577 2.498e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.3       0          0                 1466 386.6 1452 3.764            1\n\n01:26:14 | time:545s total_exs:29760 total_steps:1488 epochs:148.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.76     0 255.1 982.4       0          0 77.01  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001815    .1192 5.955 .0001541 2.498e-05 119.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.6       0          0                 1488 374.2 1441 3.866            1\n\n01:26:14 | running eval: valid\n01:26:15 | eval completed in 0.21s\n01:26:15 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1696       0          0 125.9   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6 1.507 2.498e-05    72 755.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1488 233.5 2452        .8322\n\u001b[0m\n01:26:15 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 17\u001b[0m\n01:26:15 | saving model checkpoint: /tmp/model1.checkpoint\n01:26:29 | time:560s total_exs:30500 total_steps:1525 epochs:152.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.08     0 261.6 950.8       0          0  72.7  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001777    .1192 5.978 .0001508 2.498e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   434.6       0          0                 1525 381.1 1385 3.643            1\n\n01:26:35 | time:566s total_exs:30920 total_steps:1546 epochs:154.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.2     0 264.1  1016       0          0 76.91  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001741    .1192 6.076 .0001477 2.498e-05 121.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   467.3       0          0                 1546 385.6 1483 3.861            1\n\n01:26:35 | running eval: valid\n01:26:35 | eval completed in 0.20s\n01:26:35 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1755       0          0 130.4   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6 1.515 2.498e-05    72 782.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1546 233.5 2538        .8322\n\u001b[0m\n01:26:35 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 18\u001b[0m\n01:26:35 | saving model checkpoint: /tmp/model1.checkpoint\n01:26:50 | time:580s total_exs:31700 total_steps:1585 epochs:158.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.15     0 262.9  1000       0          0 76.09  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001699    .1192 6.038 .0001442 2.498e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.5       0          0                 1585 383.7 1460 3.813            1\n\n01:26:55 | time:586s total_exs:32100 total_steps:1605 epochs:160.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.11     0 262.2 960.2       0          0 73.24  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001659    .1192 6.015 .0001408 2.498e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   440.5       0          0                 1605 382.5 1401 3.677            1\n\n01:26:55 | running eval: valid\n01:26:55 | eval completed in 0.20s\n01:26:55 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1747       0          0 129.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 1.523 2.498e-05    72 778.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1605 233.5 2525        .8322\n\u001b[0m\n01:26:55 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 19\u001b[0m\n01:26:55 | saving model checkpoint: /tmp/model1.checkpoint\n01:27:10 | time:601s total_exs:32860 total_steps:1643 epochs:164.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.03     0 260.5 983.3       0          0 75.49  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001619    .1192 5.992 .0001374 2.498e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   452.3       0          0                 1643 380.4 1436 3.783            1\n\n01:27:16 | time:606s total_exs:33300 total_steps:1665 epochs:166.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.33     0 266.7  1004       0          0 75.29  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001581    .1192     6 .0001341 2.498e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.8       0          0                 1665 386.7 1456 3.779            1\n\n01:27:16 | running eval: valid\n01:27:16 | eval completed in 0.20s\n01:27:16 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1762       0          0 130.8   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 1.531 2.498e-05    72 785.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1665 233.5 2547        .8322\n\u001b[0m\nEpoch 00012: reducing learning rate of group 0 to 1.2488e-05.\n01:27:16 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 20\u001b[0m\n01:27:16 | saving model checkpoint: /tmp/model1.checkpoint\n01:27:30 | time:621s total_exs:34040 total_steps:1702 epochs:170.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.73     0 254.5 939.5       0          0 73.82  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001555    .1192 5.992 .0001319 1.249e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   442.3       0          0                 1702 374.4 1382 3.699            1\n\n01:27:36 | time:627s total_exs:34480 total_steps:1724 epochs:172.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.93     0 258.6 970.1       0          0 75.03  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001536    .1192 5.982 .0001303 1.249e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   448.8       0          0                 1724 378.2 1419 3.766            1\n\n01:27:36 | running eval: valid\n01:27:36 | eval completed in 0.20s\n01:27:36 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1739       0          0 129.1   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 1.535 1.249e-05    72   775       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1724 233.5 2514        .8322\n\u001b[0m\n01:27:36 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 21\u001b[0m\n01:27:36 | saving model checkpoint: /tmp/model1.checkpoint\n01:27:51 | time:641s total_exs:35240 total_steps:1762 epochs:176.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.18     0 263.6 988.8       0          0 75.04  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00152    .1192 6.003 .0001289 1.249e-05 120.1 450.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1762 383.6 1439 3.76            1\n\n01:27:57 | time:647s total_exs:35680 total_steps:1784 epochs:178.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.01     0 260.2 974.4       0          0  74.9  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001498    .1192 5.982 .0001271 1.249e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     448       0          0                 1784 379.8 1422 3.759            1\n\n01:27:57 | running eval: valid\n01:27:57 | eval completed in 0.20s\n01:27:57 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1763       0          0   131   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6  1.54 1.249e-05    72   786       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1784 233.5 2549        .8322\n\u001b[0m\n01:27:57 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 22\u001b[0m\n01:27:57 | saving model checkpoint: /tmp/model1.checkpoint\n01:28:11 | time:662s total_exs:36440 total_steps:1822 epochs:182.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.22     0 264.4 993.9       0          0 75.19  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00148    .1192 6.013 .0001255 1.249e-05 120.3 452.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1822 384.6 1446 3.768            1\n\n01:28:17 | time:668s total_exs:36860 total_steps:1843 epochs:184.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.42     0 268.5  1031       0          0 76.78  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001462    .1193 6.062 .000124 1.249e-05 121.2 465.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1843 389.7 1496 3.853            1\n\n01:28:17 | running eval: valid\n01:28:17 | eval completed in 0.21s\n01:28:17 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1692       0          0 125.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 1.544 1.249e-05    72 754.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1843 233.5 2446        .8322\n\u001b[0m\n01:28:17 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 23\u001b[0m\n01:28:17 | saving model checkpoint: /tmp/model1.checkpoint\n01:28:32 | time:682s total_exs:37600 total_steps:1880 epochs:188.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.03     0 260.6 952.6       0          0 73.11  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001442    .1193 6.041 .0001223 1.249e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   441.6       0          0                 1880 381.4 1394 3.664            1\n\n01:28:37 | time:688s total_exs:38020 total_steps:1901 epochs:190.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.19     0 263.9  1010       0          0 76.54  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00142    .1193 5.943 .0001204 1.249e-05 118.9 454.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1901 382.7 1465 3.842            1\n\n01:28:37 | running eval: valid\n01:28:37 | eval completed in 0.20s\n01:28:37 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1756       0          0 130.4   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08122     6 1.549 1.249e-05    72 782.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1901 233.5 2538        .8322\n\u001b[0m\nEpoch 00016: reducing learning rate of group 0 to 6.2438e-06.\n01:28:37 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 24\u001b[0m\n01:28:37 | saving model checkpoint: /tmp/model1.checkpoint\n01:28:52 | time:703s total_exs:38780 total_steps:1939 epochs:193.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.88     0 257.5 972.2       0          0  75.5  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00141    .1193 6.013 .0001195 6.244e-06 120.3   454   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1939 377.8 1426 3.783            1\n\n01:28:57 | time:708s total_exs:39200 total_steps:1960 epochs:196.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.12     0 262.5 992.9       0          0 75.66  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001401    .1193 6.067 .0001189 6.244e-06 121.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     459       0          0                 1960 383.8 1452 3.798            1\n\n01:28:57 | running eval: valid\n01:28:58 | eval completed in 0.20s\n01:28:58 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1787       0          0 132.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08123     6 1.551 6.244e-06    72 796.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1960 233.5 2583        .8322\n\u001b[0m\n01:28:58 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 25\u001b[0m\n01:28:58 | saving model checkpoint: /tmp/model1.checkpoint\n01:29:13 | time:723s total_exs:39960 total_steps:1998 epochs:199.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.05     0 261.1 989.2       0          0 75.78  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001391    .1193 6.026 .000118 6.244e-06 120.5 456.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1998 381.6 1446 3.798            1\n\n01:29:18 | time:728s total_exs:40340 total_steps:2017 epochs:201.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.12     0 262.5  1003       0          0 76.42  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             63811 .001382    .1193     6 .0001172 6.244e-06   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.5       0          0                 2017 382.5 1461 3.839            1\n\n01:29:18 | running eval: valid\n01:29:18 | eval completed in 0.22s\n01:29:18 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1631       0          0 121.2   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08124     6 1.553 6.244e-06    72 727.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   2017 233.5 2359        .8322\n\u001b[0m\n01:29:18 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 26\u001b[0m\n01:29:18 | saving model checkpoint: /tmp/model1.checkpoint\n01:29:32 | time:743s total_exs:41100 total_steps:2055 epochs:205.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.06 .02632 261.2   984       0          0 75.35   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n    760   1             65536  .1701    .1193 5.921 .0001308 6.244e-06 118.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   446.2       0          0                 2055 379.6 1430 3.776            1\n\n01:29:38 | time:749s total_exs:41520 total_steps:2076 epochs:207.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.31     0 266.3 968.7       0          0 72.75  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             65536 .001363    .1193 6.043 .0001155 6.244e-06 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   439.6       0          0                 2076 387.1 1408 3.652            1\n\n01:29:38 | running eval: valid\n01:29:38 | eval completed in 0.21s\n01:29:38 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1697       0          0   126   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08125     6  1.49 6.244e-06    72 756.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   2076 233.5 2453        .7884\n\u001b[0m\n01:29:38 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 27\u001b[0m\n01:29:38 | saving model checkpoint: /tmp/model1.checkpoint\n01:29:53 | time:763s total_exs:42280 total_steps:2114 epochs:211.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.37     0 267.4  1012       0          0 75.66  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             65536 .001374    .1193 6.082 .0001148 6.244e-06 121.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.1       0          0                 2114 389.1 1472 3.792            1\n\n01:29:58 | time:769s total_exs:42720 total_steps:2136 epochs:213.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  10.9     0   258 964.3       0          0 74.74  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             65536 .001374    .1193 6.027 .0001137 6.244e-06 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   450.5       0          0                 2136 378.6 1415 3.751            1\n\n01:29:58 | running eval: valid\n01:29:59 | eval completed in 0.20s\n01:29:59 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1766       0          0 131.2   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08126     6 1.496 6.244e-06    72 787.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   2136 233.5 2554        .8322\n\u001b[0m\nEpoch 00020: reducing learning rate of group 0 to 3.1219e-06.\n01:29:59 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 28\u001b[0m\n01:29:59 | saving model checkpoint: /tmp/model1.checkpoint\n01:30:13 | time:784s total_exs:43460 total_steps:2173 epochs:217.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.22     0 264.5 972.8       0          0 73.56  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             65536 .001337    .1193 6.062 .0001132 3.122e-06 121.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   445.9       0          0                 2173 385.7 1419 3.686            1\n\n01:30:19 | time:790s total_exs:43900 total_steps:2195 epochs:219.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1    11     0   260 971.9       0          0 74.75  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             65536 .001326    .1193 6.014 .0001124 3.122e-06 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.5       0          0                 2195 380.3 1421 3.752            1\n\n01:30:19 | running eval: valid\n01:30:19 | eval completed in 0.20s\n01:30:19 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1757       0          0 130.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08127     6 1.501 3.122e-06    72 783.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   2195 233.5 2540        .8322\n\u001b[0m\n01:30:19 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 29\u001b[0m\n01:30:19 | saving model checkpoint: /tmp/model1.checkpoint\n01:30:33 | time:804s total_exs:44660 total_steps:2233 epochs:223.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.27     0 265.3  1000       0          0  75.4  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             65536 .001323    .1193 6.037 .0001121 3.122e-06 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   455.2       0          0                 2233 386.1 1455 3.779            1\n\n01:30:39 | time:810s total_exs:45100 total_steps:2255 epochs:225.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.84     0 256.7 960.8       0          0 74.85  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             65536 .00132    .1193 6.091 .0001119 3.122e-06 121.8 455.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 2255 378.5 1417 3.757            1\n\n01:30:39 | running eval: valid\n01:30:40 | eval completed in 0.22s\n01:30:40 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1601       0          0 118.9   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08128     6  1.51 3.122e-06    72 713.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   2255 233.5 2314        .8322\n\u001b[0m\n01:30:40 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 30\u001b[0m\n01:30:40 | saving model checkpoint: /tmp/model1.checkpoint\n01:30:44 | ran out of patience! stopping training.\n01:30:44 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n01:30:44 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n01:30:44 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run1/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n01:30:44 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n01:30:44 | Using CUDA\n01:30:44 | loading dictionary from /tmp/model1.dict\n01:30:44 | num words = 54944\n01:30:48 | Loading existing model parameters from /tmp/model1\n01:30:56 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:30:57 | creating task(s): fromfile:parlaiformat\n01:30:57 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run1/data_valid.txt\n01:30:57 | running eval: valid\n01:30:57 | eval completed in 0.31s\n01:30:57 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1162       0          0 86.19   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298     6 .9126 2.485e-05    72 517.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    497 233.5 1680        .8748\n\u001b[0m\n01:30:57 | creating task(s): fromfile:parlaiformat\n01:30:57 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run1/data_test.txt\n01:30:57 | running eval: test\n01:31:03 | eval completed in 5.13s\n01:31:03 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9330 9.33e-10               .7331                 .6093   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9200            .9617              .9906   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9344 12.07 281.4  2758       0          0   196 1000 .9330   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298   5.2 .4262 2.485e-05   104  1019       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    497 385.4 3777        .9388\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type2/run1/data_test.txt -m transformer/classifier -mf /tmp/model1 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:31:04.934340Z","iopub.execute_input":"2022-12-04T01:31:04.934825Z","iopub.status.idle":"2022-12-04T01:31:36.180604Z","shell.execute_reply.started":"2022-12-04T01:31:04.934771Z","shell.execute_reply":"2022-12-04T01:31:36.179431Z"},"scrolled":true,"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"01:31:14 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr1type2/run1/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr1type2/run1/data)\u001b[0m\n01:31:14 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n01:31:14 | Using CUDA\n01:31:14 | loading dictionary from /tmp/model1.dict\n01:31:14 | num words = 54944\n01:31:19 | Loading existing model parameters from /tmp/model1\n01:31:24 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:31:26 | Opt:\n01:31:26 |     activation: gelu\n01:31:26 |     adafactor_eps: '[1e-30, 0.001]'\n01:31:26 |     adam_eps: 1e-08\n01:31:26 |     add_p1_after_newln: False\n01:31:26 |     aggregate_micro: False\n01:31:26 |     allow_missing_init_opts: False\n01:31:26 |     area_under_curve_class: None\n01:31:26 |     area_under_curve_digits: -1\n01:31:26 |     attention_dropout: 0.1\n01:31:26 |     batchsize: 40\n01:31:26 |     betas: '[0.9, 0.999]'\n01:31:26 |     bpe_add_prefix_space: None\n01:31:26 |     bpe_debug: False\n01:31:26 |     bpe_dropout: None\n01:31:26 |     bpe_merge: None\n01:31:26 |     bpe_vocab: None\n01:31:26 |     candidates: inline\n01:31:26 |     cap_num_predictions: 100\n01:31:26 |     checkpoint_activations: False\n01:31:26 |     class_weights: None\n01:31:26 |     classes: \"['__notok__', '__ok__']\"\n01:31:26 |     classes_from_file: None\n01:31:26 |     data_parallel: True\n01:31:26 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n01:31:26 |     datatype: train\n01:31:26 |     delimiter: '\\n'\n01:31:26 |     dict_class: parlai.core.dict:DictionaryAgent\n01:31:26 |     dict_endtoken: __start__\n01:31:26 |     dict_file: /tmp/model1.dict\n01:31:26 |     dict_include_test: False\n01:31:26 |     dict_include_valid: False\n01:31:26 |     dict_initpath: None\n01:31:26 |     dict_language: english\n01:31:26 |     dict_loaded: True\n01:31:26 |     dict_lower: True\n01:31:26 |     dict_max_ngram_size: -1\n01:31:26 |     dict_maxexs: -1\n01:31:26 |     dict_maxtokens: -1\n01:31:26 |     dict_minfreq: 0\n01:31:26 |     dict_nulltoken: __null__\n01:31:26 |     dict_starttoken: __start__\n01:31:26 |     dict_textfields: text,labels\n01:31:26 |     dict_tokenizer: bpe\n01:31:26 |     dict_unktoken: __unk__\n01:31:26 |     display_examples: False\n01:31:26 |     download_path: None\n01:31:26 |     dropout: 0.1\n01:31:26 |     dynamic_batching: None\n01:31:26 |     embedding_projection: random\n01:31:26 |     embedding_size: 768\n01:31:26 |     embedding_type: random\n01:31:26 |     embeddings_scale: False\n01:31:26 |     encode_candidate_vecs: True\n01:31:26 |     encode_candidate_vecs_batchsize: 256\n01:31:26 |     eval_batchsize: None\n01:31:26 |     eval_candidates: inline\n01:31:26 |     eval_dynamic_batching: None\n01:31:26 |     evaltask: None\n01:31:26 |     ffn_size: 3072\n01:31:26 |     final_extra_opt: \n01:31:26 |     fixed_candidate_vecs: reuse\n01:31:26 |     fixed_candidates_path: None\n01:31:26 |     force_fp16_tokens: True\n01:31:26 |     fp16: True\n01:31:26 |     fp16_impl: safe\n01:31:26 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run1/data_test.txt\n01:31:26 |     fromfile_datatype_extension: True\n01:31:26 |     gpu: -1\n01:31:26 |     gradient_clip: 0.1\n01:31:26 |     hide_labels: False\n01:31:26 |     history_add_global_end_token: None\n01:31:26 |     history_reversed: False\n01:31:26 |     history_size: 20\n01:31:26 |     ignore_bad_candidates: False\n01:31:26 |     ignore_labels: None\n01:31:26 |     image_cropsize: 224\n01:31:26 |     image_mode: raw\n01:31:26 |     image_size: 256\n01:31:26 |     inference: max\n01:31:26 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:31:26 |     init_opt: None\n01:31:26 |     interactive_candidates: fixed\n01:31:26 |     interactive_mode: False\n01:31:26 |     invsqrt_lr_decay_gamma: -1\n01:31:26 |     is_debug: False\n01:31:26 |     label_truncate: 72\n01:31:26 |     learn_embeddings: True\n01:31:26 |     learn_positional_embeddings: True\n01:31:26 |     learningrate: 5e-05\n01:31:26 |     load_from_pretrained_ranker: True\n01:31:26 |     log_every_n_secs: 10.0\n01:31:26 |     log_every_n_steps: 50\n01:31:26 |     log_keep_fields: all\n01:31:26 |     loglevel: info\n01:31:26 |     lr_scheduler: reduceonplateau\n01:31:26 |     lr_scheduler_decay: 0.5\n01:31:26 |     lr_scheduler_patience: 3\n01:31:26 |     max_train_steps: -1\n01:31:26 |     max_train_time: 7200.0\n01:31:26 |     memory_attention: sqrt\n01:31:26 |     metrics: default\n01:31:26 |     model: transformer/classifier\n01:31:26 |     model_file: /tmp/model1\n01:31:26 |     model_parallel: False\n01:31:26 |     momentum: 0\n01:31:26 |     multitask_weights: [1]\n01:31:26 |     mutators: None\n01:31:26 |     n_decoder_layers: -1\n01:31:26 |     n_encoder_layers: -1\n01:31:26 |     n_heads: 12\n01:31:26 |     n_layers: 12\n01:31:26 |     n_positions: 1024\n01:31:26 |     n_segments: 2\n01:31:26 |     nesterov: True\n01:31:26 |     no_cuda: False\n01:31:26 |     normalize_sent_emb: False\n01:31:26 |     num_epochs: -1\n01:31:26 |     num_examples: -1\n01:31:26 |     num_workers: 0\n01:31:26 |     nus: [0.7]\n01:31:26 |     optimizer: adamax\n01:31:26 |     output_scaling: 0.06\n01:31:26 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type2/run1/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model1', 'batchsize': 40}\"\n01:31:26 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n01:31:26 |     person_tokens: False\n01:31:26 |     print_scores: False\n01:31:26 |     rank_candidates: False\n01:31:26 |     rank_top_k: -1\n01:31:26 |     reduction_type: mean\n01:31:26 |     ref_class: None\n01:31:26 |     relu_dropout: 0.0\n01:31:26 |     repeat_blocking_heuristic: True\n01:31:26 |     report_filename: \n01:31:26 |     return_cand_scores: False\n01:31:26 |     save_after_valid: True\n01:31:26 |     save_every_n_secs: -1\n01:31:26 |     save_format: conversations\n01:31:26 |     share_encoders: False\n01:31:26 |     share_word_embeddings: False\n01:31:26 |     short_final_eval: False\n01:31:26 |     special_tok_lst: None\n01:31:26 |     split_lines: False\n01:31:26 |     starttime: Dec04_01-16\n01:31:26 |     task: fromfile:parlaiformat\n01:31:26 |     tensorboard_log: False\n01:31:26 |     tensorboard_logdir: None\n01:31:26 |     text_truncate: 360\n01:31:26 |     threshold: 0.5\n01:31:26 |     topk: 5\n01:31:26 |     train_predict: False\n01:31:26 |     truncate: 1024\n01:31:26 |     update_classifier_head_only: False\n01:31:26 |     update_freq: 1\n01:31:26 |     use_memories: False\n01:31:26 |     use_reply: none\n01:31:26 |     validation_cutoff: 1.0\n01:31:26 |     validation_every_n_epochs: -1\n01:31:26 |     validation_every_n_secs: 20.0\n01:31:26 |     validation_every_n_steps: -1\n01:31:26 |     validation_max_exs: -1\n01:31:26 |     validation_metric: accuracy\n01:31:26 |     validation_metric_mode: max\n01:31:26 |     validation_patience: 30\n01:31:26 |     validation_share_agent: False\n01:31:26 |     variant: xlm\n01:31:26 |     verbose: False\n01:31:26 |     wandb_entity: None\n01:31:26 |     wandb_log: False\n01:31:26 |     wandb_name: None\n01:31:26 |     wandb_project: None\n01:31:26 |     warmup_rate: 0.0001\n01:31:26 |     warmup_updates: 1000\n01:31:26 |     weight_decay: None\n01:31:26 |     world_logs: \n01:31:26 |     wrap_memory_encoder: False\n01:31:26 | Evaluating task fromfile:parlaiformat using datatype valid.\n01:31:26 | creating task(s): fromfile:parlaiformat\n01:31:26 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n01:31:26 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run1/data_test.txt\n01:31:34 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9330 9.33e-10               .7331                 .6093   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9200            .9617              .9906   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9344 12.07 562.9  1912       0          0 135.9 1000 .9330   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .4262 2.485e-05   208 706.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    497 770.9 2619        .9388\u001b[0m\n01:31:34 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9330 9.33e-10               .7331                 .6093   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9200            .9617              .9906   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9344 12.07 562.9  1912       0          0 135.9 1000 .9330   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .4262 2.485e-05   208 706.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    497 770.9 2619        .9388\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model1*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:31:36.185773Z","iopub.execute_input":"2022-12-04T01:31:36.186442Z","iopub.status.idle":"2022-12-04T01:31:37.481828Z","shell.execute_reply.started":"2022-12-04T01:31:36.186396Z","shell.execute_reply":"2022-12-04T01:31:37.480509Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"run 2","metadata":{}},{"cell_type":"code","source":"# run 2 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type2/run2/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model2","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:31:37.483959Z","iopub.execute_input":"2022-12-04T01:31:37.484268Z","iopub.status.idle":"2022-12-04T01:44:46.630215Z","shell.execute_reply.started":"2022-12-04T01:31:37.484237Z","shell.execute_reply":"2022-12-04T01:44:46.628884Z"},"scrolled":true,"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"01:31:44 | building dictionary first...\n01:31:44 | No model with opt yet at: /tmp/model2(.opt)\n01:31:44 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run2/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n01:31:44 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n01:31:44 | Using CUDA\n01:31:44 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n01:31:45 | num words = 54944\n01:31:49 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:31:59 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:31:59 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n01:31:59 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n01:31:59 | Opt:\n01:31:59 |     activation: gelu\n01:31:59 |     adafactor_eps: '(1e-30, 0.001)'\n01:31:59 |     adam_eps: 1e-08\n01:31:59 |     add_p1_after_newln: False\n01:31:59 |     aggregate_micro: False\n01:31:59 |     allow_missing_init_opts: False\n01:31:59 |     attention_dropout: 0.1\n01:31:59 |     batchsize: 20\n01:31:59 |     betas: '(0.9, 0.999)'\n01:31:59 |     bpe_add_prefix_space: None\n01:31:59 |     bpe_debug: False\n01:31:59 |     bpe_dropout: None\n01:31:59 |     bpe_merge: None\n01:31:59 |     bpe_vocab: None\n01:31:59 |     candidates: inline\n01:31:59 |     cap_num_predictions: 100\n01:31:59 |     checkpoint_activations: False\n01:31:59 |     class_weights: None\n01:31:59 |     classes: \"['__notok__', '__ok__']\"\n01:31:59 |     classes_from_file: None\n01:31:59 |     data_parallel: True\n01:31:59 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n01:31:59 |     datatype: train\n01:31:59 |     delimiter: '\\n'\n01:31:59 |     dict_class: parlai.core.dict:DictionaryAgent\n01:31:59 |     dict_endtoken: __start__\n01:31:59 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n01:31:59 |     dict_include_test: False\n01:31:59 |     dict_include_valid: False\n01:31:59 |     dict_initpath: None\n01:31:59 |     dict_language: english\n01:31:59 |     dict_loaded: True\n01:31:59 |     dict_lower: True\n01:31:59 |     dict_max_ngram_size: -1\n01:31:59 |     dict_maxexs: -1\n01:31:59 |     dict_maxtokens: -1\n01:31:59 |     dict_minfreq: 0\n01:31:59 |     dict_nulltoken: __null__\n01:31:59 |     dict_starttoken: __start__\n01:31:59 |     dict_textfields: text,labels\n01:31:59 |     dict_tokenizer: bpe\n01:31:59 |     dict_unktoken: __unk__\n01:31:59 |     display_examples: False\n01:31:59 |     download_path: None\n01:31:59 |     dropout: 0.1\n01:31:59 |     dynamic_batching: None\n01:31:59 |     embedding_projection: random\n01:31:59 |     embedding_size: 768\n01:31:59 |     embedding_type: random\n01:31:59 |     embeddings_scale: False\n01:31:59 |     encode_candidate_vecs: True\n01:31:59 |     encode_candidate_vecs_batchsize: 256\n01:31:59 |     eval_batchsize: None\n01:31:59 |     eval_candidates: inline\n01:31:59 |     eval_dynamic_batching: None\n01:31:59 |     evaltask: None\n01:31:59 |     ffn_size: 3072\n01:31:59 |     final_extra_opt: \n01:31:59 |     fixed_candidate_vecs: reuse\n01:31:59 |     fixed_candidates_path: None\n01:31:59 |     force_fp16_tokens: False\n01:31:59 |     fp16: True\n01:31:59 |     fp16_impl: safe\n01:31:59 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run2/data\n01:31:59 |     fromfile_datatype_extension: True\n01:31:59 |     gpu: -1\n01:31:59 |     gradient_clip: 0.1\n01:31:59 |     hide_labels: False\n01:31:59 |     history_add_global_end_token: None\n01:31:59 |     history_reversed: False\n01:31:59 |     history_size: 20\n01:31:59 |     ignore_bad_candidates: False\n01:31:59 |     ignore_labels: None\n01:31:59 |     image_cropsize: 224\n01:31:59 |     image_mode: raw\n01:31:59 |     image_size: 256\n01:31:59 |     inference: max\n01:31:59 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:31:59 |     init_opt: None\n01:31:59 |     interactive_candidates: fixed\n01:31:59 |     interactive_mode: False\n01:31:59 |     invsqrt_lr_decay_gamma: -1\n01:31:59 |     is_debug: False\n01:31:59 |     label_truncate: 72\n01:31:59 |     learn_embeddings: True\n01:31:59 |     learn_positional_embeddings: True\n01:31:59 |     learningrate: 5e-05\n01:31:59 |     load_from_checkpoint: False\n01:31:59 |     load_from_pretrained_ranker: True\n01:31:59 |     log_every_n_secs: 10.0\n01:31:59 |     log_every_n_steps: 50\n01:31:59 |     log_keep_fields: all\n01:31:59 |     loglevel: info\n01:31:59 |     lr_scheduler: reduceonplateau\n01:31:59 |     lr_scheduler_decay: 0.5\n01:31:59 |     lr_scheduler_patience: 3\n01:31:59 |     max_train_steps: -1\n01:31:59 |     max_train_time: 7200.0\n01:31:59 |     memory_attention: sqrt\n01:31:59 |     metrics: default\n01:31:59 |     model: transformer/classifier\n01:31:59 |     model_file: /tmp/model2\n01:31:59 |     model_parallel: False\n01:31:59 |     momentum: 0\n01:31:59 |     multitask_weights: [1]\n01:31:59 |     mutators: None\n01:31:59 |     n_decoder_layers: -1\n01:31:59 |     n_encoder_layers: -1\n01:31:59 |     n_heads: 12\n01:31:59 |     n_layers: 12\n01:31:59 |     n_positions: 1024\n01:31:59 |     n_segments: 2\n01:31:59 |     nesterov: True\n01:31:59 |     no_cuda: False\n01:31:59 |     normalize_sent_emb: False\n01:31:59 |     num_epochs: -1\n01:31:59 |     num_workers: 0\n01:31:59 |     nus: (0.7,)\n01:31:59 |     optimizer: adamax\n01:31:59 |     output_scaling: 0.06\n01:31:59 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type2/run2/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model2'}\"\n01:31:59 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n01:31:59 |     person_tokens: False\n01:31:59 |     print_scores: False\n01:31:59 |     rank_candidates: False\n01:31:59 |     rank_top_k: -1\n01:31:59 |     reduction_type: mean\n01:31:59 |     ref_class: None\n01:31:59 |     relu_dropout: 0.0\n01:31:59 |     repeat_blocking_heuristic: True\n01:31:59 |     return_cand_scores: False\n01:31:59 |     save_after_valid: True\n01:31:59 |     save_every_n_secs: -1\n01:31:59 |     save_format: conversations\n01:31:59 |     share_encoders: False\n01:31:59 |     share_word_embeddings: False\n01:31:59 |     short_final_eval: False\n01:31:59 |     special_tok_lst: None\n01:31:59 |     split_lines: False\n01:31:59 |     starttime: Dec04_01-31\n01:31:59 |     task: fromfile:parlaiformat\n01:31:59 |     tensorboard_log: False\n01:31:59 |     tensorboard_logdir: None\n01:31:59 |     text_truncate: 360\n01:31:59 |     threshold: 0.5\n01:31:59 |     topk: 5\n01:31:59 |     train_predict: False\n01:31:59 |     truncate: 1024\n01:31:59 |     update_classifier_head_only: False\n01:31:59 |     update_freq: 1\n01:31:59 |     use_memories: False\n01:31:59 |     use_reply: none\n01:31:59 |     validation_cutoff: 1.0\n01:31:59 |     validation_every_n_epochs: -1\n01:31:59 |     validation_every_n_secs: 20.0\n01:31:59 |     validation_every_n_steps: -1\n01:31:59 |     validation_max_exs: -1\n01:31:59 |     validation_metric: accuracy\n01:31:59 |     validation_metric_mode: max\n01:31:59 |     validation_patience: 30\n01:31:59 |     validation_share_agent: False\n01:31:59 |     variant: xlm\n01:31:59 |     verbose: False\n01:31:59 |     wandb_entity: None\n01:31:59 |     wandb_log: False\n01:31:59 |     wandb_name: None\n01:31:59 |     wandb_project: None\n01:31:59 |     warmup_rate: 0.0001\n01:31:59 |     warmup_updates: 1000\n01:31:59 |     weight_decay: None\n01:31:59 |     world_logs: \n01:31:59 |     wrap_memory_encoder: False\n01:31:59 | creating task(s): fromfile:parlaiformat\n01:31:59 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run2/data_train.txt\n01:31:59 | training...\n01:32:10 | time:10s total_exs:420 total_steps:21 epochs:2.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .4595 4.595e-10               .1167                 .3333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                    .07075            .6106              .4747   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8558  11.7     1 273.9 563.1       0          0 41.11  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .4595             32768  2.785    .1206  6.01 .7113 1.055e-06 120.2 247.1   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps  ups  weighted_f1  \n         0          0                   21 394.1 810.2 2.06        .3613\n\n01:32:20 | time:20s total_exs:1160 total_steps:58 epochs:5.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5473 5.473e-10               .4790                 .6553   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .3775            .5998              .4970   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7560 11.67     1 273.5  1034       0          0 75.58  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5473             32768  2.558    .1207 6.103 .6860 2.905e-06 122.1 461.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   58 395.5 1495 3.788        .5332\n\n01:32:20 | creating task(s): fromfile:parlaiformat\n01:32:20 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run2/data_valid.txt\n01:32:20 | running eval: valid\n01:32:20 | eval completed in 0.22s\n01:32:20 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .4167 4.167e-10               .5333                 .4444   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .2222              .3333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .1667    11   156  1612       0          0   124   24 .4167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6997 2.905e-06    72 743.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                     58  228 2356        .3778\n\u001b[0m\n01:32:20 | \u001b[1;32mnew best accuracy: 0.4167\u001b[0m\n01:32:20 | saving best valid model: /tmp/model2\n01:32:20 | Saving dictionary to /tmp/model2.dict\n01:32:24 | saving model checkpoint: /tmp/model2.checkpoint\n01:32:24 | Saving dictionary to /tmp/model2.checkpoint.dict\n01:32:40 | time:41s total_exs:1880 total_steps:94 epochs:9.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7333 7.333e-10               .7895                 .6716   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9574            .6364              .9130   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .4884 11.82     1 276.4   986       0          0 71.36  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7333             32768  2.571    .1207 6.044 .6332 4.705e-06 120.9 431.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   94 397.2 1417 3.574        .7163\n\n01:32:44 | time:45s total_exs:2140 total_steps:107 epochs:10.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8808 8.808e-10               .8912                 .8301   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9621            .8681              .9533   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7969 11.62     1 272.3 962.8       0          0 70.71  260   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8808             32768  3.199    .1207 6.015 .5770 5.354e-06 120.3 425.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  107 392.6 1388 3.557        .8798\n\n01:32:44 | running eval: valid\n01:32:44 | eval completed in 0.20s\n01:32:44 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8148                 .7333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .7619              .8889   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .6667    11   156  1767       0          0 135.9   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6101 5.354e-06    72 815.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    107  228 2583        .7884\n\u001b[0m\n01:32:44 | \u001b[1;32mnew best accuracy: 0.7917 (previous best was 0.4167)\u001b[0m\n01:32:44 | saving best valid model: /tmp/model2\n01:32:54 | saving model checkpoint: /tmp/model2.checkpoint\n01:33:09 | time:70s total_exs:2900 total_steps:145 epochs:14.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9408 9.408e-10               .9413                 .9328   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9402              .9491   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9316 11.93     1 278.7  1051       0          0 75.46  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9408             32768   3.17    .1207     6 .4740 7.254e-06   120 452.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  145 398.7 1504 3.782        .9408\n\n01:33:14 | time:75s total_exs:3260 total_steps:163 epochs:16.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9639 9.639e-10               .9657                 .9734   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9581            .9619              .9535   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9704 12.37     1 287.4  1113       0          0 77.42  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9639             32768  3.632    .1207 6.061 .3178 8.154e-06 121.2 469.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  163 408.7 1582 3.887        .9639\n\n01:33:14 | running eval: valid\n01:33:14 | eval completed in 0.20s\n01:33:14 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1803       0          0 138.6   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .3431 8.154e-06    72 831.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    163  228 2635        .8748\n\u001b[0m\n01:33:14 | \u001b[1;32mnew best accuracy: 0.875 (previous best was 0.7917)\u001b[0m\n01:33:14 | saving best valid model: /tmp/model2\n01:33:23 | saving model checkpoint: /tmp/model2.checkpoint\n01:33:43 | time:104s total_exs:4040 total_steps:202 epochs:20.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9615 9.615e-10               .9639                 .9732   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9547            .9589              .9485   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9695 11.48     1 269.5  1035       0          0 76.84  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9615             32768  4.091    .1207 6.074 .1748 1.01e-05 121.5 466.8   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  202  391 1502 3.851        .9616\n\n01:33:43 | running eval: valid\n01:33:43 | eval completed in 0.20s\n01:33:43 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1753       0          0 134.8   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .2452 1.01e-05    72 808.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    202  228 2561        .8748\n\u001b[0m\n01:33:43 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 1\u001b[0m\n01:33:43 | saving model checkpoint: /tmp/model2.checkpoint\n01:34:04 | time:124s total_exs:4760 total_steps:238 epochs:23.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9847 9.847e-10               .9840                 .9941   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9741            .9854              .9763   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9946 11.34     1 266.9  1012       0          0 75.82  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9847             32768  2.694    .1207 5.967 .05552 1.19e-05 119.3 452.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  238 386.2 1464  3.8        .9847\n\n01:34:04 | running eval: valid\n01:34:04 | eval completed in 0.19s\n01:34:04 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1781       0          0   137   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .3026 1.19e-05    72 822.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    238  228 2604        .9167\n\u001b[0m\n01:34:04 | \u001b[1;32mnew best accuracy: 0.9167 (previous best was 0.875)\u001b[0m\n01:34:04 | saving best valid model: /tmp/model2\n01:34:09 | saving model checkpoint: /tmp/model2.checkpoint\n01:34:27 | time:148s total_exs:5500 total_steps:275 epochs:27.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9986 9.986e-10               .9987                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9974            .9986              .9972   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.92 .4865 278.5  1025       0          0 73.59  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9986             32768  1.237    .1207  6.03 .007897 1.375e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   443.7       0          0                  275 399.1 1468 3.688        .9986\n\n01:34:29 | time:149s total_exs:5620 total_steps:281 epochs:28.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.6     0   272  1065       0          0 78.29  120   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .03547    .1207 5.883 .002668 1.405e-05 117.7 460.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  281 389.7 1525 3.973            1\n\n01:34:29 | running eval: valid\n01:34:29 | eval completed in 0.19s\n01:34:29 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1787       0          0 137.4   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .4848 1.405e-05    72 824.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    281  228 2612        .9167\n\u001b[0m\n01:34:29 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 1\u001b[0m\n01:34:29 | saving model checkpoint: /tmp/model2.checkpoint\n01:34:49 | time:170s total_exs:6340 total_steps:317 epochs:31.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.64 .02778 272.7  1044       0          0 76.54   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    720   1             32768 .03082    .1207 6.025 .002044 1.585e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.2       0          0                  317 393.2 1505 3.836            1\n\n01:34:49 | running eval: valid\n01:34:49 | eval completed in 0.20s\n01:34:49 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1727       0          0 132.8   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 .5409 1.585e-05    72   797       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    317  228 2524        .9167\n\u001b[0m\n01:34:49 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 2\u001b[0m\n01:34:49 | saving model checkpoint: /tmp/model2.checkpoint\n01:35:10 | time:190s total_exs:7100 total_steps:355 epochs:35.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.94     0 278.8  1054       0          0 75.61  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01795    .1207  5.95 .001526 1.775e-05   119 449.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  355 397.8 1504 3.789            1\n\n01:35:10 | running eval: valid\n01:35:10 | eval completed in 0.19s\n01:35:10 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1776       0          0 136.5   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 .5596 1.775e-05    72 819.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    355  228 2595        .9167\n\u001b[0m\n01:35:10 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 3\u001b[0m\n01:35:10 | saving model checkpoint: /tmp/model2.checkpoint\n01:35:25 | time:205s total_exs:7860 total_steps:393 epochs:39.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.93 .02632 278.7  1036       0          0 74.32   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    760   1             32768  .3113    .1207  6.05 .001425 1.965e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.7       0          0                  393 399.7 1485 3.725            1\n\n01:35:30 | time:210s total_exs:8260 total_steps:413 epochs:41.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.5     0 270.1  1027       0          0 76.03  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01416    .1207 5.905 .001198 2.065e-05 118.1   449   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  413 388.1 1476 3.818            1\n\n01:35:30 | running eval: valid\n01:35:30 | eval completed in 0.20s\n01:35:30 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1757       0          0 135.1   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08095     6 .5790 2.065e-05    72 810.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    413  228 2567        .9167\n\u001b[0m\n01:35:30 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 4\u001b[0m\n01:35:30 | saving model checkpoint: /tmp/model2.checkpoint\n01:35:45 | time:225s total_exs:9020 total_steps:451 epochs:45.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.59     0 271.8  1027       0          0 75.57  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01306    .1207 5.997 .001119 2.255e-05 119.9 453.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  451 391.7 1480 3.787            1\n\n01:35:50 | time:231s total_exs:9420 total_steps:471 epochs:47.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.65     0 273.1  1054       0          0 77.16  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01221    .1207  5.97 .001046 2.355e-05 119.4 460.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  471 392.5 1514 3.875            1\n\n01:35:50 | running eval: valid\n01:35:50 | eval completed in 0.19s\n01:35:50 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1792       0          0 137.8   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 .5931 2.355e-05    72 827.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    471  228 2619        .9167\n\u001b[0m\n01:35:50 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 5\u001b[0m\n01:35:50 | saving model checkpoint: /tmp/model2.checkpoint\n01:36:05 | time:246s total_exs:10180 total_steps:509 epochs:50.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.73     0 274.7  1040       0          0 75.69  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768  .0115    .1207 6.037 .0009851 2.545e-05 120.7 456.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  509 395.4 1496 3.793            1\n\n01:36:11 | time:251s total_exs:10580 total_steps:529 epochs:52.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.29     0 265.9  1031       0          0 77.59  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01086    .1207 6.075 .0009291 2.645e-05 121.5 471.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  529 387.4 1503 3.897            1\n\n01:36:11 | running eval: valid\n01:36:11 | eval completed in 0.22s\n01:36:11 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1598       0          0 122.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 .6059 2.645e-05    72 737.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    529  228 2335        .9167\n\u001b[0m\n01:36:11 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 6\u001b[0m\n01:36:11 | saving model checkpoint: /tmp/model2.checkpoint\n01:36:26 | time:266s total_exs:11360 total_steps:568 epochs:56.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.73     0 274.5  1051       0          0 76.54  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .01018    .1208 6.033 .0008706 2.84e-05 120.7 461.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  568 395.2 1513 3.836            1\n\n01:36:31 | time:271s total_exs:11740 total_steps:587 epochs:58.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.89     0 277.9  1031       0          0 74.22  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .009609    .1208 6.016 .0008183 2.935e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   446.5       0          0                  587 398.2 1478 3.728            1\n\n01:36:31 | running eval: valid\n01:36:31 | eval completed in 0.19s\n01:36:31 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1770       0          0 136.1   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 .6176 2.935e-05    72 816.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    587  228 2587        .9167\n\u001b[0m\n01:36:31 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 7\u001b[0m\n01:36:31 | saving model checkpoint: /tmp/model2.checkpoint\n01:36:46 | time:287s total_exs:12520 total_steps:626 epochs:62.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.59     0 271.8  1037       0          0 76.32  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .00912    .1208 6.018 .000771 3.13e-05 120.4 459.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  626 392.2 1497 3.825            1\n\n01:36:51 | time:292s total_exs:12920 total_steps:646 epochs:64.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.48     0 269.6  1045       0          0 77.49  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .008479    .1208 6.015 .0007249 3.23e-05 120.3 466.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  646 389.9 1511 3.891            1\n\n01:36:51 | running eval: valid\n01:36:51 | eval completed in 0.19s\n01:36:51 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1764       0          0 135.7   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 .6283 3.23e-05    72 814.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    646  228 2579        .9167\n\u001b[0m\n01:36:51 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 8\u001b[0m\n01:36:51 | saving model checkpoint: /tmp/model2.checkpoint\n01:37:06 | time:307s total_exs:13660 total_steps:683 epochs:68.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.83     0 276.6  1017       0          0 73.52  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .008005    .1208 6.065 .0006841 3.415e-05 121.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   445.9       0          0                  683 397.9 1463 3.685            1\n\n01:37:12 | time:312s total_exs:14060 total_steps:703 epochs:70.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.75     0 275.1  1075       0          0 78.19  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .007487    .1208 5.925 .0006393 3.515e-05 118.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.2       0          0                  703 393.6 1539 3.927            1\n\n01:37:12 | running eval: valid\n01:37:12 | eval completed in 0.20s\n01:37:12 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1757       0          0 135.1   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 .6378 3.515e-05    72   811       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    703  228 2569        .9167\n\u001b[0m\n01:37:12 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 9\u001b[0m\n01:37:12 | saving model checkpoint: /tmp/model2.checkpoint\n01:37:27 | time:327s total_exs:14840 total_steps:742 epochs:74.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.61     0 272.2  1039       0          0 76.33  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .007083    .1208 6.033 .0006043 3.71e-05 120.7 460.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  742 392.8 1499 3.825            1\n\n01:37:32 | time:333s total_exs:15220 total_steps:761 epochs:76.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.95     0 279.1  1018       0          0 72.95  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006678    .1208 6.053 .0005694 3.805e-05 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   441.5       0          0                  761 400.1 1459 3.663            1\n\n01:37:32 | running eval: valid\n01:37:32 | eval completed in 0.19s\n01:37:32 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1768       0          0   136   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 .6484 3.805e-05    72   816       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    761  228 2584        .9167\n\u001b[0m\n01:37:32 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 10\u001b[0m\n01:37:32 | saving model checkpoint: /tmp/model2.checkpoint\n01:37:47 | time:348s total_exs:15980 total_steps:799 epochs:79.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.85     0   277  1052       0          0 75.99  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006269    .1208 5.987 .0005341 3.995e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     455       0          0                  799 396.7 1507 3.808            1\n\n01:37:52 | time:353s total_exs:16400 total_steps:820 epochs:82.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.85     0 276.9  1064       0          0 76.88  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss      lr  ltpb  ltps  \\\n     1             32768 .00591    .1208  6.01 .0005022 4.1e-05 120.2   462   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  820 397.1 1526 3.86            1\n\n01:37:52 | running eval: valid\n01:37:53 | eval completed in 0.20s\n01:37:53 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1757       0          0 135.1   24 .9167   \n    gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 .6592 4.1e-05    72 810.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    820  228 2568        .9167\n\u001b[0m\n01:37:53 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 11\u001b[0m\n01:37:53 | saving model checkpoint: /tmp/model2.checkpoint\n01:38:08 | time:368s total_exs:17160 total_steps:858 epochs:85.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.47     0 269.4 997.4       0          0 74.04  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .005548    .1208 6.013 .0004724 4.29e-05 120.3 445.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  858 389.7 1443 3.71            1\n\n01:38:13 | time:373s total_exs:17560 total_steps:878 epochs:87.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.55     0   271  1032       0          0 76.18  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .005218    .1208 6.045 .0004446 4.39e-05 120.9 460.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  878 391.9 1493 3.826            1\n\n01:38:13 | running eval: valid\n01:38:13 | eval completed in 0.19s\n01:38:13 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1780       0          0 136.8   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 .6694 4.39e-05    72 821.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    878  228 2601        .9167\n\u001b[0m\n01:38:13 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 12\u001b[0m\n01:38:13 | saving model checkpoint: /tmp/model2.checkpoint\n01:38:28 | time:388s total_exs:18320 total_steps:916 epochs:91.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.68     0 273.5  1034       0          0 75.57  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .004926    .1208 6.082 .000419 4.58e-05 121.6 459.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  916 395.2 1493 3.787            1\n\n01:38:33 | time:394s total_exs:18740 total_steps:937 epochs:93.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.6     0 272.1  1023       0          0 75.18  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004616    .1208 5.976 .0003913 4.685e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.3       0          0                  937 391.6 1472 3.775            1\n\n01:38:33 | running eval: valid\n01:38:34 | eval completed in 0.33s\n01:38:34 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1084       0          0 83.37   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 .6830 4.685e-05    72 500.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    937  228 1584        .9167\n\u001b[0m\n01:38:34 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 13\u001b[0m\n01:38:34 | saving model checkpoint: /tmp/model2.checkpoint\n01:38:49 | time:409s total_exs:19500 total_steps:975 epochs:97.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.59     0 271.8  1020       0          0 75.05  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004332    .1208 5.987 .0003681 4.875e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.3       0          0                  975 391.5 1469 3.761            1\n\n01:38:54 | time:415s total_exs:19900 total_steps:995 epochs:99.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.38     0 267.7  1041       0          0 77.77  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .004085    .1208 6.015 .000347 4.975e-05 120.3 467.8   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  995  388 1509 3.906            1\n\n01:38:54 | running eval: valid\n01:38:54 | eval completed in 0.20s\n01:38:54 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1759       0          0 135.3   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 .6914 4.975e-05    72 811.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    995  228 2571        .9167\n\u001b[0m\n01:38:54 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 14\u001b[0m\n01:38:54 | saving model checkpoint: /tmp/model2.checkpoint\n01:39:09 | time:429s total_exs:20640 total_steps:1032 epochs:103.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.63     0 272.7  1010       0          0 74.06  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003855    .1208 6.014 .0003268 4.995e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   445.4       0          0                 1032 392.9 1455 3.712            1\n\n01:39:14 | time:435s total_exs:21060 total_steps:1053 epochs:105.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.75     0   275  1068       0          0 77.67  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003634    .1208 6.052 .0003085 4.995e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps  ups  weighted_f1  \n   470.1       0          0                 1053  396 1538  3.9            1\n\n01:39:14 | running eval: valid\n01:39:14 | eval completed in 0.19s\n01:39:14 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1768       0          0   136   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 .7007 4.995e-05    72   816       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1053  228 2584        .9167\n\u001b[0m\n01:39:14 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 15\u001b[0m\n01:39:14 | saving model checkpoint: /tmp/model2.checkpoint\n01:39:30 | time:450s total_exs:21840 total_steps:1092 epochs:109.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1    12     0 279.9  1066       0          0 76.15  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00341    .1209 5.979 .0002894 4.995e-05 119.6 455.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1092 399.5 1521 3.816            1\n\n01:39:34 | time:455s total_exs:22200 total_steps:1110 epochs:111.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.81     0 276.2  1018       0          0 73.72  360   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003232    .1209 6.017 .0002743 4.995e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   443.5       0          0                 1110 396.5 1461 3.703            1\n\n01:39:34 | running eval: valid\n01:39:35 | eval completed in 0.20s\n01:39:35 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1737       0          0 133.6   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 .7121 4.995e-05    72 801.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1110  228 2538        .9167\n\u001b[0m\n01:39:35 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 16\u001b[0m\n01:39:35 | saving model checkpoint: /tmp/model2.checkpoint\n01:39:50 | time:471s total_exs:22980 total_steps:1149 epochs:114.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.49     0 269.9  1027       0          0 76.11  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003072    .1209 6.028 .0002603 4.995e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.8       0          0                 1149 390.5 1486 3.814            1\n\n01:39:55 | time:476s total_exs:23340 total_steps:1167 epochs:116.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.7     0   274  1044       0          0 76.19  360   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002905    .1209     6 .0002464 4.995e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   457.2       0          0                 1167  394 1501 3.828            1\n\n01:39:55 | running eval: valid\n01:39:55 | eval completed in 0.19s\n01:39:55 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1816       0          0 139.6   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6 .7266 4.995e-05    72 837.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1167  228 2654        .9167\n\u001b[0m\n01:39:55 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 17\u001b[0m\n01:39:55 | saving model checkpoint: /tmp/model2.checkpoint\n01:40:10 | time:491s total_exs:24100 total_steps:1205 epochs:120.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.1  1023       0          0 74.66  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003507    .1209 6.034 .0002356 4.995e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   450.5       0          0                 1205 394.8 1474 3.741            1\n\n01:40:15 | time:496s total_exs:24500 total_steps:1225 epochs:122.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.81     0 276.2  1030       0          0 74.57  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004526    .1209  6.07 .0002259 4.995e-05 121.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   452.6       0          0                 1225 397.6 1483 3.744            1\n\n01:40:15 | running eval: valid\n01:40:16 | eval completed in 0.19s\n01:40:16 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1782       0          0   137   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 .7272 4.995e-05    72 822.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1225  228 2605        .9167\n\u001b[0m\n01:40:16 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 18\u001b[0m\n01:40:16 | saving model checkpoint: /tmp/model2.checkpoint\n01:40:30 | time:511s total_exs:25280 total_steps:1264 epochs:126.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.69     0 273.8  1043       0          0 76.22  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002676    .1209 6.074 .0002135 4.995e-05 121.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n     463       0          0                 1264 395.3 1506 3.82            1\n\n01:40:36 | time:516s total_exs:25680 total_steps:1284 epochs:128.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.41     0 268.3  1014       0          0 75.59  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002385    .1209  6.04 .0002021 4.995e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.5       0          0                 1284 389.1 1471 3.796            1\n\n01:40:36 | running eval: valid\n01:40:36 | eval completed in 0.20s\n01:40:36 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1747       0          0 134.3   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 .7333 4.995e-05    72 806.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1284  228 2553        .9167\n\u001b[0m\nEpoch 00005: reducing learning rate of group 0 to 2.4975e-05.\n01:40:36 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 19\u001b[0m\n01:40:36 | saving model checkpoint: /tmp/model2.checkpoint\n01:40:51 | time:532s total_exs:26440 total_steps:1322 epochs:132.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.48     0 269.6  1025       0          0 76.01  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002332    .1209 6.005 .0001953 2.498e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.5       0          0                 1322 389.7 1481 3.809            1\n\n01:40:56 | time:537s total_exs:26820 total_steps:1341 epochs:134.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.74     0 274.8  1063       0          0 77.38  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002253    .1209 6.016 .0001908 2.498e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   465.5       0          0                 1341 395.1 1529 3.887            1\n\n01:40:56 | running eval: valid\n01:40:56 | eval completed in 0.21s\n01:40:56 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1664       0          0   128   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 .7382 2.498e-05    72 768.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1341  228 2433        .9167\n\u001b[0m\n01:40:56 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 20\u001b[0m\n01:40:56 | saving model checkpoint: /tmp/model2.checkpoint\n01:41:11 | time:552s total_exs:27580 total_steps:1379 epochs:137.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.76     0 275.1  1040       0          0 75.62  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002198    .1209 6.008 .0001862 2.498e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   454.4       0          0                 1379 395.3 1495 3.79            1\n\n01:41:17 | time:557s total_exs:27980 total_steps:1399 epochs:139.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.46     0 269.1  1011       0          0 75.12  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002153    .1209 6.055 .0001822 2.498e-05 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   454.8       0          0                 1399 390.2 1466 3.772            1\n\n01:41:17 | running eval: valid\n01:41:17 | eval completed in 0.20s\n01:41:17 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1755       0          0   135   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6 .7425 2.498e-05    72 809.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1399  228 2565        .9167\n\u001b[0m\n01:41:17 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 21\u001b[0m\n01:41:17 | saving model checkpoint: /tmp/model2.checkpoint\n01:41:32 | time:572s total_exs:28760 total_steps:1438 epochs:143.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.54     0 270.9  1036       0          0 76.52  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002101    .1209 6.056 .0001778 2.498e-05 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   463.5       0          0                 1438  392 1500 3.835            1\n\n01:41:37 | time:578s total_exs:29180 total_steps:1459 epochs:145.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.91     0 278.2  1093       0          0 78.53  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00204    .1209 5.995 .0001727 2.498e-05 119.9 470.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1459 398.1 1563 3.943            1\n\n01:41:37 | running eval: valid\n01:41:37 | eval completed in 0.19s\n01:41:37 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1777       0          0 136.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 .7468 2.498e-05    72 820.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1459  228 2598        .9167\n\u001b[0m\n01:41:37 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 22\u001b[0m\n01:41:37 | saving model checkpoint: /tmp/model2.checkpoint\n01:41:52 | time:593s total_exs:29940 total_steps:1497 epochs:149.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.89     0 277.9  1039       0          0  74.8  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00199    .1209 5.995 .0001685 2.498e-05 119.9 448.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1497 397.8 1488 3.748            1\n\n01:41:57 | time:598s total_exs:30320 total_steps:1516 epochs:151.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.11     0 282.2  1090       0          0 77.26  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001945    .1209 6.053 .0001647 2.498e-05 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   467.6       0          0                 1516 403.3 1558 3.881            1\n\n01:41:57 | running eval: valid\n01:41:57 | eval completed in 0.20s\n01:41:57 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1733       0          0 133.3   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 .7510 2.498e-05    72   800       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1516  228 2533        .9167\n\u001b[0m\nEpoch 00009: reducing learning rate of group 0 to 1.2488e-05.\n01:41:57 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 23\u001b[0m\n01:41:57 | saving model checkpoint: /tmp/model2.checkpoint\n01:42:12 | time:613s total_exs:31100 total_steps:1555 epochs:155.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.1  1050       0          0 76.64  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001917    .1209 6.079 .0001622 1.249e-05 121.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   465.9       0          0                 1555 395.7 1516 3.841            1\n\n01:42:18 | time:618s total_exs:31520 total_steps:1576 epochs:157.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.68     0 273.6  1015       0          0 74.21  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001887    .1209 6.005 .0001597 1.249e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   445.6       0          0                 1576 393.7 1461 3.726            1\n\n01:42:18 | running eval: valid\n01:42:18 | eval completed in 0.20s\n01:42:18 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1758       0          0 135.2   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 .7531 1.249e-05    72 811.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1576  228 2570        .9167\n\u001b[0m\n01:42:18 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 24\u001b[0m\n01:42:18 | saving model checkpoint: /tmp/model2.checkpoint\n01:42:32 | time:633s total_exs:32300 total_steps:1615 epochs:161.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.78     0 275.6  1055       0          0 76.58  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001859    .1210 5.962 .0001572 1.249e-05 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.5       0          0                 1615 394.9 1512 3.838            1\n\n01:42:38 | time:639s total_exs:32740 total_steps:1637 epochs:163.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.78     0 275.7  1061       0          0 76.96  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001839    .1210 6.018 .0001556 1.249e-05 120.4   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   463.1       0          0                 1637  396 1524 3.863            1\n\n01:42:38 | running eval: valid\n01:42:38 | eval completed in 0.19s\n01:42:38 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1776       0          0 136.6   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 .7555 1.249e-05    72 819.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1637  228 2595        .9167\n\u001b[0m\n01:42:38 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 25\u001b[0m\n01:42:38 | saving model checkpoint: /tmp/model2.checkpoint\n01:42:53 | time:653s total_exs:33480 total_steps:1674 epochs:167.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.51     0 270.3 994.4       0          0 73.58  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001812    .1210 5.978 .0001533 1.249e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   439.9       0          0                 1674 389.9 1434 3.687            1\n\n01:42:58 | time:659s total_exs:33920 total_steps:1696 epochs:169.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.56     0 271.2  1040       0          0  76.7  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001785    .1210 5.964 .000151 1.249e-05 119.3 457.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1696 390.5 1498 3.85            1\n\n01:42:58 | running eval: valid\n01:42:59 | eval completed in 0.19s\n01:42:59 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1792       0          0 137.8   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 .7578 1.249e-05    72 827.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1696  228 2619        .9167\n\u001b[0m\n01:42:59 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 26\u001b[0m\n01:42:59 | saving model checkpoint: /tmp/model2.checkpoint\n01:43:13 | time:674s total_exs:34700 total_steps:1735 epochs:173.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.2  1048       0          0 76.43  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001762    .1210 5.979 .000149 1.249e-05 119.6   457   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1735 393.8 1505 3.83            1\n\n01:43:19 | time:679s total_exs:35140 total_steps:1757 epochs:175.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.63     0 272.6  1029       0          0 75.46  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00174    .1210 6.055 .0001472 1.249e-05 121.1 456.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1757 393.7 1486 3.782            1\n\n01:43:19 | running eval: valid\n01:43:19 | eval completed in 0.26s\n01:43:19 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1341       0          0 103.1   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 .7604 1.249e-05    72 618.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1757  228 1960        .9167\n\u001b[0m\nEpoch 00013: reducing learning rate of group 0 to 6.2438e-06.\n01:43:19 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 27\u001b[0m\n01:43:19 | saving model checkpoint: /tmp/model2.checkpoint\n01:43:34 | time:694s total_exs:35920 total_steps:1796 epochs:179.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.7     0   274  1049       0          0 76.61  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001722    .1210 6.036 .0001457 6.244e-06 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   462.4       0          0                 1796 394.7 1512 3.839            1\n\n01:43:39 | time:700s total_exs:36340 total_steps:1817 epochs:181.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.83     0 276.7  1077       0          0 77.89  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001703    .1210 5.986 .0001441 6.244e-06 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   466.2       0          0                 1817 396.4 1544 3.911            1\n\n01:43:39 | running eval: valid\n01:43:39 | eval completed in 0.20s\n01:43:39 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1751       0          0 134.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08122     6 .7616 6.244e-06    72 808.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1817  228 2560        .9167\n\u001b[0m\n01:43:39 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 28\u001b[0m\n01:43:39 | saving model checkpoint: /tmp/model2.checkpoint\n01:43:54 | time:715s total_exs:37100 total_steps:1855 epochs:185.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.49     0 269.7  1014       0          0 75.21  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001694    .1210 6.016 .0001434 6.244e-06 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   452.5       0          0                 1855 390.1 1467 3.769            1\n\n01:44:00 | time:720s total_exs:37520 total_steps:1876 epochs:187.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.91     0 278.1  1083       0          0 77.85  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001686    .1210 6.029 .0001424 6.244e-06 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   469.3       0          0                 1876 398.7 1552 3.909            1\n\n01:44:00 | running eval: valid\n01:44:00 | eval completed in 0.19s\n01:44:00 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1791       0          0 137.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08124     6 .7629 6.244e-06    72 826.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1876  228 2617        .9167\n\u001b[0m\n01:44:00 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 29\u001b[0m\n01:44:00 | saving model checkpoint: /tmp/model2.checkpoint\n01:44:14 | time:735s total_exs:38300 total_steps:1915 epochs:191.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.67     0 273.5  1047       0          0  76.6  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001666    .1210 5.985 .0001409 6.244e-06 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.4       0          0                 1915 393.2 1506 3.839            1\n\n01:44:20 | time:741s total_exs:38720 total_steps:1936 epochs:193.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.94     0 278.9  1068       0          0 76.61  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001659    .1210 6.048 .0001402 6.244e-06   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.3       0          0                 1936 399.8 1532 3.847            1\n\n01:44:20 | running eval: valid\n01:44:20 | eval completed in 0.20s\n01:44:20 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1759       0          0 135.3   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08125     6 .7644 6.244e-06    72 811.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1936  228 2571        .9167\n\u001b[0m\n01:44:20 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 30\u001b[0m\n01:44:20 | saving model checkpoint: /tmp/model2.checkpoint\n01:44:25 | ran out of patience! stopping training.\n01:44:25 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n01:44:25 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n01:44:25 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run2/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n01:44:25 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n01:44:25 | Using CUDA\n01:44:25 | loading dictionary from /tmp/model2.dict\n01:44:25 | num words = 54944\n01:44:29 | Loading existing model parameters from /tmp/model2\n01:44:38 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:44:39 | creating task(s): fromfile:parlaiformat\n01:44:39 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run2/data_valid.txt\n01:44:39 | running eval: valid\n01:44:39 | eval completed in 0.30s\n01:44:39 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1150       0          0  88.4   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298     6 .3026 1.19e-05    72 530.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    238  228 1681        .9167\n\u001b[0m\n01:44:39 | creating task(s): fromfile:parlaiformat\n01:44:39 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run2/data_test.txt\n01:44:40 | running eval: test\n01:44:44 | eval completed in 4.85s\n01:44:44 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9330 9.33e-10               .7413                 .6038   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9600            .9615              .9952   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9300 12.07 281.4  2917       0          0 207.3 1000 .9330   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298   5.2 .2236 1.19e-05   104  1078       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    238 385.4 3995        .9395\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type2/run2/data_test.txt -m transformer/classifier -mf /tmp/model2 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:44:46.634166Z","iopub.execute_input":"2022-12-04T01:44:46.634581Z","iopub.status.idle":"2022-12-04T01:45:17.470135Z","shell.execute_reply.started":"2022-12-04T01:44:46.634531Z","shell.execute_reply":"2022-12-04T01:45:17.468840Z"},"scrolled":true,"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"01:44:55 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr1type2/run2/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr1type2/run2/data)\u001b[0m\n01:44:55 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n01:44:55 | Using CUDA\n01:44:55 | loading dictionary from /tmp/model2.dict\n01:44:55 | num words = 54944\n01:45:00 | Loading existing model parameters from /tmp/model2\n01:45:06 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:45:07 | Opt:\n01:45:07 |     activation: gelu\n01:45:07 |     adafactor_eps: '[1e-30, 0.001]'\n01:45:07 |     adam_eps: 1e-08\n01:45:07 |     add_p1_after_newln: False\n01:45:07 |     aggregate_micro: False\n01:45:07 |     allow_missing_init_opts: False\n01:45:07 |     area_under_curve_class: None\n01:45:07 |     area_under_curve_digits: -1\n01:45:07 |     attention_dropout: 0.1\n01:45:07 |     batchsize: 40\n01:45:07 |     betas: '[0.9, 0.999]'\n01:45:07 |     bpe_add_prefix_space: None\n01:45:07 |     bpe_debug: False\n01:45:07 |     bpe_dropout: None\n01:45:07 |     bpe_merge: None\n01:45:07 |     bpe_vocab: None\n01:45:07 |     candidates: inline\n01:45:07 |     cap_num_predictions: 100\n01:45:07 |     checkpoint_activations: False\n01:45:07 |     class_weights: None\n01:45:07 |     classes: \"['__notok__', '__ok__']\"\n01:45:07 |     classes_from_file: None\n01:45:07 |     data_parallel: True\n01:45:07 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n01:45:07 |     datatype: train\n01:45:07 |     delimiter: '\\n'\n01:45:07 |     dict_class: parlai.core.dict:DictionaryAgent\n01:45:07 |     dict_endtoken: __start__\n01:45:07 |     dict_file: /tmp/model2.dict\n01:45:07 |     dict_include_test: False\n01:45:07 |     dict_include_valid: False\n01:45:07 |     dict_initpath: None\n01:45:07 |     dict_language: english\n01:45:07 |     dict_loaded: True\n01:45:07 |     dict_lower: True\n01:45:07 |     dict_max_ngram_size: -1\n01:45:07 |     dict_maxexs: -1\n01:45:07 |     dict_maxtokens: -1\n01:45:07 |     dict_minfreq: 0\n01:45:07 |     dict_nulltoken: __null__\n01:45:07 |     dict_starttoken: __start__\n01:45:07 |     dict_textfields: text,labels\n01:45:07 |     dict_tokenizer: bpe\n01:45:07 |     dict_unktoken: __unk__\n01:45:07 |     display_examples: False\n01:45:07 |     download_path: None\n01:45:07 |     dropout: 0.1\n01:45:07 |     dynamic_batching: None\n01:45:07 |     embedding_projection: random\n01:45:07 |     embedding_size: 768\n01:45:07 |     embedding_type: random\n01:45:07 |     embeddings_scale: False\n01:45:07 |     encode_candidate_vecs: True\n01:45:07 |     encode_candidate_vecs_batchsize: 256\n01:45:07 |     eval_batchsize: None\n01:45:07 |     eval_candidates: inline\n01:45:07 |     eval_dynamic_batching: None\n01:45:07 |     evaltask: None\n01:45:07 |     ffn_size: 3072\n01:45:07 |     final_extra_opt: \n01:45:07 |     fixed_candidate_vecs: reuse\n01:45:07 |     fixed_candidates_path: None\n01:45:07 |     force_fp16_tokens: True\n01:45:07 |     fp16: True\n01:45:07 |     fp16_impl: safe\n01:45:07 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run2/data_test.txt\n01:45:07 |     fromfile_datatype_extension: True\n01:45:07 |     gpu: -1\n01:45:07 |     gradient_clip: 0.1\n01:45:07 |     hide_labels: False\n01:45:07 |     history_add_global_end_token: None\n01:45:07 |     history_reversed: False\n01:45:07 |     history_size: 20\n01:45:07 |     ignore_bad_candidates: False\n01:45:07 |     ignore_labels: None\n01:45:07 |     image_cropsize: 224\n01:45:07 |     image_mode: raw\n01:45:07 |     image_size: 256\n01:45:07 |     inference: max\n01:45:07 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:45:07 |     init_opt: None\n01:45:07 |     interactive_candidates: fixed\n01:45:07 |     interactive_mode: False\n01:45:07 |     invsqrt_lr_decay_gamma: -1\n01:45:07 |     is_debug: False\n01:45:07 |     label_truncate: 72\n01:45:07 |     learn_embeddings: True\n01:45:07 |     learn_positional_embeddings: True\n01:45:07 |     learningrate: 5e-05\n01:45:07 |     load_from_pretrained_ranker: True\n01:45:07 |     log_every_n_secs: 10.0\n01:45:07 |     log_every_n_steps: 50\n01:45:07 |     log_keep_fields: all\n01:45:07 |     loglevel: info\n01:45:07 |     lr_scheduler: reduceonplateau\n01:45:07 |     lr_scheduler_decay: 0.5\n01:45:07 |     lr_scheduler_patience: 3\n01:45:07 |     max_train_steps: -1\n01:45:07 |     max_train_time: 7200.0\n01:45:07 |     memory_attention: sqrt\n01:45:07 |     metrics: default\n01:45:07 |     model: transformer/classifier\n01:45:07 |     model_file: /tmp/model2\n01:45:07 |     model_parallel: False\n01:45:07 |     momentum: 0\n01:45:07 |     multitask_weights: [1]\n01:45:07 |     mutators: None\n01:45:07 |     n_decoder_layers: -1\n01:45:07 |     n_encoder_layers: -1\n01:45:07 |     n_heads: 12\n01:45:07 |     n_layers: 12\n01:45:07 |     n_positions: 1024\n01:45:07 |     n_segments: 2\n01:45:07 |     nesterov: True\n01:45:07 |     no_cuda: False\n01:45:07 |     normalize_sent_emb: False\n01:45:07 |     num_epochs: -1\n01:45:07 |     num_examples: -1\n01:45:07 |     num_workers: 0\n01:45:07 |     nus: [0.7]\n01:45:07 |     optimizer: adamax\n01:45:07 |     output_scaling: 0.06\n01:45:07 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type2/run2/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model2', 'batchsize': 40}\"\n01:45:07 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n01:45:07 |     person_tokens: False\n01:45:07 |     print_scores: False\n01:45:07 |     rank_candidates: False\n01:45:07 |     rank_top_k: -1\n01:45:07 |     reduction_type: mean\n01:45:07 |     ref_class: None\n01:45:07 |     relu_dropout: 0.0\n01:45:07 |     repeat_blocking_heuristic: True\n01:45:07 |     report_filename: \n01:45:07 |     return_cand_scores: False\n01:45:07 |     save_after_valid: True\n01:45:07 |     save_every_n_secs: -1\n01:45:07 |     save_format: conversations\n01:45:07 |     share_encoders: False\n01:45:07 |     share_word_embeddings: False\n01:45:07 |     short_final_eval: False\n01:45:07 |     special_tok_lst: None\n01:45:07 |     split_lines: False\n01:45:07 |     starttime: Dec04_01-31\n01:45:07 |     task: fromfile:parlaiformat\n01:45:07 |     tensorboard_log: False\n01:45:07 |     tensorboard_logdir: None\n01:45:07 |     text_truncate: 360\n01:45:07 |     threshold: 0.5\n01:45:07 |     topk: 5\n01:45:07 |     train_predict: False\n01:45:07 |     truncate: 1024\n01:45:07 |     update_classifier_head_only: False\n01:45:07 |     update_freq: 1\n01:45:07 |     use_memories: False\n01:45:07 |     use_reply: none\n01:45:07 |     validation_cutoff: 1.0\n01:45:07 |     validation_every_n_epochs: -1\n01:45:07 |     validation_every_n_secs: 20.0\n01:45:07 |     validation_every_n_steps: -1\n01:45:07 |     validation_max_exs: -1\n01:45:07 |     validation_metric: accuracy\n01:45:07 |     validation_metric_mode: max\n01:45:07 |     validation_patience: 30\n01:45:07 |     validation_share_agent: False\n01:45:07 |     variant: xlm\n01:45:07 |     verbose: False\n01:45:07 |     wandb_entity: None\n01:45:07 |     wandb_log: False\n01:45:07 |     wandb_name: None\n01:45:07 |     wandb_project: None\n01:45:07 |     warmup_rate: 0.0001\n01:45:07 |     warmup_updates: 1000\n01:45:07 |     weight_decay: None\n01:45:07 |     world_logs: \n01:45:07 |     wrap_memory_encoder: False\n01:45:07 | Evaluating task fromfile:parlaiformat using datatype valid.\n01:45:07 | creating task(s): fromfile:parlaiformat\n01:45:07 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n01:45:07 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run2/data_test.txt\n01:45:15 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9330 9.33e-10               .7413                 .6038   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9600            .9615              .9952   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9300 12.07 562.9  1829       0          0   130 1000 .9330   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2236 1.19e-05   208 675.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    238 770.9 2505        .9395\u001b[0m\n01:45:15 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9330 9.33e-10               .7413                 .6038   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9600            .9615              .9952   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9300 12.07 562.9  1829       0          0   130 1000 .9330   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2236 1.19e-05   208 675.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    238 770.9 2505        .9395\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model2*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:45:17.472776Z","iopub.execute_input":"2022-12-04T01:45:17.473200Z","iopub.status.idle":"2022-12-04T01:45:18.713132Z","shell.execute_reply.started":"2022-12-04T01:45:17.473155Z","shell.execute_reply":"2022-12-04T01:45:18.711811Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":"run 3","metadata":{}},{"cell_type":"code","source":"# run 3 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type2/run3/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model3","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:45:18.715289Z","iopub.execute_input":"2022-12-04T01:45:18.715740Z","iopub.status.idle":"2022-12-04T01:47:47.884702Z","shell.execute_reply.started":"2022-12-04T01:45:18.715697Z","shell.execute_reply":"2022-12-04T01:47:47.883465Z"},"scrolled":true,"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"01:45:26 | building dictionary first...\n01:45:26 | No model with opt yet at: /tmp/model3(.opt)\n01:45:26 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run3/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n01:45:26 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n01:45:26 | Using CUDA\n01:45:26 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n01:45:26 | num words = 54944\n01:45:30 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:45:41 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:45:41 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n01:45:41 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n01:45:41 | Opt:\n01:45:41 |     activation: gelu\n01:45:41 |     adafactor_eps: '(1e-30, 0.001)'\n01:45:41 |     adam_eps: 1e-08\n01:45:41 |     add_p1_after_newln: False\n01:45:41 |     aggregate_micro: False\n01:45:41 |     allow_missing_init_opts: False\n01:45:41 |     attention_dropout: 0.1\n01:45:41 |     batchsize: 20\n01:45:41 |     betas: '(0.9, 0.999)'\n01:45:41 |     bpe_add_prefix_space: None\n01:45:41 |     bpe_debug: False\n01:45:41 |     bpe_dropout: None\n01:45:41 |     bpe_merge: None\n01:45:41 |     bpe_vocab: None\n01:45:41 |     candidates: inline\n01:45:41 |     cap_num_predictions: 100\n01:45:41 |     checkpoint_activations: False\n01:45:41 |     class_weights: None\n01:45:41 |     classes: \"['__notok__', '__ok__']\"\n01:45:41 |     classes_from_file: None\n01:45:41 |     data_parallel: True\n01:45:41 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n01:45:41 |     datatype: train\n01:45:41 |     delimiter: '\\n'\n01:45:41 |     dict_class: parlai.core.dict:DictionaryAgent\n01:45:41 |     dict_endtoken: __start__\n01:45:41 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n01:45:41 |     dict_include_test: False\n01:45:41 |     dict_include_valid: False\n01:45:41 |     dict_initpath: None\n01:45:41 |     dict_language: english\n01:45:41 |     dict_loaded: True\n01:45:41 |     dict_lower: True\n01:45:41 |     dict_max_ngram_size: -1\n01:45:41 |     dict_maxexs: -1\n01:45:41 |     dict_maxtokens: -1\n01:45:41 |     dict_minfreq: 0\n01:45:41 |     dict_nulltoken: __null__\n01:45:41 |     dict_starttoken: __start__\n01:45:41 |     dict_textfields: text,labels\n01:45:41 |     dict_tokenizer: bpe\n01:45:41 |     dict_unktoken: __unk__\n01:45:41 |     display_examples: False\n01:45:41 |     download_path: None\n01:45:41 |     dropout: 0.1\n01:45:41 |     dynamic_batching: None\n01:45:41 |     embedding_projection: random\n01:45:41 |     embedding_size: 768\n01:45:41 |     embedding_type: random\n01:45:41 |     embeddings_scale: False\n01:45:41 |     encode_candidate_vecs: True\n01:45:41 |     encode_candidate_vecs_batchsize: 256\n01:45:41 |     eval_batchsize: None\n01:45:41 |     eval_candidates: inline\n01:45:41 |     eval_dynamic_batching: None\n01:45:41 |     evaltask: None\n01:45:41 |     ffn_size: 3072\n01:45:41 |     final_extra_opt: \n01:45:41 |     fixed_candidate_vecs: reuse\n01:45:41 |     fixed_candidates_path: None\n01:45:41 |     force_fp16_tokens: False\n01:45:41 |     fp16: True\n01:45:41 |     fp16_impl: safe\n01:45:41 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run3/data\n01:45:41 |     fromfile_datatype_extension: True\n01:45:41 |     gpu: -1\n01:45:41 |     gradient_clip: 0.1\n01:45:41 |     hide_labels: False\n01:45:41 |     history_add_global_end_token: None\n01:45:41 |     history_reversed: False\n01:45:41 |     history_size: 20\n01:45:41 |     ignore_bad_candidates: False\n01:45:41 |     ignore_labels: None\n01:45:41 |     image_cropsize: 224\n01:45:41 |     image_mode: raw\n01:45:41 |     image_size: 256\n01:45:41 |     inference: max\n01:45:41 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:45:41 |     init_opt: None\n01:45:41 |     interactive_candidates: fixed\n01:45:41 |     interactive_mode: False\n01:45:41 |     invsqrt_lr_decay_gamma: -1\n01:45:41 |     is_debug: False\n01:45:41 |     label_truncate: 72\n01:45:41 |     learn_embeddings: True\n01:45:41 |     learn_positional_embeddings: True\n01:45:41 |     learningrate: 5e-05\n01:45:41 |     load_from_checkpoint: False\n01:45:41 |     load_from_pretrained_ranker: True\n01:45:41 |     log_every_n_secs: 10.0\n01:45:41 |     log_every_n_steps: 50\n01:45:41 |     log_keep_fields: all\n01:45:41 |     loglevel: info\n01:45:41 |     lr_scheduler: reduceonplateau\n01:45:41 |     lr_scheduler_decay: 0.5\n01:45:41 |     lr_scheduler_patience: 3\n01:45:41 |     max_train_steps: -1\n01:45:41 |     max_train_time: 7200.0\n01:45:41 |     memory_attention: sqrt\n01:45:41 |     metrics: default\n01:45:41 |     model: transformer/classifier\n01:45:41 |     model_file: /tmp/model3\n01:45:41 |     model_parallel: False\n01:45:41 |     momentum: 0\n01:45:41 |     multitask_weights: [1]\n01:45:41 |     mutators: None\n01:45:41 |     n_decoder_layers: -1\n01:45:41 |     n_encoder_layers: -1\n01:45:41 |     n_heads: 12\n01:45:41 |     n_layers: 12\n01:45:41 |     n_positions: 1024\n01:45:41 |     n_segments: 2\n01:45:41 |     nesterov: True\n01:45:41 |     no_cuda: False\n01:45:41 |     normalize_sent_emb: False\n01:45:41 |     num_epochs: -1\n01:45:41 |     num_workers: 0\n01:45:41 |     nus: (0.7,)\n01:45:41 |     optimizer: adamax\n01:45:41 |     output_scaling: 0.06\n01:45:41 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type2/run3/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model3'}\"\n01:45:41 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n01:45:41 |     person_tokens: False\n01:45:41 |     print_scores: False\n01:45:41 |     rank_candidates: False\n01:45:41 |     rank_top_k: -1\n01:45:41 |     reduction_type: mean\n01:45:41 |     ref_class: None\n01:45:41 |     relu_dropout: 0.0\n01:45:41 |     repeat_blocking_heuristic: True\n01:45:41 |     return_cand_scores: False\n01:45:41 |     save_after_valid: True\n01:45:41 |     save_every_n_secs: -1\n01:45:41 |     save_format: conversations\n01:45:41 |     share_encoders: False\n01:45:41 |     share_word_embeddings: False\n01:45:41 |     short_final_eval: False\n01:45:41 |     special_tok_lst: None\n01:45:41 |     split_lines: False\n01:45:41 |     starttime: Dec04_01-45\n01:45:41 |     task: fromfile:parlaiformat\n01:45:41 |     tensorboard_log: False\n01:45:41 |     tensorboard_logdir: None\n01:45:41 |     text_truncate: 360\n01:45:41 |     threshold: 0.5\n01:45:41 |     topk: 5\n01:45:41 |     train_predict: False\n01:45:41 |     truncate: 1024\n01:45:41 |     update_classifier_head_only: False\n01:45:41 |     update_freq: 1\n01:45:41 |     use_memories: False\n01:45:41 |     use_reply: none\n01:45:41 |     validation_cutoff: 1.0\n01:45:41 |     validation_every_n_epochs: -1\n01:45:41 |     validation_every_n_secs: 20.0\n01:45:41 |     validation_every_n_steps: -1\n01:45:41 |     validation_max_exs: -1\n01:45:41 |     validation_metric: accuracy\n01:45:41 |     validation_metric_mode: max\n01:45:41 |     validation_patience: 30\n01:45:41 |     validation_share_agent: False\n01:45:41 |     variant: xlm\n01:45:41 |     verbose: False\n01:45:41 |     wandb_entity: None\n01:45:41 |     wandb_log: False\n01:45:41 |     wandb_name: None\n01:45:41 |     wandb_project: None\n01:45:41 |     warmup_rate: 0.0001\n01:45:41 |     warmup_updates: 1000\n01:45:41 |     weight_decay: None\n01:45:41 |     world_logs: \n01:45:41 |     wrap_memory_encoder: False\n01:45:41 | creating task(s): fromfile:parlaiformat\n01:45:41 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run3/data_train.txt\n01:45:41 | training...\n01:45:51 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .3900 3.9e-10               .4404                 .4192   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .4638            .3297              .3509   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .3109 11.29     1 265.9 527.4       0          0 39.67  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .3900             32768  2.408    .1206 6.035 .7139 1.005e-06 120.7 239.4   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 386.6 766.7 1.988        .3870\n\n01:46:01 | time:20s total_exs:1140 total_steps:57 epochs:5.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .4946 4.946e-10               .4820                 .4728   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .4915            .5066              .5161   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .4974 11.24     1 264.7  1006       0          0 75.99  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .4946             32768   2.36    .1206 5.957 .6919 2.855e-06 119.1 452.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   57 383.9 1459 3.809        .4948\n\n01:46:01 | creating task(s): fromfile:parlaiformat\n01:46:01 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run3/data_valid.txt\n01:46:01 | running eval: valid\n01:46:01 | eval completed in 0.19s\n01:46:01 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5833 5.833e-10               .5455                 .6000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5000            .6154              .5714   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .6667 11.71 164.5  1865       0          0   136   24 .5833   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6793 2.855e-06    72 816.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     57 236.5 2682        .5804\n\u001b[0m\n01:46:01 | \u001b[1;32mnew best accuracy: 0.5833\u001b[0m\n01:46:01 | saving best valid model: /tmp/model3\n01:46:01 | Saving dictionary to /tmp/model3.dict\n01:46:05 | saving model checkpoint: /tmp/model3.checkpoint\n01:46:05 | Saving dictionary to /tmp/model3.checkpoint.dict\n01:46:22 | time:41s total_exs:1840 total_steps:92 epochs:9.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8043 8.043e-10               .8073                 .8107   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8039            .8012              .7977   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8047 11.34     1 266.7   932       0          0 69.89  700   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8043             32768  2.469    .1207  6.02 .6376 4.605e-06 120.4 420.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   92 387.1 1353 3.502        .8043\n\n01:46:26 | time:45s total_exs:2080 total_steps:104 epochs:10.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9083 9.083e-10               .9147                 .8429   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9009                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8197  11.5     1 270.1  1040       0          0 76.99  240   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9083             32768  2.851    .1207 5.983 .5849 5.204e-06 119.7 460.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  104 389.8 1500 3.878        .9077\n\n01:46:26 | running eval: valid\n01:46:26 | eval completed in 0.19s\n01:46:26 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8889                 .8000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .8571                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.71 164.5  1891       0          0 137.9   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5736 5.204e-06    72 827.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    104 236.5 2719        .8730\n\u001b[0m\n01:46:26 | \u001b[1;32mnew best accuracy: 0.875 (previous best was 0.5833)\u001b[0m\n01:46:26 | saving best valid model: /tmp/model3\n01:46:36 | saving model checkpoint: /tmp/model3.checkpoint\n01:46:56 | time:75s total_exs:2860 total_steps:143 epochs:14.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9628 9.628e-10               .9642                 .9466   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9824            .9614              .9810   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9426 11.23     1 264.6  1028       0          0 77.69  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9628             32768  3.761    .1207 6.018 .4576 7.154e-06 120.4 467.5   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  143  385 1495 3.893        .9628\n\n01:46:56 | time:75s total_exs:2900 total_steps:145 epochs:14.50\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8780                 .8182   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9474            .8718              .9444   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8095 11.53     1 270.5  1086       0          0 80.26   40   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8750             32768   5.21    .1207  5.95 .3892 7.254e-06   119 477.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  145 389.5 1563 4.201        .8748\n\n01:46:56 | running eval: valid\n01:46:57 | eval completed in 0.19s\n01:46:57 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.71 164.5  1879       0          0   137   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .3441 7.254e-06    72 822.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    145 236.5 2701        .9583\n\u001b[0m\n01:46:57 | \u001b[1;32mnew best accuracy: 0.9583 (previous best was 0.875)\u001b[0m\n01:46:57 | saving best valid model: /tmp/model3\n01:47:07 | saving model checkpoint: /tmp/model3.checkpoint\n01:47:22 | time:101s total_exs:3680 total_steps:184 epochs:18.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9641 9.641e-10               .9646                 .9455   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9845            .9635              .9840   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9439 11.52     1 270.3  1039       0          0 76.89  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9641             32768  4.973    .1207 5.995 .2148 9.204e-06 119.9 460.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  184 390.2 1500 3.853        .9641\n\n01:47:27 | time:106s total_exs:4060 total_steps:203 epochs:20.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9921 9.921e-10               .9917                 .9836   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9924                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9850 11.91     1 278.2  1088       0          0  78.2  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9921             32768  4.266    .1207 5.947 .07789 1.015e-05 118.9 465.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  203 397.1 1553 3.928        .9921\n\n01:47:27 | running eval: valid\n01:47:27 | eval completed in 0.19s\n01:47:27 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 11.71 164.5  1907       0          0 139.1   24   1   \n    gpu_mem  llen   loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .03929 1.015e-05    72 834.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    203 236.5 2741            1\n\u001b[0m\n01:47:27 | \u001b[1;32mnew best accuracy: 1 (previous best was 0.9583)\u001b[0m\n01:47:27 | saving best valid model: /tmp/model3\n01:47:32 | task solved! stopping.\n01:47:32 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n01:47:32 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n01:47:32 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run3/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n01:47:32 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n01:47:32 | Using CUDA\n01:47:32 | loading dictionary from /tmp/model3.dict\n01:47:32 | num words = 54944\n01:47:38 | Loading existing model parameters from /tmp/model3\n01:47:39 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:47:40 | creating task(s): fromfile:parlaiformat\n01:47:40 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run3/data_valid.txt\n01:47:40 | running eval: valid\n01:47:41 | eval completed in 0.20s\n01:47:41 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 11.71 164.5  1802       0          0 131.4   24   1   \n    gpu_mem  llen   loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294     6 .03929 1.015e-05    72 788.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    203 236.5 2590            1\n\u001b[0m\n01:47:41 | creating task(s): fromfile:parlaiformat\n01:47:41 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run3/data_test.txt\n01:47:41 | running eval: test\n01:47:46 | eval completed in 4.94s\n01:47:46 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9310 9.31e-10               .7336                 .5975   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9604              .9941   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9289 12.07 281.4  2865       0          0 203.6 1000 .9310   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294   5.2 .2022 1.015e-05   104  1059       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    203 385.4 3923        .9377\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type2/run3/data_test.txt -m transformer/classifier -mf /tmp/model3 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:47:47.888480Z","iopub.execute_input":"2022-12-04T01:47:47.888869Z","iopub.status.idle":"2022-12-04T01:48:18.387716Z","shell.execute_reply.started":"2022-12-04T01:47:47.888826Z","shell.execute_reply":"2022-12-04T01:48:18.385959Z"},"scrolled":true,"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"01:47:56 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr1type2/run3/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr1type2/run3/data)\u001b[0m\n01:47:56 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n01:47:56 | Using CUDA\n01:47:56 | loading dictionary from /tmp/model3.dict\n01:47:56 | num words = 54944\n01:48:00 | Loading existing model parameters from /tmp/model3\n01:48:07 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:48:08 | Opt:\n01:48:08 |     activation: gelu\n01:48:08 |     adafactor_eps: '[1e-30, 0.001]'\n01:48:08 |     adam_eps: 1e-08\n01:48:08 |     add_p1_after_newln: False\n01:48:08 |     aggregate_micro: False\n01:48:08 |     allow_missing_init_opts: False\n01:48:08 |     area_under_curve_class: None\n01:48:08 |     area_under_curve_digits: -1\n01:48:08 |     attention_dropout: 0.1\n01:48:08 |     batchsize: 40\n01:48:08 |     betas: '[0.9, 0.999]'\n01:48:08 |     bpe_add_prefix_space: None\n01:48:08 |     bpe_debug: False\n01:48:08 |     bpe_dropout: None\n01:48:08 |     bpe_merge: None\n01:48:08 |     bpe_vocab: None\n01:48:08 |     candidates: inline\n01:48:08 |     cap_num_predictions: 100\n01:48:08 |     checkpoint_activations: False\n01:48:08 |     class_weights: None\n01:48:08 |     classes: \"['__notok__', '__ok__']\"\n01:48:08 |     classes_from_file: None\n01:48:08 |     data_parallel: True\n01:48:08 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n01:48:08 |     datatype: train\n01:48:08 |     delimiter: '\\n'\n01:48:08 |     dict_class: parlai.core.dict:DictionaryAgent\n01:48:08 |     dict_endtoken: __start__\n01:48:08 |     dict_file: /tmp/model3.dict\n01:48:08 |     dict_include_test: False\n01:48:08 |     dict_include_valid: False\n01:48:08 |     dict_initpath: None\n01:48:08 |     dict_language: english\n01:48:08 |     dict_loaded: True\n01:48:08 |     dict_lower: True\n01:48:08 |     dict_max_ngram_size: -1\n01:48:08 |     dict_maxexs: -1\n01:48:08 |     dict_maxtokens: -1\n01:48:08 |     dict_minfreq: 0\n01:48:08 |     dict_nulltoken: __null__\n01:48:08 |     dict_starttoken: __start__\n01:48:08 |     dict_textfields: text,labels\n01:48:08 |     dict_tokenizer: bpe\n01:48:08 |     dict_unktoken: __unk__\n01:48:08 |     display_examples: False\n01:48:08 |     download_path: None\n01:48:08 |     dropout: 0.1\n01:48:08 |     dynamic_batching: None\n01:48:08 |     embedding_projection: random\n01:48:08 |     embedding_size: 768\n01:48:08 |     embedding_type: random\n01:48:08 |     embeddings_scale: False\n01:48:08 |     encode_candidate_vecs: True\n01:48:08 |     encode_candidate_vecs_batchsize: 256\n01:48:08 |     eval_batchsize: None\n01:48:08 |     eval_candidates: inline\n01:48:08 |     eval_dynamic_batching: None\n01:48:08 |     evaltask: None\n01:48:08 |     ffn_size: 3072\n01:48:08 |     final_extra_opt: \n01:48:08 |     fixed_candidate_vecs: reuse\n01:48:08 |     fixed_candidates_path: None\n01:48:08 |     force_fp16_tokens: True\n01:48:08 |     fp16: True\n01:48:08 |     fp16_impl: safe\n01:48:08 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run3/data_test.txt\n01:48:08 |     fromfile_datatype_extension: True\n01:48:08 |     gpu: -1\n01:48:08 |     gradient_clip: 0.1\n01:48:08 |     hide_labels: False\n01:48:08 |     history_add_global_end_token: None\n01:48:08 |     history_reversed: False\n01:48:08 |     history_size: 20\n01:48:08 |     ignore_bad_candidates: False\n01:48:08 |     ignore_labels: None\n01:48:08 |     image_cropsize: 224\n01:48:08 |     image_mode: raw\n01:48:08 |     image_size: 256\n01:48:08 |     inference: max\n01:48:08 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:48:08 |     init_opt: None\n01:48:08 |     interactive_candidates: fixed\n01:48:08 |     interactive_mode: False\n01:48:08 |     invsqrt_lr_decay_gamma: -1\n01:48:08 |     is_debug: False\n01:48:08 |     label_truncate: 72\n01:48:08 |     learn_embeddings: True\n01:48:08 |     learn_positional_embeddings: True\n01:48:08 |     learningrate: 5e-05\n01:48:08 |     load_from_pretrained_ranker: True\n01:48:08 |     log_every_n_secs: 10.0\n01:48:08 |     log_every_n_steps: 50\n01:48:08 |     log_keep_fields: all\n01:48:08 |     loglevel: info\n01:48:08 |     lr_scheduler: reduceonplateau\n01:48:08 |     lr_scheduler_decay: 0.5\n01:48:08 |     lr_scheduler_patience: 3\n01:48:08 |     max_train_steps: -1\n01:48:08 |     max_train_time: 7200.0\n01:48:08 |     memory_attention: sqrt\n01:48:08 |     metrics: default\n01:48:08 |     model: transformer/classifier\n01:48:08 |     model_file: /tmp/model3\n01:48:08 |     model_parallel: False\n01:48:08 |     momentum: 0\n01:48:08 |     multitask_weights: [1]\n01:48:08 |     mutators: None\n01:48:08 |     n_decoder_layers: -1\n01:48:08 |     n_encoder_layers: -1\n01:48:08 |     n_heads: 12\n01:48:08 |     n_layers: 12\n01:48:08 |     n_positions: 1024\n01:48:08 |     n_segments: 2\n01:48:08 |     nesterov: True\n01:48:08 |     no_cuda: False\n01:48:08 |     normalize_sent_emb: False\n01:48:08 |     num_epochs: -1\n01:48:08 |     num_examples: -1\n01:48:08 |     num_workers: 0\n01:48:08 |     nus: [0.7]\n01:48:08 |     optimizer: adamax\n01:48:08 |     output_scaling: 0.06\n01:48:08 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type2/run3/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model3', 'batchsize': 40}\"\n01:48:08 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n01:48:08 |     person_tokens: False\n01:48:08 |     print_scores: False\n01:48:08 |     rank_candidates: False\n01:48:08 |     rank_top_k: -1\n01:48:08 |     reduction_type: mean\n01:48:08 |     ref_class: None\n01:48:08 |     relu_dropout: 0.0\n01:48:08 |     repeat_blocking_heuristic: True\n01:48:08 |     report_filename: \n01:48:08 |     return_cand_scores: False\n01:48:08 |     save_after_valid: True\n01:48:08 |     save_every_n_secs: -1\n01:48:08 |     save_format: conversations\n01:48:08 |     share_encoders: False\n01:48:08 |     share_word_embeddings: False\n01:48:08 |     short_final_eval: False\n01:48:08 |     special_tok_lst: None\n01:48:08 |     split_lines: False\n01:48:08 |     starttime: Dec04_01-45\n01:48:08 |     task: fromfile:parlaiformat\n01:48:08 |     tensorboard_log: False\n01:48:08 |     tensorboard_logdir: None\n01:48:08 |     text_truncate: 360\n01:48:08 |     threshold: 0.5\n01:48:08 |     topk: 5\n01:48:08 |     train_predict: False\n01:48:08 |     truncate: 1024\n01:48:08 |     update_classifier_head_only: False\n01:48:08 |     update_freq: 1\n01:48:08 |     use_memories: False\n01:48:08 |     use_reply: none\n01:48:08 |     validation_cutoff: 1.0\n01:48:08 |     validation_every_n_epochs: -1\n01:48:08 |     validation_every_n_secs: 20.0\n01:48:08 |     validation_every_n_steps: -1\n01:48:08 |     validation_max_exs: -1\n01:48:08 |     validation_metric: accuracy\n01:48:08 |     validation_metric_mode: max\n01:48:08 |     validation_patience: 30\n01:48:08 |     validation_share_agent: False\n01:48:08 |     variant: xlm\n01:48:08 |     verbose: False\n01:48:08 |     wandb_entity: None\n01:48:08 |     wandb_log: False\n01:48:08 |     wandb_name: None\n01:48:08 |     wandb_project: None\n01:48:08 |     warmup_rate: 0.0001\n01:48:08 |     warmup_updates: 1000\n01:48:08 |     weight_decay: None\n01:48:08 |     world_logs: \n01:48:08 |     wrap_memory_encoder: False\n01:48:08 | Evaluating task fromfile:parlaiformat using datatype valid.\n01:48:08 | creating task(s): fromfile:parlaiformat\n01:48:08 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n01:48:08 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run3/data_test.txt\n01:48:16 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9310 9.31e-10               .7336                 .5975   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9604              .9941   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9289 12.07 562.9  1882       0          0 133.7 1000 .9310   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2022 1.015e-05   208 695.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    203 770.9 2578        .9377\u001b[0m\n01:48:16 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9310 9.31e-10               .7336                 .5975   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9604              .9941   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9289 12.07 562.9  1882       0          0 133.7 1000 .9310   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2022 1.015e-05   208 695.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    203 770.9 2578        .9377\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model3*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:48:18.395801Z","iopub.execute_input":"2022-12-04T01:48:18.396864Z","iopub.status.idle":"2022-12-04T01:48:19.791679Z","shell.execute_reply.started":"2022-12-04T01:48:18.396798Z","shell.execute_reply":"2022-12-04T01:48:19.790279Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":"run 4","metadata":{}},{"cell_type":"code","source":"# run 4 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type2/run4/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model4","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:48:19.794009Z","iopub.execute_input":"2022-12-04T01:48:19.794409Z","iopub.status.idle":"2022-12-04T01:50:31.090075Z","shell.execute_reply.started":"2022-12-04T01:48:19.794366Z","shell.execute_reply":"2022-12-04T01:50:31.088819Z"},"scrolled":true,"trusted":true},"execution_count":90,"outputs":[{"name":"stdout","text":"01:48:26 | building dictionary first...\n01:48:26 | No model with opt yet at: /tmp/model4(.opt)\n01:48:26 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run4/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n01:48:26 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n01:48:26 | Using CUDA\n01:48:26 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n01:48:26 | num words = 54944\n01:48:31 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:48:41 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:48:41 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n01:48:41 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n01:48:41 | Opt:\n01:48:41 |     activation: gelu\n01:48:41 |     adafactor_eps: '(1e-30, 0.001)'\n01:48:41 |     adam_eps: 1e-08\n01:48:41 |     add_p1_after_newln: False\n01:48:41 |     aggregate_micro: False\n01:48:41 |     allow_missing_init_opts: False\n01:48:41 |     attention_dropout: 0.1\n01:48:41 |     batchsize: 20\n01:48:41 |     betas: '(0.9, 0.999)'\n01:48:41 |     bpe_add_prefix_space: None\n01:48:41 |     bpe_debug: False\n01:48:41 |     bpe_dropout: None\n01:48:41 |     bpe_merge: None\n01:48:41 |     bpe_vocab: None\n01:48:41 |     candidates: inline\n01:48:41 |     cap_num_predictions: 100\n01:48:41 |     checkpoint_activations: False\n01:48:41 |     class_weights: None\n01:48:41 |     classes: \"['__notok__', '__ok__']\"\n01:48:41 |     classes_from_file: None\n01:48:41 |     data_parallel: True\n01:48:41 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n01:48:41 |     datatype: train\n01:48:41 |     delimiter: '\\n'\n01:48:41 |     dict_class: parlai.core.dict:DictionaryAgent\n01:48:41 |     dict_endtoken: __start__\n01:48:41 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n01:48:41 |     dict_include_test: False\n01:48:41 |     dict_include_valid: False\n01:48:41 |     dict_initpath: None\n01:48:41 |     dict_language: english\n01:48:41 |     dict_loaded: True\n01:48:41 |     dict_lower: True\n01:48:41 |     dict_max_ngram_size: -1\n01:48:41 |     dict_maxexs: -1\n01:48:41 |     dict_maxtokens: -1\n01:48:41 |     dict_minfreq: 0\n01:48:41 |     dict_nulltoken: __null__\n01:48:41 |     dict_starttoken: __start__\n01:48:41 |     dict_textfields: text,labels\n01:48:41 |     dict_tokenizer: bpe\n01:48:41 |     dict_unktoken: __unk__\n01:48:41 |     display_examples: False\n01:48:41 |     download_path: None\n01:48:41 |     dropout: 0.1\n01:48:41 |     dynamic_batching: None\n01:48:41 |     embedding_projection: random\n01:48:41 |     embedding_size: 768\n01:48:41 |     embedding_type: random\n01:48:41 |     embeddings_scale: False\n01:48:41 |     encode_candidate_vecs: True\n01:48:41 |     encode_candidate_vecs_batchsize: 256\n01:48:41 |     eval_batchsize: None\n01:48:41 |     eval_candidates: inline\n01:48:41 |     eval_dynamic_batching: None\n01:48:41 |     evaltask: None\n01:48:41 |     ffn_size: 3072\n01:48:41 |     final_extra_opt: \n01:48:41 |     fixed_candidate_vecs: reuse\n01:48:41 |     fixed_candidates_path: None\n01:48:41 |     force_fp16_tokens: False\n01:48:41 |     fp16: True\n01:48:41 |     fp16_impl: safe\n01:48:41 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run4/data\n01:48:41 |     fromfile_datatype_extension: True\n01:48:41 |     gpu: -1\n01:48:41 |     gradient_clip: 0.1\n01:48:41 |     hide_labels: False\n01:48:41 |     history_add_global_end_token: None\n01:48:41 |     history_reversed: False\n01:48:41 |     history_size: 20\n01:48:41 |     ignore_bad_candidates: False\n01:48:41 |     ignore_labels: None\n01:48:41 |     image_cropsize: 224\n01:48:41 |     image_mode: raw\n01:48:41 |     image_size: 256\n01:48:41 |     inference: max\n01:48:41 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:48:41 |     init_opt: None\n01:48:41 |     interactive_candidates: fixed\n01:48:41 |     interactive_mode: False\n01:48:41 |     invsqrt_lr_decay_gamma: -1\n01:48:41 |     is_debug: False\n01:48:41 |     label_truncate: 72\n01:48:41 |     learn_embeddings: True\n01:48:41 |     learn_positional_embeddings: True\n01:48:41 |     learningrate: 5e-05\n01:48:41 |     load_from_checkpoint: False\n01:48:41 |     load_from_pretrained_ranker: True\n01:48:41 |     log_every_n_secs: 10.0\n01:48:41 |     log_every_n_steps: 50\n01:48:41 |     log_keep_fields: all\n01:48:41 |     loglevel: info\n01:48:41 |     lr_scheduler: reduceonplateau\n01:48:41 |     lr_scheduler_decay: 0.5\n01:48:41 |     lr_scheduler_patience: 3\n01:48:41 |     max_train_steps: -1\n01:48:41 |     max_train_time: 7200.0\n01:48:41 |     memory_attention: sqrt\n01:48:41 |     metrics: default\n01:48:41 |     model: transformer/classifier\n01:48:41 |     model_file: /tmp/model4\n01:48:41 |     model_parallel: False\n01:48:41 |     momentum: 0\n01:48:41 |     multitask_weights: [1]\n01:48:41 |     mutators: None\n01:48:41 |     n_decoder_layers: -1\n01:48:41 |     n_encoder_layers: -1\n01:48:41 |     n_heads: 12\n01:48:41 |     n_layers: 12\n01:48:41 |     n_positions: 1024\n01:48:41 |     n_segments: 2\n01:48:41 |     nesterov: True\n01:48:41 |     no_cuda: False\n01:48:41 |     normalize_sent_emb: False\n01:48:41 |     num_epochs: -1\n01:48:41 |     num_workers: 0\n01:48:41 |     nus: (0.7,)\n01:48:41 |     optimizer: adamax\n01:48:41 |     output_scaling: 0.06\n01:48:41 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type2/run4/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model4'}\"\n01:48:41 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n01:48:41 |     person_tokens: False\n01:48:41 |     print_scores: False\n01:48:41 |     rank_candidates: False\n01:48:41 |     rank_top_k: -1\n01:48:41 |     reduction_type: mean\n01:48:41 |     ref_class: None\n01:48:41 |     relu_dropout: 0.0\n01:48:41 |     repeat_blocking_heuristic: True\n01:48:41 |     return_cand_scores: False\n01:48:41 |     save_after_valid: True\n01:48:41 |     save_every_n_secs: -1\n01:48:41 |     save_format: conversations\n01:48:41 |     share_encoders: False\n01:48:41 |     share_word_embeddings: False\n01:48:41 |     short_final_eval: False\n01:48:41 |     special_tok_lst: None\n01:48:41 |     split_lines: False\n01:48:41 |     starttime: Dec04_01-48\n01:48:41 |     task: fromfile:parlaiformat\n01:48:41 |     tensorboard_log: False\n01:48:41 |     tensorboard_logdir: None\n01:48:41 |     text_truncate: 360\n01:48:41 |     threshold: 0.5\n01:48:41 |     topk: 5\n01:48:41 |     train_predict: False\n01:48:41 |     truncate: 1024\n01:48:41 |     update_classifier_head_only: False\n01:48:41 |     update_freq: 1\n01:48:41 |     use_memories: False\n01:48:41 |     use_reply: none\n01:48:41 |     validation_cutoff: 1.0\n01:48:41 |     validation_every_n_epochs: -1\n01:48:41 |     validation_every_n_secs: 20.0\n01:48:41 |     validation_every_n_steps: -1\n01:48:41 |     validation_max_exs: -1\n01:48:41 |     validation_metric: accuracy\n01:48:41 |     validation_metric_mode: max\n01:48:41 |     validation_patience: 30\n01:48:41 |     validation_share_agent: False\n01:48:41 |     variant: xlm\n01:48:41 |     verbose: False\n01:48:41 |     wandb_entity: None\n01:48:41 |     wandb_log: False\n01:48:41 |     wandb_name: None\n01:48:41 |     wandb_project: None\n01:48:41 |     warmup_rate: 0.0001\n01:48:41 |     warmup_updates: 1000\n01:48:41 |     weight_decay: None\n01:48:41 |     world_logs: \n01:48:41 |     wrap_memory_encoder: False\n01:48:42 | creating task(s): fromfile:parlaiformat\n01:48:42 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run4/data_train.txt\n01:48:42 | training...\n01:48:52 | time:10s total_exs:420 total_steps:21 epochs:2.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5214 5.214e-10               .5956                 .5343   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6727            .4140              .4965   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .3550 11.73     1 274.6 566.7       0          0 41.27  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5214             32768  2.265    .1245 6.048 .6909 1.055e-06   121 249.6   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   21 395.6 816.3 2.068        .5091\n\n01:49:02 | time:20s total_exs:1200 total_steps:60 epochs:6.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6359 6.359e-10               .6619                 .5940   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7473            .6056              .6987   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .5343 11.48     1 269.6  1069       0          0 79.33  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6359             32768  2.513    .1245 5.954 .6710 3.005e-06 119.1 472.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   60 388.7 1542 3.976        .6324\n\n01:49:02 | creating task(s): fromfile:parlaiformat\n01:49:02 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run4/data_valid.txt\n01:49:02 | running eval: valid\n01:49:02 | eval completed in 0.18s\n01:49:02 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7273                 .8000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .7692              .7143   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 12.04 168.5  2042       0          0 145.4   24 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .6549 3.005e-06    72 872.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     60 240.5 2915        .7483\n\u001b[0m\n01:49:02 | \u001b[1;32mnew best accuracy: 0.75\u001b[0m\n01:49:02 | saving best valid model: /tmp/model4\n01:49:02 | Saving dictionary to /tmp/model4.dict\n01:49:06 | saving model checkpoint: /tmp/model4.checkpoint\n01:49:06 | Saving dictionary to /tmp/model4.checkpoint.dict\n01:49:23 | time:41s total_exs:1940 total_steps:97 epochs:9.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9000   9e-10               .8989                 .9014   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8965            .9011              .8987   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9035 11.24     1 264.7 967.1       0          0 73.07  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9000             32768  2.742    .1245 5.992 .6116 4.855e-06 119.8 437.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                   97 384.5 1405 3.66        .9000\n\n01:49:26 | time:44s total_exs:2180 total_steps:109 epochs:10.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9590                 .9669   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9512            .9576              .9496   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9658 11.49     1 269.8  1086       0          0 80.46  240   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9583             32768  3.272    .1245 6.025 .5410 5.454e-06 120.5 484.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  109 390.3 1570 4.054        .9583\n\n01:49:26 | running eval: valid\n01:49:26 | eval completed in 0.19s\n01:49:26 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.04 168.5  2017       0          0 143.6   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .5271 5.454e-06    72 861.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    109 240.5 2879        .9583\n\u001b[0m\n01:49:26 | \u001b[1;32mnew best accuracy: 0.9583 (previous best was 0.75)\u001b[0m\n01:49:26 | saving best valid model: /tmp/model4\n01:49:31 | saving model checkpoint: /tmp/model4.checkpoint\n01:49:50 | time:68s total_exs:2960 total_steps:148 epochs:14.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9346 9.346e-10               .9371                 .9406   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9337            .9319              .9282   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9357 11.54     1 270.9  1057       0          0 78.06  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9346             32768  3.645    .1245 6.044 .4127 7.404e-06 120.9 471.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  148 391.7 1529 3.912        .9346\n\n01:49:51 | time:69s total_exs:3040 total_steps:152 epochs:15.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9125 9.125e-10               .9231                 .9545   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8936            .8986              .8611   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9394 11.93     1 278.5  1117       0          0 80.22   80   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9125             32768  4.497    .1246 6.175 .2951 7.604e-06 123.5 495.4   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  152  402 1612 4.103        .9130\n\n01:49:51 | running eval: valid\n01:49:51 | eval completed in 0.19s\n01:49:51 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.04 168.5  1985       0          0 141.3   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .2546 7.604e-06    72 848.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    152 240.5 2834        .9583\n\u001b[0m\n01:49:51 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 1\u001b[0m\n01:49:51 | saving model checkpoint: /tmp/model4.checkpoint\n01:50:11 | time:90s total_exs:3820 total_steps:191 epochs:19.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9718 9.718e-10               .9728                 .9704   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9752            .9707              .9733   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9682 11.56     1 271.1  1033       0          0 76.19  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9718             32768  3.634    .1246 6.033 .1585 9.554e-06 120.7 459.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  191 391.8 1493 3.818        .9718\n\n01:50:12 | time:90s total_exs:3840 total_steps:192 epochs:19.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  10.5     1   250 896.3       0          0 71.67   20   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n     1             32768  1.004    .1189   6.1 .04963 9.604e-06   122 437.3   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  192  372 1334 3.893            1\n\n01:50:12 | running eval: valid\n01:50:12 | eval completed in 0.22s\n01:50:12 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 12.04 168.5  1722       0          0 122.6   24   1   \n    gpu_mem  llen   loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .05165 9.604e-06    72 735.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    192 240.5 2458            1\n\u001b[0m\n01:50:12 | \u001b[1;32mnew best accuracy: 1 (previous best was 0.9583)\u001b[0m\n01:50:12 | saving best valid model: /tmp/model4\n01:50:16 | task solved! stopping.\n01:50:16 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n01:50:16 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n01:50:16 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run4/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n01:50:16 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n01:50:16 | Using CUDA\n01:50:16 | loading dictionary from /tmp/model4.dict\n01:50:16 | num words = 54944\n01:50:21 | Loading existing model parameters from /tmp/model4\n01:50:23 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:50:24 | creating task(s): fromfile:parlaiformat\n01:50:24 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run4/data_valid.txt\n01:50:24 | running eval: valid\n01:50:24 | eval completed in 0.20s\n01:50:24 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 12.04 168.5  1928       0          0 137.3   24   1   \n    gpu_mem  llen   loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294     6 .05165 9.604e-06    72 823.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    192 240.5 2752            1\n\u001b[0m\n01:50:24 | creating task(s): fromfile:parlaiformat\n01:50:24 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run4/data_test.txt\n01:50:24 | running eval: test\n01:50:29 | eval completed in 4.70s\n01:50:29 | \u001b[1mtest:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9400 9.4e-10               .7619                 .6316   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9600            .9657              .9953   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9378 12.07 281.4  3010       0          0 213.9 1000 .9400   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294   5.2 .1769 9.604e-06   104  1112       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    192 385.4 4122        .9453\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type2/run4/data_test.txt -m transformer/classifier -mf /tmp/model4 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:50:31.093709Z","iopub.execute_input":"2022-12-04T01:50:31.094113Z","iopub.status.idle":"2022-12-04T01:51:01.507115Z","shell.execute_reply.started":"2022-12-04T01:50:31.094079Z","shell.execute_reply":"2022-12-04T01:51:01.505915Z"},"scrolled":true,"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"01:50:39 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr1type2/run4/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr1type2/run4/data)\u001b[0m\n01:50:39 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n01:50:39 | Using CUDA\n01:50:39 | loading dictionary from /tmp/model4.dict\n01:50:39 | num words = 54944\n01:50:44 | Loading existing model parameters from /tmp/model4\n01:50:50 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:50:51 | Opt:\n01:50:51 |     activation: gelu\n01:50:51 |     adafactor_eps: '[1e-30, 0.001]'\n01:50:51 |     adam_eps: 1e-08\n01:50:51 |     add_p1_after_newln: False\n01:50:51 |     aggregate_micro: False\n01:50:51 |     allow_missing_init_opts: False\n01:50:51 |     area_under_curve_class: None\n01:50:51 |     area_under_curve_digits: -1\n01:50:51 |     attention_dropout: 0.1\n01:50:51 |     batchsize: 40\n01:50:51 |     betas: '[0.9, 0.999]'\n01:50:51 |     bpe_add_prefix_space: None\n01:50:51 |     bpe_debug: False\n01:50:51 |     bpe_dropout: None\n01:50:51 |     bpe_merge: None\n01:50:51 |     bpe_vocab: None\n01:50:51 |     candidates: inline\n01:50:51 |     cap_num_predictions: 100\n01:50:51 |     checkpoint_activations: False\n01:50:51 |     class_weights: None\n01:50:51 |     classes: \"['__notok__', '__ok__']\"\n01:50:51 |     classes_from_file: None\n01:50:51 |     data_parallel: True\n01:50:51 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n01:50:51 |     datatype: train\n01:50:51 |     delimiter: '\\n'\n01:50:51 |     dict_class: parlai.core.dict:DictionaryAgent\n01:50:51 |     dict_endtoken: __start__\n01:50:51 |     dict_file: /tmp/model4.dict\n01:50:51 |     dict_include_test: False\n01:50:51 |     dict_include_valid: False\n01:50:51 |     dict_initpath: None\n01:50:51 |     dict_language: english\n01:50:51 |     dict_loaded: True\n01:50:51 |     dict_lower: True\n01:50:51 |     dict_max_ngram_size: -1\n01:50:51 |     dict_maxexs: -1\n01:50:51 |     dict_maxtokens: -1\n01:50:51 |     dict_minfreq: 0\n01:50:51 |     dict_nulltoken: __null__\n01:50:51 |     dict_starttoken: __start__\n01:50:51 |     dict_textfields: text,labels\n01:50:51 |     dict_tokenizer: bpe\n01:50:51 |     dict_unktoken: __unk__\n01:50:51 |     display_examples: False\n01:50:51 |     download_path: None\n01:50:51 |     dropout: 0.1\n01:50:51 |     dynamic_batching: None\n01:50:51 |     embedding_projection: random\n01:50:51 |     embedding_size: 768\n01:50:51 |     embedding_type: random\n01:50:51 |     embeddings_scale: False\n01:50:51 |     encode_candidate_vecs: True\n01:50:51 |     encode_candidate_vecs_batchsize: 256\n01:50:51 |     eval_batchsize: None\n01:50:51 |     eval_candidates: inline\n01:50:51 |     eval_dynamic_batching: None\n01:50:51 |     evaltask: None\n01:50:51 |     ffn_size: 3072\n01:50:51 |     final_extra_opt: \n01:50:51 |     fixed_candidate_vecs: reuse\n01:50:51 |     fixed_candidates_path: None\n01:50:51 |     force_fp16_tokens: True\n01:50:51 |     fp16: True\n01:50:51 |     fp16_impl: safe\n01:50:51 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run4/data_test.txt\n01:50:51 |     fromfile_datatype_extension: True\n01:50:51 |     gpu: -1\n01:50:51 |     gradient_clip: 0.1\n01:50:51 |     hide_labels: False\n01:50:51 |     history_add_global_end_token: None\n01:50:51 |     history_reversed: False\n01:50:51 |     history_size: 20\n01:50:51 |     ignore_bad_candidates: False\n01:50:51 |     ignore_labels: None\n01:50:51 |     image_cropsize: 224\n01:50:51 |     image_mode: raw\n01:50:51 |     image_size: 256\n01:50:51 |     inference: max\n01:50:51 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:50:51 |     init_opt: None\n01:50:51 |     interactive_candidates: fixed\n01:50:51 |     interactive_mode: False\n01:50:51 |     invsqrt_lr_decay_gamma: -1\n01:50:51 |     is_debug: False\n01:50:51 |     label_truncate: 72\n01:50:51 |     learn_embeddings: True\n01:50:51 |     learn_positional_embeddings: True\n01:50:51 |     learningrate: 5e-05\n01:50:51 |     load_from_pretrained_ranker: True\n01:50:51 |     log_every_n_secs: 10.0\n01:50:51 |     log_every_n_steps: 50\n01:50:51 |     log_keep_fields: all\n01:50:51 |     loglevel: info\n01:50:51 |     lr_scheduler: reduceonplateau\n01:50:51 |     lr_scheduler_decay: 0.5\n01:50:51 |     lr_scheduler_patience: 3\n01:50:51 |     max_train_steps: -1\n01:50:51 |     max_train_time: 7200.0\n01:50:51 |     memory_attention: sqrt\n01:50:51 |     metrics: default\n01:50:51 |     model: transformer/classifier\n01:50:51 |     model_file: /tmp/model4\n01:50:51 |     model_parallel: False\n01:50:51 |     momentum: 0\n01:50:51 |     multitask_weights: [1]\n01:50:51 |     mutators: None\n01:50:51 |     n_decoder_layers: -1\n01:50:51 |     n_encoder_layers: -1\n01:50:51 |     n_heads: 12\n01:50:51 |     n_layers: 12\n01:50:51 |     n_positions: 1024\n01:50:51 |     n_segments: 2\n01:50:51 |     nesterov: True\n01:50:51 |     no_cuda: False\n01:50:51 |     normalize_sent_emb: False\n01:50:51 |     num_epochs: -1\n01:50:51 |     num_examples: -1\n01:50:51 |     num_workers: 0\n01:50:51 |     nus: [0.7]\n01:50:51 |     optimizer: adamax\n01:50:51 |     output_scaling: 0.06\n01:50:51 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type2/run4/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model4', 'batchsize': 40}\"\n01:50:51 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n01:50:51 |     person_tokens: False\n01:50:51 |     print_scores: False\n01:50:51 |     rank_candidates: False\n01:50:51 |     rank_top_k: -1\n01:50:51 |     reduction_type: mean\n01:50:51 |     ref_class: None\n01:50:51 |     relu_dropout: 0.0\n01:50:51 |     repeat_blocking_heuristic: True\n01:50:51 |     report_filename: \n01:50:51 |     return_cand_scores: False\n01:50:51 |     save_after_valid: True\n01:50:51 |     save_every_n_secs: -1\n01:50:51 |     save_format: conversations\n01:50:51 |     share_encoders: False\n01:50:51 |     share_word_embeddings: False\n01:50:51 |     short_final_eval: False\n01:50:51 |     special_tok_lst: None\n01:50:51 |     split_lines: False\n01:50:51 |     starttime: Dec04_01-48\n01:50:51 |     task: fromfile:parlaiformat\n01:50:51 |     tensorboard_log: False\n01:50:51 |     tensorboard_logdir: None\n01:50:51 |     text_truncate: 360\n01:50:51 |     threshold: 0.5\n01:50:51 |     topk: 5\n01:50:51 |     train_predict: False\n01:50:51 |     truncate: 1024\n01:50:51 |     update_classifier_head_only: False\n01:50:51 |     update_freq: 1\n01:50:51 |     use_memories: False\n01:50:51 |     use_reply: none\n01:50:51 |     validation_cutoff: 1.0\n01:50:51 |     validation_every_n_epochs: -1\n01:50:51 |     validation_every_n_secs: 20.0\n01:50:51 |     validation_every_n_steps: -1\n01:50:51 |     validation_max_exs: -1\n01:50:51 |     validation_metric: accuracy\n01:50:51 |     validation_metric_mode: max\n01:50:51 |     validation_patience: 30\n01:50:51 |     validation_share_agent: False\n01:50:51 |     variant: xlm\n01:50:51 |     verbose: False\n01:50:51 |     wandb_entity: None\n01:50:51 |     wandb_log: False\n01:50:51 |     wandb_name: None\n01:50:51 |     wandb_project: None\n01:50:51 |     warmup_rate: 0.0001\n01:50:51 |     warmup_updates: 1000\n01:50:51 |     weight_decay: None\n01:50:51 |     world_logs: \n01:50:51 |     wrap_memory_encoder: False\n01:50:52 | Evaluating task fromfile:parlaiformat using datatype valid.\n01:50:52 | creating task(s): fromfile:parlaiformat\n01:50:52 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n01:50:52 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run4/data_test.txt\n01:50:59 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9400 9.4e-10               .7619                 .6316   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9600            .9657              .9953   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9378 12.07 562.9  1913       0          0   136 1000 .9400   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .1769 9.604e-06   208 707.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    192 770.9 2621        .9453\u001b[0m\n01:50:59 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9400 9.4e-10               .7619                 .6316   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9600            .9657              .9953   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9378 12.07 562.9  1913       0          0   136 1000 .9400   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .1769 9.604e-06   208 707.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    192 770.9 2621        .9453\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model4*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:51:01.509068Z","iopub.execute_input":"2022-12-04T01:51:01.509466Z","iopub.status.idle":"2022-12-04T01:51:02.941736Z","shell.execute_reply.started":"2022-12-04T01:51:01.509423Z","shell.execute_reply":"2022-12-04T01:51:02.940461Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":"run 5","metadata":{}},{"cell_type":"code","source":"# run 5 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type2/run5/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model5","metadata":{"execution":{"iopub.status.busy":"2022-12-04T01:51:02.943578Z","iopub.execute_input":"2022-12-04T01:51:02.945223Z","iopub.status.idle":"2022-12-04T02:02:50.190141Z","shell.execute_reply.started":"2022-12-04T01:51:02.945171Z","shell.execute_reply":"2022-12-04T02:02:50.188959Z"},"scrolled":true,"trusted":true},"execution_count":93,"outputs":[{"name":"stdout","text":"01:51:09 | building dictionary first...\n01:51:09 | No model with opt yet at: /tmp/model5(.opt)\n01:51:09 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run5/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n01:51:09 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n01:51:09 | Using CUDA\n01:51:09 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n01:51:10 | num words = 54944\n01:51:14 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:51:24 | Total parameters: 128,042,498 (128,042,498 trainable)\n01:51:24 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n01:51:24 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n01:51:24 | Opt:\n01:51:24 |     activation: gelu\n01:51:24 |     adafactor_eps: '(1e-30, 0.001)'\n01:51:24 |     adam_eps: 1e-08\n01:51:24 |     add_p1_after_newln: False\n01:51:24 |     aggregate_micro: False\n01:51:24 |     allow_missing_init_opts: False\n01:51:24 |     attention_dropout: 0.1\n01:51:24 |     batchsize: 20\n01:51:24 |     betas: '(0.9, 0.999)'\n01:51:24 |     bpe_add_prefix_space: None\n01:51:24 |     bpe_debug: False\n01:51:24 |     bpe_dropout: None\n01:51:24 |     bpe_merge: None\n01:51:24 |     bpe_vocab: None\n01:51:24 |     candidates: inline\n01:51:24 |     cap_num_predictions: 100\n01:51:24 |     checkpoint_activations: False\n01:51:24 |     class_weights: None\n01:51:24 |     classes: \"['__notok__', '__ok__']\"\n01:51:24 |     classes_from_file: None\n01:51:24 |     data_parallel: True\n01:51:24 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n01:51:24 |     datatype: train\n01:51:24 |     delimiter: '\\n'\n01:51:24 |     dict_class: parlai.core.dict:DictionaryAgent\n01:51:24 |     dict_endtoken: __start__\n01:51:24 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n01:51:24 |     dict_include_test: False\n01:51:24 |     dict_include_valid: False\n01:51:24 |     dict_initpath: None\n01:51:24 |     dict_language: english\n01:51:24 |     dict_loaded: True\n01:51:24 |     dict_lower: True\n01:51:24 |     dict_max_ngram_size: -1\n01:51:24 |     dict_maxexs: -1\n01:51:24 |     dict_maxtokens: -1\n01:51:24 |     dict_minfreq: 0\n01:51:24 |     dict_nulltoken: __null__\n01:51:24 |     dict_starttoken: __start__\n01:51:24 |     dict_textfields: text,labels\n01:51:24 |     dict_tokenizer: bpe\n01:51:24 |     dict_unktoken: __unk__\n01:51:24 |     display_examples: False\n01:51:24 |     download_path: None\n01:51:24 |     dropout: 0.1\n01:51:24 |     dynamic_batching: None\n01:51:24 |     embedding_projection: random\n01:51:24 |     embedding_size: 768\n01:51:24 |     embedding_type: random\n01:51:24 |     embeddings_scale: False\n01:51:24 |     encode_candidate_vecs: True\n01:51:24 |     encode_candidate_vecs_batchsize: 256\n01:51:24 |     eval_batchsize: None\n01:51:24 |     eval_candidates: inline\n01:51:24 |     eval_dynamic_batching: None\n01:51:24 |     evaltask: None\n01:51:24 |     ffn_size: 3072\n01:51:24 |     final_extra_opt: \n01:51:24 |     fixed_candidate_vecs: reuse\n01:51:24 |     fixed_candidates_path: None\n01:51:24 |     force_fp16_tokens: False\n01:51:24 |     fp16: True\n01:51:24 |     fp16_impl: safe\n01:51:24 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run5/data\n01:51:24 |     fromfile_datatype_extension: True\n01:51:24 |     gpu: -1\n01:51:24 |     gradient_clip: 0.1\n01:51:24 |     hide_labels: False\n01:51:24 |     history_add_global_end_token: None\n01:51:24 |     history_reversed: False\n01:51:24 |     history_size: 20\n01:51:24 |     ignore_bad_candidates: False\n01:51:24 |     ignore_labels: None\n01:51:24 |     image_cropsize: 224\n01:51:24 |     image_mode: raw\n01:51:24 |     image_size: 256\n01:51:24 |     inference: max\n01:51:24 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n01:51:24 |     init_opt: None\n01:51:24 |     interactive_candidates: fixed\n01:51:24 |     interactive_mode: False\n01:51:24 |     invsqrt_lr_decay_gamma: -1\n01:51:24 |     is_debug: False\n01:51:24 |     label_truncate: 72\n01:51:24 |     learn_embeddings: True\n01:51:24 |     learn_positional_embeddings: True\n01:51:24 |     learningrate: 5e-05\n01:51:24 |     load_from_checkpoint: False\n01:51:24 |     load_from_pretrained_ranker: True\n01:51:24 |     log_every_n_secs: 10.0\n01:51:24 |     log_every_n_steps: 50\n01:51:24 |     log_keep_fields: all\n01:51:24 |     loglevel: info\n01:51:24 |     lr_scheduler: reduceonplateau\n01:51:24 |     lr_scheduler_decay: 0.5\n01:51:24 |     lr_scheduler_patience: 3\n01:51:24 |     max_train_steps: -1\n01:51:24 |     max_train_time: 7200.0\n01:51:24 |     memory_attention: sqrt\n01:51:24 |     metrics: default\n01:51:24 |     model: transformer/classifier\n01:51:24 |     model_file: /tmp/model5\n01:51:24 |     model_parallel: False\n01:51:24 |     momentum: 0\n01:51:24 |     multitask_weights: [1]\n01:51:24 |     mutators: None\n01:51:24 |     n_decoder_layers: -1\n01:51:24 |     n_encoder_layers: -1\n01:51:24 |     n_heads: 12\n01:51:24 |     n_layers: 12\n01:51:24 |     n_positions: 1024\n01:51:24 |     n_segments: 2\n01:51:24 |     nesterov: True\n01:51:24 |     no_cuda: False\n01:51:24 |     normalize_sent_emb: False\n01:51:24 |     num_epochs: -1\n01:51:24 |     num_workers: 0\n01:51:24 |     nus: (0.7,)\n01:51:24 |     optimizer: adamax\n01:51:24 |     output_scaling: 0.06\n01:51:24 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type2/run5/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model5'}\"\n01:51:24 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n01:51:24 |     person_tokens: False\n01:51:24 |     print_scores: False\n01:51:24 |     rank_candidates: False\n01:51:24 |     rank_top_k: -1\n01:51:24 |     reduction_type: mean\n01:51:24 |     ref_class: None\n01:51:24 |     relu_dropout: 0.0\n01:51:24 |     repeat_blocking_heuristic: True\n01:51:24 |     return_cand_scores: False\n01:51:24 |     save_after_valid: True\n01:51:24 |     save_every_n_secs: -1\n01:51:24 |     save_format: conversations\n01:51:24 |     share_encoders: False\n01:51:24 |     share_word_embeddings: False\n01:51:24 |     short_final_eval: False\n01:51:24 |     special_tok_lst: None\n01:51:24 |     split_lines: False\n01:51:24 |     starttime: Dec04_01-51\n01:51:24 |     task: fromfile:parlaiformat\n01:51:24 |     tensorboard_log: False\n01:51:24 |     tensorboard_logdir: None\n01:51:24 |     text_truncate: 360\n01:51:24 |     threshold: 0.5\n01:51:24 |     topk: 5\n01:51:24 |     train_predict: False\n01:51:24 |     truncate: 1024\n01:51:24 |     update_classifier_head_only: False\n01:51:24 |     update_freq: 1\n01:51:24 |     use_memories: False\n01:51:24 |     use_reply: none\n01:51:24 |     validation_cutoff: 1.0\n01:51:24 |     validation_every_n_epochs: -1\n01:51:24 |     validation_every_n_secs: 20.0\n01:51:24 |     validation_every_n_steps: -1\n01:51:24 |     validation_max_exs: -1\n01:51:24 |     validation_metric: accuracy\n01:51:24 |     validation_metric_mode: max\n01:51:24 |     validation_patience: 30\n01:51:24 |     validation_share_agent: False\n01:51:24 |     variant: xlm\n01:51:24 |     verbose: False\n01:51:24 |     wandb_entity: None\n01:51:24 |     wandb_log: False\n01:51:24 |     wandb_name: None\n01:51:24 |     wandb_project: None\n01:51:24 |     warmup_rate: 0.0001\n01:51:24 |     warmup_updates: 1000\n01:51:24 |     weight_decay: None\n01:51:24 |     world_logs: \n01:51:24 |     wrap_memory_encoder: False\n01:51:25 | creating task(s): fromfile:parlaiformat\n01:51:25 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run5/data_train.txt\n01:51:25 | training...\n01:51:35 | time:10s total_exs:420 total_steps:21 epochs:2.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6333 6.333e-10               .6188                 .6757   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5708            .6468              .6000   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7015 11.68     1 273.6 561.5       0          0 41.05  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6333             32768  2.614    .1189 6.043 .6769 1.055e-06 120.9   248   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   21 394.4 809.5 2.057        .6322\n\n01:51:45 | time:20s total_exs:1160 total_steps:58 epochs:5.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6986 6.986e-10               .6941                 .7028   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6856            .7031              .6947   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7116 11.92     1 278.4  1063       0          0  76.4  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6986             32768  2.449    .1207 5.997 .6568 2.905e-06 119.9 458.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   58 398.3 1522 3.829        .6986\n\n01:51:45 | creating task(s): fromfile:parlaiformat\n01:51:45 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run5/data_valid.txt\n01:51:45 | running eval: valid\n01:51:45 | eval completed in 0.20s\n01:51:45 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1666       0          0 131.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6314 2.905e-06    72   789       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                     58  224 2455        .8322\n\u001b[0m\n01:51:45 | \u001b[1;32mnew best accuracy: 0.8333\u001b[0m\n01:51:45 | saving best valid model: /tmp/model5\n01:51:45 | Saving dictionary to /tmp/model5.dict\n01:51:49 | saving model checkpoint: /tmp/model5.checkpoint\n01:51:49 | Saving dictionary to /tmp/model5.checkpoint.dict\n01:52:07 | time:42s total_exs:1880 total_steps:94 epochs:9.40\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8777                 .8613   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8947            .8722              .8899   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8552 11.93     1 278.6 988.7       0          0 70.97  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8750             32768  3.006    .1207 6.003 .5863 4.705e-06 120.1   426   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   94 398.7 1415 3.556        .8749\n\n01:52:09 | time:45s total_exs:2080 total_steps:104 epochs:10.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9100 9.1e-10               .9109                 .8932   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9293            .9091              .9278   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8911 12.07     1 281.5  1056       0          0 75.03  200   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9100             32768  3.189    .1207  5.99 .5338 5.204e-06 119.8 449.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  104 401.3 1506 3.783        .9100\n\n01:52:09 | running eval: valid\n01:52:10 | eval completed in 0.20s\n01:52:10 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1672       0          0 131.9   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .4971 5.204e-06    72 791.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    104  224 2463        .9583\n\u001b[0m\n01:52:10 | \u001b[1;32mnew best accuracy: 0.9583 (previous best was 0.8333)\u001b[0m\n01:52:10 | saving best valid model: /tmp/model5\n01:52:14 | saving model checkpoint: /tmp/model5.checkpoint\n01:52:33 | time:69s total_exs:2840 total_steps:142 epochs:14.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9487 9.487e-10               .9498                 .9584   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9413            .9475              .9387   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9565 11.88     1 277.7  1056       0          0 76.06  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9487             32768  4.153    .1207 6.032 .3652 7.104e-06 120.6 458.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  142 398.3 1515 3.811        .9487\n\n01:52:34 | time:70s total_exs:2920 total_steps:146 epochs:14.60\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9750 9.75e-10               .9756                 .9756   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9756            .9744              .9744   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9744  11.6     1   272  1050       0          0 77.21   80   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9750             32768  6.555    .1207 6.025 .2262 7.304e-06 120.5 465.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  146 392.5 1515 3.946        .9750\n\n01:52:34 | running eval: valid\n01:52:35 | eval completed in 0.20s\n01:52:35 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1713       0          0 135.2   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .2593 7.304e-06    72 811.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    146  224 2524        .9583\n\u001b[0m\n01:52:35 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 1\u001b[0m\n01:52:35 | saving model checkpoint: /tmp/model5.checkpoint\n01:52:50 | time:85s total_exs:3660 total_steps:183 epochs:18.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9662 9.662e-10               .9649                 .9663   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9636            .9674              .9661   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9687 11.66     1 273.1  1005       0          0 73.58  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9662             32768  6.149    .1207 5.965 .1646 9.154e-06 119.3 438.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  183 392.4 1444 3.687        .9662\n\n01:52:55 | time:90s total_exs:4020 total_steps:201 epochs:20.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9889 9.889e-10               .9894                 .9841   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9947            .9884              .9942   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9827 11.61     1 272.1  1019       0          0 74.86  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9889             32768  3.716    .1207 6.039 .07729 1.005e-05 120.8 452.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  201 392.9 1471 3.76        .9889\n\n01:52:55 | running eval: valid\n01:52:55 | eval completed in 0.20s\n01:52:55 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1679       0          0 132.5   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .2809 1.005e-05    72 795.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    201  224 2474        .9167\n\u001b[0m\n01:52:55 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 2\u001b[0m\n01:52:55 | saving model checkpoint: /tmp/model5.checkpoint\n01:53:09 | time:105s total_exs:4780 total_steps:239 epochs:23.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9934 9.934e-10               .9936                 .9873   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9932                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9865 12.02 .8421 280.3  1064       0          0 75.91  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9934             32768  1.661    .1207 6.026 .03634 1.195e-05 120.5 457.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  239 400.8 1521 3.804        .9934\n\n01:53:15 | time:110s total_exs:5220 total_steps:261 epochs:26.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9909 9.909e-10               .9912                 .9825   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9907                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9815 11.49 .4091 269.8  1024       0          0 75.89  440   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9909             32768   2.63    .1190 6.018 .0448 1.305e-05 120.4 456.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  261 390.1 1480 3.809        .9909\n\n01:53:15 | running eval: valid\n01:53:15 | eval completed in 0.20s\n01:53:15 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1655       0          0 130.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .5319 1.305e-05    72 783.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    261  224 2439        .8322\n\u001b[0m\n01:53:15 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 3\u001b[0m\n01:53:15 | saving model checkpoint: /tmp/model5.checkpoint\n01:53:30 | time:125s total_exs:5980 total_steps:299 epochs:29.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.77 .1316 275.5  1030       0          0 74.75  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768  .3091    .1207 5.979 .002823 1.495e-05 119.6 446.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  299 395.1 1476 3.746            1\n\n01:53:35 | time:131s total_exs:6420 total_steps:321 epochs:32.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.52     0 270.3  1043       0          0  77.2  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .02409    .1207 6.064 .001939 1.605e-05 121.3 468.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  321 391.6 1512 3.876            1\n\n01:53:35 | running eval: valid\n01:53:36 | eval completed in 0.23s\n01:53:36 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1520       0          0   120   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .5830 1.605e-05    72   720       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    321  224 2240        .8748\n\u001b[0m\n01:53:36 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 4\u001b[0m\n01:53:36 | saving model checkpoint: /tmp/model5.checkpoint\n01:53:50 | time:145s total_exs:7180 total_steps:359 epochs:35.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.77     0 275.4  1045       0          0 75.88  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .02082    .1207 5.945 .001615 1.795e-05 118.9 451.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  359 394.3 1496 3.803            1\n\n01:53:56 | time:151s total_exs:7620 total_steps:381 epochs:38.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.62     0 272.3  1016       0          0 74.63  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01698    .1190 5.964 .001436 1.905e-05 119.3 445.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  381 391.6 1461 3.746            1\n\n01:53:56 | running eval: valid\n01:53:56 | eval completed in 0.20s\n01:53:56 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1706       0          0 134.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 .5787 1.905e-05    72 808.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    381  224 2514        .9161\n\u001b[0m\n01:53:56 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 5\u001b[0m\n01:53:56 | saving model checkpoint: /tmp/model5.checkpoint\n01:54:11 | time:166s total_exs:8380 total_steps:419 epochs:41.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.93     0 278.6  1054       0          0 75.63  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01621    .1207 6.068 .001324 2.095e-05 121.4   459   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps  ups  weighted_f1  \n         0          0                  419  400 1513 3.79            1\n\n01:54:16 | time:172s total_exs:8820 total_steps:441 epochs:44.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.98     0 279.5  1072       0          0 76.73  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01499    .1207     6 .001209 2.205e-05   120 460.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  441 399.5 1533 3.852            1\n\n01:54:16 | running eval: valid\n01:54:17 | eval completed in 0.20s\n01:54:17 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1666       0          0 131.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 .6564 2.205e-05    72 789.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    441  224 2456        .8730\n\u001b[0m\n01:54:17 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 6\u001b[0m\n01:54:17 | saving model checkpoint: /tmp/model5.checkpoint\n01:54:31 | time:186s total_exs:9560 total_steps:478 epochs:47.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.79 .02703 275.7  1021       0          0 74.06   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  \\\n    740   1             32768 .02654    .1207 5.986 .001125 2.39e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   443.4       0          0                  478 395.4 1464 3.712            1\n\n01:54:37 | time:192s total_exs:10000 total_steps:500 epochs:50.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.48     0 269.6  1040       0          0 77.11  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss      lr  ltpb  ltps  \\\n     1             32768 .01229    .1207 5.986 .001042 2.5e-05 119.7 461.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  500 389.4 1501 3.871            1\n\n01:54:37 | running eval: valid\n01:54:37 | eval completed in 0.20s\n01:54:37 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1684       0          0 132.9   24 .8750   \n    gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 .7398 2.5e-05    72 797.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    500  224 2481        .8748\n\u001b[0m\n01:54:37 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 7\u001b[0m\n01:54:37 | saving model checkpoint: /tmp/model5.checkpoint\n01:54:51 | time:207s total_exs:10760 total_steps:538 epochs:53.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1  11.5 .02632   270  1014       0          0 75.12   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  \\\n    760   1             32768  .0224    .1207 6.013 .0009782 2.69e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.7       0          0                  538 390.3 1466 3.765            1\n\n01:54:57 | time:212s total_exs:11180 total_steps:559 epochs:55.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.49     0 269.8 991.4       0          0  73.5  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01097    .1207 6.033 .000913 2.795e-05 120.7 443.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  559 390.4 1435 3.69            1\n\n01:54:57 | running eval: valid\n01:54:57 | eval completed in 0.20s\n01:54:57 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1657       0          0 130.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 .5965 2.795e-05    72 784.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    559  224 2441        .9167\n\u001b[0m\n01:54:57 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 8\u001b[0m\n01:54:57 | saving model checkpoint: /tmp/model5.checkpoint\n01:55:12 | time:227s total_exs:11960 total_steps:598 epochs:59.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.59     0 271.8  1035       0          0 76.12  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .01003    .1208 6.028 .0008506 2.99e-05 120.6 458.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  598 392.4 1493 3.815            1\n\n01:55:17 | time:233s total_exs:12380 total_steps:619 epochs:61.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0 276.1  1044       0          0 75.65  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .009304    .1208 5.943 .0007891 3.095e-05 118.9   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   449.6       0          0                  619  395 1494 3.798            1\n\n01:55:17 | running eval: valid\n01:55:17 | eval completed in 0.20s\n01:55:17 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1658       0          0 130.8   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 .7774 3.095e-05    72 785.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    619  224 2443        .8322\n\u001b[0m\n01:55:17 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 9\u001b[0m\n01:55:17 | saving model checkpoint: /tmp/model5.checkpoint\n01:55:32 | time:247s total_exs:13120 total_steps:656 epochs:65.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.44 .02703 268.9 984.3       0          0 73.22   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  \\\n    740   1             32768 .02253    .1208 5.986 .000751 3.28e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   438.3       0          0                  656 388.6 1423 3.669            1\n\n01:55:38 | time:253s total_exs:13560 total_steps:678 epochs:67.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.74     0 274.8  1044       0          0 75.99  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .009096    .1208 6.055 .0007022 3.39e-05 121.1 460.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  678 395.9 1504 3.814            1\n\n01:55:38 | running eval: valid\n01:55:38 | eval completed in 0.20s\n01:55:38 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1667       0          0 131.6   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 .9478 3.39e-05    72 789.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    678  224 2457        .8322\n\u001b[0m\n01:55:38 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 10\u001b[0m\n01:55:38 | saving model checkpoint: /tmp/model5.checkpoint\n01:55:52 | time:267s total_exs:14320 total_steps:716 epochs:71.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.84     0 276.9  1045       0          0 75.46  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .008404    .1208 5.979 .0006528 3.58e-05 119.6 451.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  716 396.5 1496 3.782            1\n\n01:55:58 | time:273s total_exs:14760 total_steps:738 epochs:73.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.04     0 280.7  1061       0          0 75.62  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .007214    .1208 6.036 .0006107 3.69e-05 120.7 456.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  738 401.5 1518 3.795            1\n\n01:55:58 | running eval: valid\n01:55:58 | eval completed in 0.23s\n01:55:58 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1519       0          0 119.9   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 .7793 3.69e-05    72 719.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    738  224 2239        .8748\n\u001b[0m\n01:55:58 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 11\u001b[0m\n01:55:58 | saving model checkpoint: /tmp/model5.checkpoint\n01:56:14 | time:289s total_exs:15520 total_steps:776 epochs:77.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.03     0 280.6  1060       0          0 75.57  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .006774    .1208 6.042 .0005717 3.88e-05 120.8 456.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  776 401.5 1517 3.787            1\n\n01:56:18 | time:293s total_exs:15880 total_steps:794 epochs:79.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.78     0 275.7  1060       0          0  76.9  360   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .006345    .1208 5.972 .0005358 3.97e-05 119.4 459.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  794 395.1 1519 3.864            1\n\n01:56:18 | running eval: valid\n01:56:18 | eval completed in 0.20s\n01:56:18 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1668       0          0 131.6   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 .9544 3.97e-05    72 789.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    794  224 2458        .8322\n\u001b[0m\n01:56:18 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 12\u001b[0m\n01:56:18 | saving model checkpoint: /tmp/model5.checkpoint\n01:56:34 | time:309s total_exs:16620 total_steps:831 epochs:83.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.98     0 279.6  1030       0          0 73.65  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .005967    .1208     6 .0005036 4.155e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   441.9       0          0                  831 399.6 1471 3.691            1\n\n01:56:39 | time:314s total_exs:17000 total_steps:850 epochs:85.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.82     0 276.4  1076       0          0 77.84  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .005616    .1208     6 .0004742 4.25e-05   120 467.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  850 396.4 1543 3.91            1\n\n01:56:39 | running eval: valid\n01:56:39 | eval completed in 0.20s\n01:56:39 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1682       0          0 132.7   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 .9959 4.25e-05    72 796.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    850  224 2478        .8322\n\u001b[0m\n01:56:39 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 13\u001b[0m\n01:56:39 | saving model checkpoint: /tmp/model5.checkpoint\n01:56:54 | time:329s total_exs:17780 total_steps:889 epochs:88.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.58     0 271.6  1023       0          0 75.36  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .005265    .1208 6.021 .0004449 4.445e-05 120.4   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   453.7       0          0                  889  392 1477 3.772            1\n\n01:56:59 | time:334s total_exs:18160 total_steps:908 epochs:90.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.62     0 272.4  1040       0          0 76.32  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .004937    .1208 5.974 .0004167 4.54e-05 119.5 455.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  908 391.9 1496 3.834            1\n\n01:56:59 | running eval: valid\n01:56:59 | eval completed in 0.20s\n01:56:59 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1660       0          0   131   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 .9485 4.54e-05    72 786.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    908  224 2446        .8322\n\u001b[0m\n01:56:59 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 14\u001b[0m\n01:56:59 | saving model checkpoint: /tmp/model5.checkpoint\n01:57:14 | time:349s total_exs:18920 total_steps:946 epochs:94.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.85     0 276.9  1050       0          0 75.86  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .00463    .1208 5.979 .0003912 4.73e-05 119.6 453.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  946 396.5 1504 3.801            1\n\n01:57:19 | time:354s total_exs:19340 total_steps:967 epochs:96.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.65 .09524   273  1033       0          0 75.69   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n    420   1             32768  .8085    .1208 6.019 .0004729 4.835e-05 120.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   455.6       0          0                  967 393.4 1489  3.8            1\n\n01:57:19 | running eval: valid\n01:57:19 | eval completed in 0.20s\n01:57:19 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1645       0          0 129.8   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 .9220 4.835e-05    72 778.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    967  224 2424        .8748\n\u001b[0m\n01:57:19 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 15\u001b[0m\n01:57:19 | saving model checkpoint: /tmp/model5.checkpoint\n01:57:34 | time:370s total_exs:20100 total_steps:1005 epochs:100.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9987                 .9975   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9986                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                  .9973 11.59 .02632 271.8  1022       0          0 75.22   \n    exs    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    760 .9987             32768   13.6    .1208 6.039 .005032 4.995e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   454.3       0          0                 1005 392.6 1477 3.769        .9987\n\n01:57:40 | time:375s total_exs:20480 total_steps:1024 epochs:102.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9947 9.947e-10               .9947                 .9947   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9947            .9948              .9948   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9948 11.72 .1579 274.5  1016       0          0 74.01  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9947             32768  37.54    .1191 5.995 .03087 4.995e-05 119.9 443.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1024 394.4 1459 3.717        .9947\n\n01:57:40 | running eval: valid\n01:57:40 | eval completed in 0.20s\n01:57:40 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1659       0          0 130.9   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6 .3641 4.995e-05    72 785.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1024  224 2444        .9583\n\u001b[0m\n01:57:40 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 16\u001b[0m\n01:57:40 | saving model checkpoint: /tmp/model5.checkpoint\n01:57:54 | time:389s total_exs:21240 total_steps:1062 epochs:106.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.72     0 274.5  1042       0          0 75.95  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n     1             32768 .003865    .1208 5.989 .00031 4.995e-05 119.8 454.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1062 394.3 1497 3.806            1\n\n01:58:00 | time:395s total_exs:21680 total_steps:1084 epochs:108.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.68     0 273.7  1043       0          0 76.19  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003498    .1208 6.018 .0002916 4.995e-05 120.4   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   458.5       0          0                 1084  394 1501 3.824            1\n\n01:58:00 | running eval: valid\n01:58:00 | eval completed in 0.19s\n01:58:00 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1717       0          0 135.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 1.028 4.995e-05    72 813.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1084  224 2530        .8748\n\u001b[0m\n01:58:00 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 17\u001b[0m\n01:58:00 | saving model checkpoint: /tmp/model5.checkpoint\n01:58:15 | time:410s total_exs:22440 total_steps:1122 epochs:112.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.59     0 271.8  1013       0          0 74.55  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003247    .1208 5.992 .0002738 4.995e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   446.7       0          0                 1122 391.6 1460 3.736            1\n\n01:58:20 | time:416s total_exs:22880 total_steps:1144 epochs:114.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.12     0 282.3  1092       0          0 77.39  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .00306    .1209 6.023 .000258 4.995e-05 120.5 466.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1144 402.8 1559 3.885            1\n\n01:58:20 | running eval: valid\n01:58:21 | eval completed in 0.21s\n01:58:21 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1701       0          0 134.1   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 1.056 4.995e-05    72 805.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1144  224 2508        .8748\n\u001b[0m\n01:58:21 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 18\u001b[0m\n01:58:21 | saving model checkpoint: /tmp/model5.checkpoint\n01:58:35 | time:430s total_exs:23640 total_steps:1182 epochs:118.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.88     0 277.7  1055       0          0 75.97  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .002896    .1209 6.011 .000244 4.995e-05 120.2 456.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1182 397.9 1511 3.807            1\n\n01:58:41 | time:436s total_exs:24060 total_steps:1203 epochs:120.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.72     0 274.3  1028       0          0 74.98  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002745    .1209 6.062 .0002313 4.995e-05 121.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   454.5       0          0                 1203 395.6 1483 3.764            1\n\n01:58:41 | running eval: valid\n01:58:41 | eval completed in 0.20s\n01:58:41 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1704       0          0 134.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6  1.07 4.995e-05    72 807.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1203  224 2511        .8748\n\u001b[0m\n01:58:41 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 19\u001b[0m\n01:58:41 | saving model checkpoint: /tmp/model5.checkpoint\n01:58:56 | time:451s total_exs:24840 total_steps:1242 epochs:124.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.84     0 276.8  1057       0          0  76.4  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002593    .1209 5.969 .0002184 4.995e-05 119.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.1       0          0                 1242 396.2 1514 3.828            1\n\n01:59:01 | time:456s total_exs:25200 total_steps:1260 epochs:126.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.92     0 278.3  1067       0          0 76.67  360   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00248    .1209 6.106 .0002087 4.995e-05 122.1 468.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1260 400.4 1535 3.852            1\n\n01:59:01 | running eval: valid\n01:59:01 | eval completed in 0.21s\n01:59:01 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1607       0          0 126.8   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 1.083 4.995e-05    72 760.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1260  224 2368        .8748\n\u001b[0m\nEpoch 00005: reducing learning rate of group 0 to 2.4975e-05.\n01:59:01 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 20\u001b[0m\n01:59:01 | saving model checkpoint: /tmp/model5.checkpoint\n01:59:16 | time:471s total_exs:25960 total_steps:1298 epochs:129.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.97     0 279.4  1040       0          0 74.46  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .002387    .1209 5.987 .000201 2.498e-05 119.7 445.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1298 399.1 1486 3.732            1\n\n01:59:21 | time:476s total_exs:26360 total_steps:1318 epochs:131.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.7     0 273.9  1036       0          0 75.62  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002341    .1209 6.035 .0001966 2.498e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.4       0          0                 1318 394.6 1492 3.797            1\n\n01:59:21 | running eval: valid\n01:59:21 | eval completed in 0.20s\n01:59:21 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1668       0          0 131.7   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6  1.09 2.498e-05    72   790       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1318  224 2458        .8748\n\u001b[0m\n01:59:21 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 21\u001b[0m\n01:59:21 | saving model checkpoint: /tmp/model5.checkpoint\n01:59:36 | time:491s total_exs:27120 total_steps:1356 epochs:135.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.08     0 281.5  1063       0          0 75.54  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002272    .1209 6.005 .0001913 2.498e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   453.6       0          0                 1356 401.6 1517 3.786            1\n\n01:59:42 | time:497s total_exs:27500 total_steps:1375 epochs:137.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.79     0 275.8 992.7       0          0 71.99  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002228    .1192 6.079 .0001873 2.498e-05 121.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   437.6       0          0                 1375 397.4 1430 3.615            1\n\n01:59:42 | running eval: valid\n01:59:42 | eval completed in 0.22s\n01:59:42 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1531       0          0 120.8   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 1.095 2.498e-05    72 724.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1375  224 2256        .8748\n\u001b[0m\n01:59:42 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 22\u001b[0m\n01:59:42 | saving model checkpoint: /tmp/model5.checkpoint\n01:59:57 | time:512s total_exs:28260 total_steps:1413 epochs:141.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.91     0 278.3  1058       0          0 76.03  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002158    .1209 5.942 .0001817 2.498e-05 118.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   451.8       0          0                 1413 397.1 1510 3.81            1\n\n02:00:02 | time:517s total_exs:28660 total_steps:1433 epochs:143.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.23     0 284.6  1069       0          0 75.14  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .002103    .1209  5.96 .000177 2.498e-05 119.2 447.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1433 403.8 1517 3.773            1\n\n02:00:02 | running eval: valid\n02:00:02 | eval completed in 0.20s\n02:00:02 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1676       0          0 132.3   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6   1.1 2.498e-05    72 793.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1433  224 2470        .8748\n\u001b[0m\n02:00:02 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 23\u001b[0m\n02:00:02 | saving model checkpoint: /tmp/model5.checkpoint\n02:00:17 | time:532s total_exs:29420 total_steps:1471 epochs:147.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.68     0 273.6  1030       0          0 75.28  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002063    .1209 6.066 .0001735 2.498e-05 121.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.6       0          0                 1471 394.9 1486 3.773            1\n\n02:00:22 | time:538s total_exs:29860 total_steps:1493 epochs:149.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0 275.9  1053       0          0 76.36  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002006    .1209 6.045 .0001687 2.498e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.6       0          0                 1493 396.8 1515 3.833            1\n\n02:00:22 | running eval: valid\n02:00:23 | eval completed in 0.23s\n02:00:23 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1500       0          0 118.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6 1.107 2.498e-05    72 710.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1493  224 2211        .8748\n\u001b[0m\nEpoch 00009: reducing learning rate of group 0 to 1.2488e-05.\n02:00:23 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 24\u001b[0m\n02:00:23 | saving model checkpoint: /tmp/model5.checkpoint\n02:00:37 | time:552s total_exs:30620 total_steps:1531 epochs:153.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.78     0 275.5  1043       0          0 75.74  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001967    .1209 6.021 .0001655 1.249e-05 120.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.1       0          0                 1531 395.9 1499 3.796            1\n\n02:00:43 | time:558s total_exs:31080 total_steps:1554 epochs:155.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.26     0 285.2  1112       0          0 77.98  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001945    .1209 5.983 .0001628 1.249e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   466.5       0          0                 1554 404.9 1579 3.914            1\n\n02:00:43 | running eval: valid\n02:00:43 | eval completed in 0.22s\n02:00:43 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1649       0          0 130.1   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 1.108 1.249e-05    72 780.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1554  224 2429        .8748\n\u001b[0m\n02:00:43 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 25\u001b[0m\n02:00:43 | saving model checkpoint: /tmp/model5.checkpoint\n02:00:58 | time:573s total_exs:31840 total_steps:1592 epochs:159.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.59     0 271.8  1030       0          0 75.83  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001914    .1209 5.995 .0001609 1.249e-05 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   454.6       0          0                 1592 391.7 1485  3.8            1\n\n02:01:03 | time:579s total_exs:32240 total_steps:1612 epochs:161.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.25     0 284.9  1092       0          0 76.62  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001888    .1209  6.04 .0001589 1.249e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   462.8       0          0                 1612 405.8 1554 3.848            1\n\n02:01:03 | running eval: valid\n02:01:03 | eval completed in 0.20s\n02:01:03 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1688       0          0 133.2   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 1.113 1.249e-05    72 799.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1612  224 2487        .8748\n\u001b[0m\n02:01:03 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 26\u001b[0m\n02:01:03 | saving model checkpoint: /tmp/model5.checkpoint\n02:01:18 | time:593s total_exs:33000 total_steps:1650 epochs:165.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.78     0 275.6  1027       0          0 74.53  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001857    .1209 5.976 .0001563 1.249e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   445.4       0          0                 1650 395.1 1472 3.735            1\n\n02:01:24 | time:599s total_exs:33420 total_steps:1671 epochs:167.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.64     0 272.7  1053       0          0 77.25  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .00183    .1192     6 .000154 1.249e-05   120 463.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1671 392.7 1517 3.879            1\n\n02:01:24 | running eval: valid\n02:01:24 | eval completed in 0.20s\n02:01:24 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1678       0          0 132.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 1.117 1.249e-05    72 794.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1671  224 2472        .8748\n\u001b[0m\n02:01:24 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 27\u001b[0m\n02:01:24 | saving model checkpoint: /tmp/model5.checkpoint\n02:01:38 | time:613s total_exs:34180 total_steps:1709 epochs:170.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.86     0 277.1  1038       0          0 74.92  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001811    .1210 6.039 .0001523 1.249e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   452.5       0          0                 1709 397.9 1491 3.754            1\n\n02:01:44 | time:619s total_exs:34620 total_steps:1731 epochs:173.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.53     0 270.5  1031       0          0 76.21  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001782    .1192 6.014 .0001499 1.249e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.3       0          0                 1731 390.8 1489 3.826            1\n\n02:01:44 | running eval: valid\n02:01:44 | eval completed in 0.22s\n02:01:44 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1533       0          0   121   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 1.121 1.249e-05    72 726.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1731  224 2259        .8748\n\u001b[0m\nEpoch 00013: reducing learning rate of group 0 to 6.2438e-06.\n02:01:44 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 28\u001b[0m\n02:01:44 | saving model checkpoint: /tmp/model5.checkpoint\n02:01:59 | time:634s total_exs:35380 total_steps:1769 epochs:176.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.78     0 275.6  1035       0          0 75.09  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001764    .1210 6.024 .0001483 6.244e-06 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   452.3       0          0                 1769 396.1 1487 3.763            1\n\n02:02:04 | time:640s total_exs:35800 total_steps:1790 epochs:179.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.2  1029       0          0 75.08  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001751    .1210  6.01 .0001472 6.244e-06 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.2       0          0                 1790 394.4 1481 3.769            1\n\n02:02:04 | running eval: valid\n02:02:05 | eval completed in 0.20s\n02:02:05 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1698       0          0   134   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 1.124 6.244e-06    72 804.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1790  224 2502        .8748\n\u001b[0m\n02:02:05 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 29\u001b[0m\n02:02:05 | saving model checkpoint: /tmp/model5.checkpoint\n02:02:19 | time:654s total_exs:36560 total_steps:1828 epochs:182.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.3  1039       0          0 75.77  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001733    .1210 5.974 .0001458 6.244e-06 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   452.6       0          0                 1828 393.7 1492 3.797            1\n\n02:02:25 | time:660s total_exs:36980 total_steps:1849 epochs:184.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.82     0 276.5  1010       0          0 73.03  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001726    .1210 6.029 .0001451 6.244e-06 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   440.2       0          0                 1849  397 1450 3.666            1\n\n02:02:25 | running eval: valid\n02:02:25 | eval completed in 0.21s\n02:02:25 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1613       0          0 127.3   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08122     6 1.125 6.244e-06    72 763.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1849  224 2377        .8748\n\u001b[0m\n02:02:25 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 30\u001b[0m\n02:02:25 | saving model checkpoint: /tmp/model5.checkpoint\n02:02:29 | ran out of patience! stopping training.\n02:02:29 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n02:02:29 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n02:02:29 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run5/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n02:02:29 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n02:02:29 | Using CUDA\n02:02:29 | loading dictionary from /tmp/model5.dict\n02:02:29 | num words = 54944\n02:02:34 | Loading existing model parameters from /tmp/model5\n02:02:41 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:02:43 | creating task(s): fromfile:parlaiformat\n02:02:43 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run5/data_valid.txt\n02:02:43 | running eval: valid\n02:02:43 | eval completed in 0.31s\n02:02:43 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9565                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9600              .9231   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1113       0          0 87.87   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297     6 .4971 5.204e-06    72 527.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    104  224 1641        .9583\n\u001b[0m\n02:02:43 | creating task(s): fromfile:parlaiformat\n02:02:43 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run5/data_test.txt\n02:02:43 | running eval: test\n02:02:48 | eval completed in 5.03s\n02:02:48 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9110 9.11e-10               .6787                 .5311   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9400            .9483              .9927   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9078 12.07 281.4  2809       0          0 199.6 1000 .9110   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297   5.2 .4713 5.204e-06   104  1038       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    104 385.4 3847        .9214\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr1type2/run5/data_test.txt -m transformer/classifier -mf /tmp/model5 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:02:50.193633Z","iopub.execute_input":"2022-12-04T02:02:50.194083Z","iopub.status.idle":"2022-12-04T02:03:20.238576Z","shell.execute_reply.started":"2022-12-04T02:02:50.194037Z","shell.execute_reply":"2022-12-04T02:03:20.237329Z"},"scrolled":true,"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"02:02:59 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr1type2/run5/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr1type2/run5/data)\u001b[0m\n02:02:59 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n02:02:59 | Using CUDA\n02:02:59 | loading dictionary from /tmp/model5.dict\n02:02:59 | num words = 54944\n02:03:03 | Loading existing model parameters from /tmp/model5\n02:03:09 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:03:10 | Opt:\n02:03:10 |     activation: gelu\n02:03:10 |     adafactor_eps: '[1e-30, 0.001]'\n02:03:10 |     adam_eps: 1e-08\n02:03:10 |     add_p1_after_newln: False\n02:03:10 |     aggregate_micro: False\n02:03:10 |     allow_missing_init_opts: False\n02:03:10 |     area_under_curve_class: None\n02:03:10 |     area_under_curve_digits: -1\n02:03:10 |     attention_dropout: 0.1\n02:03:10 |     batchsize: 40\n02:03:10 |     betas: '[0.9, 0.999]'\n02:03:10 |     bpe_add_prefix_space: None\n02:03:10 |     bpe_debug: False\n02:03:10 |     bpe_dropout: None\n02:03:10 |     bpe_merge: None\n02:03:10 |     bpe_vocab: None\n02:03:10 |     candidates: inline\n02:03:10 |     cap_num_predictions: 100\n02:03:10 |     checkpoint_activations: False\n02:03:10 |     class_weights: None\n02:03:10 |     classes: \"['__notok__', '__ok__']\"\n02:03:10 |     classes_from_file: None\n02:03:10 |     data_parallel: True\n02:03:10 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n02:03:10 |     datatype: train\n02:03:10 |     delimiter: '\\n'\n02:03:10 |     dict_class: parlai.core.dict:DictionaryAgent\n02:03:10 |     dict_endtoken: __start__\n02:03:10 |     dict_file: /tmp/model5.dict\n02:03:10 |     dict_include_test: False\n02:03:10 |     dict_include_valid: False\n02:03:10 |     dict_initpath: None\n02:03:10 |     dict_language: english\n02:03:10 |     dict_loaded: True\n02:03:10 |     dict_lower: True\n02:03:10 |     dict_max_ngram_size: -1\n02:03:10 |     dict_maxexs: -1\n02:03:10 |     dict_maxtokens: -1\n02:03:10 |     dict_minfreq: 0\n02:03:10 |     dict_nulltoken: __null__\n02:03:10 |     dict_starttoken: __start__\n02:03:10 |     dict_textfields: text,labels\n02:03:10 |     dict_tokenizer: bpe\n02:03:10 |     dict_unktoken: __unk__\n02:03:10 |     display_examples: False\n02:03:10 |     download_path: None\n02:03:10 |     dropout: 0.1\n02:03:10 |     dynamic_batching: None\n02:03:10 |     embedding_projection: random\n02:03:10 |     embedding_size: 768\n02:03:10 |     embedding_type: random\n02:03:10 |     embeddings_scale: False\n02:03:10 |     encode_candidate_vecs: True\n02:03:10 |     encode_candidate_vecs_batchsize: 256\n02:03:10 |     eval_batchsize: None\n02:03:10 |     eval_candidates: inline\n02:03:10 |     eval_dynamic_batching: None\n02:03:10 |     evaltask: None\n02:03:10 |     ffn_size: 3072\n02:03:10 |     final_extra_opt: \n02:03:10 |     fixed_candidate_vecs: reuse\n02:03:10 |     fixed_candidates_path: None\n02:03:10 |     force_fp16_tokens: True\n02:03:10 |     fp16: True\n02:03:10 |     fp16_impl: safe\n02:03:10 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr1type2/run5/data_test.txt\n02:03:10 |     fromfile_datatype_extension: True\n02:03:10 |     gpu: -1\n02:03:10 |     gradient_clip: 0.1\n02:03:10 |     hide_labels: False\n02:03:10 |     history_add_global_end_token: None\n02:03:10 |     history_reversed: False\n02:03:10 |     history_size: 20\n02:03:10 |     ignore_bad_candidates: False\n02:03:10 |     ignore_labels: None\n02:03:10 |     image_cropsize: 224\n02:03:10 |     image_mode: raw\n02:03:10 |     image_size: 256\n02:03:10 |     inference: max\n02:03:10 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:03:10 |     init_opt: None\n02:03:10 |     interactive_candidates: fixed\n02:03:10 |     interactive_mode: False\n02:03:10 |     invsqrt_lr_decay_gamma: -1\n02:03:10 |     is_debug: False\n02:03:10 |     label_truncate: 72\n02:03:10 |     learn_embeddings: True\n02:03:10 |     learn_positional_embeddings: True\n02:03:10 |     learningrate: 5e-05\n02:03:10 |     load_from_pretrained_ranker: True\n02:03:10 |     log_every_n_secs: 10.0\n02:03:10 |     log_every_n_steps: 50\n02:03:10 |     log_keep_fields: all\n02:03:10 |     loglevel: info\n02:03:10 |     lr_scheduler: reduceonplateau\n02:03:10 |     lr_scheduler_decay: 0.5\n02:03:10 |     lr_scheduler_patience: 3\n02:03:10 |     max_train_steps: -1\n02:03:10 |     max_train_time: 7200.0\n02:03:10 |     memory_attention: sqrt\n02:03:10 |     metrics: default\n02:03:10 |     model: transformer/classifier\n02:03:10 |     model_file: /tmp/model5\n02:03:10 |     model_parallel: False\n02:03:10 |     momentum: 0\n02:03:10 |     multitask_weights: [1]\n02:03:10 |     mutators: None\n02:03:10 |     n_decoder_layers: -1\n02:03:10 |     n_encoder_layers: -1\n02:03:10 |     n_heads: 12\n02:03:10 |     n_layers: 12\n02:03:10 |     n_positions: 1024\n02:03:10 |     n_segments: 2\n02:03:10 |     nesterov: True\n02:03:10 |     no_cuda: False\n02:03:10 |     normalize_sent_emb: False\n02:03:10 |     num_epochs: -1\n02:03:10 |     num_examples: -1\n02:03:10 |     num_workers: 0\n02:03:10 |     nus: [0.7]\n02:03:10 |     optimizer: adamax\n02:03:10 |     output_scaling: 0.06\n02:03:10 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr1type2/run5/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model5', 'batchsize': 40}\"\n02:03:10 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n02:03:10 |     person_tokens: False\n02:03:10 |     print_scores: False\n02:03:10 |     rank_candidates: False\n02:03:10 |     rank_top_k: -1\n02:03:10 |     reduction_type: mean\n02:03:10 |     ref_class: None\n02:03:10 |     relu_dropout: 0.0\n02:03:10 |     repeat_blocking_heuristic: True\n02:03:10 |     report_filename: \n02:03:10 |     return_cand_scores: False\n02:03:10 |     save_after_valid: True\n02:03:10 |     save_every_n_secs: -1\n02:03:10 |     save_format: conversations\n02:03:10 |     share_encoders: False\n02:03:10 |     share_word_embeddings: False\n02:03:10 |     short_final_eval: False\n02:03:10 |     special_tok_lst: None\n02:03:10 |     split_lines: False\n02:03:10 |     starttime: Dec04_01-51\n02:03:10 |     task: fromfile:parlaiformat\n02:03:10 |     tensorboard_log: False\n02:03:10 |     tensorboard_logdir: None\n02:03:10 |     text_truncate: 360\n02:03:10 |     threshold: 0.5\n02:03:10 |     topk: 5\n02:03:10 |     train_predict: False\n02:03:10 |     truncate: 1024\n02:03:10 |     update_classifier_head_only: False\n02:03:10 |     update_freq: 1\n02:03:10 |     use_memories: False\n02:03:10 |     use_reply: none\n02:03:10 |     validation_cutoff: 1.0\n02:03:10 |     validation_every_n_epochs: -1\n02:03:10 |     validation_every_n_secs: 20.0\n02:03:10 |     validation_every_n_steps: -1\n02:03:10 |     validation_max_exs: -1\n02:03:10 |     validation_metric: accuracy\n02:03:10 |     validation_metric_mode: max\n02:03:10 |     validation_patience: 30\n02:03:10 |     validation_share_agent: False\n02:03:10 |     variant: xlm\n02:03:10 |     verbose: False\n02:03:10 |     wandb_entity: None\n02:03:10 |     wandb_log: False\n02:03:10 |     wandb_name: None\n02:03:10 |     wandb_project: None\n02:03:10 |     warmup_rate: 0.0001\n02:03:10 |     warmup_updates: 1000\n02:03:10 |     weight_decay: None\n02:03:10 |     world_logs: \n02:03:10 |     wrap_memory_encoder: False\n02:03:10 | Evaluating task fromfile:parlaiformat using datatype valid.\n02:03:10 | creating task(s): fromfile:parlaiformat\n02:03:10 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n02:03:10 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr1type2/run5/data_test.txt\n02:03:18 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9110 9.11e-10               .6787                 .5311   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9400            .9483              .9927   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9078 12.07 562.9  1918       0          0 136.3 1000 .9110   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .4713 5.204e-06   208 708.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    104 770.9 2627        .9214\u001b[0m\n02:03:18 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9110 9.11e-10               .6787                 .5311   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9400            .9483              .9927   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9078 12.07 562.9  1918       0          0 136.3 1000 .9110   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .4713 5.204e-06   208 708.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    104 770.9 2627        .9214\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model5*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:03:20.240284Z","iopub.execute_input":"2022-12-04T02:03:20.241025Z","iopub.status.idle":"2022-12-04T02:03:21.493796Z","shell.execute_reply.started":"2022-12-04T02:03:20.240981Z","shell.execute_reply":"2022-12-04T02:03:21.492502Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":"# Actual work prev2corr2type1","metadata":{}},{"cell_type":"markdown","source":"run 1","metadata":{}},{"cell_type":"code","source":"# run 1 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type1/run1/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model1","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:03:21.507089Z","iopub.execute_input":"2022-12-04T02:03:21.508151Z","iopub.status.idle":"2022-12-04T02:15:09.404673Z","shell.execute_reply.started":"2022-12-04T02:03:21.508102Z","shell.execute_reply":"2022-12-04T02:15:09.403474Z"},"scrolled":true,"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"02:03:28 | building dictionary first...\n02:03:28 | No model with opt yet at: /tmp/model1(.opt)\n02:03:28 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run1/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n02:03:28 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n02:03:28 | Using CUDA\n02:03:28 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n02:03:29 | num words = 54944\n02:03:33 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:03:43 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:03:43 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n02:03:43 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n02:03:43 | Opt:\n02:03:43 |     activation: gelu\n02:03:43 |     adafactor_eps: '(1e-30, 0.001)'\n02:03:43 |     adam_eps: 1e-08\n02:03:43 |     add_p1_after_newln: False\n02:03:43 |     aggregate_micro: False\n02:03:43 |     allow_missing_init_opts: False\n02:03:43 |     attention_dropout: 0.1\n02:03:43 |     batchsize: 20\n02:03:43 |     betas: '(0.9, 0.999)'\n02:03:43 |     bpe_add_prefix_space: None\n02:03:43 |     bpe_debug: False\n02:03:43 |     bpe_dropout: None\n02:03:43 |     bpe_merge: None\n02:03:43 |     bpe_vocab: None\n02:03:43 |     candidates: inline\n02:03:43 |     cap_num_predictions: 100\n02:03:43 |     checkpoint_activations: False\n02:03:43 |     class_weights: None\n02:03:43 |     classes: \"['__notok__', '__ok__']\"\n02:03:43 |     classes_from_file: None\n02:03:43 |     data_parallel: True\n02:03:43 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n02:03:43 |     datatype: train\n02:03:43 |     delimiter: '\\n'\n02:03:43 |     dict_class: parlai.core.dict:DictionaryAgent\n02:03:43 |     dict_endtoken: __start__\n02:03:43 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n02:03:43 |     dict_include_test: False\n02:03:43 |     dict_include_valid: False\n02:03:43 |     dict_initpath: None\n02:03:43 |     dict_language: english\n02:03:43 |     dict_loaded: True\n02:03:43 |     dict_lower: True\n02:03:43 |     dict_max_ngram_size: -1\n02:03:43 |     dict_maxexs: -1\n02:03:43 |     dict_maxtokens: -1\n02:03:43 |     dict_minfreq: 0\n02:03:43 |     dict_nulltoken: __null__\n02:03:43 |     dict_starttoken: __start__\n02:03:43 |     dict_textfields: text,labels\n02:03:43 |     dict_tokenizer: bpe\n02:03:43 |     dict_unktoken: __unk__\n02:03:43 |     display_examples: False\n02:03:43 |     download_path: None\n02:03:43 |     dropout: 0.1\n02:03:43 |     dynamic_batching: None\n02:03:43 |     embedding_projection: random\n02:03:43 |     embedding_size: 768\n02:03:43 |     embedding_type: random\n02:03:43 |     embeddings_scale: False\n02:03:43 |     encode_candidate_vecs: True\n02:03:43 |     encode_candidate_vecs_batchsize: 256\n02:03:43 |     eval_batchsize: None\n02:03:43 |     eval_candidates: inline\n02:03:43 |     eval_dynamic_batching: None\n02:03:43 |     evaltask: None\n02:03:43 |     ffn_size: 3072\n02:03:43 |     final_extra_opt: \n02:03:43 |     fixed_candidate_vecs: reuse\n02:03:43 |     fixed_candidates_path: None\n02:03:43 |     force_fp16_tokens: False\n02:03:43 |     fp16: True\n02:03:43 |     fp16_impl: safe\n02:03:43 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run1/data\n02:03:43 |     fromfile_datatype_extension: True\n02:03:43 |     gpu: -1\n02:03:43 |     gradient_clip: 0.1\n02:03:43 |     hide_labels: False\n02:03:43 |     history_add_global_end_token: None\n02:03:43 |     history_reversed: False\n02:03:43 |     history_size: 20\n02:03:43 |     ignore_bad_candidates: False\n02:03:43 |     ignore_labels: None\n02:03:43 |     image_cropsize: 224\n02:03:43 |     image_mode: raw\n02:03:43 |     image_size: 256\n02:03:43 |     inference: max\n02:03:43 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:03:43 |     init_opt: None\n02:03:43 |     interactive_candidates: fixed\n02:03:43 |     interactive_mode: False\n02:03:43 |     invsqrt_lr_decay_gamma: -1\n02:03:43 |     is_debug: False\n02:03:43 |     label_truncate: 72\n02:03:43 |     learn_embeddings: True\n02:03:43 |     learn_positional_embeddings: True\n02:03:43 |     learningrate: 5e-05\n02:03:43 |     load_from_checkpoint: False\n02:03:43 |     load_from_pretrained_ranker: True\n02:03:43 |     log_every_n_secs: 10.0\n02:03:43 |     log_every_n_steps: 50\n02:03:43 |     log_keep_fields: all\n02:03:43 |     loglevel: info\n02:03:43 |     lr_scheduler: reduceonplateau\n02:03:43 |     lr_scheduler_decay: 0.5\n02:03:43 |     lr_scheduler_patience: 3\n02:03:43 |     max_train_steps: -1\n02:03:43 |     max_train_time: 7200.0\n02:03:43 |     memory_attention: sqrt\n02:03:43 |     metrics: default\n02:03:43 |     model: transformer/classifier\n02:03:43 |     model_file: /tmp/model1\n02:03:43 |     model_parallel: False\n02:03:43 |     momentum: 0\n02:03:43 |     multitask_weights: [1]\n02:03:43 |     mutators: None\n02:03:43 |     n_decoder_layers: -1\n02:03:43 |     n_encoder_layers: -1\n02:03:43 |     n_heads: 12\n02:03:43 |     n_layers: 12\n02:03:43 |     n_positions: 1024\n02:03:43 |     n_segments: 2\n02:03:43 |     nesterov: True\n02:03:43 |     no_cuda: False\n02:03:43 |     normalize_sent_emb: False\n02:03:43 |     num_epochs: -1\n02:03:43 |     num_workers: 0\n02:03:43 |     nus: (0.7,)\n02:03:43 |     optimizer: adamax\n02:03:43 |     output_scaling: 0.06\n02:03:43 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type1/run1/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model1'}\"\n02:03:43 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n02:03:43 |     person_tokens: False\n02:03:43 |     print_scores: False\n02:03:43 |     rank_candidates: False\n02:03:43 |     rank_top_k: -1\n02:03:43 |     reduction_type: mean\n02:03:43 |     ref_class: None\n02:03:43 |     relu_dropout: 0.0\n02:03:43 |     repeat_blocking_heuristic: True\n02:03:43 |     return_cand_scores: False\n02:03:43 |     save_after_valid: True\n02:03:43 |     save_every_n_secs: -1\n02:03:43 |     save_format: conversations\n02:03:43 |     share_encoders: False\n02:03:43 |     share_word_embeddings: False\n02:03:43 |     short_final_eval: False\n02:03:43 |     special_tok_lst: None\n02:03:43 |     split_lines: False\n02:03:43 |     starttime: Dec04_02-03\n02:03:43 |     task: fromfile:parlaiformat\n02:03:43 |     tensorboard_log: False\n02:03:43 |     tensorboard_logdir: None\n02:03:43 |     text_truncate: 360\n02:03:43 |     threshold: 0.5\n02:03:43 |     topk: 5\n02:03:43 |     train_predict: False\n02:03:43 |     truncate: 1024\n02:03:43 |     update_classifier_head_only: False\n02:03:43 |     update_freq: 1\n02:03:43 |     use_memories: False\n02:03:43 |     use_reply: none\n02:03:43 |     validation_cutoff: 1.0\n02:03:43 |     validation_every_n_epochs: -1\n02:03:43 |     validation_every_n_secs: 20.0\n02:03:43 |     validation_every_n_steps: -1\n02:03:43 |     validation_max_exs: -1\n02:03:43 |     validation_metric: accuracy\n02:03:43 |     validation_metric_mode: max\n02:03:43 |     validation_patience: 30\n02:03:43 |     validation_share_agent: False\n02:03:43 |     variant: xlm\n02:03:43 |     verbose: False\n02:03:43 |     wandb_entity: None\n02:03:43 |     wandb_log: False\n02:03:43 |     wandb_name: None\n02:03:43 |     wandb_project: None\n02:03:43 |     warmup_rate: 0.0001\n02:03:43 |     warmup_updates: 1000\n02:03:43 |     weight_decay: None\n02:03:43 |     world_logs: \n02:03:43 |     wrap_memory_encoder: False\n02:03:44 | creating task(s): fromfile:parlaiformat\n02:03:44 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run1/data_train.txt\n02:03:44 | training...\n02:03:54 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .5650 5.65e-10               .6588                 .5472   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8276            .4000              .6237   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .2944  11.2     1 264.1 525.2       0          0 39.78  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5650             32768  2.367    .1189 6.015 .6854 1.005e-06 120.3 239.3   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 384.4 764.5 1.994        .5314\n\n02:04:04 | time:20s total_exs:1140 total_steps:57 epochs:5.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7081 7.081e-10               .7562                 .6530   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8981            .6364              .8326   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .5150 11.19     1 263.9 999.4       0          0 75.75  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7081             32768  2.564    .1189 6.008 .6537 2.855e-06 120.2 455.1   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                   57  384 1455 3.796        .6968\n\n02:04:04 | creating task(s): fromfile:parlaiformat\n02:04:04 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run1/data_valid.txt\n02:04:04 | running eval: valid\n02:04:04 | eval completed in 0.21s\n02:04:04 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7500                 .7500   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .7500              .7500   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.46 161.5  1690       0          0 125.5   24 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6384 2.855e-06    72 753.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     57 233.5 2443        .7500\n\u001b[0m\n02:04:04 | \u001b[1;32mnew best accuracy: 0.75\u001b[0m\n02:04:04 | saving best valid model: /tmp/model1\n02:04:04 | Saving dictionary to /tmp/model1.dict\n02:04:08 | saving model checkpoint: /tmp/model1.checkpoint\n02:04:08 | Saving dictionary to /tmp/model1.checkpoint.dict\n02:04:24 | time:40s total_exs:1860 total_steps:93 epochs:9.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9028 9.028e-10               .9036                 .8865   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9213            .9020              .9200   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8846 10.66     1 253.3 895.6       0          0 70.72  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9028             32768  2.862    .1189 5.989 .5788 4.655e-06 119.8 423.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   93 373.1 1319 3.544        .9028\n\n02:04:28 | time:44s total_exs:2120 total_steps:106 epochs:10.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9538 9.538e-10               .9559                 .9489   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9630            .9516              .9593   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9440  11.2     1 264.1 964.4       0          0 73.04  260   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9538             32768  3.525    .1189 6.038 .4763 5.304e-06 120.8 441.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  106 384.8 1405 3.675        .9538\n\n02:04:28 | running eval: valid\n02:04:28 | eval completed in 0.20s\n02:04:28 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1789       0          0 132.9   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5059 5.304e-06    72 797.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    106 233.5 2586        .8322\n\u001b[0m\n02:04:28 | \u001b[1;32mnew best accuracy: 0.8333 (previous best was 0.75)\u001b[0m\n02:04:28 | saving best valid model: /tmp/model1\n02:04:33 | saving model checkpoint: /tmp/model1.checkpoint\n02:04:52 | time:68s total_exs:2900 total_steps:145 epochs:14.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9654 9.654e-10               .9642                 .9785   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9504            .9665              .9534   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9798 11.15     1   263  1011       0          0 76.89  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9654             32768  4.097    .1189 5.982 .3096 7.254e-06 119.6   460   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  145 382.7 1471 3.853        .9654\n\n02:04:53 | time:69s total_exs:3000 total_steps:150 epochs:15.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9800 9.8e-10               .9792                 .9592   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9808                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9623 11.74     1 274.8  1082       0          0 78.76  100   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9800             32768  3.154    .1189  5.94 .1634 7.504e-06 118.8 467.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  150 393.6 1550 4.009        .9800\n\n02:04:53 | running eval: valid\n02:04:53 | eval completed in 0.20s\n02:04:53 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1786       0          0 132.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .3402 7.504e-06    72   796       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    150 233.5 2582        .8322\n\u001b[0m\n02:04:53 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 1\u001b[0m\n02:04:53 | saving model checkpoint: /tmp/model1.checkpoint\n02:05:13 | time:89s total_exs:3760 total_steps:188 epochs:18.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9842 9.842e-10               .9842                 .9868   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9816            .9843              .9817   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9868 11.18     1 263.6 995.6       0          0 75.55  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9842             32768  4.723    .1190     6 .0933 9.404e-06   120 453.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  188 383.6 1449 3.786        .9842\n\n02:05:13 | time:90s total_exs:3800 total_steps:190 epochs:19.00\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9750 9.75e-10               .9714                 .9444   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9778                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9565  11.2     1   264  1013       0          0 76.75   40   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9750             32768  4.871    .1190  5.85 .08278 9.504e-06   117   449   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  190  381 1462 4.009        .9751\n\n02:05:13 | running eval: valid\n02:05:14 | eval completed in 0.20s\n02:05:14 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1774       0          0 131.8   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .4928 9.504e-06    72 790.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    190 233.5 2565        .7884\n\u001b[0m\n02:05:14 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 2\u001b[0m\n02:05:14 | saving model checkpoint: /tmp/model1.checkpoint\n02:05:28 | time:104s total_exs:4580 total_steps:229 epochs:22.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9987                 .9975   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9987                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9974 10.96 .5641 259.3 995.2       0          0 76.77  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9987             32768  .6514    .1190 6.021 .01164 1.145e-05 120.4 462.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  229 379.7 1457 3.847        .9987\n\n02:05:34 | time:110s total_exs:4980 total_steps:249 epochs:24.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9975 9.975e-10               .9977                 .9953   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9973                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9946 11.03 .1500 260.6   947       0          0 72.66  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9975             32768  5.533    .1190  6.07 .007373 1.245e-05 121.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   441.1       0          0                  249 382.1 1388 3.648        .9975\n\n02:05:34 | running eval: valid\n02:05:34 | eval completed in 0.20s\n02:05:34 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1782       0          0 132.4   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 1.052 1.245e-05    72 794.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    249 233.5 2577        .7884\n\u001b[0m\n02:05:34 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 3\u001b[0m\n02:05:34 | saving model checkpoint: /tmp/model1.checkpoint\n02:05:48 | time:124s total_exs:5740 total_steps:287 epochs:28.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 10.95 .02632   259 984.1       0          0 75.99   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    760   1             32768 .05457    .1190 5.997 .002141 1.435e-05 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   455.7       0          0                  287 378.9 1440 3.808            1\n\n02:05:54 | time:130s total_exs:6200 total_steps:310 epochs:31.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.16 .04348 263.2  1013       0          0 76.95   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  \\\n    460   1             32768 .02749    .1190 5.974 .001694 1.55e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.7       0          0                  310 382.7 1472 3.862            1\n\n02:05:54 | running eval: valid\n02:05:54 | eval completed in 0.20s\n02:05:54 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1775       0          0 131.9   24 .7917   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 1.215 1.55e-05    72 791.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    310 233.5 2567        .7884\n\u001b[0m\n02:05:54 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 4\u001b[0m\n02:05:54 | saving model checkpoint: /tmp/model1.checkpoint\n02:06:09 | time:145s total_exs:6960 total_steps:348 epochs:34.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.31 .02632 266.2 994.3       0          0  74.7   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  \\\n    760   1             32768  .2471    .1190 5.989 .00154 1.74e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   447.4       0          0                  348  386 1442 3.743            1\n\n02:06:14 | time:151s total_exs:7400 total_steps:370 epochs:37.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.97     0 259.5  1009       0          0 77.76  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .01555    .1190 6.032 .001328 1.85e-05 120.6   469   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  370 380.1 1478 3.903            1\n\n02:06:14 | running eval: valid\n02:06:15 | eval completed in 0.22s\n02:06:15 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1637       0          0 121.5   24 .7917   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6  1.33 1.85e-05    72 729.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    370 233.5 2366        .7884\n\u001b[0m\n02:06:15 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 5\u001b[0m\n02:06:15 | saving model checkpoint: /tmp/model1.checkpoint\n02:06:29 | time:165s total_exs:8180 total_steps:409 epochs:40.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.42     0 268.4  1026       0          0 76.48  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01425    .1190 6.013 .001218 2.045e-05 120.3 459.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  409 388.7 1486 3.833            1\n\n02:06:35 | time:171s total_exs:8600 total_steps:430 epochs:43.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.14     0 262.8 992.4       0          0 75.52  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .01325    .1190 6.057 .001132 2.15e-05 121.1 457.4   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  430  384 1450 3.791            1\n\n02:06:35 | running eval: valid\n02:06:35 | eval completed in 0.20s\n02:06:35 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1760       0          0 130.7   24 .7917   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08095     6 1.293 2.15e-05    72 784.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    430 233.5 2545        .7884\n\u001b[0m\n02:06:35 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 6\u001b[0m\n02:06:35 | saving model checkpoint: /tmp/model1.checkpoint\n02:06:50 | time:186s total_exs:9380 total_steps:469 epochs:46.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.03     0 260.5  1004       0          0 77.07  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01258    .1190 5.997 .001061 2.345e-05 119.9 462.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  469 380.5 1466 3.862            1\n\n02:06:55 | time:191s total_exs:9820 total_steps:491 epochs:49.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.11     0 262.3  1031       0          0 78.58  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01164    .1190 5.995 .0009934 2.455e-05 119.9 471.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  491 382.2 1502 3.945            1\n\n02:06:55 | running eval: valid\n02:06:55 | eval completed in 0.20s\n02:06:55 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1808       0          0 134.3   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 1.406 2.455e-05    72 806.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    491 233.5 2615        .7884\n\u001b[0m\n02:06:55 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 7\u001b[0m\n02:06:55 | saving model checkpoint: /tmp/model1.checkpoint\n02:07:10 | time:206s total_exs:10580 total_steps:529 epochs:52.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.22     0 264.4 996.4       0          0 75.38  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01092    .1190 5.987 .000932 2.645e-05 119.7 451.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  529 384.1 1448 3.777            1\n\n02:07:16 | time:212s total_exs:11020 total_steps:551 epochs:55.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.08     0 261.7  1021       0          0    78  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01029    .1190 5.995 .0008762 2.755e-05 119.9 467.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  551 381.6 1488 3.915            1\n\n02:07:16 | running eval: valid\n02:07:16 | eval completed in 0.20s\n02:07:16 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1764       0          0   131   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 1.474 2.755e-05    72 786.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    551 233.5 2550        .7884\n\u001b[0m\n02:07:16 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 8\u001b[0m\n02:07:16 | saving model checkpoint: /tmp/model1.checkpoint\n02:07:30 | time:226s total_exs:11800 total_steps:590 epochs:59.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.3     0   266  1025       0          0 77.08  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .009647    .1190 5.959 .0008226 2.95e-05 119.2 459.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  590 385.2 1484 3.863            1\n\n02:07:36 | time:232s total_exs:12240 total_steps:612 epochs:61.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.09     0 261.8 993.8       0          0 75.93  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .009048    .1190 6.023 .000771 3.06e-05 120.5 457.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  612 382.2 1451 3.812            1\n\n02:07:36 | running eval: valid\n02:07:36 | eval completed in 0.23s\n02:07:36 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1545       0          0 114.8   24 .7917   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 1.472 3.06e-05    72 688.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    612 233.5 2234        .7884\n\u001b[0m\n02:07:36 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 9\u001b[0m\n02:07:36 | saving model checkpoint: /tmp/model1.checkpoint\n02:07:51 | time:247s total_exs:13020 total_steps:651 epochs:65.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.23     0 264.6  1015       0          0 76.69  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .008507    .1190 6.033 .000724 3.255e-05 120.7 462.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  651 385.3 1477 3.843            1\n\n02:07:56 | time:253s total_exs:13440 total_steps:672 epochs:67.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.05     0   261  1001       0          0 76.66  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768  .0080    .1190 6.048 .0006802 3.36e-05   121 463.6   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  672  382 1464 3.849            1\n\n02:07:56 | running eval: valid\n02:07:57 | eval completed in 0.21s\n02:07:57 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1694       0          0 125.8   24 .7917   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 1.496 3.36e-05    72 755.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    672 233.5 2449        .7884\n\u001b[0m\n02:07:57 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 10\u001b[0m\n02:07:57 | saving model checkpoint: /tmp/model1.checkpoint\n02:08:11 | time:267s total_exs:14180 total_steps:709 epochs:70.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.02     0 260.5 964.1       0          0 74.02  740   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .007582    .1190 6.003 .0006411 3.545e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   444.3       0          0                  709 380.5 1408 3.709            1\n\n02:08:17 | time:273s total_exs:14640 total_steps:732 epochs:73.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.26     0 265.2  1017       0          0 76.67  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .007134    .1190 6.035 .0006014 3.66e-05 120.7 462.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  732 385.9 1479 3.848            1\n\n02:08:17 | running eval: valid\n02:08:17 | eval completed in 0.20s\n02:08:17 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1802       0          0 133.8   24 .7917   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 1.503 3.66e-05    72 803.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    732 233.5 2605        .7884\n\u001b[0m\n02:08:17 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 11\u001b[0m\n02:08:17 | saving model checkpoint: /tmp/model1.checkpoint\n02:08:31 | time:287s total_exs:15400 total_steps:770 epochs:77.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.92     0 258.3 982.1       0          0 76.03  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .006635    .1191 6.045 .0005633 3.85e-05 120.9 459.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  770 379.2 1442 3.81            1\n\n02:08:37 | time:293s total_exs:15860 total_steps:793 epochs:79.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.18     0 263.6  1024       0          0 77.67  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006249    .1191  6.03 .0005289 3.965e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   468.4       0          0                  793 384.2 1492 3.899            1\n\n02:08:37 | running eval: valid\n02:08:37 | eval completed in 0.23s\n02:08:37 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1601       0          0 118.9   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 1.452 3.965e-05    72 713.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    793 233.5 2315        .7884\n\u001b[0m\n02:08:37 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 12\u001b[0m\n02:08:37 | saving model checkpoint: /tmp/model1.checkpoint\n02:08:52 | time:308s total_exs:16620 total_steps:831 epochs:83.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.29     0 265.9  1007       0          0 75.76  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .005843    .1191 5.989 .0004957 4.155e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   453.8       0          0                  831 385.7 1461 3.797            1\n\n02:08:57 | time:314s total_exs:17020 total_steps:851 epochs:85.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.4     0 268.1  1038       0          0 77.41  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .005496    .1191  6.03 .0004659 4.255e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   466.8       0          0                  851 388.7 1504 3.887            1\n\n02:08:57 | running eval: valid\n02:08:58 | eval completed in 0.21s\n02:08:58 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1732       0          0 128.6   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 1.569 4.255e-05    72   772       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    851 233.5 2504        .7884\n\u001b[0m\n02:08:58 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 13\u001b[0m\n02:08:58 | saving model checkpoint: /tmp/model1.checkpoint\n02:09:12 | time:328s total_exs:17780 total_steps:889 epochs:88.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.35     0 266.9 998.4       0          0  74.8  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .005172    .1191     6 .0004382 4.445e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   448.8       0          0                  889 386.9 1447 3.748            1\n\n02:09:18 | time:334s total_exs:18220 total_steps:911 epochs:91.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  10.9     0 257.9  1008       0          0 78.16  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004859    .1191 5.982 .0004113 4.555e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   467.5       0          0                  911 377.5 1475 3.924            1\n\n02:09:18 | running eval: valid\n02:09:18 | eval completed in 0.21s\n02:09:18 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1716       0          0 127.5   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 1.611 4.555e-05    72 764.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    911 233.5 2481        .7884\n\u001b[0m\n02:09:18 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 14\u001b[0m\n02:09:18 | saving model checkpoint: /tmp/model1.checkpoint\n02:09:33 | time:349s total_exs:19000 total_steps:950 epochs:95.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.24     0 264.8  1017       0          0 76.78  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .004554    .1191 6.028 .0003856 4.75e-05 120.6 462.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  950 385.4 1480 3.847            1\n\n02:09:38 | time:354s total_exs:19420 total_steps:971 epochs:97.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.29     0 265.7  1027       0          0  77.3  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004274    .1191 6.043 .0003616 4.855e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   467.1       0          0                  971 386.6 1494 3.881            1\n\n02:09:38 | running eval: valid\n02:09:38 | eval completed in 0.20s\n02:09:38 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1788       0          0 132.8   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 1.652 4.855e-05    72 796.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    971 233.5 2585        .7884\n\u001b[0m\n02:09:38 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 15\u001b[0m\n02:09:38 | saving model checkpoint: /tmp/model1.checkpoint\n02:09:53 | time:369s total_exs:20180 total_steps:1009 epochs:100.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.96     0 259.2 978.3       0          0 75.48  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004027    .1191 5.961 .0003408 4.995e-05 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.9       0          0                 1009 378.4 1428 3.782            1\n\n02:09:59 | time:375s total_exs:20620 total_steps:1031 epochs:103.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.38     0 267.6  1021       0          0 76.32  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003775    .1191 6.027 .0003192 4.995e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     460       0          0                 1031 388.2 1481 3.831            1\n\n02:09:59 | running eval: valid\n02:09:59 | eval completed in 0.19s\n02:09:59 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1842       0          0 136.9   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6  1.65 4.995e-05    72 821.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1031 233.5 2663        .7884\n\u001b[0m\n02:09:59 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 16\u001b[0m\n02:09:59 | saving model checkpoint: /tmp/model1.checkpoint\n02:10:13 | time:389s total_exs:21400 total_steps:1070 epochs:107.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.73     0 254.7 975.1       0          0 76.58  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00355    .1191 6.085 .0003001 4.995e-05 121.7   466   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1070 376.4 1441 3.838            1\n\n02:10:19 | time:395s total_exs:21820 total_steps:1091 epochs:109.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.07     0 261.5   967       0          0 73.97  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003347    .1191 6.095 .0002827 4.995e-05 121.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   450.9       0          0                 1091 383.4 1418 3.713            1\n\n02:10:19 | running eval: valid\n02:10:19 | eval completed in 0.20s\n02:10:19 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1760       0          0 130.8   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 1.687 4.995e-05    72 784.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1091 233.5 2545        .7884\n\u001b[0m\n02:10:19 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 17\u001b[0m\n02:10:19 | saving model checkpoint: /tmp/model1.checkpoint\n02:10:33 | time:410s total_exs:22600 total_steps:1130 epochs:113.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.82     0 256.4 990.4       0          0 77.26  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003164    .1191 5.977 .0002674 4.995e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.8       0          0                 1130 375.9 1452 3.872            1\n\n02:10:39 | time:415s total_exs:23040 total_steps:1152 epochs:115.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.58     0 271.6  1035       0          0 76.22  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002985    .1191  6.05 .0002521 4.995e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.1       0          0                 1152 392.6 1496 3.826            1\n\n02:10:39 | running eval: valid\n02:10:39 | eval completed in 0.20s\n02:10:39 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1812       0          0 134.6   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 1.723 4.995e-05    72 807.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1152 233.5 2620        .7884\n\u001b[0m\n02:10:39 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 18\u001b[0m\n02:10:39 | saving model checkpoint: /tmp/model1.checkpoint\n02:10:54 | time:430s total_exs:23800 total_steps:1190 epochs:119.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.29     0 265.8  1004       0          0 75.51  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002832    .1191 5.939 .0002391 4.995e-05 118.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   448.5       0          0                 1190 384.6 1452 3.784            1\n\n02:11:00 | time:436s total_exs:24260 total_steps:1213 epochs:121.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.55     0 271.1  1061       0          0 78.24  460   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00268    .1191 6.052 .0002263 4.995e-05   121 473.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1213 392.1 1534 3.927            1\n\n02:11:00 | running eval: valid\n02:11:00 | eval completed in 0.23s\n02:11:00 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1628       0          0   121   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 1.753 4.995e-05    72 725.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1213 233.5 2354        .7884\n\u001b[0m\n02:11:00 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 19\u001b[0m\n02:11:00 | saving model checkpoint: /tmp/model1.checkpoint\n02:11:14 | time:450s total_exs:25020 total_steps:1251 epochs:125.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.84     0 256.8 976.8       0          0 76.07  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .002569    .1191 5.968 .000215 4.995e-05 119.4   454   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1251 376.2 1431 3.812            1\n\n02:11:20 | time:456s total_exs:25460 total_steps:1273 epochs:127.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.29     0 265.8  1015       0          0  76.4  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00242    .1191 5.955 .0002042 4.995e-05 119.1 454.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1273 384.9 1470 3.835            1\n\n02:11:20 | running eval: valid\n02:11:20 | eval completed in 0.19s\n02:11:20 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1835       0          0 136.3   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 1.722 4.995e-05    72 818.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1273 233.5 2653        .7884\n\u001b[0m\nEpoch 00005: reducing learning rate of group 0 to 2.4975e-05.\n02:11:20 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 20\u001b[0m\n02:11:20 | saving model checkpoint: /tmp/model1.checkpoint\n02:11:35 | time:471s total_exs:26220 total_steps:1311 epochs:131.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.19     0 263.7  1002       0          0    76  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002343    .1192 5.979 .0001973 2.498e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   454.4       0          0                 1311 383.3 1457 3.809            1\n\n02:11:40 | time:477s total_exs:26660 total_steps:1333 epochs:133.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.09     0 261.8  1027       0          0 78.41  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002282    .1192 5.918 .0001925 2.498e-05 118.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   464.1       0          0                 1333 380.2 1491 3.936            1\n\n02:11:40 | running eval: valid\n02:11:41 | eval completed in 0.20s\n02:11:41 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1815       0          0 134.8   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 1.694 2.498e-05    72 809.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1333 233.5 2624        .7884\n\u001b[0m\n02:11:41 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 21\u001b[0m\n02:11:41 | saving model checkpoint: /tmp/model1.checkpoint\n02:11:55 | time:492s total_exs:27420 total_steps:1371 epochs:137.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.27     0 265.4  1002       0          0  75.5  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002218    .1192 6.055 .0001871 2.498e-05 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.2       0          0                 1371 386.5 1459 3.784            1\n\n02:12:01 | time:497s total_exs:27840 total_steps:1392 epochs:139.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.96     0 259.3 997.3       0          0 76.93  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002168    .1192 6.033 .0001828 2.498e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   464.1       0          0                 1392  380 1461 3.862            1\n\n02:12:01 | running eval: valid\n02:12:01 | eval completed in 0.20s\n02:12:01 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1753       0          0 130.2   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 1.707 2.498e-05    72 781.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1392 233.5 2534        .7884\n\u001b[0m\n02:12:01 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 22\u001b[0m\n02:12:01 | saving model checkpoint: /tmp/model1.checkpoint\n02:12:16 | time:512s total_exs:28620 total_steps:1431 epochs:143.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.16     0 263.2  1003       0          0 76.23  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002114    .1192 6.036 .0001782 2.498e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   460.1       0          0                 1431 383.9 1463 3.82            1\n\n02:12:21 | time:517s total_exs:29040 total_steps:1452 epochs:145.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.02     0 260.5 979.3       0          0  75.2  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002065    .1192 5.995 .0001738 2.498e-05 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   450.8       0          0                 1452 380.4 1430 3.775            1\n\n02:12:21 | running eval: valid\n02:12:21 | eval completed in 0.22s\n02:12:21 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1629       0          0   121   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6 1.754 2.498e-05    72   726       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1452 233.5 2355        .7884\n\u001b[0m\n02:12:21 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 23\u001b[0m\n02:12:21 | saving model checkpoint: /tmp/model1.checkpoint\n02:12:36 | time:532s total_exs:29820 total_steps:1491 epochs:149.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.14     0 262.7  1012       0          0 77.01  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00201    .1192 5.997 .0001695 2.498e-05 119.9 461.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1491 382.7 1473 3.859            1\n\n02:12:42 | time:538s total_exs:30260 total_steps:1513 epochs:151.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.12     0 262.4  1011       0          0 77.02  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001959    .1192 6.045 .0001651 2.498e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   465.6       0          0                 1513 383.3 1476 3.867            1\n\n02:12:42 | running eval: valid\n02:12:42 | eval completed in 0.20s\n02:12:42 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1826       0          0 135.6   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6 1.793 2.498e-05    72   814       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1513 233.5 2640        .7884\n\u001b[0m\nEpoch 00009: reducing learning rate of group 0 to 1.2488e-05.\n02:12:42 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 24\u001b[0m\n02:12:42 | saving model checkpoint: /tmp/model1.checkpoint\n02:12:56 | time:552s total_exs:31020 total_steps:1551 epochs:155.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.93     0 258.6 982.2       0          0 75.96  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001922    .1192 6.076 .0001619 1.249e-05 121.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.6       0          0                 1551 380.1 1444 3.807            1\n\n02:13:02 | time:558s total_exs:31480 total_steps:1574 epochs:157.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.08     0 261.7  1009       0          0  77.1  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n     1             32768 .001899    .1192 6.022 .00016 1.249e-05 120.4 464.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1574 382.1 1473 3.87            1\n\n02:13:02 | running eval: valid\n02:13:02 | eval completed in 0.20s\n02:13:02 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1795       0          0 133.3   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 1.806 1.249e-05    72 800.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1574 233.5 2595        .7884\n\u001b[0m\n02:13:02 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 25\u001b[0m\n02:13:02 | saving model checkpoint: /tmp/model1.checkpoint\n02:13:16 | time:573s total_exs:32240 total_steps:1612 epochs:161.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.23     0 264.6  1003       0          0 75.79  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00187    .1192 6.074 .0001575 1.249e-05 121.5 460.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1612 386.1 1463  3.8            1\n\n02:13:22 | time:578s total_exs:32680 total_steps:1634 epochs:163.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.42     0 268.5  1028       0          0 76.58  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001848    .1192 5.982 .0001557 1.249e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.1       0          0                 1634 388.1 1486 3.844            1\n\n02:13:22 | running eval: valid\n02:13:22 | eval completed in 0.21s\n02:13:22 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1751       0          0 130.1   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 1.821 1.249e-05    72 780.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1634 233.5 2532        .7884\n\u001b[0m\n02:13:22 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 26\u001b[0m\n02:13:22 | saving model checkpoint: /tmp/model1.checkpoint\n02:13:38 | time:594s total_exs:33460 total_steps:1673 epochs:167.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.31     0 266.2  1026       0          0 77.05  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001825    .1192 5.956 .0001538 1.249e-05 119.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.9       0          0                 1673 385.3 1485 3.861            1\n\n02:13:43 | time:599s total_exs:33860 total_steps:1693 epochs:169.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1    11     0 260.1  1019       0          0 78.36  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001796    .1192     6 .0001513 1.249e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   470.2       0          0                 1693 380.1 1489 3.935            1\n\n02:13:43 | running eval: valid\n02:13:43 | eval completed in 0.20s\n02:13:43 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1776       0          0 131.9   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 1.837 1.249e-05    72 791.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1693 233.5 2568        .7884\n\u001b[0m\n02:13:43 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 27\u001b[0m\n02:13:43 | saving model checkpoint: /tmp/model1.checkpoint\n02:13:58 | time:614s total_exs:34620 total_steps:1731 epochs:173.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.14     0 262.7 986.3       0          0 75.09  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001772    .1192 6.008 .0001493 1.249e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.1       0          0                 1731 382.9 1437 3.763            1\n\n02:14:03 | time:619s total_exs:35040 total_steps:1752 epochs:175.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.12     0 262.4  1026       0          0 78.16  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001746    .1192  6.01 .0001471 1.249e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   469.7       0          0                 1752 382.6 1495 3.924            1\n\n02:14:03 | running eval: valid\n02:14:03 | eval completed in 0.22s\n02:14:03 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1659       0          0 123.2   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 1.843 1.249e-05    72 739.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1752 233.5 2398        .7884\n\u001b[0m\nEpoch 00013: reducing learning rate of group 0 to 6.2438e-06.\n02:14:03 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 28\u001b[0m\n02:14:03 | saving model checkpoint: /tmp/model1.checkpoint\n02:14:18 | time:634s total_exs:35820 total_steps:1791 epochs:179.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.23     0 264.7  1015       0          0 76.71  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001729    .1192 6.003 .0001456 6.244e-06 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.5       0          0                 1791 384.7 1476 3.844            1\n\n02:14:23 | time:640s total_exs:36260 total_steps:1813 epochs:181.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.09     0 261.8  1008       0          0 77.02  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001721    .1192 5.923 .000145 6.244e-06 118.5 456.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1813 380.3 1464 3.866            1\n\n02:14:23 | running eval: valid\n02:14:24 | eval completed in 0.20s\n02:14:24 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1791       0          0 133.1   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 1.846 6.244e-06    72 798.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1813 233.5 2590        .7884\n\u001b[0m\n02:14:24 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 29\u001b[0m\n02:14:24 | saving model checkpoint: /tmp/model1.checkpoint\n02:14:38 | time:654s total_exs:37040 total_steps:1852 epochs:185.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.03     0 260.5 999.7       0          0 76.74  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001702    .1193 6.036 .0001434 6.244e-06 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.2       0          0                 1852 381.3 1463 3.846            1\n\n02:14:44 | time:660s total_exs:37460 total_steps:1873 epochs:187.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.87     0 257.3 981.2       0          0 76.26  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001691    .1193     6 .0001424 6.244e-06   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.6       0          0                 1873 377.3 1439 3.829            1\n\n02:14:44 | running eval: valid\n02:14:44 | eval completed in 0.20s\n02:14:44 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .7619                 .8889   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8148              .7333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1789       0          0 132.9   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 1.849 6.244e-06    72 797.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1873 233.5 2586        .7884\n\u001b[0m\n02:14:44 | \u001b[1mdid not beat best accuracy: 0.8333 impatience: 30\u001b[0m\n02:14:44 | saving model checkpoint: /tmp/model1.checkpoint\n02:14:48 | ran out of patience! stopping training.\n02:14:48 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n02:14:48 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n02:14:48 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run1/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n02:14:48 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n02:14:48 | Using CUDA\n02:14:48 | loading dictionary from /tmp/model1.dict\n02:14:48 | num words = 54944\n02:14:53 | Loading existing model parameters from /tmp/model1\n02:15:00 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:15:02 | creating task(s): fromfile:parlaiformat\n02:15:02 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run1/data_valid.txt\n02:15:02 | running eval: valid\n02:15:02 | eval completed in 0.23s\n02:15:02 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1636       0          0 121.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297     6 .5059 5.304e-06    72 729.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    106 233.5 2366        .8322\n\u001b[0m\n02:15:02 | creating task(s): fromfile:parlaiformat\n02:15:02 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run1/data_test.txt\n02:15:02 | running eval: test\n02:15:07 | eval completed in 5.12s\n02:15:07 | \u001b[1mtest:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9000   9e-10               .6575                 .5000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9600            .9415              .9950   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8933 12.07 281.4  2769       0          0 196.8 1000 .9000   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297   5.2 .4825 5.304e-06   104  1023       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    106 385.4 3793        .9131\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type1/run1/data_test.txt -m transformer/classifier -mf /tmp/model1 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:15:09.411861Z","iopub.execute_input":"2022-12-04T02:15:09.412295Z","iopub.status.idle":"2022-12-04T02:15:40.109061Z","shell.execute_reply.started":"2022-12-04T02:15:09.412236Z","shell.execute_reply":"2022-12-04T02:15:40.107852Z"},"scrolled":true,"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"02:15:18 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr2type1/run1/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr2type1/run1/data)\u001b[0m\n02:15:18 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n02:15:18 | Using CUDA\n02:15:18 | loading dictionary from /tmp/model1.dict\n02:15:18 | num words = 54944\n02:15:22 | Loading existing model parameters from /tmp/model1\n02:15:28 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:15:29 | Opt:\n02:15:29 |     activation: gelu\n02:15:29 |     adafactor_eps: '[1e-30, 0.001]'\n02:15:29 |     adam_eps: 1e-08\n02:15:29 |     add_p1_after_newln: False\n02:15:29 |     aggregate_micro: False\n02:15:29 |     allow_missing_init_opts: False\n02:15:29 |     area_under_curve_class: None\n02:15:29 |     area_under_curve_digits: -1\n02:15:29 |     attention_dropout: 0.1\n02:15:29 |     batchsize: 40\n02:15:29 |     betas: '[0.9, 0.999]'\n02:15:29 |     bpe_add_prefix_space: None\n02:15:29 |     bpe_debug: False\n02:15:29 |     bpe_dropout: None\n02:15:29 |     bpe_merge: None\n02:15:29 |     bpe_vocab: None\n02:15:29 |     candidates: inline\n02:15:29 |     cap_num_predictions: 100\n02:15:29 |     checkpoint_activations: False\n02:15:29 |     class_weights: None\n02:15:29 |     classes: \"['__notok__', '__ok__']\"\n02:15:29 |     classes_from_file: None\n02:15:29 |     data_parallel: True\n02:15:29 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n02:15:29 |     datatype: train\n02:15:29 |     delimiter: '\\n'\n02:15:29 |     dict_class: parlai.core.dict:DictionaryAgent\n02:15:29 |     dict_endtoken: __start__\n02:15:29 |     dict_file: /tmp/model1.dict\n02:15:29 |     dict_include_test: False\n02:15:29 |     dict_include_valid: False\n02:15:29 |     dict_initpath: None\n02:15:29 |     dict_language: english\n02:15:29 |     dict_loaded: True\n02:15:29 |     dict_lower: True\n02:15:29 |     dict_max_ngram_size: -1\n02:15:29 |     dict_maxexs: -1\n02:15:29 |     dict_maxtokens: -1\n02:15:29 |     dict_minfreq: 0\n02:15:29 |     dict_nulltoken: __null__\n02:15:29 |     dict_starttoken: __start__\n02:15:29 |     dict_textfields: text,labels\n02:15:29 |     dict_tokenizer: bpe\n02:15:29 |     dict_unktoken: __unk__\n02:15:29 |     display_examples: False\n02:15:29 |     download_path: None\n02:15:29 |     dropout: 0.1\n02:15:29 |     dynamic_batching: None\n02:15:29 |     embedding_projection: random\n02:15:29 |     embedding_size: 768\n02:15:29 |     embedding_type: random\n02:15:29 |     embeddings_scale: False\n02:15:29 |     encode_candidate_vecs: True\n02:15:29 |     encode_candidate_vecs_batchsize: 256\n02:15:29 |     eval_batchsize: None\n02:15:29 |     eval_candidates: inline\n02:15:29 |     eval_dynamic_batching: None\n02:15:29 |     evaltask: None\n02:15:29 |     ffn_size: 3072\n02:15:29 |     final_extra_opt: \n02:15:29 |     fixed_candidate_vecs: reuse\n02:15:29 |     fixed_candidates_path: None\n02:15:29 |     force_fp16_tokens: True\n02:15:29 |     fp16: True\n02:15:29 |     fp16_impl: safe\n02:15:29 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run1/data_test.txt\n02:15:29 |     fromfile_datatype_extension: True\n02:15:29 |     gpu: -1\n02:15:29 |     gradient_clip: 0.1\n02:15:29 |     hide_labels: False\n02:15:29 |     history_add_global_end_token: None\n02:15:29 |     history_reversed: False\n02:15:29 |     history_size: 20\n02:15:29 |     ignore_bad_candidates: False\n02:15:29 |     ignore_labels: None\n02:15:29 |     image_cropsize: 224\n02:15:29 |     image_mode: raw\n02:15:29 |     image_size: 256\n02:15:29 |     inference: max\n02:15:29 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:15:29 |     init_opt: None\n02:15:29 |     interactive_candidates: fixed\n02:15:29 |     interactive_mode: False\n02:15:29 |     invsqrt_lr_decay_gamma: -1\n02:15:29 |     is_debug: False\n02:15:29 |     label_truncate: 72\n02:15:29 |     learn_embeddings: True\n02:15:29 |     learn_positional_embeddings: True\n02:15:29 |     learningrate: 5e-05\n02:15:29 |     load_from_pretrained_ranker: True\n02:15:29 |     log_every_n_secs: 10.0\n02:15:29 |     log_every_n_steps: 50\n02:15:29 |     log_keep_fields: all\n02:15:29 |     loglevel: info\n02:15:29 |     lr_scheduler: reduceonplateau\n02:15:29 |     lr_scheduler_decay: 0.5\n02:15:29 |     lr_scheduler_patience: 3\n02:15:29 |     max_train_steps: -1\n02:15:29 |     max_train_time: 7200.0\n02:15:29 |     memory_attention: sqrt\n02:15:29 |     metrics: default\n02:15:29 |     model: transformer/classifier\n02:15:29 |     model_file: /tmp/model1\n02:15:29 |     model_parallel: False\n02:15:29 |     momentum: 0\n02:15:29 |     multitask_weights: [1]\n02:15:29 |     mutators: None\n02:15:29 |     n_decoder_layers: -1\n02:15:29 |     n_encoder_layers: -1\n02:15:29 |     n_heads: 12\n02:15:29 |     n_layers: 12\n02:15:29 |     n_positions: 1024\n02:15:29 |     n_segments: 2\n02:15:29 |     nesterov: True\n02:15:29 |     no_cuda: False\n02:15:29 |     normalize_sent_emb: False\n02:15:29 |     num_epochs: -1\n02:15:29 |     num_examples: -1\n02:15:29 |     num_workers: 0\n02:15:29 |     nus: [0.7]\n02:15:29 |     optimizer: adamax\n02:15:29 |     output_scaling: 0.06\n02:15:29 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type1/run1/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model1', 'batchsize': 40}\"\n02:15:29 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n02:15:29 |     person_tokens: False\n02:15:29 |     print_scores: False\n02:15:29 |     rank_candidates: False\n02:15:29 |     rank_top_k: -1\n02:15:29 |     reduction_type: mean\n02:15:29 |     ref_class: None\n02:15:29 |     relu_dropout: 0.0\n02:15:29 |     repeat_blocking_heuristic: True\n02:15:29 |     report_filename: \n02:15:29 |     return_cand_scores: False\n02:15:29 |     save_after_valid: True\n02:15:29 |     save_every_n_secs: -1\n02:15:29 |     save_format: conversations\n02:15:29 |     share_encoders: False\n02:15:29 |     share_word_embeddings: False\n02:15:29 |     short_final_eval: False\n02:15:29 |     special_tok_lst: None\n02:15:29 |     split_lines: False\n02:15:29 |     starttime: Dec04_02-03\n02:15:29 |     task: fromfile:parlaiformat\n02:15:29 |     tensorboard_log: False\n02:15:29 |     tensorboard_logdir: None\n02:15:29 |     text_truncate: 360\n02:15:29 |     threshold: 0.5\n02:15:29 |     topk: 5\n02:15:29 |     train_predict: False\n02:15:29 |     truncate: 1024\n02:15:29 |     update_classifier_head_only: False\n02:15:29 |     update_freq: 1\n02:15:29 |     use_memories: False\n02:15:29 |     use_reply: none\n02:15:29 |     validation_cutoff: 1.0\n02:15:29 |     validation_every_n_epochs: -1\n02:15:29 |     validation_every_n_secs: 20.0\n02:15:29 |     validation_every_n_steps: -1\n02:15:29 |     validation_max_exs: -1\n02:15:29 |     validation_metric: accuracy\n02:15:29 |     validation_metric_mode: max\n02:15:29 |     validation_patience: 30\n02:15:29 |     validation_share_agent: False\n02:15:29 |     variant: xlm\n02:15:29 |     verbose: False\n02:15:29 |     wandb_entity: None\n02:15:29 |     wandb_log: False\n02:15:29 |     wandb_name: None\n02:15:29 |     wandb_project: None\n02:15:29 |     warmup_rate: 0.0001\n02:15:29 |     warmup_updates: 1000\n02:15:29 |     weight_decay: None\n02:15:29 |     world_logs: \n02:15:29 |     wrap_memory_encoder: False\n02:15:30 | Evaluating task fromfile:parlaiformat using datatype valid.\n02:15:30 | creating task(s): fromfile:parlaiformat\n02:15:30 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n02:15:30 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run1/data_test.txt\n02:15:38 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9000   9e-10               .6575                 .5000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9600            .9415              .9950   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8933 12.07 562.9  1812       0          0 128.7 1000 .9000   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .4825 5.304e-06   208 669.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    106 770.9 2481        .9131\u001b[0m\n02:15:38 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9000   9e-10               .6575                 .5000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9600            .9415              .9950   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8933 12.07 562.9  1812       0          0 128.7 1000 .9000   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .4825 5.304e-06   208 669.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    106 770.9 2481        .9131\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model1*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:15:40.110750Z","iopub.execute_input":"2022-12-04T02:15:40.112180Z","iopub.status.idle":"2022-12-04T02:15:41.372923Z","shell.execute_reply.started":"2022-12-04T02:15:40.112130Z","shell.execute_reply":"2022-12-04T02:15:41.371583Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"markdown","source":"run 2","metadata":{}},{"cell_type":"code","source":"# run 2 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type1/run2/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model2","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:15:41.375201Z","iopub.execute_input":"2022-12-04T02:15:41.375605Z","iopub.status.idle":"2022-12-04T02:27:58.327452Z","shell.execute_reply.started":"2022-12-04T02:15:41.375562Z","shell.execute_reply":"2022-12-04T02:27:58.326142Z"},"scrolled":true,"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"02:15:48 | building dictionary first...\n02:15:48 | No model with opt yet at: /tmp/model2(.opt)\n02:15:48 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run2/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n02:15:48 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n02:15:48 | Using CUDA\n02:15:48 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n02:15:48 | num words = 54944\n02:15:52 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:16:03 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:16:03 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n02:16:03 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n02:16:03 | Opt:\n02:16:03 |     activation: gelu\n02:16:03 |     adafactor_eps: '(1e-30, 0.001)'\n02:16:03 |     adam_eps: 1e-08\n02:16:03 |     add_p1_after_newln: False\n02:16:03 |     aggregate_micro: False\n02:16:03 |     allow_missing_init_opts: False\n02:16:03 |     attention_dropout: 0.1\n02:16:03 |     batchsize: 20\n02:16:03 |     betas: '(0.9, 0.999)'\n02:16:03 |     bpe_add_prefix_space: None\n02:16:03 |     bpe_debug: False\n02:16:03 |     bpe_dropout: None\n02:16:03 |     bpe_merge: None\n02:16:03 |     bpe_vocab: None\n02:16:03 |     candidates: inline\n02:16:03 |     cap_num_predictions: 100\n02:16:03 |     checkpoint_activations: False\n02:16:03 |     class_weights: None\n02:16:03 |     classes: \"['__notok__', '__ok__']\"\n02:16:03 |     classes_from_file: None\n02:16:03 |     data_parallel: True\n02:16:03 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n02:16:03 |     datatype: train\n02:16:03 |     delimiter: '\\n'\n02:16:03 |     dict_class: parlai.core.dict:DictionaryAgent\n02:16:03 |     dict_endtoken: __start__\n02:16:03 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n02:16:03 |     dict_include_test: False\n02:16:03 |     dict_include_valid: False\n02:16:03 |     dict_initpath: None\n02:16:03 |     dict_language: english\n02:16:03 |     dict_loaded: True\n02:16:03 |     dict_lower: True\n02:16:03 |     dict_max_ngram_size: -1\n02:16:03 |     dict_maxexs: -1\n02:16:03 |     dict_maxtokens: -1\n02:16:03 |     dict_minfreq: 0\n02:16:03 |     dict_nulltoken: __null__\n02:16:03 |     dict_starttoken: __start__\n02:16:03 |     dict_textfields: text,labels\n02:16:03 |     dict_tokenizer: bpe\n02:16:03 |     dict_unktoken: __unk__\n02:16:03 |     display_examples: False\n02:16:03 |     download_path: None\n02:16:03 |     dropout: 0.1\n02:16:03 |     dynamic_batching: None\n02:16:03 |     embedding_projection: random\n02:16:03 |     embedding_size: 768\n02:16:03 |     embedding_type: random\n02:16:03 |     embeddings_scale: False\n02:16:03 |     encode_candidate_vecs: True\n02:16:03 |     encode_candidate_vecs_batchsize: 256\n02:16:03 |     eval_batchsize: None\n02:16:03 |     eval_candidates: inline\n02:16:03 |     eval_dynamic_batching: None\n02:16:03 |     evaltask: None\n02:16:03 |     ffn_size: 3072\n02:16:03 |     final_extra_opt: \n02:16:03 |     fixed_candidate_vecs: reuse\n02:16:03 |     fixed_candidates_path: None\n02:16:03 |     force_fp16_tokens: False\n02:16:03 |     fp16: True\n02:16:03 |     fp16_impl: safe\n02:16:03 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run2/data\n02:16:03 |     fromfile_datatype_extension: True\n02:16:03 |     gpu: -1\n02:16:03 |     gradient_clip: 0.1\n02:16:03 |     hide_labels: False\n02:16:03 |     history_add_global_end_token: None\n02:16:03 |     history_reversed: False\n02:16:03 |     history_size: 20\n02:16:03 |     ignore_bad_candidates: False\n02:16:03 |     ignore_labels: None\n02:16:03 |     image_cropsize: 224\n02:16:03 |     image_mode: raw\n02:16:03 |     image_size: 256\n02:16:03 |     inference: max\n02:16:03 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:16:03 |     init_opt: None\n02:16:03 |     interactive_candidates: fixed\n02:16:03 |     interactive_mode: False\n02:16:03 |     invsqrt_lr_decay_gamma: -1\n02:16:03 |     is_debug: False\n02:16:03 |     label_truncate: 72\n02:16:03 |     learn_embeddings: True\n02:16:03 |     learn_positional_embeddings: True\n02:16:03 |     learningrate: 5e-05\n02:16:03 |     load_from_checkpoint: False\n02:16:03 |     load_from_pretrained_ranker: True\n02:16:03 |     log_every_n_secs: 10.0\n02:16:03 |     log_every_n_steps: 50\n02:16:03 |     log_keep_fields: all\n02:16:03 |     loglevel: info\n02:16:03 |     lr_scheduler: reduceonplateau\n02:16:03 |     lr_scheduler_decay: 0.5\n02:16:03 |     lr_scheduler_patience: 3\n02:16:03 |     max_train_steps: -1\n02:16:03 |     max_train_time: 7200.0\n02:16:03 |     memory_attention: sqrt\n02:16:03 |     metrics: default\n02:16:03 |     model: transformer/classifier\n02:16:03 |     model_file: /tmp/model2\n02:16:03 |     model_parallel: False\n02:16:03 |     momentum: 0\n02:16:03 |     multitask_weights: [1]\n02:16:03 |     mutators: None\n02:16:03 |     n_decoder_layers: -1\n02:16:03 |     n_encoder_layers: -1\n02:16:03 |     n_heads: 12\n02:16:03 |     n_layers: 12\n02:16:03 |     n_positions: 1024\n02:16:03 |     n_segments: 2\n02:16:03 |     nesterov: True\n02:16:03 |     no_cuda: False\n02:16:03 |     normalize_sent_emb: False\n02:16:03 |     num_epochs: -1\n02:16:03 |     num_workers: 0\n02:16:03 |     nus: (0.7,)\n02:16:03 |     optimizer: adamax\n02:16:03 |     output_scaling: 0.06\n02:16:03 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type1/run2/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model2'}\"\n02:16:03 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n02:16:03 |     person_tokens: False\n02:16:03 |     print_scores: False\n02:16:03 |     rank_candidates: False\n02:16:03 |     rank_top_k: -1\n02:16:03 |     reduction_type: mean\n02:16:03 |     ref_class: None\n02:16:03 |     relu_dropout: 0.0\n02:16:03 |     repeat_blocking_heuristic: True\n02:16:03 |     return_cand_scores: False\n02:16:03 |     save_after_valid: True\n02:16:03 |     save_every_n_secs: -1\n02:16:03 |     save_format: conversations\n02:16:03 |     share_encoders: False\n02:16:03 |     share_word_embeddings: False\n02:16:03 |     short_final_eval: False\n02:16:03 |     special_tok_lst: None\n02:16:03 |     split_lines: False\n02:16:03 |     starttime: Dec04_02-15\n02:16:03 |     task: fromfile:parlaiformat\n02:16:03 |     tensorboard_log: False\n02:16:03 |     tensorboard_logdir: None\n02:16:03 |     text_truncate: 360\n02:16:03 |     threshold: 0.5\n02:16:03 |     topk: 5\n02:16:03 |     train_predict: False\n02:16:03 |     truncate: 1024\n02:16:03 |     update_classifier_head_only: False\n02:16:03 |     update_freq: 1\n02:16:03 |     use_memories: False\n02:16:03 |     use_reply: none\n02:16:03 |     validation_cutoff: 1.0\n02:16:03 |     validation_every_n_epochs: -1\n02:16:03 |     validation_every_n_secs: 20.0\n02:16:03 |     validation_every_n_steps: -1\n02:16:03 |     validation_max_exs: -1\n02:16:03 |     validation_metric: accuracy\n02:16:03 |     validation_metric_mode: max\n02:16:03 |     validation_patience: 30\n02:16:03 |     validation_share_agent: False\n02:16:03 |     variant: xlm\n02:16:03 |     verbose: False\n02:16:03 |     wandb_entity: None\n02:16:03 |     wandb_log: False\n02:16:03 |     wandb_name: None\n02:16:03 |     wandb_project: None\n02:16:03 |     warmup_rate: 0.0001\n02:16:03 |     warmup_updates: 1000\n02:16:03 |     weight_decay: None\n02:16:03 |     world_logs: \n02:16:03 |     wrap_memory_encoder: False\n02:16:04 | creating task(s): fromfile:parlaiformat\n02:16:04 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run2/data_train.txt\n02:16:04 | training...\n02:16:14 | time:10s total_exs:380 total_steps:19 epochs:1.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5421 5.421e-10               .1553                 .6154   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                    .08889            .6859              .5367   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9500 11.63     1 272.7 514.2       0          0 37.72  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5421             32768  2.404    .1206 5.947 .6845 9.549e-07 118.9 224.3   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps  ups  weighted_f1  \n         0          0                   19 391.6 738.5 1.89        .4346\n\n02:16:24 | time:20s total_exs:1120 total_steps:56 epochs:5.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6176 6.176e-10               .4189                 .8095   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .2825            .7150              .5782   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9367  11.7     1 273.9  1036       0          0 75.65  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6176             32768  2.724    .1207 5.976 .6642 2.805e-06 119.5 452.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   56 393.4 1488 3.791        .5705\n\n02:16:24 | creating task(s): fromfile:parlaiformat\n02:16:24 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run2/data_valid.txt\n02:16:24 | running eval: valid\n02:16:24 | eval completed in 0.20s\n02:16:24 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6667 6.667e-10               .6364                 .7000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5833            .6923              .6429   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500    11   156  1760       0          0 135.4   24 .6667   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6607 2.805e-06    72 812.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                     56  228 2573        .6643\n\u001b[0m\n02:16:24 | \u001b[1;32mnew best accuracy: 0.6667\u001b[0m\n02:16:24 | saving best valid model: /tmp/model2\n02:16:24 | Saving dictionary to /tmp/model2.dict\n02:16:28 | saving model checkpoint: /tmp/model2.checkpoint\n02:16:28 | Saving dictionary to /tmp/model2.checkpoint.dict\n02:16:44 | time:40s total_exs:1780 total_steps:89 epochs:8.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8242 8.242e-10               .8153                 .9046   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7420            .8324              .7639   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9143 11.68     1 273.6 889.7       0          0 65.03  660   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8242             32768  2.735    .1207 6.045 .6139 4.455e-06 120.9 393.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   89 394.5 1283 3.259        .8234\n\n02:16:48 | time:44s total_exs:2080 total_steps:104 epochs:10.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9367 9.367e-10               .9412                 .9325   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9314              .9416   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9214 11.74     1 274.7  1074       0          0 78.19  300   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9367             32768  3.275    .1207 6.067 .5346 5.204e-06 121.3 474.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  104 396.1 1549 3.933        .9366\n\n02:16:48 | running eval: valid\n02:16:48 | eval completed in 0.19s\n02:16:48 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1777       0          0 136.7   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5306 5.204e-06    72 820.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    104  228 2598        .8748\n\u001b[0m\n02:16:48 | \u001b[1;32mnew best accuracy: 0.875 (previous best was 0.6667)\u001b[0m\n02:16:48 | saving best valid model: /tmp/model2\n02:16:53 | saving model checkpoint: /tmp/model2.checkpoint\n02:17:12 | time:68s total_exs:2840 total_steps:142 epochs:14.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9487 9.487e-10               .9479                 .9492   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9467            .9494              .9482   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9506 11.43     1 268.6  1014       0          0  75.5  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9487             32768  4.036    .1207 5.987 .3736 7.104e-06 119.7   452   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  142 388.4 1466 3.783        .9487\n\n02:17:13 | time:70s total_exs:2960 total_steps:148 epochs:14.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9333 9.333e-10               .9322                 .9649   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9016            .9344              .9048   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9661 11.28     1 265.5  1037       0          0 78.08  120   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9333             32768  4.994    .1207 6.017 .2656 7.404e-06 120.3 469.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  148 385.8 1506 3.962        .9333\n\n02:17:13 | running eval: valid\n02:17:13 | eval completed in 0.20s\n02:17:13 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1724       0          0 132.6   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .2979 7.404e-06    72 795.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    148  228 2520        .9167\n\u001b[0m\n02:17:13 | \u001b[1;32mnew best accuracy: 0.9167 (previous best was 0.875)\u001b[0m\n02:17:13 | saving best valid model: /tmp/model2\n02:17:22 | saving model checkpoint: /tmp/model2.checkpoint\n02:17:37 | time:94s total_exs:3720 total_steps:186 epochs:18.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9697 9.697e-10               .9709                 .9722   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9697            .9684              .9671   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9698 11.86     1 277.1  1039       0          0    75  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9697             32768  4.265    .1207 6.042 .1511 9.304e-06 120.8 453.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  186 397.9 1492 3.758        .9697\n\n02:17:42 | time:99s total_exs:4100 total_steps:205 epochs:20.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9684 9.684e-10               .9698                 .9797   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9602            .9669              .9563   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9777 12.15     1 283.1  1099       0          0 77.68  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9684             32768  5.215    .1207 6.058 .08421 1.025e-05 121.2 470.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  205 404.2 1570 3.902        .9684\n\n02:17:42 | running eval: valid\n02:17:42 | eval completed in 0.19s\n02:17:42 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1792       0          0 137.8   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .2800 1.025e-05    72 827.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    205  228 2620        .9167\n\u001b[0m\n02:17:42 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 1\u001b[0m\n02:17:42 | saving model checkpoint: /tmp/model2.checkpoint\n02:18:03 | time:119s total_exs:4880 total_steps:244 epochs:24.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9949 9.949e-10               .9949                 .9974   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9924            .9948              .9923   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9974  11.7     1   274  1051       0          0 76.75  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9949             32768  3.971    .1207  6.01 .02799 1.22e-05 120.2 461.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  244 394.2 1513 3.846        .9949\n\n02:18:03 | running eval: valid\n02:18:03 | eval completed in 0.19s\n02:18:03 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1820       0          0   140   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .4053 1.22e-05    72 840.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    244  228 2661        .9167\n\u001b[0m\n02:18:03 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 2\u001b[0m\n02:18:03 | saving model checkpoint: /tmp/model2.checkpoint\n02:18:17 | time:133s total_exs:5640 total_steps:282 epochs:28.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9987 9.987e-10               .9987                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9974            .9986              .9973   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.68 .1053 273.7  1036       0          0 75.69  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n   .9987             32768  .8229    .1207 6.029 .007059 1.41e-05 120.6 456.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  282 394.2 1492 3.793        .9987\n\n02:18:23 | time:139s total_exs:6080 total_steps:304 epochs:30.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.45     0 269.1  1038       0          0 77.16  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .02557    .1207 5.973 .002051 1.52e-05 119.5 460.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  304 388.5 1499 3.873            1\n\n02:18:23 | running eval: valid\n02:18:23 | eval completed in 0.20s\n02:18:23 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1757       0          0 135.1   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .5348 1.52e-05    72   811       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    304  228 2568        .9167\n\u001b[0m\n02:18:23 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 3\u001b[0m\n02:18:23 | saving model checkpoint: /tmp/model2.checkpoint\n02:18:37 | time:154s total_exs:6860 total_steps:343 epochs:34.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.52 .02564 270.4  1045       0          0 77.27   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    780   1             32768 .02267    .1207 5.974 .001615 1.715e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.7       0          0                  343 389.9 1506 3.872            1\n\n02:18:43 | time:160s total_exs:7300 total_steps:365 epochs:36.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.98     0 279.7  1049       0          0 75.03  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768  .0168    .1207 6.009 .001384 1.825e-05 120.2 450.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  365 399.9 1500 3.766            1\n\n02:18:43 | running eval: valid\n02:18:43 | eval completed in 0.20s\n02:18:43 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1739       0          0 133.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 .5728 1.825e-05    72 802.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    365  228 2541        .9167\n\u001b[0m\n02:18:43 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 4\u001b[0m\n02:18:43 | saving model checkpoint: /tmp/model2.checkpoint\n02:18:58 | time:174s total_exs:8080 total_steps:404 epochs:40.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.95     0   279  1074       0          0 77.01  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n     1             32768 .01455    .1207 5.946 .00123 2.02e-05 118.9 457.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  404 397.9 1532 3.859            1\n\n02:19:04 | time:180s total_exs:8520 total_steps:426 epochs:42.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.29     0 265.7  1037       0          0 78.07  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .01371    .1207 5.932 .001123 2.13e-05 118.6 463.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  426 384.4 1500 3.919            1\n\n02:19:04 | running eval: valid\n02:19:04 | eval completed in 0.19s\n02:19:04 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1784       0          0 137.2   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 .5887 2.13e-05    72 823.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    426  228 2607        .9167\n\u001b[0m\n02:19:04 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 5\u001b[0m\n02:19:04 | saving model checkpoint: /tmp/model2.checkpoint\n02:19:18 | time:195s total_exs:9300 total_steps:465 epochs:46.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.58     0 271.6  1037       0          0 76.33  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01479    .1207 5.979 .001044 2.325e-05 119.6 456.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  465 391.2 1493 3.825            1\n\n02:19:24 | time:200s total_exs:9740 total_steps:487 epochs:48.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.72     0 274.5  1071       0          0 78.04  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768  .0119    .1207 5.995 .0009638 2.435e-05 119.9 467.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  487 394.4 1539 3.918            1\n\n02:19:24 | running eval: valid\n02:19:24 | eval completed in 0.20s\n02:19:24 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1753       0          0 134.8   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 .6183 2.435e-05    72 808.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    487  228 2562        .9167\n\u001b[0m\n02:19:24 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 6\u001b[0m\n02:19:24 | saving model checkpoint: /tmp/model2.checkpoint\n02:19:39 | time:215s total_exs:10520 total_steps:526 epochs:52.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.04     0 280.8  1073       0          0  76.4  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .01067    .1207 5.956 .0008984 2.63e-05 119.1 455.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  526 399.9 1528 3.829            1\n\n02:19:44 | time:220s total_exs:10940 total_steps:547 epochs:54.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.7     0   274  1055       0          0 76.99  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .009796    .1207 5.962 .0008392 2.735e-05 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     459       0          0                  547 393.2 1514 3.866            1\n\n02:19:44 | running eval: valid\n02:19:44 | eval completed in 0.20s\n02:19:44 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1769       0          0   136   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 .6171 2.735e-05    72 816.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    547  228 2585        .9167\n\u001b[0m\n02:19:44 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 7\u001b[0m\n02:19:44 | saving model checkpoint: /tmp/model2.checkpoint\n02:19:59 | time:235s total_exs:11720 total_steps:586 epochs:58.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.9     0   278  1077       0          0 77.48  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .00923    .1208 5.992 .0007891 2.93e-05 119.8 464.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  586 397.8 1541 3.883            1\n\n02:20:04 | time:241s total_exs:12140 total_steps:607 epochs:60.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.43     0 268.5  1033       0          0 76.94  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .008707    .1208     6 .0007413 3.035e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.6       0          0                  607 388.5 1495 3.863            1\n\n02:20:04 | running eval: valid\n02:20:05 | eval completed in 0.19s\n02:20:05 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1801       0          0 138.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 .6749 3.035e-05    72 831.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    607  228 2633        .8748\n\u001b[0m\n02:20:05 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 8\u001b[0m\n02:20:05 | saving model checkpoint: /tmp/model2.checkpoint\n02:20:19 | time:255s total_exs:12900 total_steps:645 epochs:64.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.46     0 269.1  1021       0          0 75.88  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .008184    .1208 5.987 .0006962 3.225e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   454.3       0          0                  645 388.9 1475 3.803            1\n\n02:20:25 | time:261s total_exs:13360 total_steps:668 epochs:66.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.82     0 276.5  1059       0          0 76.59  460   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .007657    .1208 6.035 .0006534 3.34e-05 120.7 462.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  668 397.2 1521 3.844            1\n\n02:20:25 | running eval: valid\n02:20:25 | eval completed in 0.19s\n02:20:25 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1814       0          0 139.5   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 .8973 3.34e-05    72 837.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    668  228 2652        .8748\n\u001b[0m\n02:20:25 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 9\u001b[0m\n02:20:25 | saving model checkpoint: /tmp/model2.checkpoint\n02:20:40 | time:276s total_exs:14120 total_steps:706 epochs:70.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.9     0 277.9  1055       0          0 75.94  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .007241    .1208 6.026 .0006145 3.53e-05 120.5 457.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  706 398.4 1513 3.806            1\n\n02:20:45 | time:282s total_exs:14540 total_steps:727 epochs:72.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.32     0 266.4  1029       0          0 77.22  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006751    .1208 5.976 .0005767 3.635e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   461.5       0          0                  727  386 1490 3.877            1\n\n02:20:45 | running eval: valid\n02:20:45 | eval completed in 0.19s\n02:20:45 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1786       0          0 137.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 .9198 3.635e-05    72 824.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    727  228 2611        .8748\n\u001b[0m\n02:20:45 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 10\u001b[0m\n02:20:45 | saving model checkpoint: /tmp/model2.checkpoint\n02:21:00 | time:296s total_exs:15320 total_steps:766 epochs:76.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.79     0 275.9  1062       0          0 76.98  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .006373    .1208 5.987 .0005432 3.83e-05 119.7 460.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  766 395.6 1523 3.858            1\n\n02:21:06 | time:302s total_exs:15740 total_steps:787 epochs:78.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.83     0 276.6  1071       0          0 77.42  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .005996    .1208 6.038 .000511 3.935e-05 120.8 467.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  787 397.3 1538 3.888            1\n\n02:21:06 | running eval: valid\n02:21:06 | eval completed in 0.23s\n02:21:06 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1559       0          0 119.9   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 .9491 3.935e-05    72 719.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    787  228 2279        .8748\n\u001b[0m\n02:21:06 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 11\u001b[0m\n02:21:06 | saving model checkpoint: /tmp/model2.checkpoint\n02:21:21 | time:317s total_exs:16500 total_steps:825 epochs:82.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.66     0 273.1  1022       0          0 74.83  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .005629    .1208 6.005 .0004792 4.125e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   449.4       0          0                  825 393.2 1471 3.75            1\n\n02:21:26 | time:322s total_exs:16920 total_steps:846 epochs:84.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.65     0   273  1067       0          0 78.15  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .005309    .1208 5.986 .0004515 4.23e-05 119.7 467.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  846 392.8 1535 3.924            1\n\n02:21:26 | running eval: valid\n02:21:26 | eval completed in 0.20s\n02:21:26 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1755       0          0   135   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 .9679 4.23e-05    72   810       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    846  228 2565        .8748\n\u001b[0m\n02:21:26 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 12\u001b[0m\n02:21:26 | saving model checkpoint: /tmp/model2.checkpoint\n02:21:41 | time:338s total_exs:17700 total_steps:885 epochs:88.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.66     0 273.2  1052       0          0 76.98  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00499    .1208 6.023 .0004249 4.425e-05 120.5 463.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  885 393.7 1515 3.858            1\n\n02:21:46 | time:343s total_exs:18100 total_steps:905 epochs:90.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.69     0 273.8  1070       0          0 78.14  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004713    .1208  6.05 .0004006 4.525e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   472.8       0          0                  905 394.8 1543 3.924            1\n\n02:21:46 | running eval: valid\n02:21:47 | eval completed in 0.19s\n02:21:47 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1784       0          0 137.2   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 .9876 4.525e-05    72 823.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    905  228 2607        .8748\n\u001b[0m\n02:21:47 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 13\u001b[0m\n02:21:47 | saving model checkpoint: /tmp/model2.checkpoint\n02:22:02 | time:358s total_exs:18880 total_steps:944 epochs:94.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.74     0 274.9  1057       0          0  76.9  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .004417    .1208     6 .0003759 4.72e-05   120 461.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  944 394.9 1518 3.853            1\n\n02:22:07 | time:363s total_exs:19260 total_steps:963 epochs:96.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.83     0 276.5  1081       0          0 78.18  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004168    .1208 6.037 .0003547 4.815e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     472       0          0                  963 397.3 1553 3.927            1\n\n02:22:07 | running eval: valid\n02:22:07 | eval completed in 0.19s\n02:22:07 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1809       0          0 139.1   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6 1.015 4.815e-05    72 834.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    963  228 2644        .8748\n\u001b[0m\n02:22:07 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 14\u001b[0m\n02:22:07 | saving model checkpoint: /tmp/model2.checkpoint\n02:22:21 | time:378s total_exs:20040 total_steps:1002 epochs:100.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.93     0 278.6  1077       0          0  77.3  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003936    .1208 6.041 .0003343 4.995e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     467       0          0                 1002 399.4 1544 3.874            1\n\n02:22:27 | time:383s total_exs:20460 total_steps:1023 epochs:102.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.46     0 269.2 970.5       0          0  72.1  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003709    .1208 5.962 .0003138 4.995e-05 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   429.9       0          0                 1023 388.4 1400 3.619            1\n\n02:22:27 | running eval: valid\n02:22:27 | eval completed in 0.20s\n02:22:27 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1752       0          0 134.7   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 1.025 4.995e-05    72 808.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1023  228 2561        .8748\n\u001b[0m\n02:22:27 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 15\u001b[0m\n02:22:27 | saving model checkpoint: /tmp/model2.checkpoint\n02:22:42 | time:398s total_exs:21240 total_steps:1062 epochs:106.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.59     0 271.8  1041       0          0 76.61  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003481    .1208 5.938 .0002954 4.995e-05 118.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     455       0          0                 1062 390.6 1496 3.839            1\n\n02:22:47 | time:404s total_exs:21680 total_steps:1084 epochs:108.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.82     0 276.4  1053       0          0 76.18  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .003406    .1209 5.991 .000279 4.995e-05 119.8 456.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1084 396.2 1509 3.824            1\n\n02:22:47 | running eval: valid\n02:22:48 | eval completed in 0.19s\n02:22:48 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1775       0          0 136.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 .9924 4.995e-05    72   819       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1084  228 2594        .8748\n\u001b[0m\n02:22:48 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 16\u001b[0m\n02:22:48 | saving model checkpoint: /tmp/model2.checkpoint\n02:23:02 | time:419s total_exs:22440 total_steps:1122 epochs:112.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.65     0   273  1026       0          0 75.15  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003112    .1209 5.982 .0002637 4.995e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.5       0          0                 1122 392.7 1475 3.766            1\n\n02:23:08 | time:424s total_exs:22860 total_steps:1143 epochs:114.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.3  1059       0          0 77.22  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n     1             32768 .002949    .1209 5.995 .00025 4.995e-05 119.9 462.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1143 394.2 1522 3.877            1\n\n02:23:08 | running eval: valid\n02:23:08 | eval completed in 0.19s\n02:23:08 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1793       0          0 137.9   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 1.058 4.995e-05    72 827.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1143  228 2620        .8748\n\u001b[0m\n02:23:08 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 17\u001b[0m\n02:23:08 | saving model checkpoint: /tmp/model2.checkpoint\n02:23:22 | time:439s total_exs:23640 total_steps:1182 epochs:118.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.53     0 270.7  1043       0          0  77.1  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002791    .1209 5.992 .0002367 4.995e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     462       0          0                 1182 390.5 1506 3.864            1\n\n02:23:28 | time:444s total_exs:24060 total_steps:1203 epochs:120.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.5     0 270.1 999.7       0          0 74.02  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002749    .1209 6.067 .0002255 4.995e-05 121.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   449.1       0          0                 1203 391.4 1449 3.716            1\n\n02:23:28 | running eval: valid\n02:23:28 | eval completed in 0.22s\n02:23:28 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1608       0          0 123.7   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 1.068 4.995e-05    72 742.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1203  228 2351        .8748\n\u001b[0m\n02:23:28 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 18\u001b[0m\n02:23:28 | saving model checkpoint: /tmp/model2.checkpoint\n02:23:43 | time:459s total_exs:24840 total_steps:1242 epochs:124.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.81     0 276.1  1066       0          0 77.18  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002518    .1209 5.982 .0002133 4.995e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.7       0          0                 1242 395.8 1527 3.868            1\n\n02:23:49 | time:465s total_exs:25280 total_steps:1264 epochs:126.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.95     0 279.1  1084       0          0 77.68  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002403    .1209 6.091 .0002034 4.995e-05 121.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   473.1       0          0                 1264 400.9 1557 3.899            1\n\n02:23:49 | running eval: valid\n02:23:49 | eval completed in 0.19s\n02:23:49 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1770       0          0 136.1   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 1.075 4.995e-05    72 816.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1264  228 2586        .8748\n\u001b[0m\n02:23:49 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 19\u001b[0m\n02:23:49 | saving model checkpoint: /tmp/model2.checkpoint\n02:24:03 | time:480s total_exs:26040 total_steps:1302 epochs:130.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.7     0 274.1  1026       0          0 74.87  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002292    .1209 6.047 .0001935 4.995e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   452.8       0          0                 1302  395 1479 3.752            1\n\n02:24:09 | time:485s total_exs:26460 total_steps:1323 epochs:132.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  12.2     0 283.9  1107       0          0 77.98  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00217    .1209 5.952 .0001837 4.995e-05   119 464.1   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1323  403 1571 3.915            1\n\n02:24:09 | running eval: valid\n02:24:09 | eval completed in 0.20s\n02:24:09 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1766       0          0 135.8   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 1.101 4.995e-05    72   815       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1323  228 2581        .8748\n\u001b[0m\nEpoch 00006: reducing learning rate of group 0 to 2.4975e-05.\n02:24:09 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 20\u001b[0m\n02:24:09 | saving model checkpoint: /tmp/model2.checkpoint\n02:24:23 | time:500s total_exs:27240 total_steps:1362 epochs:136.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.38     0 267.6  1038       0          0 77.59  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002107    .1209 6.003 .0001784 2.498e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   465.7       0          0                 1362 387.6 1504 3.887            1\n\n02:24:29 | time:505s total_exs:27660 total_steps:1383 epochs:138.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.81     0 276.2  1047       0          0 75.78  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .002053    .1209  5.99 .000174 2.498e-05 119.8 453.9   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1383  396 1501 3.804            1\n\n02:24:29 | running eval: valid\n02:24:29 | eval completed in 0.22s\n02:24:29 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1643       0          0 126.3   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6 1.108 2.498e-05    72 758.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1383  228 2401        .8748\n\u001b[0m\n02:24:29 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 21\u001b[0m\n02:24:29 | saving model checkpoint: /tmp/model2.checkpoint\n02:24:45 | time:521s total_exs:28440 total_steps:1422 epochs:142.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.79     0 275.9  1059       0          0 76.78  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002006    .1209 5.967 .0001697 2.498e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.1       0          0                 1422 395.2 1517 3.843            1\n\n02:24:49 | time:526s total_exs:28820 total_steps:1441 epochs:144.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.5     0   270  1037       0          0 76.79  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001966    .1209 6.089 .0001664 2.498e-05 121.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   467.6       0          0                 1441 391.8 1504 3.857            1\n\n02:24:49 | running eval: valid\n02:24:50 | eval completed in 0.19s\n02:24:50 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1801       0          0 138.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6 1.115 2.498e-05    72 831.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1441  228 2633        .8748\n\u001b[0m\n02:24:50 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 22\u001b[0m\n02:24:50 | saving model checkpoint: /tmp/model2.checkpoint\n02:25:04 | time:540s total_exs:29580 total_steps:1479 epochs:147.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.92     0 278.4  1045       0          0 75.09  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001918    .1209 6.003 .0001623 2.498e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   450.7       0          0                 1479 398.5 1496 3.763            1\n\n02:25:10 | time:546s total_exs:30020 total_steps:1501 epochs:150.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.6     0   272  1030       0          0 75.74  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001876    .1209 6.055 .0001587 2.498e-05 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.5       0          0                 1501 393.1 1489 3.801            1\n\n02:25:10 | running eval: valid\n02:25:10 | eval completed in 0.21s\n02:25:10 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1694       0          0 130.3   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 1.121 2.498e-05    72 781.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1501  228 2476        .8748\n\u001b[0m\n02:25:10 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 23\u001b[0m\n02:25:10 | saving model checkpoint: /tmp/model2.checkpoint\n02:25:25 | time:561s total_exs:30800 total_steps:1540 epochs:154.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.76     0 275.3  1066       0          0 77.41  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001826    .1209 6.008 .0001545 2.498e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   465.1       0          0                 1540 395.4 1531 3.879            1\n\n02:25:30 | time:567s total_exs:31220 total_steps:1561 epochs:156.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.75     0 274.9  1049       0          0 76.31  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001777    .1209 5.914 .0001503 2.498e-05 118.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.3       0          0                 1561 393.2 1500 3.831            1\n\n02:25:30 | running eval: valid\n02:25:31 | eval completed in 0.19s\n02:25:31 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1801       0          0 138.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 1.127 2.498e-05    72 831.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1561  228 2632        .8748\n\u001b[0m\nEpoch 00010: reducing learning rate of group 0 to 1.2488e-05.\n02:25:31 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 24\u001b[0m\n02:25:31 | saving model checkpoint: /tmp/model2.checkpoint\n02:25:45 | time:582s total_exs:32000 total_steps:1600 epochs:160.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.01     0 280.2  1083       0          0 77.31  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001749    .1209 5.974 .0001479 1.249e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.9       0          0                 1600 399.7 1545 3.874            1\n\n02:25:51 | time:587s total_exs:32420 total_steps:1621 epochs:162.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.01     0 260.3  1013       0          0 77.87  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001733    .1210 6.024 .0001465 1.249e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   469.1       0          0                 1621 380.8 1482 3.91            1\n\n02:25:51 | running eval: valid\n02:25:51 | eval completed in 0.22s\n02:25:51 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1555       0          0 119.6   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 1.131 1.249e-05    72 717.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1621  228 2273        .8748\n\u001b[0m\n02:25:51 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 25\u001b[0m\n02:25:51 | saving model checkpoint: /tmp/model2.checkpoint\n02:26:06 | time:602s total_exs:33180 total_steps:1659 epochs:165.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.68     0 273.6  1035       0          0 75.64  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001708    .1210 5.966 .0001442 1.249e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.3       0          0                 1659 392.9 1486 3.791            1\n\n02:26:11 | time:607s total_exs:33620 total_steps:1681 epochs:168.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.2  1084       0          0 79.04  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001716    .1210 5.977 .0001424 1.249e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   472.5       0          0                 1681 393.7 1556 3.968            1\n\n02:26:11 | running eval: valid\n02:26:11 | eval completed in 0.20s\n02:26:11 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1751       0          0 134.6   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 1.132 1.249e-05    72   808       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1681  228 2559        .8748\n\u001b[0m\n02:26:11 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 26\u001b[0m\n02:26:11 | saving model checkpoint: /tmp/model2.checkpoint\n02:26:26 | time:622s total_exs:34400 total_steps:1720 epochs:172.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.37     0 267.3  1026       0          0 76.78  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001663    .1210 5.979 .0001407 1.249e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.1       0          0                 1720 386.9 1485 3.847            1\n\n02:26:31 | time:628s total_exs:34820 total_steps:1741 epochs:174.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.82     0 276.5  1078       0          0 77.96  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00164    .1210 6.019 .0001387 1.249e-05 120.4 469.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1741 396.9 1547 3.914            1\n\n02:26:31 | running eval: valid\n02:26:32 | eval completed in 0.19s\n02:26:32 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1797       0          0 138.2   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 1.136 1.249e-05    72 829.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1741  228 2626        .8748\n\u001b[0m\n02:26:32 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 27\u001b[0m\n02:26:32 | saving model checkpoint: /tmp/model2.checkpoint\n02:26:46 | time:643s total_exs:35600 total_steps:1780 epochs:178.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.56     0 271.2  1049       0          0 77.35  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001622    .1210 6.056 .0001371 1.249e-05 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   468.5       0          0                 1780 392.3 1517 3.876            1\n\n02:26:52 | time:648s total_exs:36000 total_steps:1800 epochs:180.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.85     0 276.9  1068       0          0 77.15  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001594    .1210 5.915 .0001348 1.249e-05 118.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.4       0          0                 1800 395.2 1525 3.875            1\n\n02:26:52 | running eval: valid\n02:26:52 | eval completed in 0.19s\n02:26:52 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1810       0          0 139.2   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08122     6  1.14 1.249e-05    72 835.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1800  228 2646        .8748\n\u001b[0m\nEpoch 00014: reducing learning rate of group 0 to 6.2438e-06.\n02:26:52 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 28\u001b[0m\n02:26:52 | saving model checkpoint: /tmp/model2.checkpoint\n02:27:07 | time:663s total_exs:36780 total_steps:1839 epochs:183.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.74     0 274.7  1057       0          0 76.93  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001583    .1210  6.01 .0001338 6.244e-06 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   462.4       0          0                 1839 394.9 1519 3.855            1\n\n02:27:12 | time:668s total_exs:37180 total_steps:1859 epochs:185.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.57     0 271.4  1013       0          0 74.65  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00157    .1210 6.005 .0001328 6.244e-06 120.1 448.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1859 391.5 1461 3.749            1\n\n02:27:12 | running eval: valid\n02:27:12 | eval completed in 0.19s\n02:27:12 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1780       0          0 136.9   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08123     6 1.143 6.244e-06    72 821.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1859  228 2601        .8748\n\u001b[0m\n02:27:12 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 29\u001b[0m\n02:27:12 | saving model checkpoint: /tmp/model2.checkpoint\n02:27:27 | time:683s total_exs:37960 total_steps:1898 epochs:189.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.49     0 269.7  1037       0          0 76.88  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001559    .1210  5.99 .0001318 6.244e-06 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.5       0          0                 1898 389.5 1497 3.852            1\n\n02:27:32 | time:689s total_exs:38380 total_steps:1919 epochs:191.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.76     0 275.3  1041       0          0 75.66  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001544    .1210 5.924 .0001305 6.244e-06 118.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   448.2       0          0                 1919 393.8 1490 3.799            1\n\n02:27:32 | running eval: valid\n02:27:32 | eval completed in 0.19s\n02:27:32 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1808       0          0   139   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08124     6 1.145 6.244e-06    72 834.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1919  228 2642        .8748\n\u001b[0m\n02:27:32 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 30\u001b[0m\n02:27:32 | saving model checkpoint: /tmp/model2.checkpoint\n02:27:37 | ran out of patience! stopping training.\n02:27:37 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n02:27:37 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n02:27:37 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run2/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n02:27:37 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n02:27:37 | Using CUDA\n02:27:37 | loading dictionary from /tmp/model2.dict\n02:27:37 | num words = 54944\n02:27:42 | Loading existing model parameters from /tmp/model2\n02:27:49 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:27:51 | creating task(s): fromfile:parlaiformat\n02:27:51 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run2/data_valid.txt\n02:27:51 | running eval: valid\n02:27:51 | eval completed in 0.20s\n02:27:51 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1702       0          0 130.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298     6 .2979 7.404e-06    72 785.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    148  228 2487        .9167\n\u001b[0m\n02:27:51 | creating task(s): fromfile:parlaiformat\n02:27:51 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run2/data_test.txt\n02:27:51 | running eval: test\n02:27:56 | eval completed in 4.95s\n02:27:56 | \u001b[1mtest:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .8900 8.9e-10               .6405                 .4757   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9800            .9351              .9975   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8800 12.07 281.4  2859       0          0 203.2 1000 .8900   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298   5.2 .2925 7.404e-06   104  1057       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    148 385.4 3916        .9056\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type1/run2/data_test.txt -m transformer/classifier -mf /tmp/model2 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:27:58.336342Z","iopub.execute_input":"2022-12-04T02:27:58.337059Z","iopub.status.idle":"2022-12-04T02:28:29.744359Z","shell.execute_reply.started":"2022-12-04T02:27:58.337000Z","shell.execute_reply":"2022-12-04T02:28:29.742964Z"},"scrolled":true,"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"02:28:07 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr2type1/run2/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr2type1/run2/data)\u001b[0m\n02:28:07 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n02:28:07 | Using CUDA\n02:28:07 | loading dictionary from /tmp/model2.dict\n02:28:07 | num words = 54944\n02:28:12 | Loading existing model parameters from /tmp/model2\n02:28:18 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:28:19 | Opt:\n02:28:19 |     activation: gelu\n02:28:19 |     adafactor_eps: '[1e-30, 0.001]'\n02:28:19 |     adam_eps: 1e-08\n02:28:19 |     add_p1_after_newln: False\n02:28:19 |     aggregate_micro: False\n02:28:19 |     allow_missing_init_opts: False\n02:28:19 |     area_under_curve_class: None\n02:28:19 |     area_under_curve_digits: -1\n02:28:19 |     attention_dropout: 0.1\n02:28:19 |     batchsize: 40\n02:28:19 |     betas: '[0.9, 0.999]'\n02:28:19 |     bpe_add_prefix_space: None\n02:28:19 |     bpe_debug: False\n02:28:19 |     bpe_dropout: None\n02:28:19 |     bpe_merge: None\n02:28:19 |     bpe_vocab: None\n02:28:19 |     candidates: inline\n02:28:19 |     cap_num_predictions: 100\n02:28:19 |     checkpoint_activations: False\n02:28:19 |     class_weights: None\n02:28:19 |     classes: \"['__notok__', '__ok__']\"\n02:28:19 |     classes_from_file: None\n02:28:19 |     data_parallel: True\n02:28:19 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n02:28:19 |     datatype: train\n02:28:19 |     delimiter: '\\n'\n02:28:19 |     dict_class: parlai.core.dict:DictionaryAgent\n02:28:19 |     dict_endtoken: __start__\n02:28:19 |     dict_file: /tmp/model2.dict\n02:28:19 |     dict_include_test: False\n02:28:19 |     dict_include_valid: False\n02:28:19 |     dict_initpath: None\n02:28:19 |     dict_language: english\n02:28:19 |     dict_loaded: True\n02:28:19 |     dict_lower: True\n02:28:19 |     dict_max_ngram_size: -1\n02:28:19 |     dict_maxexs: -1\n02:28:19 |     dict_maxtokens: -1\n02:28:19 |     dict_minfreq: 0\n02:28:19 |     dict_nulltoken: __null__\n02:28:19 |     dict_starttoken: __start__\n02:28:19 |     dict_textfields: text,labels\n02:28:19 |     dict_tokenizer: bpe\n02:28:19 |     dict_unktoken: __unk__\n02:28:19 |     display_examples: False\n02:28:19 |     download_path: None\n02:28:19 |     dropout: 0.1\n02:28:19 |     dynamic_batching: None\n02:28:19 |     embedding_projection: random\n02:28:19 |     embedding_size: 768\n02:28:19 |     embedding_type: random\n02:28:19 |     embeddings_scale: False\n02:28:19 |     encode_candidate_vecs: True\n02:28:19 |     encode_candidate_vecs_batchsize: 256\n02:28:19 |     eval_batchsize: None\n02:28:19 |     eval_candidates: inline\n02:28:19 |     eval_dynamic_batching: None\n02:28:19 |     evaltask: None\n02:28:19 |     ffn_size: 3072\n02:28:19 |     final_extra_opt: \n02:28:19 |     fixed_candidate_vecs: reuse\n02:28:19 |     fixed_candidates_path: None\n02:28:19 |     force_fp16_tokens: True\n02:28:19 |     fp16: True\n02:28:19 |     fp16_impl: safe\n02:28:19 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run2/data_test.txt\n02:28:19 |     fromfile_datatype_extension: True\n02:28:19 |     gpu: -1\n02:28:19 |     gradient_clip: 0.1\n02:28:19 |     hide_labels: False\n02:28:19 |     history_add_global_end_token: None\n02:28:19 |     history_reversed: False\n02:28:19 |     history_size: 20\n02:28:19 |     ignore_bad_candidates: False\n02:28:19 |     ignore_labels: None\n02:28:19 |     image_cropsize: 224\n02:28:19 |     image_mode: raw\n02:28:19 |     image_size: 256\n02:28:19 |     inference: max\n02:28:19 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:28:19 |     init_opt: None\n02:28:19 |     interactive_candidates: fixed\n02:28:19 |     interactive_mode: False\n02:28:19 |     invsqrt_lr_decay_gamma: -1\n02:28:19 |     is_debug: False\n02:28:19 |     label_truncate: 72\n02:28:19 |     learn_embeddings: True\n02:28:19 |     learn_positional_embeddings: True\n02:28:19 |     learningrate: 5e-05\n02:28:19 |     load_from_pretrained_ranker: True\n02:28:19 |     log_every_n_secs: 10.0\n02:28:19 |     log_every_n_steps: 50\n02:28:19 |     log_keep_fields: all\n02:28:19 |     loglevel: info\n02:28:19 |     lr_scheduler: reduceonplateau\n02:28:19 |     lr_scheduler_decay: 0.5\n02:28:19 |     lr_scheduler_patience: 3\n02:28:19 |     max_train_steps: -1\n02:28:19 |     max_train_time: 7200.0\n02:28:19 |     memory_attention: sqrt\n02:28:19 |     metrics: default\n02:28:19 |     model: transformer/classifier\n02:28:19 |     model_file: /tmp/model2\n02:28:19 |     model_parallel: False\n02:28:19 |     momentum: 0\n02:28:19 |     multitask_weights: [1]\n02:28:19 |     mutators: None\n02:28:19 |     n_decoder_layers: -1\n02:28:19 |     n_encoder_layers: -1\n02:28:19 |     n_heads: 12\n02:28:19 |     n_layers: 12\n02:28:19 |     n_positions: 1024\n02:28:19 |     n_segments: 2\n02:28:19 |     nesterov: True\n02:28:19 |     no_cuda: False\n02:28:19 |     normalize_sent_emb: False\n02:28:19 |     num_epochs: -1\n02:28:19 |     num_examples: -1\n02:28:19 |     num_workers: 0\n02:28:19 |     nus: [0.7]\n02:28:19 |     optimizer: adamax\n02:28:19 |     output_scaling: 0.06\n02:28:19 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type1/run2/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model2', 'batchsize': 40}\"\n02:28:19 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n02:28:19 |     person_tokens: False\n02:28:19 |     print_scores: False\n02:28:19 |     rank_candidates: False\n02:28:19 |     rank_top_k: -1\n02:28:19 |     reduction_type: mean\n02:28:19 |     ref_class: None\n02:28:19 |     relu_dropout: 0.0\n02:28:19 |     repeat_blocking_heuristic: True\n02:28:19 |     report_filename: \n02:28:19 |     return_cand_scores: False\n02:28:19 |     save_after_valid: True\n02:28:19 |     save_every_n_secs: -1\n02:28:19 |     save_format: conversations\n02:28:19 |     share_encoders: False\n02:28:19 |     share_word_embeddings: False\n02:28:19 |     short_final_eval: False\n02:28:19 |     special_tok_lst: None\n02:28:19 |     split_lines: False\n02:28:19 |     starttime: Dec04_02-15\n02:28:19 |     task: fromfile:parlaiformat\n02:28:19 |     tensorboard_log: False\n02:28:19 |     tensorboard_logdir: None\n02:28:19 |     text_truncate: 360\n02:28:19 |     threshold: 0.5\n02:28:19 |     topk: 5\n02:28:19 |     train_predict: False\n02:28:19 |     truncate: 1024\n02:28:19 |     update_classifier_head_only: False\n02:28:19 |     update_freq: 1\n02:28:19 |     use_memories: False\n02:28:19 |     use_reply: none\n02:28:19 |     validation_cutoff: 1.0\n02:28:19 |     validation_every_n_epochs: -1\n02:28:19 |     validation_every_n_secs: 20.0\n02:28:19 |     validation_every_n_steps: -1\n02:28:19 |     validation_max_exs: -1\n02:28:19 |     validation_metric: accuracy\n02:28:19 |     validation_metric_mode: max\n02:28:19 |     validation_patience: 30\n02:28:19 |     validation_share_agent: False\n02:28:19 |     variant: xlm\n02:28:19 |     verbose: False\n02:28:19 |     wandb_entity: None\n02:28:19 |     wandb_log: False\n02:28:19 |     wandb_name: None\n02:28:19 |     wandb_project: None\n02:28:19 |     warmup_rate: 0.0001\n02:28:19 |     warmup_updates: 1000\n02:28:19 |     weight_decay: None\n02:28:19 |     world_logs: \n02:28:19 |     wrap_memory_encoder: False\n02:28:19 | Evaluating task fromfile:parlaiformat using datatype valid.\n02:28:19 | creating task(s): fromfile:parlaiformat\n02:28:19 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n02:28:19 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run2/data_test.txt\n02:28:28 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .8900 8.9e-10               .6405                 .4757   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9800            .9351              .9975   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8800 12.07 562.9  1848       0          0 131.3 1000 .8900   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2925 7.404e-06   208 682.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    148 770.9 2530        .9056\u001b[0m\n02:28:28 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .8900 8.9e-10               .6405                 .4757   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9800            .9351              .9975   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8800 12.07 562.9  1848       0          0 131.3 1000 .8900   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2925 7.404e-06   208 682.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    148 770.9 2530        .9056\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model2*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:28:29.746589Z","iopub.execute_input":"2022-12-04T02:28:29.747031Z","iopub.status.idle":"2022-12-04T02:28:30.960677Z","shell.execute_reply.started":"2022-12-04T02:28:29.746985Z","shell.execute_reply":"2022-12-04T02:28:30.959380Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"markdown","source":"run 3","metadata":{}},{"cell_type":"code","source":"# run 3 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type1/run3/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model3","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:28:30.962669Z","iopub.execute_input":"2022-12-04T02:28:30.963081Z","iopub.status.idle":"2022-12-04T02:30:27.606522Z","shell.execute_reply.started":"2022-12-04T02:28:30.963035Z","shell.execute_reply":"2022-12-04T02:30:27.605311Z"},"scrolled":true,"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"02:28:38 | building dictionary first...\n02:28:38 | No model with opt yet at: /tmp/model3(.opt)\n02:28:38 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run3/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n02:28:38 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n02:28:38 | Using CUDA\n02:28:38 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n02:28:38 | num words = 54944\n02:28:42 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:28:52 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:28:52 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n02:28:52 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n02:28:52 | Opt:\n02:28:52 |     activation: gelu\n02:28:52 |     adafactor_eps: '(1e-30, 0.001)'\n02:28:52 |     adam_eps: 1e-08\n02:28:52 |     add_p1_after_newln: False\n02:28:52 |     aggregate_micro: False\n02:28:52 |     allow_missing_init_opts: False\n02:28:52 |     attention_dropout: 0.1\n02:28:52 |     batchsize: 20\n02:28:52 |     betas: '(0.9, 0.999)'\n02:28:52 |     bpe_add_prefix_space: None\n02:28:52 |     bpe_debug: False\n02:28:52 |     bpe_dropout: None\n02:28:52 |     bpe_merge: None\n02:28:52 |     bpe_vocab: None\n02:28:52 |     candidates: inline\n02:28:52 |     cap_num_predictions: 100\n02:28:52 |     checkpoint_activations: False\n02:28:52 |     class_weights: None\n02:28:52 |     classes: \"['__notok__', '__ok__']\"\n02:28:52 |     classes_from_file: None\n02:28:52 |     data_parallel: True\n02:28:52 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n02:28:52 |     datatype: train\n02:28:52 |     delimiter: '\\n'\n02:28:52 |     dict_class: parlai.core.dict:DictionaryAgent\n02:28:52 |     dict_endtoken: __start__\n02:28:52 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n02:28:52 |     dict_include_test: False\n02:28:52 |     dict_include_valid: False\n02:28:52 |     dict_initpath: None\n02:28:52 |     dict_language: english\n02:28:52 |     dict_loaded: True\n02:28:52 |     dict_lower: True\n02:28:52 |     dict_max_ngram_size: -1\n02:28:52 |     dict_maxexs: -1\n02:28:52 |     dict_maxtokens: -1\n02:28:52 |     dict_minfreq: 0\n02:28:52 |     dict_nulltoken: __null__\n02:28:52 |     dict_starttoken: __start__\n02:28:52 |     dict_textfields: text,labels\n02:28:52 |     dict_tokenizer: bpe\n02:28:52 |     dict_unktoken: __unk__\n02:28:52 |     display_examples: False\n02:28:52 |     download_path: None\n02:28:52 |     dropout: 0.1\n02:28:52 |     dynamic_batching: None\n02:28:52 |     embedding_projection: random\n02:28:52 |     embedding_size: 768\n02:28:52 |     embedding_type: random\n02:28:52 |     embeddings_scale: False\n02:28:52 |     encode_candidate_vecs: True\n02:28:52 |     encode_candidate_vecs_batchsize: 256\n02:28:52 |     eval_batchsize: None\n02:28:52 |     eval_candidates: inline\n02:28:52 |     eval_dynamic_batching: None\n02:28:52 |     evaltask: None\n02:28:52 |     ffn_size: 3072\n02:28:52 |     final_extra_opt: \n02:28:52 |     fixed_candidate_vecs: reuse\n02:28:52 |     fixed_candidates_path: None\n02:28:52 |     force_fp16_tokens: False\n02:28:52 |     fp16: True\n02:28:52 |     fp16_impl: safe\n02:28:52 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run3/data\n02:28:52 |     fromfile_datatype_extension: True\n02:28:52 |     gpu: -1\n02:28:52 |     gradient_clip: 0.1\n02:28:52 |     hide_labels: False\n02:28:52 |     history_add_global_end_token: None\n02:28:52 |     history_reversed: False\n02:28:52 |     history_size: 20\n02:28:52 |     ignore_bad_candidates: False\n02:28:52 |     ignore_labels: None\n02:28:52 |     image_cropsize: 224\n02:28:52 |     image_mode: raw\n02:28:52 |     image_size: 256\n02:28:52 |     inference: max\n02:28:52 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:28:52 |     init_opt: None\n02:28:52 |     interactive_candidates: fixed\n02:28:52 |     interactive_mode: False\n02:28:52 |     invsqrt_lr_decay_gamma: -1\n02:28:52 |     is_debug: False\n02:28:52 |     label_truncate: 72\n02:28:52 |     learn_embeddings: True\n02:28:52 |     learn_positional_embeddings: True\n02:28:52 |     learningrate: 5e-05\n02:28:52 |     load_from_checkpoint: False\n02:28:52 |     load_from_pretrained_ranker: True\n02:28:52 |     log_every_n_secs: 10.0\n02:28:52 |     log_every_n_steps: 50\n02:28:52 |     log_keep_fields: all\n02:28:52 |     loglevel: info\n02:28:52 |     lr_scheduler: reduceonplateau\n02:28:52 |     lr_scheduler_decay: 0.5\n02:28:52 |     lr_scheduler_patience: 3\n02:28:52 |     max_train_steps: -1\n02:28:52 |     max_train_time: 7200.0\n02:28:52 |     memory_attention: sqrt\n02:28:52 |     metrics: default\n02:28:52 |     model: transformer/classifier\n02:28:52 |     model_file: /tmp/model3\n02:28:52 |     model_parallel: False\n02:28:52 |     momentum: 0\n02:28:52 |     multitask_weights: [1]\n02:28:52 |     mutators: None\n02:28:52 |     n_decoder_layers: -1\n02:28:52 |     n_encoder_layers: -1\n02:28:52 |     n_heads: 12\n02:28:52 |     n_layers: 12\n02:28:52 |     n_positions: 1024\n02:28:52 |     n_segments: 2\n02:28:52 |     nesterov: True\n02:28:52 |     no_cuda: False\n02:28:52 |     normalize_sent_emb: False\n02:28:52 |     num_epochs: -1\n02:28:52 |     num_workers: 0\n02:28:52 |     nus: (0.7,)\n02:28:52 |     optimizer: adamax\n02:28:52 |     output_scaling: 0.06\n02:28:52 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type1/run3/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model3'}\"\n02:28:52 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n02:28:52 |     person_tokens: False\n02:28:52 |     print_scores: False\n02:28:52 |     rank_candidates: False\n02:28:52 |     rank_top_k: -1\n02:28:52 |     reduction_type: mean\n02:28:52 |     ref_class: None\n02:28:52 |     relu_dropout: 0.0\n02:28:52 |     repeat_blocking_heuristic: True\n02:28:52 |     return_cand_scores: False\n02:28:52 |     save_after_valid: True\n02:28:52 |     save_every_n_secs: -1\n02:28:52 |     save_format: conversations\n02:28:52 |     share_encoders: False\n02:28:52 |     share_word_embeddings: False\n02:28:52 |     short_final_eval: False\n02:28:52 |     special_tok_lst: None\n02:28:52 |     split_lines: False\n02:28:52 |     starttime: Dec04_02-28\n02:28:52 |     task: fromfile:parlaiformat\n02:28:52 |     tensorboard_log: False\n02:28:52 |     tensorboard_logdir: None\n02:28:52 |     text_truncate: 360\n02:28:52 |     threshold: 0.5\n02:28:52 |     topk: 5\n02:28:52 |     train_predict: False\n02:28:52 |     truncate: 1024\n02:28:52 |     update_classifier_head_only: False\n02:28:52 |     update_freq: 1\n02:28:52 |     use_memories: False\n02:28:52 |     use_reply: none\n02:28:52 |     validation_cutoff: 1.0\n02:28:52 |     validation_every_n_epochs: -1\n02:28:52 |     validation_every_n_secs: 20.0\n02:28:52 |     validation_every_n_steps: -1\n02:28:52 |     validation_max_exs: -1\n02:28:52 |     validation_metric: accuracy\n02:28:52 |     validation_metric_mode: max\n02:28:52 |     validation_patience: 30\n02:28:52 |     validation_share_agent: False\n02:28:52 |     variant: xlm\n02:28:52 |     verbose: False\n02:28:52 |     wandb_entity: None\n02:28:52 |     wandb_log: False\n02:28:52 |     wandb_name: None\n02:28:52 |     wandb_project: None\n02:28:52 |     warmup_rate: 0.0001\n02:28:52 |     warmup_updates: 1000\n02:28:52 |     weight_decay: None\n02:28:52 |     world_logs: \n02:28:52 |     wrap_memory_encoder: False\n02:28:53 | creating task(s): fromfile:parlaiformat\n02:28:53 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run3/data_train.txt\n02:28:53 | training...\n02:29:03 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5675 5.675e-10               .4611                 .6727   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .3507            .6388              .5276   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8095 11.32     1 266.4 529.5       0          0 39.74  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5675             32768  2.392    .1206 6.055 .6790 1.005e-06 121.1 240.6   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 387.6 770.1 1.992        .5451\n\n02:29:13 | time:20s total_exs:1160 total_steps:58 epochs:5.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6908 6.908e-10               .6529                 .7492   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5785            .7212              .6538   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8042 11.78     1 275.6  1052       0          0 76.35  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6908             32768  2.581    .1207 6.005 .6615 2.905e-06 120.1 458.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   58 395.7 1511 3.821        .6869\n\n02:29:13 | creating task(s): fromfile:parlaiformat\n02:29:13 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run3/data_valid.txt\n02:29:13 | running eval: valid\n02:29:13 | eval completed in 0.24s\n02:29:13 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8462                 .7857   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8182              .9000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.71 164.5  1540       0          0 112.3   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6421 2.905e-06    72   674       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     58 236.5 2214        .8322\n\u001b[0m\n02:29:13 | \u001b[1;32mnew best accuracy: 0.8333\u001b[0m\n02:29:13 | saving best valid model: /tmp/model3\n02:29:13 | Saving dictionary to /tmp/model3.dict\n02:29:17 | saving model checkpoint: /tmp/model3.checkpoint\n02:29:17 | Saving dictionary to /tmp/model3.checkpoint.dict\n02:29:34 | time:41s total_exs:1860 total_steps:93 epochs:9.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8857 8.857e-10               .8765                 .8875   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8659            .8936              .8842   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9032  11.4     1 267.9   916       0          0 68.37  700   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8857             32768  2.777    .1207 5.937 .5763 4.655e-06 118.7 405.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   93 386.7 1322 3.426        .8856\n\n02:29:37 | time:44s total_exs:2120 total_steps:106 epochs:10.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9077 9.077e-10               .9016                 .9402   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8661            .9130              .8811   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9474 11.53     1 270.6  1050       0          0 77.64  260   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9077             32768  3.755    .1207 5.977 .4908 5.304e-06 119.5   464   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  106 390.2 1515 3.908        .9075\n\n02:29:37 | running eval: valid\n02:29:37 | eval completed in 0.19s\n02:29:37 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.71 164.5  1853       0          0 135.1   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .4642 5.304e-06    72 810.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    106 236.5 2664        .9167\n\u001b[0m\n02:29:37 | \u001b[1;32mnew best accuracy: 0.9167 (previous best was 0.8333)\u001b[0m\n02:29:37 | saving best valid model: /tmp/model3\n02:29:42 | saving model checkpoint: /tmp/model3.checkpoint\n02:30:02 | time:69s total_exs:2900 total_steps:145 epochs:14.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9462 9.462e-10               .9457                 .9433   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9482            .9466              .9490   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9442 11.53     1 270.5  1032       0          0 76.31  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9462             32768  4.212    .1207  5.99 .3438 7.254e-06 119.8 457.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  145 390.3 1489 3.824        .9462\n\n02:30:02 | time:70s total_exs:2960 total_steps:148 epochs:14.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9333 9.333e-10               .9310                 .8710   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9355                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8788  11.4     1   268  1031       0          0 76.95   60   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9333             32768  6.858    .1189   5.9 .2203 7.404e-06   118 454.1   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  148  386 1485 3.963        .9335\n\n02:30:02 | running eval: valid\n02:30:03 | eval completed in 0.20s\n02:30:03 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 11.71 164.5  1856       0          0 135.4   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .1810 7.404e-06    72 812.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    148 236.5 2669            1\n\u001b[0m\n02:30:03 | \u001b[1;32mnew best accuracy: 1 (previous best was 0.9167)\u001b[0m\n02:30:03 | saving best valid model: /tmp/model3\n02:30:12 | task solved! stopping.\n02:30:12 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n02:30:12 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n02:30:12 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run3/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n02:30:12 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n02:30:12 | Using CUDA\n02:30:12 | loading dictionary from /tmp/model3.dict\n02:30:12 | num words = 54944\n02:30:17 | Loading existing model parameters from /tmp/model3\n02:30:19 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:30:20 | creating task(s): fromfile:parlaiformat\n02:30:20 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run3/data_valid.txt\n02:30:20 | running eval: valid\n02:30:20 | eval completed in 0.22s\n02:30:20 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 11.71 164.5  1658       0          0 120.9   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294     6 .1810 7.404e-06    72 725.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    148 236.5 2383            1\n\u001b[0m\n02:30:20 | creating task(s): fromfile:parlaiformat\n02:30:20 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run3/data_test.txt\n02:30:20 | running eval: test\n02:30:25 | eval completed in 4.90s\n02:30:25 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9530 9.53e-10               .8000                 .6963   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9400            .9734              .9931   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9544 12.07 281.4  2888       0          0 205.2 1000 .9530   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294   5.2 .1965 7.404e-06   104  1067       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    148 385.4 3955        .9560\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type1/run3/data_test.txt -m transformer/classifier -mf /tmp/model3 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:30:27.610806Z","iopub.execute_input":"2022-12-04T02:30:27.611214Z","iopub.status.idle":"2022-12-04T02:30:57.964441Z","shell.execute_reply.started":"2022-12-04T02:30:27.611171Z","shell.execute_reply":"2022-12-04T02:30:57.963202Z"},"scrolled":true,"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"02:30:36 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr2type1/run3/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr2type1/run3/data)\u001b[0m\n02:30:36 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n02:30:36 | Using CUDA\n02:30:36 | loading dictionary from /tmp/model3.dict\n02:30:36 | num words = 54944\n02:30:40 | Loading existing model parameters from /tmp/model3\n02:30:46 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:30:47 | Opt:\n02:30:47 |     activation: gelu\n02:30:47 |     adafactor_eps: '[1e-30, 0.001]'\n02:30:47 |     adam_eps: 1e-08\n02:30:47 |     add_p1_after_newln: False\n02:30:47 |     aggregate_micro: False\n02:30:47 |     allow_missing_init_opts: False\n02:30:47 |     area_under_curve_class: None\n02:30:47 |     area_under_curve_digits: -1\n02:30:47 |     attention_dropout: 0.1\n02:30:47 |     batchsize: 40\n02:30:47 |     betas: '[0.9, 0.999]'\n02:30:47 |     bpe_add_prefix_space: None\n02:30:47 |     bpe_debug: False\n02:30:47 |     bpe_dropout: None\n02:30:47 |     bpe_merge: None\n02:30:47 |     bpe_vocab: None\n02:30:47 |     candidates: inline\n02:30:47 |     cap_num_predictions: 100\n02:30:47 |     checkpoint_activations: False\n02:30:47 |     class_weights: None\n02:30:47 |     classes: \"['__notok__', '__ok__']\"\n02:30:47 |     classes_from_file: None\n02:30:47 |     data_parallel: True\n02:30:47 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n02:30:47 |     datatype: train\n02:30:47 |     delimiter: '\\n'\n02:30:47 |     dict_class: parlai.core.dict:DictionaryAgent\n02:30:47 |     dict_endtoken: __start__\n02:30:47 |     dict_file: /tmp/model3.dict\n02:30:47 |     dict_include_test: False\n02:30:47 |     dict_include_valid: False\n02:30:47 |     dict_initpath: None\n02:30:47 |     dict_language: english\n02:30:47 |     dict_loaded: True\n02:30:47 |     dict_lower: True\n02:30:47 |     dict_max_ngram_size: -1\n02:30:47 |     dict_maxexs: -1\n02:30:47 |     dict_maxtokens: -1\n02:30:47 |     dict_minfreq: 0\n02:30:47 |     dict_nulltoken: __null__\n02:30:47 |     dict_starttoken: __start__\n02:30:47 |     dict_textfields: text,labels\n02:30:47 |     dict_tokenizer: bpe\n02:30:47 |     dict_unktoken: __unk__\n02:30:47 |     display_examples: False\n02:30:47 |     download_path: None\n02:30:47 |     dropout: 0.1\n02:30:47 |     dynamic_batching: None\n02:30:47 |     embedding_projection: random\n02:30:47 |     embedding_size: 768\n02:30:47 |     embedding_type: random\n02:30:47 |     embeddings_scale: False\n02:30:47 |     encode_candidate_vecs: True\n02:30:47 |     encode_candidate_vecs_batchsize: 256\n02:30:47 |     eval_batchsize: None\n02:30:47 |     eval_candidates: inline\n02:30:47 |     eval_dynamic_batching: None\n02:30:47 |     evaltask: None\n02:30:47 |     ffn_size: 3072\n02:30:47 |     final_extra_opt: \n02:30:47 |     fixed_candidate_vecs: reuse\n02:30:47 |     fixed_candidates_path: None\n02:30:47 |     force_fp16_tokens: True\n02:30:47 |     fp16: True\n02:30:47 |     fp16_impl: safe\n02:30:47 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run3/data_test.txt\n02:30:47 |     fromfile_datatype_extension: True\n02:30:47 |     gpu: -1\n02:30:47 |     gradient_clip: 0.1\n02:30:47 |     hide_labels: False\n02:30:47 |     history_add_global_end_token: None\n02:30:47 |     history_reversed: False\n02:30:47 |     history_size: 20\n02:30:47 |     ignore_bad_candidates: False\n02:30:47 |     ignore_labels: None\n02:30:47 |     image_cropsize: 224\n02:30:47 |     image_mode: raw\n02:30:47 |     image_size: 256\n02:30:47 |     inference: max\n02:30:47 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:30:47 |     init_opt: None\n02:30:47 |     interactive_candidates: fixed\n02:30:47 |     interactive_mode: False\n02:30:47 |     invsqrt_lr_decay_gamma: -1\n02:30:47 |     is_debug: False\n02:30:47 |     label_truncate: 72\n02:30:47 |     learn_embeddings: True\n02:30:47 |     learn_positional_embeddings: True\n02:30:47 |     learningrate: 5e-05\n02:30:47 |     load_from_pretrained_ranker: True\n02:30:47 |     log_every_n_secs: 10.0\n02:30:47 |     log_every_n_steps: 50\n02:30:47 |     log_keep_fields: all\n02:30:47 |     loglevel: info\n02:30:47 |     lr_scheduler: reduceonplateau\n02:30:47 |     lr_scheduler_decay: 0.5\n02:30:47 |     lr_scheduler_patience: 3\n02:30:47 |     max_train_steps: -1\n02:30:47 |     max_train_time: 7200.0\n02:30:47 |     memory_attention: sqrt\n02:30:47 |     metrics: default\n02:30:47 |     model: transformer/classifier\n02:30:47 |     model_file: /tmp/model3\n02:30:47 |     model_parallel: False\n02:30:47 |     momentum: 0\n02:30:47 |     multitask_weights: [1]\n02:30:47 |     mutators: None\n02:30:47 |     n_decoder_layers: -1\n02:30:47 |     n_encoder_layers: -1\n02:30:47 |     n_heads: 12\n02:30:47 |     n_layers: 12\n02:30:47 |     n_positions: 1024\n02:30:47 |     n_segments: 2\n02:30:47 |     nesterov: True\n02:30:47 |     no_cuda: False\n02:30:47 |     normalize_sent_emb: False\n02:30:47 |     num_epochs: -1\n02:30:47 |     num_examples: -1\n02:30:47 |     num_workers: 0\n02:30:47 |     nus: [0.7]\n02:30:47 |     optimizer: adamax\n02:30:47 |     output_scaling: 0.06\n02:30:47 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type1/run3/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model3', 'batchsize': 40}\"\n02:30:47 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n02:30:47 |     person_tokens: False\n02:30:47 |     print_scores: False\n02:30:47 |     rank_candidates: False\n02:30:47 |     rank_top_k: -1\n02:30:47 |     reduction_type: mean\n02:30:47 |     ref_class: None\n02:30:47 |     relu_dropout: 0.0\n02:30:47 |     repeat_blocking_heuristic: True\n02:30:47 |     report_filename: \n02:30:47 |     return_cand_scores: False\n02:30:47 |     save_after_valid: True\n02:30:47 |     save_every_n_secs: -1\n02:30:47 |     save_format: conversations\n02:30:47 |     share_encoders: False\n02:30:47 |     share_word_embeddings: False\n02:30:47 |     short_final_eval: False\n02:30:47 |     special_tok_lst: None\n02:30:47 |     split_lines: False\n02:30:47 |     starttime: Dec04_02-28\n02:30:47 |     task: fromfile:parlaiformat\n02:30:47 |     tensorboard_log: False\n02:30:47 |     tensorboard_logdir: None\n02:30:47 |     text_truncate: 360\n02:30:47 |     threshold: 0.5\n02:30:47 |     topk: 5\n02:30:47 |     train_predict: False\n02:30:47 |     truncate: 1024\n02:30:47 |     update_classifier_head_only: False\n02:30:47 |     update_freq: 1\n02:30:47 |     use_memories: False\n02:30:47 |     use_reply: none\n02:30:47 |     validation_cutoff: 1.0\n02:30:47 |     validation_every_n_epochs: -1\n02:30:47 |     validation_every_n_secs: 20.0\n02:30:47 |     validation_every_n_steps: -1\n02:30:47 |     validation_max_exs: -1\n02:30:47 |     validation_metric: accuracy\n02:30:47 |     validation_metric_mode: max\n02:30:47 |     validation_patience: 30\n02:30:47 |     validation_share_agent: False\n02:30:47 |     variant: xlm\n02:30:47 |     verbose: False\n02:30:47 |     wandb_entity: None\n02:30:47 |     wandb_log: False\n02:30:47 |     wandb_name: None\n02:30:47 |     wandb_project: None\n02:30:47 |     warmup_rate: 0.0001\n02:30:47 |     warmup_updates: 1000\n02:30:47 |     weight_decay: None\n02:30:47 |     world_logs: \n02:30:47 |     wrap_memory_encoder: False\n02:30:47 | Evaluating task fromfile:parlaiformat using datatype valid.\n02:30:47 | creating task(s): fromfile:parlaiformat\n02:30:47 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n02:30:47 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run3/data_test.txt\n02:30:56 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9530 9.53e-10               .8000                 .6963   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9400            .9734              .9931   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9544 12.07 562.9  1769       0          0 125.7 1000 .9530   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .1965 7.404e-06   208 653.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    148 770.9 2423        .9560\u001b[0m\n02:30:56 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9530 9.53e-10               .8000                 .6963   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9400            .9734              .9931   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9544 12.07 562.9  1769       0          0 125.7 1000 .9530   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .1965 7.404e-06   208 653.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    148 770.9 2423        .9560\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model3*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:30:57.966135Z","iopub.execute_input":"2022-12-04T02:30:57.966557Z","iopub.status.idle":"2022-12-04T02:30:59.228499Z","shell.execute_reply.started":"2022-12-04T02:30:57.966509Z","shell.execute_reply":"2022-12-04T02:30:59.227144Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"markdown","source":"run 4","metadata":{}},{"cell_type":"code","source":"# run 4 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type1/run4/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model4","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:30:59.230550Z","iopub.execute_input":"2022-12-04T02:30:59.230960Z","iopub.status.idle":"2022-12-04T02:33:11.466440Z","shell.execute_reply.started":"2022-12-04T02:30:59.230917Z","shell.execute_reply":"2022-12-04T02:33:11.465033Z"},"scrolled":true,"trusted":true},"execution_count":105,"outputs":[{"name":"stdout","text":"02:31:06 | building dictionary first...\n02:31:06 | No model with opt yet at: /tmp/model4(.opt)\n02:31:06 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run4/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n02:31:06 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n02:31:06 | Using CUDA\n02:31:06 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n02:31:06 | num words = 54944\n02:31:10 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:31:21 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:31:21 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n02:31:21 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n02:31:21 | Opt:\n02:31:21 |     activation: gelu\n02:31:21 |     adafactor_eps: '(1e-30, 0.001)'\n02:31:21 |     adam_eps: 1e-08\n02:31:21 |     add_p1_after_newln: False\n02:31:21 |     aggregate_micro: False\n02:31:21 |     allow_missing_init_opts: False\n02:31:21 |     attention_dropout: 0.1\n02:31:21 |     batchsize: 20\n02:31:21 |     betas: '(0.9, 0.999)'\n02:31:21 |     bpe_add_prefix_space: None\n02:31:21 |     bpe_debug: False\n02:31:21 |     bpe_dropout: None\n02:31:21 |     bpe_merge: None\n02:31:21 |     bpe_vocab: None\n02:31:21 |     candidates: inline\n02:31:21 |     cap_num_predictions: 100\n02:31:21 |     checkpoint_activations: False\n02:31:21 |     class_weights: None\n02:31:21 |     classes: \"['__notok__', '__ok__']\"\n02:31:21 |     classes_from_file: None\n02:31:21 |     data_parallel: True\n02:31:21 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n02:31:21 |     datatype: train\n02:31:21 |     delimiter: '\\n'\n02:31:21 |     dict_class: parlai.core.dict:DictionaryAgent\n02:31:21 |     dict_endtoken: __start__\n02:31:21 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n02:31:21 |     dict_include_test: False\n02:31:21 |     dict_include_valid: False\n02:31:21 |     dict_initpath: None\n02:31:21 |     dict_language: english\n02:31:21 |     dict_loaded: True\n02:31:21 |     dict_lower: True\n02:31:21 |     dict_max_ngram_size: -1\n02:31:21 |     dict_maxexs: -1\n02:31:21 |     dict_maxtokens: -1\n02:31:21 |     dict_minfreq: 0\n02:31:21 |     dict_nulltoken: __null__\n02:31:21 |     dict_starttoken: __start__\n02:31:21 |     dict_textfields: text,labels\n02:31:21 |     dict_tokenizer: bpe\n02:31:21 |     dict_unktoken: __unk__\n02:31:21 |     display_examples: False\n02:31:21 |     download_path: None\n02:31:21 |     dropout: 0.1\n02:31:21 |     dynamic_batching: None\n02:31:21 |     embedding_projection: random\n02:31:21 |     embedding_size: 768\n02:31:21 |     embedding_type: random\n02:31:21 |     embeddings_scale: False\n02:31:21 |     encode_candidate_vecs: True\n02:31:21 |     encode_candidate_vecs_batchsize: 256\n02:31:21 |     eval_batchsize: None\n02:31:21 |     eval_candidates: inline\n02:31:21 |     eval_dynamic_batching: None\n02:31:21 |     evaltask: None\n02:31:21 |     ffn_size: 3072\n02:31:21 |     final_extra_opt: \n02:31:21 |     fixed_candidate_vecs: reuse\n02:31:21 |     fixed_candidates_path: None\n02:31:21 |     force_fp16_tokens: False\n02:31:21 |     fp16: True\n02:31:21 |     fp16_impl: safe\n02:31:21 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run4/data\n02:31:21 |     fromfile_datatype_extension: True\n02:31:21 |     gpu: -1\n02:31:21 |     gradient_clip: 0.1\n02:31:21 |     hide_labels: False\n02:31:21 |     history_add_global_end_token: None\n02:31:21 |     history_reversed: False\n02:31:21 |     history_size: 20\n02:31:21 |     ignore_bad_candidates: False\n02:31:21 |     ignore_labels: None\n02:31:21 |     image_cropsize: 224\n02:31:21 |     image_mode: raw\n02:31:21 |     image_size: 256\n02:31:21 |     inference: max\n02:31:21 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:31:21 |     init_opt: None\n02:31:21 |     interactive_candidates: fixed\n02:31:21 |     interactive_mode: False\n02:31:21 |     invsqrt_lr_decay_gamma: -1\n02:31:21 |     is_debug: False\n02:31:21 |     label_truncate: 72\n02:31:21 |     learn_embeddings: True\n02:31:21 |     learn_positional_embeddings: True\n02:31:21 |     learningrate: 5e-05\n02:31:21 |     load_from_checkpoint: False\n02:31:21 |     load_from_pretrained_ranker: True\n02:31:21 |     log_every_n_secs: 10.0\n02:31:21 |     log_every_n_steps: 50\n02:31:21 |     log_keep_fields: all\n02:31:21 |     loglevel: info\n02:31:21 |     lr_scheduler: reduceonplateau\n02:31:21 |     lr_scheduler_decay: 0.5\n02:31:21 |     lr_scheduler_patience: 3\n02:31:21 |     max_train_steps: -1\n02:31:21 |     max_train_time: 7200.0\n02:31:21 |     memory_attention: sqrt\n02:31:21 |     metrics: default\n02:31:21 |     model: transformer/classifier\n02:31:21 |     model_file: /tmp/model4\n02:31:21 |     model_parallel: False\n02:31:21 |     momentum: 0\n02:31:21 |     multitask_weights: [1]\n02:31:21 |     mutators: None\n02:31:21 |     n_decoder_layers: -1\n02:31:21 |     n_encoder_layers: -1\n02:31:21 |     n_heads: 12\n02:31:21 |     n_layers: 12\n02:31:21 |     n_positions: 1024\n02:31:21 |     n_segments: 2\n02:31:21 |     nesterov: True\n02:31:21 |     no_cuda: False\n02:31:21 |     normalize_sent_emb: False\n02:31:21 |     num_epochs: -1\n02:31:21 |     num_workers: 0\n02:31:21 |     nus: (0.7,)\n02:31:21 |     optimizer: adamax\n02:31:21 |     output_scaling: 0.06\n02:31:21 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type1/run4/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model4'}\"\n02:31:21 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n02:31:21 |     person_tokens: False\n02:31:21 |     print_scores: False\n02:31:21 |     rank_candidates: False\n02:31:21 |     rank_top_k: -1\n02:31:21 |     reduction_type: mean\n02:31:21 |     ref_class: None\n02:31:21 |     relu_dropout: 0.0\n02:31:21 |     repeat_blocking_heuristic: True\n02:31:21 |     return_cand_scores: False\n02:31:21 |     save_after_valid: True\n02:31:21 |     save_every_n_secs: -1\n02:31:21 |     save_format: conversations\n02:31:21 |     share_encoders: False\n02:31:21 |     share_word_embeddings: False\n02:31:21 |     short_final_eval: False\n02:31:21 |     special_tok_lst: None\n02:31:21 |     split_lines: False\n02:31:21 |     starttime: Dec04_02-31\n02:31:21 |     task: fromfile:parlaiformat\n02:31:21 |     tensorboard_log: False\n02:31:21 |     tensorboard_logdir: None\n02:31:21 |     text_truncate: 360\n02:31:21 |     threshold: 0.5\n02:31:21 |     topk: 5\n02:31:21 |     train_predict: False\n02:31:21 |     truncate: 1024\n02:31:21 |     update_classifier_head_only: False\n02:31:21 |     update_freq: 1\n02:31:21 |     use_memories: False\n02:31:21 |     use_reply: none\n02:31:21 |     validation_cutoff: 1.0\n02:31:21 |     validation_every_n_epochs: -1\n02:31:21 |     validation_every_n_secs: 20.0\n02:31:21 |     validation_every_n_steps: -1\n02:31:21 |     validation_max_exs: -1\n02:31:21 |     validation_metric: accuracy\n02:31:21 |     validation_metric_mode: max\n02:31:21 |     validation_patience: 30\n02:31:21 |     validation_share_agent: False\n02:31:21 |     variant: xlm\n02:31:21 |     verbose: False\n02:31:21 |     wandb_entity: None\n02:31:21 |     wandb_log: False\n02:31:21 |     wandb_name: None\n02:31:21 |     wandb_project: None\n02:31:21 |     warmup_rate: 0.0001\n02:31:21 |     warmup_updates: 1000\n02:31:21 |     weight_decay: None\n02:31:21 |     world_logs: \n02:31:21 |     wrap_memory_encoder: False\n02:31:21 | creating task(s): fromfile:parlaiformat\n02:31:21 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run4/data_train.txt\n02:31:21 | training...\n02:31:31 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5375 5.375e-10               .6463                 .5060   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8942            .3321              .6970   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .2180 11.15     1 262.9 523.1       0          0 39.79  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5375             32768  2.624    .1245 5.945 .6857 1.005e-06 118.9 236.6   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 381.9 759.7 1.994        .4806\n\n02:31:41 | time:20s total_exs:1160 total_steps:58 epochs:5.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7158 7.158e-10               .7410                 .6688   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8306            .6851              .7886   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6057 11.41     1 268.2  1031       0          0 76.85  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7158             32768  2.408    .1245 5.979 .6585 2.905e-06 119.6 459.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   58 387.8 1490 3.851        .7125\n\n02:31:41 | creating task(s): fromfile:parlaiformat\n02:31:41 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run4/data_valid.txt\n02:31:41 | running eval: valid\n02:31:42 | eval completed in 0.20s\n02:31:42 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .7200                 .6923   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .6957              .7273   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .6667 12.04 168.5  1885       0          0 134.2   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6541 2.905e-06    72 805.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     58 240.5 2690        .7078\n\u001b[0m\n02:31:42 | \u001b[1;32mnew best accuracy: 0.7083\u001b[0m\n02:31:42 | saving best valid model: /tmp/model4\n02:31:42 | Saving dictionary to /tmp/model4.dict\n02:31:45 | saving model checkpoint: /tmp/model4.checkpoint\n02:31:45 | Saving dictionary to /tmp/model4.checkpoint.dict\n02:32:03 | time:41s total_exs:1840 total_steps:92 epochs:9.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8912 8.912e-10               .8928                 .9006   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8851            .8896              .8817   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8976 11.45     1   269   911       0          0 67.74  680   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8912             32768  2.835    .1245 6.024 .6050 4.605e-06 120.5   408   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   92 389.4 1319 3.395        .8912\n\n02:32:06 | time:44s total_exs:2060 total_steps:103 epochs:10.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9545 9.545e-10               .9561                 .9316   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9820            .9528              .9806   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9266 11.41     1 268.3  1027       0          0 76.53  220   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9545             32768  2.861    .1207 6.009 .5417 5.154e-06 120.2 459.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  103 388.5 1486 3.857        .9545\n\n02:32:06 | running eval: valid\n02:32:06 | eval completed in 0.23s\n02:32:06 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.04 168.5  1659       0          0 118.1   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5559 5.154e-06    72   709       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    103 240.5 2369        .9583\n\u001b[0m\n02:32:06 | \u001b[1;32mnew best accuracy: 0.9583 (previous best was 0.7083)\u001b[0m\n02:32:06 | saving best valid model: /tmp/model4\n02:32:11 | saving model checkpoint: /tmp/model4.checkpoint\n02:32:29 | time:68s total_exs:2800 total_steps:140 epochs:14.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9581 9.581e-10               .9593                 .9555   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9631            .9569              .9609   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9529 11.47     1 269.5 990.6       0          0 73.53  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9581             32768  3.337    .1245 6.024 .4287 7.004e-06 120.5   443   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  140 389.9 1434 3.685        .9581\n\n02:32:31 | time:70s total_exs:2960 total_steps:148 epochs:14.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9563 9.562e-10               .9586                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9205            .9536              .9114   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.17     1 263.4  1012       0          0 76.84  160   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9563             32768  3.535    .1207   6.1 .3025 7.404e-06   122 468.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  148 385.4 1481 3.884        .9564\n\n02:32:31 | running eval: valid\n02:32:31 | eval completed in 0.20s\n02:32:31 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.04 168.5  1828       0          0 130.2   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .2792 7.404e-06    72 781.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    148 240.5 2609        .9583\n\u001b[0m\n02:32:31 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 1\u001b[0m\n02:32:31 | saving model checkpoint: /tmp/model4.checkpoint\n02:32:47 | time:85s total_exs:3740 total_steps:187 epochs:18.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9731 9.731e-10               .9720                 .9891   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9554            .9741              .9587   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9900 11.47     1 269.3  1025       0          0 76.13  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9731             32768  4.122    .1245 5.977 .1647 9.354e-06 119.5 455.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  187 388.9 1480 3.815        .9731\n\n02:32:51 | time:90s total_exs:4080 total_steps:204 epochs:20.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9676 9.676e-10               .9688                 .9771   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9607            .9664              .9576   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9753 11.28     1 265.6  1007       0          0 75.79  340   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  ltps  \\\n   .9676             32768  5.254    .1245 6.047 .1096 1.02e-05 120.9 458.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  204 386.6 1465 3.809        .9677\n\n02:32:51 | running eval: valid\n02:32:51 | eval completed in 0.20s\n02:32:51 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 12.04 168.5  1857       0          0 132.2   24   1   \n    gpu_mem  llen   loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .02453 1.02e-05    72 793.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    204 240.5 2650            1\n\u001b[0m\n02:32:51 | \u001b[1;32mnew best accuracy: 1 (previous best was 0.9583)\u001b[0m\n02:32:51 | saving best valid model: /tmp/model4\n02:32:56 | task solved! stopping.\n02:32:56 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n02:32:56 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n02:32:56 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run4/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n02:32:56 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n02:32:56 | Using CUDA\n02:32:56 | loading dictionary from /tmp/model4.dict\n02:32:56 | num words = 54944\n02:33:01 | Loading existing model parameters from /tmp/model4\n02:33:02 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:33:04 | creating task(s): fromfile:parlaiformat\n02:33:04 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run4/data_valid.txt\n02:33:04 | running eval: valid\n02:33:04 | eval completed in 0.21s\n02:33:04 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 12.04 168.5  1815       0          0 129.2   24   1   \n    gpu_mem  llen   loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294     6 .02453 1.02e-05    72 775.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    204 240.5 2590            1\n\u001b[0m\n02:33:04 | creating task(s): fromfile:parlaiformat\n02:33:04 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run4/data_test.txt\n02:33:04 | running eval: test\n02:33:09 | eval completed in 5.29s\n02:33:09 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9420 9.42e-10               .7603                 .6479   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9200            .9670              .9907   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9444 12.07 281.4  2672       0          0 189.9 1000 .9420   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294   5.2 .1789 1.02e-05   104 987.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    204 385.4 3660        .9463\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type1/run4/data_test.txt -m transformer/classifier -mf /tmp/model4 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:33:11.477497Z","iopub.execute_input":"2022-12-04T02:33:11.479095Z","iopub.status.idle":"2022-12-04T02:33:42.100503Z","shell.execute_reply.started":"2022-12-04T02:33:11.479039Z","shell.execute_reply":"2022-12-04T02:33:42.099338Z"},"scrolled":true,"trusted":true},"execution_count":106,"outputs":[{"name":"stdout","text":"02:33:20 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr2type1/run4/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr2type1/run4/data)\u001b[0m\n02:33:20 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n02:33:20 | Using CUDA\n02:33:20 | loading dictionary from /tmp/model4.dict\n02:33:20 | num words = 54944\n02:33:24 | Loading existing model parameters from /tmp/model4\n02:33:30 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:33:32 | Opt:\n02:33:32 |     activation: gelu\n02:33:32 |     adafactor_eps: '[1e-30, 0.001]'\n02:33:32 |     adam_eps: 1e-08\n02:33:32 |     add_p1_after_newln: False\n02:33:32 |     aggregate_micro: False\n02:33:32 |     allow_missing_init_opts: False\n02:33:32 |     area_under_curve_class: None\n02:33:32 |     area_under_curve_digits: -1\n02:33:32 |     attention_dropout: 0.1\n02:33:32 |     batchsize: 40\n02:33:32 |     betas: '[0.9, 0.999]'\n02:33:32 |     bpe_add_prefix_space: None\n02:33:32 |     bpe_debug: False\n02:33:32 |     bpe_dropout: None\n02:33:32 |     bpe_merge: None\n02:33:32 |     bpe_vocab: None\n02:33:32 |     candidates: inline\n02:33:32 |     cap_num_predictions: 100\n02:33:32 |     checkpoint_activations: False\n02:33:32 |     class_weights: None\n02:33:32 |     classes: \"['__notok__', '__ok__']\"\n02:33:32 |     classes_from_file: None\n02:33:32 |     data_parallel: True\n02:33:32 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n02:33:32 |     datatype: train\n02:33:32 |     delimiter: '\\n'\n02:33:32 |     dict_class: parlai.core.dict:DictionaryAgent\n02:33:32 |     dict_endtoken: __start__\n02:33:32 |     dict_file: /tmp/model4.dict\n02:33:32 |     dict_include_test: False\n02:33:32 |     dict_include_valid: False\n02:33:32 |     dict_initpath: None\n02:33:32 |     dict_language: english\n02:33:32 |     dict_loaded: True\n02:33:32 |     dict_lower: True\n02:33:32 |     dict_max_ngram_size: -1\n02:33:32 |     dict_maxexs: -1\n02:33:32 |     dict_maxtokens: -1\n02:33:32 |     dict_minfreq: 0\n02:33:32 |     dict_nulltoken: __null__\n02:33:32 |     dict_starttoken: __start__\n02:33:32 |     dict_textfields: text,labels\n02:33:32 |     dict_tokenizer: bpe\n02:33:32 |     dict_unktoken: __unk__\n02:33:32 |     display_examples: False\n02:33:32 |     download_path: None\n02:33:32 |     dropout: 0.1\n02:33:32 |     dynamic_batching: None\n02:33:32 |     embedding_projection: random\n02:33:32 |     embedding_size: 768\n02:33:32 |     embedding_type: random\n02:33:32 |     embeddings_scale: False\n02:33:32 |     encode_candidate_vecs: True\n02:33:32 |     encode_candidate_vecs_batchsize: 256\n02:33:32 |     eval_batchsize: None\n02:33:32 |     eval_candidates: inline\n02:33:32 |     eval_dynamic_batching: None\n02:33:32 |     evaltask: None\n02:33:32 |     ffn_size: 3072\n02:33:32 |     final_extra_opt: \n02:33:32 |     fixed_candidate_vecs: reuse\n02:33:32 |     fixed_candidates_path: None\n02:33:32 |     force_fp16_tokens: True\n02:33:32 |     fp16: True\n02:33:32 |     fp16_impl: safe\n02:33:32 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run4/data_test.txt\n02:33:32 |     fromfile_datatype_extension: True\n02:33:32 |     gpu: -1\n02:33:32 |     gradient_clip: 0.1\n02:33:32 |     hide_labels: False\n02:33:32 |     history_add_global_end_token: None\n02:33:32 |     history_reversed: False\n02:33:32 |     history_size: 20\n02:33:32 |     ignore_bad_candidates: False\n02:33:32 |     ignore_labels: None\n02:33:32 |     image_cropsize: 224\n02:33:32 |     image_mode: raw\n02:33:32 |     image_size: 256\n02:33:32 |     inference: max\n02:33:32 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:33:32 |     init_opt: None\n02:33:32 |     interactive_candidates: fixed\n02:33:32 |     interactive_mode: False\n02:33:32 |     invsqrt_lr_decay_gamma: -1\n02:33:32 |     is_debug: False\n02:33:32 |     label_truncate: 72\n02:33:32 |     learn_embeddings: True\n02:33:32 |     learn_positional_embeddings: True\n02:33:32 |     learningrate: 5e-05\n02:33:32 |     load_from_pretrained_ranker: True\n02:33:32 |     log_every_n_secs: 10.0\n02:33:32 |     log_every_n_steps: 50\n02:33:32 |     log_keep_fields: all\n02:33:32 |     loglevel: info\n02:33:32 |     lr_scheduler: reduceonplateau\n02:33:32 |     lr_scheduler_decay: 0.5\n02:33:32 |     lr_scheduler_patience: 3\n02:33:32 |     max_train_steps: -1\n02:33:32 |     max_train_time: 7200.0\n02:33:32 |     memory_attention: sqrt\n02:33:32 |     metrics: default\n02:33:32 |     model: transformer/classifier\n02:33:32 |     model_file: /tmp/model4\n02:33:32 |     model_parallel: False\n02:33:32 |     momentum: 0\n02:33:32 |     multitask_weights: [1]\n02:33:32 |     mutators: None\n02:33:32 |     n_decoder_layers: -1\n02:33:32 |     n_encoder_layers: -1\n02:33:32 |     n_heads: 12\n02:33:32 |     n_layers: 12\n02:33:32 |     n_positions: 1024\n02:33:32 |     n_segments: 2\n02:33:32 |     nesterov: True\n02:33:32 |     no_cuda: False\n02:33:32 |     normalize_sent_emb: False\n02:33:32 |     num_epochs: -1\n02:33:32 |     num_examples: -1\n02:33:32 |     num_workers: 0\n02:33:32 |     nus: [0.7]\n02:33:32 |     optimizer: adamax\n02:33:32 |     output_scaling: 0.06\n02:33:32 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type1/run4/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model4', 'batchsize': 40}\"\n02:33:32 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n02:33:32 |     person_tokens: False\n02:33:32 |     print_scores: False\n02:33:32 |     rank_candidates: False\n02:33:32 |     rank_top_k: -1\n02:33:32 |     reduction_type: mean\n02:33:32 |     ref_class: None\n02:33:32 |     relu_dropout: 0.0\n02:33:32 |     repeat_blocking_heuristic: True\n02:33:32 |     report_filename: \n02:33:32 |     return_cand_scores: False\n02:33:32 |     save_after_valid: True\n02:33:32 |     save_every_n_secs: -1\n02:33:32 |     save_format: conversations\n02:33:32 |     share_encoders: False\n02:33:32 |     share_word_embeddings: False\n02:33:32 |     short_final_eval: False\n02:33:32 |     special_tok_lst: None\n02:33:32 |     split_lines: False\n02:33:32 |     starttime: Dec04_02-31\n02:33:32 |     task: fromfile:parlaiformat\n02:33:32 |     tensorboard_log: False\n02:33:32 |     tensorboard_logdir: None\n02:33:32 |     text_truncate: 360\n02:33:32 |     threshold: 0.5\n02:33:32 |     topk: 5\n02:33:32 |     train_predict: False\n02:33:32 |     truncate: 1024\n02:33:32 |     update_classifier_head_only: False\n02:33:32 |     update_freq: 1\n02:33:32 |     use_memories: False\n02:33:32 |     use_reply: none\n02:33:32 |     validation_cutoff: 1.0\n02:33:32 |     validation_every_n_epochs: -1\n02:33:32 |     validation_every_n_secs: 20.0\n02:33:32 |     validation_every_n_steps: -1\n02:33:32 |     validation_max_exs: -1\n02:33:32 |     validation_metric: accuracy\n02:33:32 |     validation_metric_mode: max\n02:33:32 |     validation_patience: 30\n02:33:32 |     validation_share_agent: False\n02:33:32 |     variant: xlm\n02:33:32 |     verbose: False\n02:33:32 |     wandb_entity: None\n02:33:32 |     wandb_log: False\n02:33:32 |     wandb_name: None\n02:33:32 |     wandb_project: None\n02:33:32 |     warmup_rate: 0.0001\n02:33:32 |     warmup_updates: 1000\n02:33:32 |     weight_decay: None\n02:33:32 |     world_logs: \n02:33:32 |     wrap_memory_encoder: False\n02:33:32 | Evaluating task fromfile:parlaiformat using datatype valid.\n02:33:32 | creating task(s): fromfile:parlaiformat\n02:33:32 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n02:33:32 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run4/data_test.txt\n02:33:40 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9420 9.42e-10               .7603                 .6479   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9200            .9670              .9907   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9444 12.07 562.9  1833       0          0 130.2 1000 .9420   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .1789 1.02e-05   208 677.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    204 770.9 2510        .9463\u001b[0m\n02:33:40 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9420 9.42e-10               .7603                 .6479   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9200            .9670              .9907   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9444 12.07 562.9  1833       0          0 130.2 1000 .9420   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .1789 1.02e-05   208 677.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    204 770.9 2510        .9463\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model4*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:33:42.102158Z","iopub.execute_input":"2022-12-04T02:33:42.102544Z","iopub.status.idle":"2022-12-04T02:33:43.393236Z","shell.execute_reply.started":"2022-12-04T02:33:42.102504Z","shell.execute_reply":"2022-12-04T02:33:43.391900Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"markdown","source":"run 5","metadata":{}},{"cell_type":"code","source":"# run 5 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type1/run5/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model5","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:33:43.397275Z","iopub.execute_input":"2022-12-04T02:33:43.397600Z","iopub.status.idle":"2022-12-04T02:35:11.321913Z","shell.execute_reply.started":"2022-12-04T02:33:43.397567Z","shell.execute_reply":"2022-12-04T02:35:11.320719Z"},"scrolled":true,"trusted":true},"execution_count":108,"outputs":[{"name":"stdout","text":"02:33:50 | building dictionary first...\n02:33:50 | No model with opt yet at: /tmp/model5(.opt)\n02:33:50 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run5/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n02:33:50 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n02:33:50 | Using CUDA\n02:33:50 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n02:33:50 | num words = 54944\n02:33:55 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:34:05 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:34:05 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n02:34:05 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n02:34:05 | Opt:\n02:34:05 |     activation: gelu\n02:34:05 |     adafactor_eps: '(1e-30, 0.001)'\n02:34:05 |     adam_eps: 1e-08\n02:34:05 |     add_p1_after_newln: False\n02:34:05 |     aggregate_micro: False\n02:34:05 |     allow_missing_init_opts: False\n02:34:05 |     attention_dropout: 0.1\n02:34:05 |     batchsize: 20\n02:34:05 |     betas: '(0.9, 0.999)'\n02:34:05 |     bpe_add_prefix_space: None\n02:34:05 |     bpe_debug: False\n02:34:05 |     bpe_dropout: None\n02:34:05 |     bpe_merge: None\n02:34:05 |     bpe_vocab: None\n02:34:05 |     candidates: inline\n02:34:05 |     cap_num_predictions: 100\n02:34:05 |     checkpoint_activations: False\n02:34:05 |     class_weights: None\n02:34:05 |     classes: \"['__notok__', '__ok__']\"\n02:34:05 |     classes_from_file: None\n02:34:05 |     data_parallel: True\n02:34:05 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n02:34:05 |     datatype: train\n02:34:05 |     delimiter: '\\n'\n02:34:05 |     dict_class: parlai.core.dict:DictionaryAgent\n02:34:05 |     dict_endtoken: __start__\n02:34:05 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n02:34:05 |     dict_include_test: False\n02:34:05 |     dict_include_valid: False\n02:34:05 |     dict_initpath: None\n02:34:05 |     dict_language: english\n02:34:05 |     dict_loaded: True\n02:34:05 |     dict_lower: True\n02:34:05 |     dict_max_ngram_size: -1\n02:34:05 |     dict_maxexs: -1\n02:34:05 |     dict_maxtokens: -1\n02:34:05 |     dict_minfreq: 0\n02:34:05 |     dict_nulltoken: __null__\n02:34:05 |     dict_starttoken: __start__\n02:34:05 |     dict_textfields: text,labels\n02:34:05 |     dict_tokenizer: bpe\n02:34:05 |     dict_unktoken: __unk__\n02:34:05 |     display_examples: False\n02:34:05 |     download_path: None\n02:34:05 |     dropout: 0.1\n02:34:05 |     dynamic_batching: None\n02:34:05 |     embedding_projection: random\n02:34:05 |     embedding_size: 768\n02:34:05 |     embedding_type: random\n02:34:05 |     embeddings_scale: False\n02:34:05 |     encode_candidate_vecs: True\n02:34:05 |     encode_candidate_vecs_batchsize: 256\n02:34:05 |     eval_batchsize: None\n02:34:05 |     eval_candidates: inline\n02:34:05 |     eval_dynamic_batching: None\n02:34:05 |     evaltask: None\n02:34:05 |     ffn_size: 3072\n02:34:05 |     final_extra_opt: \n02:34:05 |     fixed_candidate_vecs: reuse\n02:34:05 |     fixed_candidates_path: None\n02:34:05 |     force_fp16_tokens: False\n02:34:05 |     fp16: True\n02:34:05 |     fp16_impl: safe\n02:34:05 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run5/data\n02:34:05 |     fromfile_datatype_extension: True\n02:34:05 |     gpu: -1\n02:34:05 |     gradient_clip: 0.1\n02:34:05 |     hide_labels: False\n02:34:05 |     history_add_global_end_token: None\n02:34:05 |     history_reversed: False\n02:34:05 |     history_size: 20\n02:34:05 |     ignore_bad_candidates: False\n02:34:05 |     ignore_labels: None\n02:34:05 |     image_cropsize: 224\n02:34:05 |     image_mode: raw\n02:34:05 |     image_size: 256\n02:34:05 |     inference: max\n02:34:05 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:34:05 |     init_opt: None\n02:34:05 |     interactive_candidates: fixed\n02:34:05 |     interactive_mode: False\n02:34:05 |     invsqrt_lr_decay_gamma: -1\n02:34:05 |     is_debug: False\n02:34:05 |     label_truncate: 72\n02:34:05 |     learn_embeddings: True\n02:34:05 |     learn_positional_embeddings: True\n02:34:05 |     learningrate: 5e-05\n02:34:05 |     load_from_checkpoint: False\n02:34:05 |     load_from_pretrained_ranker: True\n02:34:05 |     log_every_n_secs: 10.0\n02:34:05 |     log_every_n_steps: 50\n02:34:05 |     log_keep_fields: all\n02:34:05 |     loglevel: info\n02:34:05 |     lr_scheduler: reduceonplateau\n02:34:05 |     lr_scheduler_decay: 0.5\n02:34:05 |     lr_scheduler_patience: 3\n02:34:05 |     max_train_steps: -1\n02:34:05 |     max_train_time: 7200.0\n02:34:05 |     memory_attention: sqrt\n02:34:05 |     metrics: default\n02:34:05 |     model: transformer/classifier\n02:34:05 |     model_file: /tmp/model5\n02:34:05 |     model_parallel: False\n02:34:05 |     momentum: 0\n02:34:05 |     multitask_weights: [1]\n02:34:05 |     mutators: None\n02:34:05 |     n_decoder_layers: -1\n02:34:05 |     n_encoder_layers: -1\n02:34:05 |     n_heads: 12\n02:34:05 |     n_layers: 12\n02:34:05 |     n_positions: 1024\n02:34:05 |     n_segments: 2\n02:34:05 |     nesterov: True\n02:34:05 |     no_cuda: False\n02:34:05 |     normalize_sent_emb: False\n02:34:05 |     num_epochs: -1\n02:34:05 |     num_workers: 0\n02:34:05 |     nus: (0.7,)\n02:34:05 |     optimizer: adamax\n02:34:05 |     output_scaling: 0.06\n02:34:05 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type1/run5/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model5'}\"\n02:34:05 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n02:34:05 |     person_tokens: False\n02:34:05 |     print_scores: False\n02:34:05 |     rank_candidates: False\n02:34:05 |     rank_top_k: -1\n02:34:05 |     reduction_type: mean\n02:34:05 |     ref_class: None\n02:34:05 |     relu_dropout: 0.0\n02:34:05 |     repeat_blocking_heuristic: True\n02:34:05 |     return_cand_scores: False\n02:34:05 |     save_after_valid: True\n02:34:05 |     save_every_n_secs: -1\n02:34:05 |     save_format: conversations\n02:34:05 |     share_encoders: False\n02:34:05 |     share_word_embeddings: False\n02:34:05 |     short_final_eval: False\n02:34:05 |     special_tok_lst: None\n02:34:05 |     split_lines: False\n02:34:05 |     starttime: Dec04_02-33\n02:34:05 |     task: fromfile:parlaiformat\n02:34:05 |     tensorboard_log: False\n02:34:05 |     tensorboard_logdir: None\n02:34:05 |     text_truncate: 360\n02:34:05 |     threshold: 0.5\n02:34:05 |     topk: 5\n02:34:05 |     train_predict: False\n02:34:05 |     truncate: 1024\n02:34:05 |     update_classifier_head_only: False\n02:34:05 |     update_freq: 1\n02:34:05 |     use_memories: False\n02:34:05 |     use_reply: none\n02:34:05 |     validation_cutoff: 1.0\n02:34:05 |     validation_every_n_epochs: -1\n02:34:05 |     validation_every_n_secs: 20.0\n02:34:05 |     validation_every_n_steps: -1\n02:34:05 |     validation_max_exs: -1\n02:34:05 |     validation_metric: accuracy\n02:34:05 |     validation_metric_mode: max\n02:34:05 |     validation_patience: 30\n02:34:05 |     validation_share_agent: False\n02:34:05 |     variant: xlm\n02:34:05 |     verbose: False\n02:34:05 |     wandb_entity: None\n02:34:05 |     wandb_log: False\n02:34:05 |     wandb_name: None\n02:34:05 |     wandb_project: None\n02:34:05 |     warmup_rate: 0.0001\n02:34:05 |     warmup_updates: 1000\n02:34:05 |     weight_decay: None\n02:34:05 |     world_logs: \n02:34:05 |     wrap_memory_encoder: False\n02:34:05 | creating task(s): fromfile:parlaiformat\n02:34:05 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run5/data_train.txt\n02:34:05 | training...\n02:34:16 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .5350 5.35e-10               .3451                 .6622   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .2333            .6395              .5061   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8684 11.39     1 267.8 532.6       0          0 39.78  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5350             32768  2.555    .1206  6.05 .6899 1.005e-06   121 240.7   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 388.8 773.3 1.994        .4849\n\n02:34:26 | time:20s total_exs:1160 total_steps:58 epochs:5.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7092 7.092e-10               .6032                 .8442   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .4693            .7705              .6613   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9229 11.79     1 275.8  1055       0          0 76.52  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7092             32768  2.509    .1207 5.942 .6544 2.905e-06 118.8 454.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   58 394.7 1510 3.835        .6917\n\n02:34:26 | creating task(s): fromfile:parlaiformat\n02:34:26 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run5/data_valid.txt\n02:34:26 | running eval: valid\n02:34:26 | eval completed in 0.20s\n02:34:26 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7083 7.083e-10               .6316                 .8571   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5000            .7586              .6471   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1698       0          0   134   24 .7083   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6485 2.905e-06    72 804.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                     58  224 2502        .6951\n\u001b[0m\n02:34:26 | \u001b[1;32mnew best accuracy: 0.7083\u001b[0m\n02:34:26 | saving best valid model: /tmp/model5\n02:34:26 | Saving dictionary to /tmp/model5.dict\n02:34:31 | saving model checkpoint: /tmp/model5.checkpoint\n02:34:31 | Saving dictionary to /tmp/model5.checkpoint.dict\n02:34:47 | time:42s total_exs:1880 total_steps:94 epochs:9.40\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8250 8.25e-10               .8043                 .8900   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7337            .8417              .7809   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9128 11.84     1 276.7 990.8       0          0 71.61  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8250             32768  2.959    .1207 5.981 .6064 4.705e-06 119.6 428.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   94 396.3 1419 3.589        .8234\n\n02:34:51 | time:46s total_exs:2160 total_steps:108 epochs:10.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9357 9.357e-10               .9313                 .9760   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8905            .9396              .9032   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9790 11.76     1 275.1  1039       0          0 75.54  280   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9357             32768  3.265    .1207 5.979 .5297 5.404e-06 119.6 451.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  108 394.7 1491  3.8        .9355\n\n02:34:51 | running eval: valid\n02:34:51 | eval completed in 0.19s\n02:34:51 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 10.67   152  1728       0          0 136.4   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5162 5.404e-06    72 818.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    108  224 2546            1\n\u001b[0m\n02:34:51 | \u001b[1;32mnew best accuracy: 1 (previous best was 0.7083)\u001b[0m\n02:34:51 | saving best valid model: /tmp/model5\n02:34:56 | task solved! stopping.\n02:34:56 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n02:34:56 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n02:34:56 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run5/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n02:34:56 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n02:34:56 | Using CUDA\n02:34:56 | loading dictionary from /tmp/model5.dict\n02:34:56 | num words = 54944\n02:35:01 | Loading existing model parameters from /tmp/model5\n02:35:03 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:35:04 | creating task(s): fromfile:parlaiformat\n02:35:04 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run5/data_valid.txt\n02:35:04 | running eval: valid\n02:35:04 | eval completed in 0.21s\n02:35:04 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 10.67   152  1622       0          0   128   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294     6 .5162 5.404e-06    72 768.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    108  224 2390            1\n\u001b[0m\n02:35:04 | creating task(s): fromfile:parlaiformat\n02:35:04 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run5/data_test.txt\n02:35:04 | running eval: test\n02:35:09 | eval completed in 4.88s\n02:35:09 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8890 8.89e-10               .6132                 .4706   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8800            .9352              .9852   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8900 12.07 281.4  2898       0          0   206 1000 .8890   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294   5.2 .5166 5.404e-06   104  1071       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    108 385.4 3969        .9030\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type1/run5/data_test.txt -m transformer/classifier -mf /tmp/model5 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:35:11.326141Z","iopub.execute_input":"2022-12-04T02:35:11.327911Z","iopub.status.idle":"2022-12-04T02:35:41.768147Z","shell.execute_reply.started":"2022-12-04T02:35:11.327850Z","shell.execute_reply":"2022-12-04T02:35:41.766968Z"},"scrolled":true,"trusted":true},"execution_count":109,"outputs":[{"name":"stdout","text":"02:35:19 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr2type1/run5/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr2type1/run5/data)\u001b[0m\n02:35:19 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n02:35:19 | Using CUDA\n02:35:19 | loading dictionary from /tmp/model5.dict\n02:35:19 | num words = 54944\n02:35:24 | Loading existing model parameters from /tmp/model5\n02:35:29 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:35:31 | Opt:\n02:35:31 |     activation: gelu\n02:35:31 |     adafactor_eps: '[1e-30, 0.001]'\n02:35:31 |     adam_eps: 1e-08\n02:35:31 |     add_p1_after_newln: False\n02:35:31 |     aggregate_micro: False\n02:35:31 |     allow_missing_init_opts: False\n02:35:31 |     area_under_curve_class: None\n02:35:31 |     area_under_curve_digits: -1\n02:35:31 |     attention_dropout: 0.1\n02:35:31 |     batchsize: 40\n02:35:31 |     betas: '[0.9, 0.999]'\n02:35:31 |     bpe_add_prefix_space: None\n02:35:31 |     bpe_debug: False\n02:35:31 |     bpe_dropout: None\n02:35:31 |     bpe_merge: None\n02:35:31 |     bpe_vocab: None\n02:35:31 |     candidates: inline\n02:35:31 |     cap_num_predictions: 100\n02:35:31 |     checkpoint_activations: False\n02:35:31 |     class_weights: None\n02:35:31 |     classes: \"['__notok__', '__ok__']\"\n02:35:31 |     classes_from_file: None\n02:35:31 |     data_parallel: True\n02:35:31 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n02:35:31 |     datatype: train\n02:35:31 |     delimiter: '\\n'\n02:35:31 |     dict_class: parlai.core.dict:DictionaryAgent\n02:35:31 |     dict_endtoken: __start__\n02:35:31 |     dict_file: /tmp/model5.dict\n02:35:31 |     dict_include_test: False\n02:35:31 |     dict_include_valid: False\n02:35:31 |     dict_initpath: None\n02:35:31 |     dict_language: english\n02:35:31 |     dict_loaded: True\n02:35:31 |     dict_lower: True\n02:35:31 |     dict_max_ngram_size: -1\n02:35:31 |     dict_maxexs: -1\n02:35:31 |     dict_maxtokens: -1\n02:35:31 |     dict_minfreq: 0\n02:35:31 |     dict_nulltoken: __null__\n02:35:31 |     dict_starttoken: __start__\n02:35:31 |     dict_textfields: text,labels\n02:35:31 |     dict_tokenizer: bpe\n02:35:31 |     dict_unktoken: __unk__\n02:35:31 |     display_examples: False\n02:35:31 |     download_path: None\n02:35:31 |     dropout: 0.1\n02:35:31 |     dynamic_batching: None\n02:35:31 |     embedding_projection: random\n02:35:31 |     embedding_size: 768\n02:35:31 |     embedding_type: random\n02:35:31 |     embeddings_scale: False\n02:35:31 |     encode_candidate_vecs: True\n02:35:31 |     encode_candidate_vecs_batchsize: 256\n02:35:31 |     eval_batchsize: None\n02:35:31 |     eval_candidates: inline\n02:35:31 |     eval_dynamic_batching: None\n02:35:31 |     evaltask: None\n02:35:31 |     ffn_size: 3072\n02:35:31 |     final_extra_opt: \n02:35:31 |     fixed_candidate_vecs: reuse\n02:35:31 |     fixed_candidates_path: None\n02:35:31 |     force_fp16_tokens: True\n02:35:31 |     fp16: True\n02:35:31 |     fp16_impl: safe\n02:35:31 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type1/run5/data_test.txt\n02:35:31 |     fromfile_datatype_extension: True\n02:35:31 |     gpu: -1\n02:35:31 |     gradient_clip: 0.1\n02:35:31 |     hide_labels: False\n02:35:31 |     history_add_global_end_token: None\n02:35:31 |     history_reversed: False\n02:35:31 |     history_size: 20\n02:35:31 |     ignore_bad_candidates: False\n02:35:31 |     ignore_labels: None\n02:35:31 |     image_cropsize: 224\n02:35:31 |     image_mode: raw\n02:35:31 |     image_size: 256\n02:35:31 |     inference: max\n02:35:31 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:35:31 |     init_opt: None\n02:35:31 |     interactive_candidates: fixed\n02:35:31 |     interactive_mode: False\n02:35:31 |     invsqrt_lr_decay_gamma: -1\n02:35:31 |     is_debug: False\n02:35:31 |     label_truncate: 72\n02:35:31 |     learn_embeddings: True\n02:35:31 |     learn_positional_embeddings: True\n02:35:31 |     learningrate: 5e-05\n02:35:31 |     load_from_pretrained_ranker: True\n02:35:31 |     log_every_n_secs: 10.0\n02:35:31 |     log_every_n_steps: 50\n02:35:31 |     log_keep_fields: all\n02:35:31 |     loglevel: info\n02:35:31 |     lr_scheduler: reduceonplateau\n02:35:31 |     lr_scheduler_decay: 0.5\n02:35:31 |     lr_scheduler_patience: 3\n02:35:31 |     max_train_steps: -1\n02:35:31 |     max_train_time: 7200.0\n02:35:31 |     memory_attention: sqrt\n02:35:31 |     metrics: default\n02:35:31 |     model: transformer/classifier\n02:35:31 |     model_file: /tmp/model5\n02:35:31 |     model_parallel: False\n02:35:31 |     momentum: 0\n02:35:31 |     multitask_weights: [1]\n02:35:31 |     mutators: None\n02:35:31 |     n_decoder_layers: -1\n02:35:31 |     n_encoder_layers: -1\n02:35:31 |     n_heads: 12\n02:35:31 |     n_layers: 12\n02:35:31 |     n_positions: 1024\n02:35:31 |     n_segments: 2\n02:35:31 |     nesterov: True\n02:35:31 |     no_cuda: False\n02:35:31 |     normalize_sent_emb: False\n02:35:31 |     num_epochs: -1\n02:35:31 |     num_examples: -1\n02:35:31 |     num_workers: 0\n02:35:31 |     nus: [0.7]\n02:35:31 |     optimizer: adamax\n02:35:31 |     output_scaling: 0.06\n02:35:31 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type1/run5/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model5', 'batchsize': 40}\"\n02:35:31 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n02:35:31 |     person_tokens: False\n02:35:31 |     print_scores: False\n02:35:31 |     rank_candidates: False\n02:35:31 |     rank_top_k: -1\n02:35:31 |     reduction_type: mean\n02:35:31 |     ref_class: None\n02:35:31 |     relu_dropout: 0.0\n02:35:31 |     repeat_blocking_heuristic: True\n02:35:31 |     report_filename: \n02:35:31 |     return_cand_scores: False\n02:35:31 |     save_after_valid: True\n02:35:31 |     save_every_n_secs: -1\n02:35:31 |     save_format: conversations\n02:35:31 |     share_encoders: False\n02:35:31 |     share_word_embeddings: False\n02:35:31 |     short_final_eval: False\n02:35:31 |     special_tok_lst: None\n02:35:31 |     split_lines: False\n02:35:31 |     starttime: Dec04_02-33\n02:35:31 |     task: fromfile:parlaiformat\n02:35:31 |     tensorboard_log: False\n02:35:31 |     tensorboard_logdir: None\n02:35:31 |     text_truncate: 360\n02:35:31 |     threshold: 0.5\n02:35:31 |     topk: 5\n02:35:31 |     train_predict: False\n02:35:31 |     truncate: 1024\n02:35:31 |     update_classifier_head_only: False\n02:35:31 |     update_freq: 1\n02:35:31 |     use_memories: False\n02:35:31 |     use_reply: none\n02:35:31 |     validation_cutoff: 1.0\n02:35:31 |     validation_every_n_epochs: -1\n02:35:31 |     validation_every_n_secs: 20.0\n02:35:31 |     validation_every_n_steps: -1\n02:35:31 |     validation_max_exs: -1\n02:35:31 |     validation_metric: accuracy\n02:35:31 |     validation_metric_mode: max\n02:35:31 |     validation_patience: 30\n02:35:31 |     validation_share_agent: False\n02:35:31 |     variant: xlm\n02:35:31 |     verbose: False\n02:35:31 |     wandb_entity: None\n02:35:31 |     wandb_log: False\n02:35:31 |     wandb_name: None\n02:35:31 |     wandb_project: None\n02:35:31 |     warmup_rate: 0.0001\n02:35:31 |     warmup_updates: 1000\n02:35:31 |     weight_decay: None\n02:35:31 |     world_logs: \n02:35:31 |     wrap_memory_encoder: False\n02:35:31 | Evaluating task fromfile:parlaiformat using datatype valid.\n02:35:31 | creating task(s): fromfile:parlaiformat\n02:35:31 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n02:35:31 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type1/run5/data_test.txt\n02:35:40 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8890 8.89e-10               .6132                 .4706   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8800            .9352              .9852   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8900 12.07 562.9  1709       0          0 121.5 1000 .8890   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5166 5.404e-06   208 631.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    108 770.9 2341        .9030\u001b[0m\n02:35:40 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8890 8.89e-10               .6132                 .4706   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8800            .9352              .9852   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8900 12.07 562.9  1709       0          0 121.5 1000 .8890   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5166 5.404e-06   208 631.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    108 770.9 2341        .9030\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model5*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:35:41.770726Z","iopub.execute_input":"2022-12-04T02:35:41.771155Z","iopub.status.idle":"2022-12-04T02:35:42.993759Z","shell.execute_reply.started":"2022-12-04T02:35:41.771111Z","shell.execute_reply":"2022-12-04T02:35:42.992476Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"markdown","source":"# Actual work prev2corr2type2","metadata":{}},{"cell_type":"markdown","source":"run 1","metadata":{}},{"cell_type":"code","source":"# run 1 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type2/run1/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model1","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:35:42.995942Z","iopub.execute_input":"2022-12-04T02:35:42.996342Z","iopub.status.idle":"2022-12-04T02:47:59.372067Z","shell.execute_reply.started":"2022-12-04T02:35:42.996299Z","shell.execute_reply":"2022-12-04T02:47:59.370910Z"},"scrolled":true,"trusted":true},"execution_count":111,"outputs":[{"name":"stdout","text":"02:35:50 | building dictionary first...\n02:35:50 | No model with opt yet at: /tmp/model1(.opt)\n02:35:50 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run1/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n02:35:50 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n02:35:50 | Using CUDA\n02:35:50 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n02:35:50 | num words = 54944\n02:35:54 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:36:04 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:36:04 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n02:36:04 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n02:36:04 | Opt:\n02:36:04 |     activation: gelu\n02:36:04 |     adafactor_eps: '(1e-30, 0.001)'\n02:36:04 |     adam_eps: 1e-08\n02:36:04 |     add_p1_after_newln: False\n02:36:04 |     aggregate_micro: False\n02:36:04 |     allow_missing_init_opts: False\n02:36:04 |     attention_dropout: 0.1\n02:36:04 |     batchsize: 20\n02:36:04 |     betas: '(0.9, 0.999)'\n02:36:04 |     bpe_add_prefix_space: None\n02:36:04 |     bpe_debug: False\n02:36:04 |     bpe_dropout: None\n02:36:04 |     bpe_merge: None\n02:36:04 |     bpe_vocab: None\n02:36:04 |     candidates: inline\n02:36:04 |     cap_num_predictions: 100\n02:36:04 |     checkpoint_activations: False\n02:36:04 |     class_weights: None\n02:36:04 |     classes: \"['__notok__', '__ok__']\"\n02:36:04 |     classes_from_file: None\n02:36:04 |     data_parallel: True\n02:36:04 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n02:36:04 |     datatype: train\n02:36:04 |     delimiter: '\\n'\n02:36:04 |     dict_class: parlai.core.dict:DictionaryAgent\n02:36:04 |     dict_endtoken: __start__\n02:36:04 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n02:36:04 |     dict_include_test: False\n02:36:04 |     dict_include_valid: False\n02:36:04 |     dict_initpath: None\n02:36:04 |     dict_language: english\n02:36:04 |     dict_loaded: True\n02:36:04 |     dict_lower: True\n02:36:04 |     dict_max_ngram_size: -1\n02:36:04 |     dict_maxexs: -1\n02:36:04 |     dict_maxtokens: -1\n02:36:04 |     dict_minfreq: 0\n02:36:04 |     dict_nulltoken: __null__\n02:36:04 |     dict_starttoken: __start__\n02:36:04 |     dict_textfields: text,labels\n02:36:04 |     dict_tokenizer: bpe\n02:36:04 |     dict_unktoken: __unk__\n02:36:04 |     display_examples: False\n02:36:04 |     download_path: None\n02:36:04 |     dropout: 0.1\n02:36:04 |     dynamic_batching: None\n02:36:04 |     embedding_projection: random\n02:36:04 |     embedding_size: 768\n02:36:04 |     embedding_type: random\n02:36:04 |     embeddings_scale: False\n02:36:04 |     encode_candidate_vecs: True\n02:36:04 |     encode_candidate_vecs_batchsize: 256\n02:36:04 |     eval_batchsize: None\n02:36:04 |     eval_candidates: inline\n02:36:04 |     eval_dynamic_batching: None\n02:36:04 |     evaltask: None\n02:36:04 |     ffn_size: 3072\n02:36:04 |     final_extra_opt: \n02:36:04 |     fixed_candidate_vecs: reuse\n02:36:04 |     fixed_candidates_path: None\n02:36:04 |     force_fp16_tokens: False\n02:36:04 |     fp16: True\n02:36:04 |     fp16_impl: safe\n02:36:04 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run1/data\n02:36:04 |     fromfile_datatype_extension: True\n02:36:04 |     gpu: -1\n02:36:04 |     gradient_clip: 0.1\n02:36:04 |     hide_labels: False\n02:36:04 |     history_add_global_end_token: None\n02:36:04 |     history_reversed: False\n02:36:04 |     history_size: 20\n02:36:04 |     ignore_bad_candidates: False\n02:36:04 |     ignore_labels: None\n02:36:04 |     image_cropsize: 224\n02:36:04 |     image_mode: raw\n02:36:04 |     image_size: 256\n02:36:04 |     inference: max\n02:36:04 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:36:04 |     init_opt: None\n02:36:04 |     interactive_candidates: fixed\n02:36:04 |     interactive_mode: False\n02:36:04 |     invsqrt_lr_decay_gamma: -1\n02:36:04 |     is_debug: False\n02:36:04 |     label_truncate: 72\n02:36:04 |     learn_embeddings: True\n02:36:04 |     learn_positional_embeddings: True\n02:36:04 |     learningrate: 5e-05\n02:36:04 |     load_from_checkpoint: False\n02:36:04 |     load_from_pretrained_ranker: True\n02:36:04 |     log_every_n_secs: 10.0\n02:36:04 |     log_every_n_steps: 50\n02:36:04 |     log_keep_fields: all\n02:36:04 |     loglevel: info\n02:36:04 |     lr_scheduler: reduceonplateau\n02:36:04 |     lr_scheduler_decay: 0.5\n02:36:04 |     lr_scheduler_patience: 3\n02:36:04 |     max_train_steps: -1\n02:36:04 |     max_train_time: 7200.0\n02:36:04 |     memory_attention: sqrt\n02:36:04 |     metrics: default\n02:36:04 |     model: transformer/classifier\n02:36:04 |     model_file: /tmp/model1\n02:36:04 |     model_parallel: False\n02:36:04 |     momentum: 0\n02:36:04 |     multitask_weights: [1]\n02:36:04 |     mutators: None\n02:36:04 |     n_decoder_layers: -1\n02:36:04 |     n_encoder_layers: -1\n02:36:04 |     n_heads: 12\n02:36:04 |     n_layers: 12\n02:36:04 |     n_positions: 1024\n02:36:04 |     n_segments: 2\n02:36:04 |     nesterov: True\n02:36:04 |     no_cuda: False\n02:36:04 |     normalize_sent_emb: False\n02:36:04 |     num_epochs: -1\n02:36:04 |     num_workers: 0\n02:36:04 |     nus: (0.7,)\n02:36:04 |     optimizer: adamax\n02:36:04 |     output_scaling: 0.06\n02:36:04 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type2/run1/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model1'}\"\n02:36:04 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n02:36:04 |     person_tokens: False\n02:36:04 |     print_scores: False\n02:36:04 |     rank_candidates: False\n02:36:04 |     rank_top_k: -1\n02:36:04 |     reduction_type: mean\n02:36:04 |     ref_class: None\n02:36:04 |     relu_dropout: 0.0\n02:36:04 |     repeat_blocking_heuristic: True\n02:36:04 |     return_cand_scores: False\n02:36:04 |     save_after_valid: True\n02:36:04 |     save_every_n_secs: -1\n02:36:04 |     save_format: conversations\n02:36:04 |     share_encoders: False\n02:36:04 |     share_word_embeddings: False\n02:36:04 |     short_final_eval: False\n02:36:04 |     special_tok_lst: None\n02:36:04 |     split_lines: False\n02:36:04 |     starttime: Dec04_02-35\n02:36:04 |     task: fromfile:parlaiformat\n02:36:04 |     tensorboard_log: False\n02:36:04 |     tensorboard_logdir: None\n02:36:04 |     text_truncate: 360\n02:36:04 |     threshold: 0.5\n02:36:04 |     topk: 5\n02:36:04 |     train_predict: False\n02:36:04 |     truncate: 1024\n02:36:04 |     update_classifier_head_only: False\n02:36:04 |     update_freq: 1\n02:36:04 |     use_memories: False\n02:36:04 |     use_reply: none\n02:36:04 |     validation_cutoff: 1.0\n02:36:04 |     validation_every_n_epochs: -1\n02:36:04 |     validation_every_n_secs: 20.0\n02:36:04 |     validation_every_n_steps: -1\n02:36:04 |     validation_max_exs: -1\n02:36:04 |     validation_metric: accuracy\n02:36:04 |     validation_metric_mode: max\n02:36:04 |     validation_patience: 30\n02:36:04 |     validation_share_agent: False\n02:36:04 |     variant: xlm\n02:36:04 |     verbose: False\n02:36:04 |     wandb_entity: None\n02:36:04 |     wandb_log: False\n02:36:04 |     wandb_name: None\n02:36:04 |     wandb_project: None\n02:36:04 |     warmup_rate: 0.0001\n02:36:04 |     warmup_updates: 1000\n02:36:04 |     weight_decay: None\n02:36:04 |     world_logs: \n02:36:04 |     wrap_memory_encoder: False\n02:36:05 | creating task(s): fromfile:parlaiformat\n02:36:05 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run1/data_train.txt\n02:36:05 | training...\n02:36:15 | time:10s total_exs:380 total_steps:19 epochs:1.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .4342 4.342e-10               .5396                 .4500   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6738            .2662              .3900   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .2021 11.21     1 264.2 493.2       0          0 37.34  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .4342             32768  3.009    .1189 5.984 .7123 9.549e-07 119.7 223.4   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   19 383.8 716.6 1.871        .4008\n\n02:36:25 | time:20s total_exs:1140 total_steps:57 epochs:5.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5526 5.526e-10               .6256                 .5483   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7282            .4444              .5620   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .3676 11.16     1 263.2  1019       0          0 77.41  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5526             32768  2.477    .1189 6.026 .6848 2.855e-06 120.5 466.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                   57 383.7 1485 3.88        .5374\n\n02:36:25 | creating task(s): fromfile:parlaiformat\n02:36:25 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run1/data_valid.txt\n02:36:25 | running eval: valid\n02:36:25 | eval completed in 0.20s\n02:36:25 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5833 5.833e-10               .5833                 .5833   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5833            .5833              .5833   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .5833 11.46 161.5  1785       0          0 132.6   24 .5833   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6858 2.855e-06    72 795.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     57 233.5 2581        .5833\n\u001b[0m\n02:36:25 | \u001b[1;32mnew best accuracy: 0.5833\u001b[0m\n02:36:25 | saving best valid model: /tmp/model1\n02:36:25 | Saving dictionary to /tmp/model1.dict\n02:36:29 | saving model checkpoint: /tmp/model1.checkpoint\n02:36:29 | Saving dictionary to /tmp/model1.checkpoint.dict\n02:36:45 | time:40s total_exs:1840 total_steps:92 epochs:9.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8386 8.386e-10               .8491                 .7990   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9060            .8264              .8907   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7708 11.39     1 267.9 938.2       0          0 70.05  700   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8386             32768  2.559    .1189 6.003 .6241 4.605e-06 120.1 420.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                   92 387.9 1359 3.51        .8378\n\n02:36:49 | time:44s total_exs:2140 total_steps:107 epochs:10.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9100 9.1e-10               .9226                 .8895   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9583            .8924              .9412   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8485  10.7     1 254.1  1002       0          0 78.91  300   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9100             32768  3.181    .1189  6.12 .5618 5.354e-06 122.4 482.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  107 376.5 1485 3.969        .9093\n\n02:36:49 | running eval: valid\n02:36:49 | eval completed in 0.20s\n02:36:49 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8000                 .7692   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .7826              .8182   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.46 161.5  1795       0          0 133.3   24 .7917   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6038 5.354e-06    72 800.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    107 233.5 2595        .7913\n\u001b[0m\n02:36:49 | \u001b[1;32mnew best accuracy: 0.7917 (previous best was 0.5833)\u001b[0m\n02:36:49 | saving best valid model: /tmp/model1\n02:36:59 | saving model checkpoint: /tmp/model1.checkpoint\n02:37:14 | time:70s total_exs:2900 total_steps:145 epochs:14.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9408 9.408e-10               .9437                 .9240   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9642            .9376              .9602   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9160  11.3     1   266 997.7       0          0 75.01  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9408             32768  3.695    .1189 6.029 .4399 7.254e-06 120.6 452.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  145 386.6 1450 3.759        .9407\n\n02:37:19 | time:74s total_exs:3260 total_steps:163 epochs:16.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9722 9.722e-10               .9701                 .9759   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9643            .9741              .9691   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9792 10.61     1 252.2 982.4       0          0  77.9  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9722             32768  4.048    .1189 5.933 .2588 8.154e-06 118.7 462.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  163 370.9 1445 3.914        .9722\n\n02:37:19 | running eval: valid\n02:37:19 | eval completed in 0.20s\n02:37:19 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 11.46 161.5  1789       0          0 132.9   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .3805 8.154e-06    72 797.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    163 233.5 2586        .8730\n\u001b[0m\n02:37:19 | \u001b[1;32mnew best accuracy: 0.875 (previous best was 0.7917)\u001b[0m\n02:37:19 | saving best valid model: /tmp/model1\n02:37:24 | saving model checkpoint: /tmp/model1.checkpoint\n02:37:43 | time:98s total_exs:4020 total_steps:201 epochs:20.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9776 9.776e-10               .9764                 .9723   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9804            .9788              .9825   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9751 11.25     1 264.9 999.2       0          0 75.43  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9776             32768  5.362    .1190 5.942 .1173 1.005e-05 118.8 448.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  201 383.8 1447 3.78        .9776\n\n02:37:44 | time:99s total_exs:4100 total_steps:205 epochs:20.50\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9750 9.75e-10               .9722                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9459            .9773              .9556   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.35     1   267  1066       0          0 79.86   80   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9750             32768  6.455    .1190 5.925 .07605 1.025e-05 118.5 473.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  205 385.5 1539 4.085        .9749\n\n02:37:44 | running eval: valid\n02:37:44 | eval completed in 0.20s\n02:37:44 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1794       0          0 133.3   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .3071 1.025e-05    72 799.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    205 233.5 2594        .8748\n\u001b[0m\n02:37:44 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 1\u001b[0m\n02:37:44 | saving model checkpoint: /tmp/model1.checkpoint\n02:38:04 | time:120s total_exs:4860 total_steps:243 epochs:24.30\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9921 9.921e-10               .9917                 .9890   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9944            .9925              .9950   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9900 11.16 .9737 263.3   996       0          0 75.67  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9921             32768  3.297    .1190 5.947 .03062 1.215e-05 118.9   450   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  243 382.2 1446 3.792        .9921\n\n02:38:04 | time:120s total_exs:4880 total_steps:244 epochs:24.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.25     1   245 982.3       0          0 80.17   20   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n     1             32768  47.23    .1190   6.5 .02837 1.22e-05   130 521.2   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  244  375 1503 4.406            1\n\n02:38:04 | running eval: valid\n02:38:05 | eval completed in 0.19s\n02:38:05 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8000                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8571              .7500   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 11.46 161.5  1823       0          0 135.4   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .5979 1.22e-05    72 812.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    244 233.5 2635        .8286\n\u001b[0m\n02:38:05 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 2\u001b[0m\n02:38:05 | saving model checkpoint: /tmp/model1.checkpoint\n02:38:19 | time:135s total_exs:5620 total_steps:281 epochs:28.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.14 .1081 262.8 965.8       0          0 73.51  740   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768  .1239    .1190 6.003 .004044 1.405e-05 120.1 441.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  281 382.8 1407 3.684            1\n\n02:38:25 | time:140s total_exs:6040 total_steps:302 epochs:30.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.63 .04762 272.7  1036       0          0 76.01   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss       lr  ltpb  \\\n    420   1             32768  2.216    .1190 6.133 .0025 1.51e-05 122.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   466.2       0          0                  302 395.3 1503 3.816            1\n\n02:38:25 | running eval: valid\n02:38:25 | eval completed in 0.20s\n02:38:25 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1825       0          0 135.6   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .6363 1.51e-05    72 813.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    302 233.5 2639        .8748\n\u001b[0m\n02:38:25 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 3\u001b[0m\n02:38:25 | saving model checkpoint: /tmp/model1.checkpoint\n02:38:39 | time:155s total_exs:6820 total_steps:341 epochs:34.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.28     0 265.5  1025       0          0 77.21  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n     1             32768 .02033    .1190 5.941 .00173 1.705e-05 118.8 458.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  341 384.4 1484 3.869            1\n\n02:38:45 | time:160s total_exs:7240 total_steps:362 epochs:36.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.76     0 255.3 943.7       0          0 73.93  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .02111    .1190 6.048 .001495 1.81e-05   121 447.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  362 376.2 1391 3.711            1\n\n02:38:45 | running eval: valid\n02:38:45 | eval completed in 0.20s\n02:38:45 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1803       0          0 133.9   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 .6806 1.81e-05    72 803.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    362 233.5 2606        .8748\n\u001b[0m\n02:38:45 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 4\u001b[0m\n02:38:45 | saving model checkpoint: /tmp/model1.checkpoint\n02:39:00 | time:175s total_exs:8020 total_steps:401 epochs:40.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.41 .02564 268.1  1031       0          0  76.9   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    780   1             32768 .02044    .1190 6.028 .001351 2.005e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.6       0          0                  401 388.7 1494 3.853            1\n\n02:39:06 | time:181s total_exs:8440 total_steps:422 epochs:42.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.12     0 262.5 990.3       0          0 75.46  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .01443    .1190 6.048 .001239 2.11e-05   121 456.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  422 383.4 1447 3.788            1\n\n02:39:06 | running eval: valid\n02:39:06 | eval completed in 0.19s\n02:39:06 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1847       0          0 137.2   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08095     6 .7749 2.11e-05    72 823.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    422 233.5 2670        .8748\n\u001b[0m\n02:39:06 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 5\u001b[0m\n02:39:06 | saving model checkpoint: /tmp/model1.checkpoint\n02:39:20 | time:195s total_exs:9200 total_steps:460 epochs:46.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.11     0 262.2 984.7       0          0 75.11  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss      lr  ltpb  ltps  \\\n     1             32768 .01335    .1190 6.021 .001154 2.3e-05 120.4 452.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  460 382.6 1437 3.764            1\n\n02:39:26 | time:201s total_exs:9640 total_steps:482 epochs:48.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.16     0 263.2  1014       0          0 77.02  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .01248    .1190 6.055 .001076 2.41e-05 121.1 466.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  482 384.3 1480 3.866            1\n\n02:39:26 | running eval: valid\n02:39:26 | eval completed in 0.20s\n02:39:26 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1839       0          0 136.6   24 .8333   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 .8206 2.41e-05    72 819.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    482 233.5 2659        .8322\n\u001b[0m\n02:39:26 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 6\u001b[0m\n02:39:26 | saving model checkpoint: /tmp/model1.checkpoint\n02:39:41 | time:216s total_exs:10420 total_steps:521 epochs:52.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.02     0 260.4 998.1       0          0 76.64  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01168    .1190 5.959 .001009 2.605e-05 119.2 456.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  521 379.6 1455 3.841            1\n\n02:39:46 | time:222s total_exs:10860 total_steps:543 epochs:54.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.29     0 265.8  1029       0          0 77.43  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01099    .1190 6.073 .0009456 2.715e-05 121.5 470.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  543 387.2 1499 3.887            1\n\n02:39:46 | running eval: valid\n02:39:47 | eval completed in 0.22s\n02:39:47 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1674       0          0 124.3   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 .8797 2.715e-05    72 746.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    543 233.5 2421        .8322\n\u001b[0m\n02:39:47 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 7\u001b[0m\n02:39:47 | saving model checkpoint: /tmp/model1.checkpoint\n02:40:02 | time:237s total_exs:11640 total_steps:582 epochs:58.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.1     0   262  1007       0          0 76.83  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768  .0103    .1190 6.018 .0008877 2.91e-05 120.4 462.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  582 382.4 1469 3.85            1\n\n02:40:07 | time:242s total_exs:12040 total_steps:602 epochs:60.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.96     0 259.2  1019       0          0 78.62  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .009676    .1190 5.945 .0008344 3.01e-05 118.9 467.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  602 378.1 1486 3.948            1\n\n02:40:07 | running eval: valid\n02:40:07 | eval completed in 0.19s\n02:40:07 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1842       0          0 136.8   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 .8790 3.01e-05    72 821.2       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    602 233.5 2663        .8748\n\u001b[0m\n02:40:07 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 8\u001b[0m\n02:40:07 | saving model checkpoint: /tmp/model1.checkpoint\n02:40:22 | time:257s total_exs:12800 total_steps:640 epochs:64.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  10.8     0 256.1 955.7       0          0 74.65  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss      lr  ltpb  ltps  \\\n     1             32768 .009184    .1190  6.05 .0007857 3.2e-05   121 451.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  640 377.1 1407 3.741            1\n\n02:40:27 | time:263s total_exs:13240 total_steps:662 epochs:66.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.99     0 259.7  1018       0          0 78.39  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .008559    .1190 5.959 .000737 3.31e-05 119.2 467.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  662 378.9 1485 3.935            1\n\n02:40:27 | running eval: valid\n02:40:27 | eval completed in 0.20s\n02:40:27 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1789       0          0 132.9   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 .9012 3.31e-05    72 797.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    662 233.5 2587        .8748\n\u001b[0m\n02:40:27 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 9\u001b[0m\n02:40:27 | saving model checkpoint: /tmp/model1.checkpoint\n02:40:42 | time:277s total_exs:14020 total_steps:701 epochs:70.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.99     0 259.9  1007       0          0 77.53  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .008024    .1190 6.082 .0006907 3.505e-05 121.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   471.5       0          0                  701 381.5 1479 3.886            1\n\n02:40:47 | time:283s total_exs:14440 total_steps:722 epochs:72.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.1     0   262  1002       0          0 76.48  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .007534    .1190  5.99 .0006484 3.61e-05 119.8 458.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  722 381.8 1460 3.84            1\n\n02:40:47 | running eval: valid\n02:40:48 | eval completed in 0.20s\n02:40:48 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1832       0          0 136.1   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 .9213 3.61e-05    72 816.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    722 233.5 2649        .8748\n\u001b[0m\n02:40:48 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 10\u001b[0m\n02:40:48 | saving model checkpoint: /tmp/model1.checkpoint\n02:41:03 | time:298s total_exs:15220 total_steps:761 epochs:76.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.37     0 267.5  1020       0          0 76.25  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .007081    .1191 5.977 .0006088 3.805e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   455.7       0          0                  761  387 1476 3.821            1\n\n02:41:08 | time:303s total_exs:15620 total_steps:781 epochs:78.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.15     0 263.1  1005       0          0 76.39  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006715    .1191  5.91 .0005718 3.905e-05 118.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.4       0          0                  781 381.2 1456 3.836            1\n\n02:41:08 | running eval: valid\n02:41:08 | eval completed in 0.20s\n02:41:08 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1820       0          0 135.2   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 .9459 3.905e-05    72 811.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    781 233.5 2631        .8748\n\u001b[0m\n02:41:08 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 11\u001b[0m\n02:41:08 | saving model checkpoint: /tmp/model1.checkpoint\n02:41:23 | time:318s total_exs:16400 total_steps:820 epochs:82.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.27     0 265.5  1006       0          0 75.81  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss      lr  ltpb  ltps  \\\n     1             32768 .00625    .1191 6.033 .0005367 4.1e-05 120.7 457.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  820 386.2 1464 3.799            1\n\n02:41:28 | time:323s total_exs:16800 total_steps:840 epochs:84.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.25     0 264.9 978.4       0          0 73.85  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss      lr  ltpb  ltps  \\\n     1             32768 .005867    .1191  6.11 .000504 4.2e-05 122.2 451.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  840 387.1 1430 3.708            1\n\n02:41:28 | running eval: valid\n02:41:28 | eval completed in 0.20s\n02:41:28 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1809       0          0 134.3   24 .8750   \n    gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 .9676 4.2e-05    72 806.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    840 233.5 2616        .8748\n\u001b[0m\n02:41:28 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 12\u001b[0m\n02:41:28 | saving model checkpoint: /tmp/model1.checkpoint\n02:41:43 | time:338s total_exs:17580 total_steps:879 epochs:87.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.22     0 264.5  1015       0          0 76.78  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .005517    .1191 6.044 .0004734 4.395e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     464       0          0                  879 385.4 1479 3.848            1\n\n02:41:48 | time:344s total_exs:18020 total_steps:901 epochs:90.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.05     0 260.9 999.2       0          0 76.59  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00518    .1191 6.023 .0004439 4.505e-05 120.5 461.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  901 381.4 1461 3.845            1\n\n02:41:48 | running eval: valid\n02:41:49 | eval completed in 0.23s\n02:41:49 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1612       0          0 119.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 1.036 4.505e-05    72 718.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    901 233.5 2330        .8322\n\u001b[0m\n02:41:49 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 13\u001b[0m\n02:41:49 | saving model checkpoint: /tmp/model1.checkpoint\n02:42:03 | time:359s total_exs:18780 total_steps:939 epochs:93.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.15     0   263 992.3       0          0 75.45  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004888    .1191 5.932 .0004159 4.695e-05 118.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   447.6       0          0                  939 381.7 1440 3.781            1\n\n02:42:09 | time:364s total_exs:19200 total_steps:960 epochs:96.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.28     0 265.7  1039       0          0  78.2  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss      lr  ltpb  ltps  \\\n     1             32768 .004562    .1191 5.952 .0003909 4.8e-05   119 465.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  960 384.7 1504 3.926            1\n\n02:42:09 | running eval: valid\n02:42:09 | eval completed in 0.19s\n02:42:09 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1847       0          0 137.2   24 .8333   \n    gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 1.088 4.8e-05    72 823.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    960 233.5 2671        .8322\n\u001b[0m\n02:42:09 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 14\u001b[0m\n02:42:09 | saving model checkpoint: /tmp/model1.checkpoint\n02:42:24 | time:379s total_exs:19980 total_steps:999 epochs:99.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.13     0 262.5  1008       0          0 76.77  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004282    .1191 6.026 .0003668 4.995e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   462.6       0          0                  999  383 1470 3.847            1\n\n02:42:29 | time:384s total_exs:20380 total_steps:1019 epochs:101.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.68     0 253.6 937.6       0          0 73.96  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004026    .1191 5.915 .0003447 4.995e-05 118.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   437.5       0          0                 1019 371.9 1375 3.714            1\n\n02:42:29 | running eval: valid\n02:42:29 | eval completed in 0.20s\n02:42:29 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1786       0          0 132.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6 1.198 4.995e-05    72   796       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1019 233.5 2582        .8322\n\u001b[0m\n02:42:29 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 15\u001b[0m\n02:42:29 | saving model checkpoint: /tmp/model1.checkpoint\n02:42:44 | time:399s total_exs:21160 total_steps:1058 epochs:105.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1    11     0   260 994.3       0          0 76.48  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00379    .1191  6.01 .0003244 4.995e-05 120.2 459.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1058 380.2 1454 3.833            1\n\n02:42:49 | time:405s total_exs:21580 total_steps:1079 epochs:107.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  10.9     0   258 996.8       0          0 77.27  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003569    .1191 5.971 .0003052 4.995e-05 119.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   461.4       0          0                 1079 377.4 1458 3.88            1\n\n02:42:49 | running eval: valid\n02:42:50 | eval completed in 0.20s\n02:42:50 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1826       0          0 135.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 1.248 4.995e-05    72 813.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1079 233.5 2640        .8322\n\u001b[0m\n02:42:50 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 16\u001b[0m\n02:42:50 | saving model checkpoint: /tmp/model1.checkpoint\n02:43:04 | time:420s total_exs:22340 total_steps:1117 epochs:111.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.03     0 260.6 978.2       0          0 75.06  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003374    .1191 6.026 .0002886 4.995e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   452.3       0          0                 1117 381.2 1431 3.762            1\n\n02:43:10 | time:425s total_exs:22780 total_steps:1139 epochs:113.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.25     0 264.9  1021       0          0 77.05  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .003193    .1191 6.068 .000273 4.995e-05 121.4 467.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1139 386.3 1488 3.868            1\n\n02:43:10 | running eval: valid\n02:43:10 | eval completed in 0.20s\n02:43:10 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1815       0          0 134.8   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 1.174 4.995e-05    72 809.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1139 233.5 2624        .8322\n\u001b[0m\n02:43:10 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 17\u001b[0m\n02:43:10 | saving model checkpoint: /tmp/model1.checkpoint\n02:43:25 | time:440s total_exs:23560 total_steps:1178 epochs:117.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.37     0 267.3  1021       0          0 76.39  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003018    .1191 6.021 .0002578 4.995e-05 120.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.9       0          0                 1178 387.7 1481 3.828            1\n\n02:43:30 | time:446s total_exs:23960 total_steps:1198 epochs:119.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.89     0 257.9 939.2       0          0 72.85  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002861    .1191 5.985 .0002445 4.995e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     436       0          0                 1198 377.6 1375 3.658            1\n\n02:43:30 | running eval: valid\n02:43:30 | eval completed in 0.20s\n02:43:30 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1818       0          0 135.1   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 1.275 4.995e-05    72 810.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1198 233.5 2629        .8322\n\u001b[0m\n02:43:30 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 18\u001b[0m\n02:43:30 | saving model checkpoint: /tmp/model1.checkpoint\n02:43:45 | time:460s total_exs:24740 total_steps:1237 epochs:123.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.33     0 266.5  1026       0          0 76.96  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002715    .1191 5.969 .0002319 4.995e-05 119.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.4       0          0                 1237 385.9 1485 3.856            1\n\n02:43:51 | time:466s total_exs:25180 total_steps:1259 epochs:125.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.15     0 263.1 999.3       0          0 75.96  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002579    .1191 6.059 .0002203 4.995e-05 121.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.3       0          0                 1259 384.3 1460 3.813            1\n\n02:43:51 | running eval: valid\n02:43:51 | eval completed in 0.19s\n02:43:51 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1868       0          0 138.8   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6  1.23 4.995e-05    72 832.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1259 233.5 2701        .8322\n\u001b[0m\n02:43:51 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 19\u001b[0m\n02:43:51 | saving model checkpoint: /tmp/model1.checkpoint\n02:44:05 | time:481s total_exs:25940 total_steps:1297 epochs:129.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.99     0 259.8 969.6       0          0 74.63  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002452    .1192 5.963 .0002094 4.995e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   445.1       0          0                 1297 379.1 1415 3.74            1\n\n02:44:11 | time:486s total_exs:26380 total_steps:1319 epochs:131.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.07     0 261.5  1021       0          0 78.07  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002337    .1192  6.05 .0001994 4.995e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   472.3       0          0                 1319 382.5 1493 3.914            1\n\n02:44:11 | running eval: valid\n02:44:11 | eval completed in 0.20s\n02:44:11 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1778       0          0 132.1   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 1.325 4.995e-05    72 792.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1319 233.5 2571        .8322\n\u001b[0m\n02:44:11 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 20\u001b[0m\n02:44:11 | saving model checkpoint: /tmp/model1.checkpoint\n02:44:26 | time:501s total_exs:27160 total_steps:1358 epochs:135.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.03     0 260.7 997.4       0          0 76.52  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002222    .1192 6.005 .0001896 4.995e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.5       0          0                 1358 380.8 1457 3.835            1\n\n02:44:31 | time:507s total_exs:27580 total_steps:1379 epochs:137.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.14     0 262.8  1029       0          0 78.33  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002122    .1192 6.052 .0001811 4.995e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   474.1       0          0                 1379 383.9 1503 3.933            1\n\n02:44:31 | running eval: valid\n02:44:31 | eval completed in 0.19s\n02:44:31 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1882       0          0 139.8   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 1.314 4.995e-05    72 838.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1379 233.5 2721        .8322\n\u001b[0m\nEpoch 00007: reducing learning rate of group 0 to 2.4975e-05.\n02:44:31 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 21\u001b[0m\n02:44:31 | saving model checkpoint: /tmp/model1.checkpoint\n02:44:47 | time:522s total_exs:28360 total_steps:1418 epochs:141.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.18     0 263.6  1016       0          0 77.06  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002053    .1192 5.959 .0001751 2.498e-05 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.2       0          0                 1418 382.8 1475 3.862            1\n\n02:44:51 | time:527s total_exs:28740 total_steps:1437 epochs:143.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.21     0 264.3  1024       0          0  77.5  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .002006    .1192 5.979 .000171 2.498e-05 119.6 463.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1437 383.8 1487 3.893            1\n\n02:44:51 | running eval: valid\n02:44:52 | eval completed in 0.20s\n02:44:52 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1801       0          0 133.8   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6 1.249 2.498e-05    72   803       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1437 233.5 2604        .8322\n\u001b[0m\n02:44:52 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 22\u001b[0m\n02:44:52 | saving model checkpoint: /tmp/model1.checkpoint\n02:45:06 | time:542s total_exs:29520 total_steps:1476 epochs:147.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1    11     0   260 995.4       0          0 76.58  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001959    .1192 6.003 .0001671 2.498e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   459.7       0          0                 1476  380 1455 3.838            1\n\n02:45:12 | time:547s total_exs:29940 total_steps:1497 epochs:149.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  10.8     0   256 991.4       0          0 77.47  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001916    .1192 5.971 .0001634 2.498e-05 119.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   462.6       0          0                 1497 375.4 1454 3.89            1\n\n02:45:12 | running eval: valid\n02:45:12 | eval completed in 0.20s\n02:45:12 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1783       0          0 132.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6 1.253 2.498e-05    72   795       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1497 233.5 2579        .8322\n\u001b[0m\n02:45:12 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 23\u001b[0m\n02:45:12 | saving model checkpoint: /tmp/model1.checkpoint\n02:45:27 | time:563s total_exs:30720 total_steps:1536 epochs:153.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.76     0 255.2 975.4       0          0 76.45  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001881    .1192 6.038 .0001597 2.498e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.6       0          0                 1536 375.9 1437 3.831            1\n\n02:45:32 | time:568s total_exs:31100 total_steps:1555 epochs:155.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.25     0 265.1  1014       0          0 76.55  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001823    .1192 5.974 .0001554 2.498e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.3       0          0                 1555 384.5 1472 3.845            1\n\n02:45:32 | running eval: valid\n02:45:32 | eval completed in 0.19s\n02:45:32 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1842       0          0 136.8   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6 1.143 2.498e-05    72 821.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1555 233.5 2663        .8748\n\u001b[0m\n02:45:32 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 24\u001b[0m\n02:45:32 | saving model checkpoint: /tmp/model1.checkpoint\n02:45:47 | time:583s total_exs:31860 total_steps:1593 epochs:159.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.1     0   262 992.6       0          0 75.76  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001784    .1192 5.971 .000152 2.498e-05 119.4 452.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1593 381.4 1445 3.797            1\n\n02:45:53 | time:588s total_exs:32260 total_steps:1613 epochs:161.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.05     0 261.1 995.6       0          0 76.26  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001742    .1192 6.065 .0001485 2.498e-05 121.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   462.5       0          0                 1613 382.4 1458 3.829            1\n\n02:45:53 | running eval: valid\n02:45:53 | eval completed in 0.19s\n02:45:53 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1830       0          0 135.9   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 1.185 2.498e-05    72 815.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1613 233.5 2646        .8322\n\u001b[0m\n02:45:53 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 25\u001b[0m\n02:45:53 | saving model checkpoint: /tmp/model1.checkpoint\n02:46:07 | time:603s total_exs:33040 total_steps:1652 epochs:165.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.19 .05128 263.8  1020       0          0 77.31   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n    780   1             32768  .6241    .1192 5.959 .0001876 2.498e-05 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   460.7       0          0                 1652  383 1480 3.874            1\n\n02:46:13 | time:608s total_exs:33460 total_steps:1673 epochs:167.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.77     0 255.5 931.6       0          0 72.93  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001666    .1192  6.01 .0001419 2.498e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   438.3       0          0                 1673 375.7 1370 3.661            1\n\n02:46:13 | running eval: valid\n02:46:13 | eval completed in 0.20s\n02:46:13 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1738       0          0 129.1   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 1.504 2.498e-05    72 774.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1673 233.5 2513        .8322\n\u001b[0m\n02:46:13 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 26\u001b[0m\n02:46:13 | saving model checkpoint: /tmp/model1.checkpoint\n02:46:28 | time:623s total_exs:34240 total_steps:1712 epochs:171.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 10.71     0 254.2 968.6       0          0  76.2  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001674    .1192 6.072 .0001386 2.498e-05 121.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   462.7       0          0                 1712 375.7 1431 3.818            1\n\n02:46:33 | time:629s total_exs:34680 total_steps:1734 epochs:173.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.12     0 262.4  1031       0          0 78.58  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001581    .1192 6.077 .0001347 2.498e-05 121.5   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   477.6       0          0                 1734  384 1509 3.945            1\n\n02:46:33 | running eval: valid\n02:46:34 | eval completed in 0.24s\n02:46:34 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1499       0          0 111.3   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 1.518 2.498e-05    72 668.1       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1734 233.5 2167        .8322\n\u001b[0m\n02:46:34 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 27\u001b[0m\n02:46:34 | saving model checkpoint: /tmp/model1.checkpoint\n02:46:49 | time:644s total_exs:35440 total_steps:1772 epochs:177.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.06     0 261.2 984.5       0          0 75.39  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001544    .1192     6 .0001315 2.498e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   452.4       0          0                 1772 381.2 1437 3.778            1\n\n02:46:54 | time:649s total_exs:35820 total_steps:1791 epochs:179.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.72     0 274.3  1075       0          0 78.36  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001508    .1192     6 .0001282 2.498e-05   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   470.2       0          0                 1791 394.3 1545 3.936            1\n\n02:46:54 | running eval: valid\n02:46:54 | eval completed in 0.20s\n02:46:54 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1757       0          0 130.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 1.527 2.498e-05    72 783.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1791 233.5 2541        .8322\n\u001b[0m\nEpoch 00014: reducing learning rate of group 0 to 1.2488e-05.\n02:46:54 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 28\u001b[0m\n02:46:54 | saving model checkpoint: /tmp/model1.checkpoint\n02:47:09 | time:664s total_exs:36600 total_steps:1830 epochs:183.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.17     0 263.4  1009       0          0 76.65  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001482    .1192  5.99 .0001262 1.249e-05 119.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.1       0          0                 1830 383.2 1468 3.841            1\n\n02:47:14 | time:669s total_exs:37020 total_steps:1851 epochs:185.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.12     0 262.3 991.4       0          0 75.59  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001462    .1193 6.081 .0001246 1.249e-05 121.6   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   459.6       0          0                 1851  384 1451 3.795            1\n\n02:47:14 | running eval: valid\n02:47:14 | eval completed in 0.20s\n02:47:14 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1783       0          0 132.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 1.532 1.249e-05    72 794.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1851 233.5 2578        .8322\n\u001b[0m\n02:47:14 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 29\u001b[0m\n02:47:14 | saving model checkpoint: /tmp/model1.checkpoint\n02:47:29 | time:684s total_exs:37800 total_steps:1890 epochs:189.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.39     0 267.8  1033       0          0 77.11  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001444    .1193 6.005 .0001229 1.249e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.1       0          0                 1890 387.9 1496 3.865            1\n\n02:47:34 | time:690s total_exs:38220 total_steps:1911 epochs:191.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.24     0 264.8  1023       0          0  77.3  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001426    .1193 6.086 .0001214 1.249e-05 121.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   470.4       0          0                 1911 386.5 1494 3.881            1\n\n02:47:34 | running eval: valid\n02:47:35 | eval completed in 0.19s\n02:47:35 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.46 161.5  1865       0          0 138.5   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08122     6 1.536 1.249e-05    72 831.4       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                   1911 233.5 2696        .8322\n\u001b[0m\n02:47:35 | \u001b[1mdid not beat best accuracy: 0.875 impatience: 30\u001b[0m\n02:47:35 | saving model checkpoint: /tmp/model1.checkpoint\n02:47:39 | ran out of patience! stopping training.\n02:47:39 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n02:47:39 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n02:47:39 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run1/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n02:47:39 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n02:47:39 | Using CUDA\n02:47:39 | loading dictionary from /tmp/model1.dict\n02:47:39 | num words = 54944\n02:47:44 | Loading existing model parameters from /tmp/model1\n02:47:51 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:47:52 | creating task(s): fromfile:parlaiformat\n02:47:52 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run1/data_valid.txt\n02:47:52 | running eval: valid\n02:47:52 | eval completed in 0.21s\n02:47:52 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 11.46 161.5  1746       0          0 129.7   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297     6 .3805 8.154e-06    72 778.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    163 233.5 2525        .8730\n\u001b[0m\n02:47:52 | creating task(s): fromfile:parlaiformat\n02:47:52 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run1/data_test.txt\n02:47:52 | running eval: test\n02:47:57 | eval completed in 4.81s\n02:47:57 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9530 9.53e-10               .8050                 .6879   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9700            .9733              .9965   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9511 12.07 281.4  2938       0          0 208.8 1000 .9530   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298   5.2 .2477 8.154e-06   104  1086       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    163 385.4 4024        .9565\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type2/run1/data_test.txt -m transformer/classifier -mf /tmp/model1 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:47:59.374195Z","iopub.execute_input":"2022-12-04T02:47:59.374581Z","iopub.status.idle":"2022-12-04T02:48:30.660600Z","shell.execute_reply.started":"2022-12-04T02:47:59.374539Z","shell.execute_reply":"2022-12-04T02:48:30.659330Z"},"scrolled":true,"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"02:48:08 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr2type2/run1/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr2type2/run1/data)\u001b[0m\n02:48:08 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n02:48:08 | Using CUDA\n02:48:08 | loading dictionary from /tmp/model1.dict\n02:48:08 | num words = 54944\n02:48:13 | Loading existing model parameters from /tmp/model1\n02:48:19 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:48:20 | Opt:\n02:48:20 |     activation: gelu\n02:48:20 |     adafactor_eps: '[1e-30, 0.001]'\n02:48:20 |     adam_eps: 1e-08\n02:48:20 |     add_p1_after_newln: False\n02:48:20 |     aggregate_micro: False\n02:48:20 |     allow_missing_init_opts: False\n02:48:20 |     area_under_curve_class: None\n02:48:20 |     area_under_curve_digits: -1\n02:48:20 |     attention_dropout: 0.1\n02:48:20 |     batchsize: 40\n02:48:20 |     betas: '[0.9, 0.999]'\n02:48:20 |     bpe_add_prefix_space: None\n02:48:20 |     bpe_debug: False\n02:48:20 |     bpe_dropout: None\n02:48:20 |     bpe_merge: None\n02:48:20 |     bpe_vocab: None\n02:48:20 |     candidates: inline\n02:48:20 |     cap_num_predictions: 100\n02:48:20 |     checkpoint_activations: False\n02:48:20 |     class_weights: None\n02:48:20 |     classes: \"['__notok__', '__ok__']\"\n02:48:20 |     classes_from_file: None\n02:48:20 |     data_parallel: True\n02:48:20 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n02:48:20 |     datatype: train\n02:48:20 |     delimiter: '\\n'\n02:48:20 |     dict_class: parlai.core.dict:DictionaryAgent\n02:48:20 |     dict_endtoken: __start__\n02:48:20 |     dict_file: /tmp/model1.dict\n02:48:20 |     dict_include_test: False\n02:48:20 |     dict_include_valid: False\n02:48:20 |     dict_initpath: None\n02:48:20 |     dict_language: english\n02:48:20 |     dict_loaded: True\n02:48:20 |     dict_lower: True\n02:48:20 |     dict_max_ngram_size: -1\n02:48:20 |     dict_maxexs: -1\n02:48:20 |     dict_maxtokens: -1\n02:48:20 |     dict_minfreq: 0\n02:48:20 |     dict_nulltoken: __null__\n02:48:20 |     dict_starttoken: __start__\n02:48:20 |     dict_textfields: text,labels\n02:48:20 |     dict_tokenizer: bpe\n02:48:20 |     dict_unktoken: __unk__\n02:48:20 |     display_examples: False\n02:48:20 |     download_path: None\n02:48:20 |     dropout: 0.1\n02:48:20 |     dynamic_batching: None\n02:48:20 |     embedding_projection: random\n02:48:20 |     embedding_size: 768\n02:48:20 |     embedding_type: random\n02:48:20 |     embeddings_scale: False\n02:48:20 |     encode_candidate_vecs: True\n02:48:20 |     encode_candidate_vecs_batchsize: 256\n02:48:20 |     eval_batchsize: None\n02:48:20 |     eval_candidates: inline\n02:48:20 |     eval_dynamic_batching: None\n02:48:20 |     evaltask: None\n02:48:20 |     ffn_size: 3072\n02:48:20 |     final_extra_opt: \n02:48:20 |     fixed_candidate_vecs: reuse\n02:48:20 |     fixed_candidates_path: None\n02:48:20 |     force_fp16_tokens: True\n02:48:20 |     fp16: True\n02:48:20 |     fp16_impl: safe\n02:48:20 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run1/data_test.txt\n02:48:20 |     fromfile_datatype_extension: True\n02:48:20 |     gpu: -1\n02:48:20 |     gradient_clip: 0.1\n02:48:20 |     hide_labels: False\n02:48:20 |     history_add_global_end_token: None\n02:48:20 |     history_reversed: False\n02:48:20 |     history_size: 20\n02:48:20 |     ignore_bad_candidates: False\n02:48:20 |     ignore_labels: None\n02:48:20 |     image_cropsize: 224\n02:48:20 |     image_mode: raw\n02:48:20 |     image_size: 256\n02:48:20 |     inference: max\n02:48:20 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:48:20 |     init_opt: None\n02:48:20 |     interactive_candidates: fixed\n02:48:20 |     interactive_mode: False\n02:48:20 |     invsqrt_lr_decay_gamma: -1\n02:48:20 |     is_debug: False\n02:48:20 |     label_truncate: 72\n02:48:20 |     learn_embeddings: True\n02:48:20 |     learn_positional_embeddings: True\n02:48:20 |     learningrate: 5e-05\n02:48:20 |     load_from_pretrained_ranker: True\n02:48:20 |     log_every_n_secs: 10.0\n02:48:20 |     log_every_n_steps: 50\n02:48:20 |     log_keep_fields: all\n02:48:20 |     loglevel: info\n02:48:20 |     lr_scheduler: reduceonplateau\n02:48:20 |     lr_scheduler_decay: 0.5\n02:48:20 |     lr_scheduler_patience: 3\n02:48:20 |     max_train_steps: -1\n02:48:20 |     max_train_time: 7200.0\n02:48:20 |     memory_attention: sqrt\n02:48:20 |     metrics: default\n02:48:20 |     model: transformer/classifier\n02:48:20 |     model_file: /tmp/model1\n02:48:20 |     model_parallel: False\n02:48:20 |     momentum: 0\n02:48:20 |     multitask_weights: [1]\n02:48:20 |     mutators: None\n02:48:20 |     n_decoder_layers: -1\n02:48:20 |     n_encoder_layers: -1\n02:48:20 |     n_heads: 12\n02:48:20 |     n_layers: 12\n02:48:20 |     n_positions: 1024\n02:48:20 |     n_segments: 2\n02:48:20 |     nesterov: True\n02:48:20 |     no_cuda: False\n02:48:20 |     normalize_sent_emb: False\n02:48:20 |     num_epochs: -1\n02:48:20 |     num_examples: -1\n02:48:20 |     num_workers: 0\n02:48:20 |     nus: [0.7]\n02:48:20 |     optimizer: adamax\n02:48:20 |     output_scaling: 0.06\n02:48:20 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type2/run1/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model1', 'batchsize': 40}\"\n02:48:20 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n02:48:20 |     person_tokens: False\n02:48:20 |     print_scores: False\n02:48:20 |     rank_candidates: False\n02:48:20 |     rank_top_k: -1\n02:48:20 |     reduction_type: mean\n02:48:20 |     ref_class: None\n02:48:20 |     relu_dropout: 0.0\n02:48:20 |     repeat_blocking_heuristic: True\n02:48:20 |     report_filename: \n02:48:20 |     return_cand_scores: False\n02:48:20 |     save_after_valid: True\n02:48:20 |     save_every_n_secs: -1\n02:48:20 |     save_format: conversations\n02:48:20 |     share_encoders: False\n02:48:20 |     share_word_embeddings: False\n02:48:20 |     short_final_eval: False\n02:48:20 |     special_tok_lst: None\n02:48:20 |     split_lines: False\n02:48:20 |     starttime: Dec04_02-35\n02:48:20 |     task: fromfile:parlaiformat\n02:48:20 |     tensorboard_log: False\n02:48:20 |     tensorboard_logdir: None\n02:48:20 |     text_truncate: 360\n02:48:20 |     threshold: 0.5\n02:48:20 |     topk: 5\n02:48:20 |     train_predict: False\n02:48:20 |     truncate: 1024\n02:48:20 |     update_classifier_head_only: False\n02:48:20 |     update_freq: 1\n02:48:20 |     use_memories: False\n02:48:20 |     use_reply: none\n02:48:20 |     validation_cutoff: 1.0\n02:48:20 |     validation_every_n_epochs: -1\n02:48:20 |     validation_every_n_secs: 20.0\n02:48:20 |     validation_every_n_steps: -1\n02:48:20 |     validation_max_exs: -1\n02:48:20 |     validation_metric: accuracy\n02:48:20 |     validation_metric_mode: max\n02:48:20 |     validation_patience: 30\n02:48:20 |     validation_share_agent: False\n02:48:20 |     variant: xlm\n02:48:20 |     verbose: False\n02:48:20 |     wandb_entity: None\n02:48:20 |     wandb_log: False\n02:48:20 |     wandb_name: None\n02:48:20 |     wandb_project: None\n02:48:20 |     warmup_rate: 0.0001\n02:48:20 |     warmup_updates: 1000\n02:48:20 |     weight_decay: None\n02:48:20 |     world_logs: \n02:48:20 |     wrap_memory_encoder: False\n02:48:20 | Evaluating task fromfile:parlaiformat using datatype valid.\n02:48:20 | creating task(s): fromfile:parlaiformat\n02:48:20 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n02:48:20 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run1/data_test.txt\n02:48:29 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9530 9.53e-10               .8050                 .6879   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9700            .9733              .9965   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9511 12.07 562.9  1861       0          0 132.2 1000 .9530   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2477 8.154e-06   208 687.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    163 770.9 2549        .9565\u001b[0m\n02:48:29 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9530 9.53e-10               .8050                 .6879   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9700            .9733              .9965   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9511 12.07 562.9  1861       0          0 132.2 1000 .9530   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .2477 8.154e-06   208 687.7       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    163 770.9 2549        .9565\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model1*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:48:30.663085Z","iopub.execute_input":"2022-12-04T02:48:30.663491Z","iopub.status.idle":"2022-12-04T02:48:31.857693Z","shell.execute_reply.started":"2022-12-04T02:48:30.663448Z","shell.execute_reply":"2022-12-04T02:48:31.856399Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"markdown","source":"run 2","metadata":{}},{"cell_type":"code","source":"# run 2 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type2/run2/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model2","metadata":{"execution":{"iopub.status.busy":"2022-12-04T02:48:31.859978Z","iopub.execute_input":"2022-12-04T02:48:31.860412Z","iopub.status.idle":"2022-12-04T03:00:22.797639Z","shell.execute_reply.started":"2022-12-04T02:48:31.860369Z","shell.execute_reply":"2022-12-04T03:00:22.796455Z"},"scrolled":true,"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"02:48:39 | building dictionary first...\n02:48:39 | No model with opt yet at: /tmp/model2(.opt)\n02:48:39 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run2/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n02:48:39 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n02:48:39 | Using CUDA\n02:48:39 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n02:48:39 | num words = 54944\n02:48:43 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:48:53 | Total parameters: 128,042,498 (128,042,498 trainable)\n02:48:53 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n02:48:53 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n02:48:53 | Opt:\n02:48:53 |     activation: gelu\n02:48:53 |     adafactor_eps: '(1e-30, 0.001)'\n02:48:53 |     adam_eps: 1e-08\n02:48:53 |     add_p1_after_newln: False\n02:48:53 |     aggregate_micro: False\n02:48:53 |     allow_missing_init_opts: False\n02:48:53 |     attention_dropout: 0.1\n02:48:53 |     batchsize: 20\n02:48:53 |     betas: '(0.9, 0.999)'\n02:48:53 |     bpe_add_prefix_space: None\n02:48:53 |     bpe_debug: False\n02:48:53 |     bpe_dropout: None\n02:48:53 |     bpe_merge: None\n02:48:53 |     bpe_vocab: None\n02:48:53 |     candidates: inline\n02:48:53 |     cap_num_predictions: 100\n02:48:53 |     checkpoint_activations: False\n02:48:53 |     class_weights: None\n02:48:53 |     classes: \"['__notok__', '__ok__']\"\n02:48:53 |     classes_from_file: None\n02:48:53 |     data_parallel: True\n02:48:53 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n02:48:53 |     datatype: train\n02:48:53 |     delimiter: '\\n'\n02:48:53 |     dict_class: parlai.core.dict:DictionaryAgent\n02:48:53 |     dict_endtoken: __start__\n02:48:53 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n02:48:53 |     dict_include_test: False\n02:48:53 |     dict_include_valid: False\n02:48:53 |     dict_initpath: None\n02:48:53 |     dict_language: english\n02:48:53 |     dict_loaded: True\n02:48:53 |     dict_lower: True\n02:48:53 |     dict_max_ngram_size: -1\n02:48:53 |     dict_maxexs: -1\n02:48:53 |     dict_maxtokens: -1\n02:48:53 |     dict_minfreq: 0\n02:48:53 |     dict_nulltoken: __null__\n02:48:53 |     dict_starttoken: __start__\n02:48:53 |     dict_textfields: text,labels\n02:48:53 |     dict_tokenizer: bpe\n02:48:53 |     dict_unktoken: __unk__\n02:48:53 |     display_examples: False\n02:48:53 |     download_path: None\n02:48:53 |     dropout: 0.1\n02:48:53 |     dynamic_batching: None\n02:48:53 |     embedding_projection: random\n02:48:53 |     embedding_size: 768\n02:48:53 |     embedding_type: random\n02:48:53 |     embeddings_scale: False\n02:48:53 |     encode_candidate_vecs: True\n02:48:53 |     encode_candidate_vecs_batchsize: 256\n02:48:53 |     eval_batchsize: None\n02:48:53 |     eval_candidates: inline\n02:48:53 |     eval_dynamic_batching: None\n02:48:53 |     evaltask: None\n02:48:53 |     ffn_size: 3072\n02:48:53 |     final_extra_opt: \n02:48:53 |     fixed_candidate_vecs: reuse\n02:48:53 |     fixed_candidates_path: None\n02:48:53 |     force_fp16_tokens: False\n02:48:53 |     fp16: True\n02:48:53 |     fp16_impl: safe\n02:48:53 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run2/data\n02:48:53 |     fromfile_datatype_extension: True\n02:48:53 |     gpu: -1\n02:48:53 |     gradient_clip: 0.1\n02:48:53 |     hide_labels: False\n02:48:53 |     history_add_global_end_token: None\n02:48:53 |     history_reversed: False\n02:48:53 |     history_size: 20\n02:48:53 |     ignore_bad_candidates: False\n02:48:53 |     ignore_labels: None\n02:48:53 |     image_cropsize: 224\n02:48:53 |     image_mode: raw\n02:48:53 |     image_size: 256\n02:48:53 |     inference: max\n02:48:53 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n02:48:53 |     init_opt: None\n02:48:53 |     interactive_candidates: fixed\n02:48:53 |     interactive_mode: False\n02:48:53 |     invsqrt_lr_decay_gamma: -1\n02:48:53 |     is_debug: False\n02:48:53 |     label_truncate: 72\n02:48:53 |     learn_embeddings: True\n02:48:53 |     learn_positional_embeddings: True\n02:48:53 |     learningrate: 5e-05\n02:48:53 |     load_from_checkpoint: False\n02:48:53 |     load_from_pretrained_ranker: True\n02:48:53 |     log_every_n_secs: 10.0\n02:48:53 |     log_every_n_steps: 50\n02:48:53 |     log_keep_fields: all\n02:48:53 |     loglevel: info\n02:48:53 |     lr_scheduler: reduceonplateau\n02:48:53 |     lr_scheduler_decay: 0.5\n02:48:53 |     lr_scheduler_patience: 3\n02:48:53 |     max_train_steps: -1\n02:48:53 |     max_train_time: 7200.0\n02:48:53 |     memory_attention: sqrt\n02:48:53 |     metrics: default\n02:48:53 |     model: transformer/classifier\n02:48:53 |     model_file: /tmp/model2\n02:48:53 |     model_parallel: False\n02:48:53 |     momentum: 0\n02:48:53 |     multitask_weights: [1]\n02:48:53 |     mutators: None\n02:48:53 |     n_decoder_layers: -1\n02:48:53 |     n_encoder_layers: -1\n02:48:53 |     n_heads: 12\n02:48:53 |     n_layers: 12\n02:48:53 |     n_positions: 1024\n02:48:53 |     n_segments: 2\n02:48:53 |     nesterov: True\n02:48:53 |     no_cuda: False\n02:48:53 |     normalize_sent_emb: False\n02:48:53 |     num_epochs: -1\n02:48:53 |     num_workers: 0\n02:48:53 |     nus: (0.7,)\n02:48:53 |     optimizer: adamax\n02:48:53 |     output_scaling: 0.06\n02:48:53 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type2/run2/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model2'}\"\n02:48:53 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n02:48:53 |     person_tokens: False\n02:48:53 |     print_scores: False\n02:48:53 |     rank_candidates: False\n02:48:53 |     rank_top_k: -1\n02:48:53 |     reduction_type: mean\n02:48:53 |     ref_class: None\n02:48:53 |     relu_dropout: 0.0\n02:48:53 |     repeat_blocking_heuristic: True\n02:48:53 |     return_cand_scores: False\n02:48:53 |     save_after_valid: True\n02:48:53 |     save_every_n_secs: -1\n02:48:53 |     save_format: conversations\n02:48:53 |     share_encoders: False\n02:48:53 |     share_word_embeddings: False\n02:48:53 |     short_final_eval: False\n02:48:53 |     special_tok_lst: None\n02:48:53 |     split_lines: False\n02:48:53 |     starttime: Dec04_02-48\n02:48:53 |     task: fromfile:parlaiformat\n02:48:53 |     tensorboard_log: False\n02:48:53 |     tensorboard_logdir: None\n02:48:53 |     text_truncate: 360\n02:48:53 |     threshold: 0.5\n02:48:53 |     topk: 5\n02:48:53 |     train_predict: False\n02:48:53 |     truncate: 1024\n02:48:53 |     update_classifier_head_only: False\n02:48:53 |     update_freq: 1\n02:48:53 |     use_memories: False\n02:48:53 |     use_reply: none\n02:48:53 |     validation_cutoff: 1.0\n02:48:53 |     validation_every_n_epochs: -1\n02:48:53 |     validation_every_n_secs: 20.0\n02:48:53 |     validation_every_n_steps: -1\n02:48:53 |     validation_max_exs: -1\n02:48:53 |     validation_metric: accuracy\n02:48:53 |     validation_metric_mode: max\n02:48:53 |     validation_patience: 30\n02:48:53 |     validation_share_agent: False\n02:48:53 |     variant: xlm\n02:48:53 |     verbose: False\n02:48:53 |     wandb_entity: None\n02:48:53 |     wandb_log: False\n02:48:53 |     wandb_name: None\n02:48:53 |     wandb_project: None\n02:48:53 |     warmup_rate: 0.0001\n02:48:53 |     warmup_updates: 1000\n02:48:53 |     weight_decay: None\n02:48:53 |     world_logs: \n02:48:53 |     wrap_memory_encoder: False\n02:48:53 | creating task(s): fromfile:parlaiformat\n02:48:53 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run2/data_train.txt\n02:48:53 | training...\n02:49:04 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5575 5.575e-10               .5014                 .5669   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .4495            .6022              .5514   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6634 11.96     1 279.3 551.3       0          0 39.48  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5575             32768  2.561    .1206  5.99 .6858 1.005e-06 119.8 236.5   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   20 399.1 787.8 1.978        .5523\n\n02:49:14 | time:20s total_exs:1160 total_steps:58 epochs:5.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6526 6.526e-10               .6048                 .7038   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5302            .6901              .6216   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .7757 11.65     1 272.9  1055       0          0  77.3  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6526             32768  2.486    .1207 6.003 .6660 2.905e-06 120.1   464   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                   58  393 1519 3.874        .6474\n\n02:49:14 | creating task(s): fromfile:parlaiformat\n02:49:14 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run2/data_valid.txt\n02:49:14 | running eval: valid\n02:49:14 | eval completed in 0.20s\n02:49:14 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .6250 6.25e-10               .6400                 .6154   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .6087              .6364   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .5833    11   156  1756       0          0 135.1   24 .6250   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6729 2.905e-06    72 810.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                     58  228 2567        .6243\n\u001b[0m\n02:49:14 | \u001b[1;32mnew best accuracy: 0.625\u001b[0m\n02:49:14 | saving best valid model: /tmp/model2\n02:49:14 | Saving dictionary to /tmp/model2.dict\n02:49:17 | saving model checkpoint: /tmp/model2.checkpoint\n02:49:17 | Saving dictionary to /tmp/model2.checkpoint.dict\n02:49:34 | time:40s total_exs:1880 total_steps:94 epochs:9.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8042 8.042e-10               .8327                 .7484   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9385            .7638              .9084   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6590 11.62     1 272.5 975.1       0          0 71.58  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8042             32768  2.785    .1207 6.039 .6050 4.705e-06 120.8 432.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   94 393.2 1407 3.587        .7996\n\n02:49:38 | time:44s total_exs:2160 total_steps:108 epochs:10.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8929 8.929e-10               .8951                 .8707   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9209            .8905              .9173   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8652 11.76     1 275.2  1067       0          0 77.57  280   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8929             32768  3.072    .1207 5.993 .5338 5.404e-06 119.9 464.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  108 395.1 1532 3.903        .8928\n\n02:49:38 | running eval: valid\n02:49:38 | eval completed in 0.20s\n02:49:38 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1742       0          0   134   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5346 5.404e-06    72   804       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    108  228 2546        .9167\n\u001b[0m\n02:49:38 | \u001b[1;32mnew best accuracy: 0.9167 (previous best was 0.625)\u001b[0m\n02:49:38 | saving best valid model: /tmp/model2\n02:49:47 | saving model checkpoint: /tmp/model2.checkpoint\n02:50:03 | time:69s total_exs:2920 total_steps:146 epochs:14.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9382 9.382e-10               .9384                 .9471   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9299            .9379              .9293   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9467 11.83     1 276.5  1048       0          0 75.82  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9382             32768  3.985    .1207 6.013 .3867 7.304e-06 120.3   456   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  146 396.8 1504  3.8        .9382\n\n02:50:07 | time:74s total_exs:3260 total_steps:163 epochs:16.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9500 9.5e-10               .9544                 .9519   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9570            .9446              .9477   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9416 11.96     1 279.2  1066       0          0 76.38  340   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9500             32768  5.676    .1207 6.094 .2318 8.154e-06 121.9 465.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  163 401.1 1532 3.839        .9500\n\n02:50:07 | running eval: valid\n02:50:08 | eval completed in 0.19s\n02:50:08 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1772       0          0 136.2   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .2629 8.154e-06    72 817.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    163  228 2589        .9167\n\u001b[0m\n02:50:08 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 1\u001b[0m\n02:50:08 | saving model checkpoint: /tmp/model2.checkpoint\n02:50:23 | time:89s total_exs:4020 total_steps:201 epochs:20.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9737 9.737e-10               .9742                 .9742   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9742            .9731              .9731   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9731 11.75     1   275  1028       0          0 74.77  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9737             32768  6.583    .1207 6.021 .1149 1.005e-05 120.4 450.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  201 395.4 1478 3.747        .9737\n\n02:50:28 | time:94s total_exs:4380 total_steps:219 epochs:21.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9972 9.972e-10               .9973                 .9947   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9971                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9942 12.19     1 283.9  1016       0          0 71.55  360   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss        lr  ltpb  ltps  \\\n   .9972             32768  3.637    .1207 6.044 .02834 1.095e-05 120.9 432.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  219 404.8 1448 3.593        .9972\n\n02:50:28 | running eval: valid\n02:50:28 | eval completed in 0.20s\n02:50:28 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1750       0          0 134.6   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .2789 1.095e-05    72 807.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    219  228 2558        .9167\n\u001b[0m\n02:50:28 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 2\u001b[0m\n02:50:28 | saving model checkpoint: /tmp/model2.checkpoint\n02:50:43 | time:109s total_exs:5160 total_steps:258 epochs:25.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9974 9.974e-10               .9975                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9949            .9974              .9948   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.53 .5128 270.5  1032       0          0 76.32  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9974             32768  3.143    .1207 6.015 .01512 1.29e-05 120.3 459.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  258 390.8 1491 3.824        .9974\n\n02:50:48 | time:115s total_exs:5580 total_steps:279 epochs:27.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0   276  1044       0          0  75.7  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .03318    .1207 6.057 .002655 1.395e-05 121.1 458.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  279 397.1 1503 3.801            1\n\n02:50:48 | running eval: valid\n02:50:48 | eval completed in 0.19s\n02:50:48 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1776       0          0 136.6   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .7336 1.395e-05    72 819.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    279  228 2596        .8748\n\u001b[0m\n02:50:48 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 3\u001b[0m\n02:50:48 | saving model checkpoint: /tmp/model2.checkpoint\n02:51:03 | time:129s total_exs:6320 total_steps:316 epochs:31.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.81     0 276.1  1016       0          0 73.61  740   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .02596    .1207 5.989 .001896 1.58e-05 119.8 440.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  316 395.9 1457 3.689            1\n\n02:51:09 | time:135s total_exs:6780 total_steps:339 epochs:33.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.8     0   276  1059       0          0 76.75  460   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01844    .1207 6.039 .001544 1.695e-05 120.8 463.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  339 396.7 1523 3.852            1\n\n02:51:09 | running eval: valid\n02:51:09 | eval completed in 0.20s\n02:51:09 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1748       0          0 134.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 .7455 1.695e-05    72 806.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    339  228 2555        .8748\n\u001b[0m\n02:51:09 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 4\u001b[0m\n02:51:09 | saving model checkpoint: /tmp/model2.checkpoint\n02:51:27 | time:153s total_exs:7540 total_steps:377 epochs:37.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.86     0 277.3  1047       0          0  75.5  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768  .0161    .1207 6.058 .001366 1.885e-05 121.2 457.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  377 398.4 1504 3.783            1\n\n02:51:29 | time:156s total_exs:7700 total_steps:385 epochs:38.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.23     0 264.6 965.6       0          0 72.98  160   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01513    .1207 6.013 .001277 1.925e-05 120.2 438.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  385 384.9 1404 3.687            1\n\n02:51:29 | running eval: valid\n02:51:29 | eval completed in 0.20s\n02:51:29 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1745       0          0 134.2   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08095     6 .7875 1.925e-05    72 805.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    385  228 2551        .8748\n\u001b[0m\n02:51:29 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 5\u001b[0m\n02:51:29 | saving model checkpoint: /tmp/model2.checkpoint\n02:51:44 | time:170s total_exs:8480 total_steps:424 epochs:42.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.45     0   269  1023       0          0  76.1  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .01419    .1207 5.992 .001199 2.12e-05 119.8   456   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  424 388.8 1480 3.814            1\n\n02:51:49 | time:176s total_exs:8900 total_steps:445 epochs:44.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.49     0 269.7  1038       0          0 76.95  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01305    .1207 5.976 .001113 2.225e-05 119.5 459.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  445 389.2 1498 3.863            1\n\n02:51:49 | running eval: valid\n02:51:49 | eval completed in 0.20s\n02:51:49 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1752       0          0 134.7   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 .7993 2.225e-05    72 808.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    445  228 2560        .8748\n\u001b[0m\n02:51:49 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 6\u001b[0m\n02:51:49 | saving model checkpoint: /tmp/model2.checkpoint\n02:52:04 | time:191s total_exs:9660 total_steps:483 epochs:48.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 12.09 .02632 281.8  1054       0          0 74.83   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n    760   1             32768 .02382    .1207 5.947 .001051 2.415e-05 118.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   445.1       0          0                  483 400.8 1500 3.75            1\n\n02:52:10 | time:196s total_exs:10080 total_steps:504 epochs:50.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.71     0 274.1  1040       0          0 75.89  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .01138    .1207 6.057 .0009763 2.52e-05 121.1 459.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  504 395.3 1500 3.81            1\n\n02:52:10 | running eval: valid\n02:52:10 | eval completed in 0.20s\n02:52:10 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1722       0          0 132.4   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 .8517 2.52e-05    72 794.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    504  228 2517        .8748\n\u001b[0m\n02:52:10 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 7\u001b[0m\n02:52:10 | saving model checkpoint: /tmp/model2.checkpoint\n02:52:24 | time:211s total_exs:10840 total_steps:542 epochs:54.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.62     0 272.4  1036       0          0 76.04  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .01071    .1207 5.968 .0009198 2.71e-05 119.4 453.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  542 391.8 1490 3.811            1\n\n02:52:30 | time:217s total_exs:11280 total_steps:564 epochs:56.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.87     0 277.4  1038       0          0 74.84  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .009997    .1207 6.068 .0008582 2.82e-05 121.4 454.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  564 398.8 1492 3.757            1\n\n02:52:30 | running eval: valid\n02:52:30 | eval completed in 0.22s\n02:52:30 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1570       0          0 120.7   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 .8640 2.82e-05    72 724.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    564  228 2294        .8748\n\u001b[0m\n02:52:30 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 8\u001b[0m\n02:52:30 | saving model checkpoint: /tmp/model2.checkpoint\n02:52:45 | time:231s total_exs:12060 total_steps:603 epochs:60.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.79     0 275.9  1061       0          0 76.93  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .009463    .1208  6.01 .0008085 3.015e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   462.4       0          0                  603 396.1 1524 3.855            1\n\n02:52:50 | time:237s total_exs:12480 total_steps:624 epochs:62.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.53     0 270.5  1026       0          0 75.88  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .00887    .1208  5.99 .0007603 3.12e-05 119.8 454.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  624 390.3 1481 3.809            1\n\n02:52:50 | running eval: valid\n02:52:50 | eval completed in 0.20s\n02:52:50 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1735       0          0 133.4   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 .8958 3.12e-05    72 800.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    624  228 2536        .8748\n\u001b[0m\n02:52:50 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 9\u001b[0m\n02:52:50 | saving model checkpoint: /tmp/model2.checkpoint\n02:53:05 | time:252s total_exs:13240 total_steps:662 epochs:66.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.78     0 275.6  1026       0          0 74.47  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .008339    .1208 5.982 .0007143 3.31e-05 119.6 445.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  662 395.3 1472 3.732            1\n\n02:53:11 | time:257s total_exs:13680 total_steps:684 epochs:68.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.66     0 273.1  1049       0          0 76.83  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .007817    .1208 6.023 .0006682 3.42e-05 120.5 462.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  684 393.6 1512 3.857            1\n\n02:53:11 | running eval: valid\n02:53:11 | eval completed in 0.23s\n02:53:11 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1539       0          0 118.3   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 .9117 3.42e-05    72 710.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    684  228 2249        .8748\n\u001b[0m\n02:53:11 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 10\u001b[0m\n02:53:11 | saving model checkpoint: /tmp/model2.checkpoint\n02:53:25 | time:272s total_exs:14460 total_steps:723 epochs:72.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.38     0 267.6  1023       0          0 76.48  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .007347    .1208 6.026 .0006279 3.615e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.8       0          0                  723 388.1 1484 3.832            1\n\n02:53:31 | time:278s total_exs:14900 total_steps:745 epochs:74.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.63     0 272.5  1055       0          0 77.41  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006905    .1208 5.927 .0005906 3.725e-05 118.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   458.9       0          0                  745 391.1 1514 3.886            1\n\n02:53:31 | running eval: valid\n02:53:31 | eval completed in 0.20s\n02:53:31 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1723       0          0 132.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 .9297 3.725e-05    72 795.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    745  228 2518        .8748\n\u001b[0m\n02:53:31 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 11\u001b[0m\n02:53:31 | saving model checkpoint: /tmp/model2.checkpoint\n02:53:46 | time:293s total_exs:15660 total_steps:783 epochs:78.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.82     0 276.4  1051       0          0 76.06  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006472    .1208 5.963 .0005531 3.915e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   453.6       0          0                  783 395.7 1505 3.812            1\n\n02:53:51 | time:298s total_exs:16080 total_steps:804 epochs:80.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.51     0 270.2  1054       0          0 78.02  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .00607    .1208  5.99 .0005188 4.02e-05 119.8 467.4   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  804  390 1522 3.917            1\n\n02:53:51 | running eval: valid\n02:53:52 | eval completed in 0.19s\n02:53:52 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1804       0          0 138.7   24 .8750   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 .9360 4.02e-05    72 832.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    804  228 2636        .8748\n\u001b[0m\n02:53:52 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 12\u001b[0m\n02:53:52 | saving model checkpoint: /tmp/model2.checkpoint\n02:54:06 | time:313s total_exs:16840 total_steps:842 epochs:84.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.85     0   277  1032       0          0 74.55  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .005749    .1208 5.968 .0004877 4.21e-05 119.4 444.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  842 396.4 1477 3.736            1\n\n02:54:12 | time:318s total_exs:17260 total_steps:863 epochs:86.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.66     0 273.2  1067       0          0 78.11  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .005388    .1208 5.971 .000458 4.315e-05 119.4 466.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  863 392.6 1533 3.922            1\n\n02:54:12 | running eval: valid\n02:54:12 | eval completed in 0.19s\n02:54:12 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1769       0          0 136.1   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 .9792 4.315e-05    72 816.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    863  228 2586        .8748\n\u001b[0m\n02:54:12 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 13\u001b[0m\n02:54:12 | saving model checkpoint: /tmp/model2.checkpoint\n02:54:26 | time:333s total_exs:18040 total_steps:902 epochs:90.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.51     0 270.2  1035       0          0 76.63  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .005024    .1208 6.044 .0004283 4.51e-05 120.9 463.1   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps  ups  weighted_f1  \n         0          0                  902  391 1498 3.84            1\n\n02:54:32 | time:338s total_exs:18460 total_steps:923 epochs:92.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.54     0 270.9  1028       0          0 75.93  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004825    .1208 6.067 .0004018 4.615e-05 121.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.6       0          0                  923 392.2 1489 3.811            1\n\n02:54:32 | running eval: valid\n02:54:32 | eval completed in 0.19s\n02:54:32 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1787       0          0 137.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08105     6 .9763 4.615e-05    72 824.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    923  228 2612        .8748\n\u001b[0m\n02:54:32 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 14\u001b[0m\n02:54:32 | saving model checkpoint: /tmp/model2.checkpoint\n02:54:46 | time:353s total_exs:19220 total_steps:961 epochs:96.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.59     0 271.7  1025       0          0 75.46  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004434    .1208 6.039 .0003778 4.805e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   455.8       0          0                  961 392.5 1481 3.782            1\n\n02:54:52 | time:359s total_exs:19660 total_steps:983 epochs:98.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.7     0   274  1046       0          0 76.37  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004412    .1208 5.914 .0003572 4.915e-05 118.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.6       0          0                  983 392.3 1498 3.833            1\n\n02:54:52 | running eval: valid\n02:54:52 | eval completed in 0.19s\n02:54:52 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1798       0          0 138.3   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6  1.02 4.915e-05    72 829.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    983  228 2628        .8748\n\u001b[0m\n02:54:52 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 15\u001b[0m\n02:54:52 | saving model checkpoint: /tmp/model2.checkpoint\n02:55:07 | time:373s total_exs:20420 total_steps:1021 epochs:102.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.77     0 275.4  1045       0          0 75.89  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00392    .1208 5.976 .0003336 4.995e-05 119.5 453.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1021 394.9 1499 3.803            1\n\n02:55:13 | time:379s total_exs:20840 total_steps:1042 epochs:104.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.69     0 273.8 993.7       0          0 72.59  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .003678    .1208 6.062 .000313 4.995e-05 121.2 440.1   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1042  395 1434 3.644            1\n\n02:55:13 | running eval: valid\n02:55:13 | eval completed in 0.20s\n02:55:13 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1731       0          0 133.1   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6  1.02 4.995e-05    72 798.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1042  228 2530        .8748\n\u001b[0m\n02:55:13 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 16\u001b[0m\n02:55:13 | saving model checkpoint: /tmp/model2.checkpoint\n02:55:27 | time:394s total_exs:21620 total_steps:1081 epochs:108.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.55     0 270.9  1038       0          0 76.64  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00348    .1208  5.99 .0002953 4.995e-05 119.8 459.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1081 390.7 1497 3.841            1\n\n02:55:33 | time:399s total_exs:22060 total_steps:1103 epochs:110.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.65     0 273.1  1052       0          0 77.01  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003272    .1209 6.036 .0002781 4.995e-05 120.7   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   464.9       0          0                 1103 393.8 1516 3.867            1\n\n02:55:33 | running eval: valid\n02:55:33 | eval completed in 0.22s\n02:55:33 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1621       0          0 124.5   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 1.001 4.995e-05    72 747.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1103  228 2370        .8748\n\u001b[0m\n02:55:33 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 17\u001b[0m\n02:55:33 | saving model checkpoint: /tmp/model2.checkpoint\n02:55:48 | time:414s total_exs:22820 total_steps:1141 epochs:114.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.64     0 272.8  1020       0          0 74.76  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003152    .1209 5.995 .0002632 4.995e-05 119.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   448.2       0          0                 1141 392.7 1468 3.747            1\n\n02:55:53 | time:420s total_exs:23260 total_steps:1163 epochs:116.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.5     0   270  1055       0          0 78.16  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002937    .1209 5.945 .0002496 4.995e-05 118.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   464.7       0          0                 1163 388.9 1520 3.924            1\n\n02:55:53 | running eval: valid\n02:55:54 | eval completed in 0.19s\n02:55:54 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1792       0          0 137.8   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6 .9975 4.995e-05    72   827       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1163  228 2619        .8748\n\u001b[0m\n02:55:54 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 18\u001b[0m\n02:55:54 | saving model checkpoint: /tmp/model2.checkpoint\n02:56:08 | time:435s total_exs:24040 total_steps:1202 epochs:120.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.73     0 274.5  1048       0          0 76.38  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002768    .1209 6.023 .0002351 4.995e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n     460       0          0                 1202  395 1508 3.827            1\n\n02:56:14 | time:440s total_exs:24460 total_steps:1223 epochs:122.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.89     0 277.8  1038       0          0 74.73  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002618    .1209 6.067 .0002223 4.995e-05 121.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   453.4       0          0                 1223 399.1 1491 3.752            1\n\n02:56:14 | running eval: valid\n02:56:14 | eval completed in 0.19s\n02:56:14 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1765       0          0 135.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 1.167 4.995e-05    72 814.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1223  228 2579        .8333\n\u001b[0m\n02:56:14 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 19\u001b[0m\n02:56:14 | saving model checkpoint: /tmp/model2.checkpoint\n02:56:28 | time:455s total_exs:25240 total_steps:1262 epochs:126.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.76     0 275.3  1057       0          0 76.81  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002501    .1209 5.987 .0002123 4.995e-05 119.7   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   459.9       0          0                 1262  395 1517 3.849            1\n\n02:56:34 | time:461s total_exs:25660 total_steps:1283 epochs:128.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.06     0 281.3  1075       0          0 76.46  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .002379    .1209 5.938 .000202 4.995e-05 118.8   454   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1283  400 1529 3.839            1\n\n02:56:34 | running eval: valid\n02:56:34 | eval completed in 0.20s\n02:56:34 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1737       0          0 133.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 1.162 4.995e-05    72 801.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1283  228 2539        .8333\n\u001b[0m\n02:56:34 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 20\u001b[0m\n02:56:34 | saving model checkpoint: /tmp/model2.checkpoint\n02:56:49 | time:475s total_exs:26420 total_steps:1321 epochs:132.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.46     0 269.3 999.4       0          0 74.23  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002267    .1209 5.979 .0001924 4.995e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   443.8       0          0                 1321 388.8 1443 3.72            1\n\n02:56:54 | time:481s total_exs:26860 total_steps:1343 epochs:134.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.75     0   275  1055       0          0 76.72  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00216    .1209  5.95 .0001833 4.995e-05   119 456.5   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1343  394 1511 3.851            1\n\n02:56:54 | running eval: valid\n02:56:55 | eval completed in 0.19s\n02:56:55 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1785       0          0 137.2   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 1.227 4.995e-05    72 823.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1343  228 2608        .8333\n\u001b[0m\n02:56:55 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 21\u001b[0m\n02:56:55 | saving model checkpoint: /tmp/model2.checkpoint\n02:57:09 | time:496s total_exs:27640 total_steps:1382 epochs:138.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.63     0 272.5  1043       0          0 76.58  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .002052    .1209 6.003 .000174 4.995e-05 120.1 459.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1382 392.6 1503 3.837            1\n\n02:57:15 | time:501s total_exs:28060 total_steps:1403 epochs:140.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.74     0 274.8  1030       0          0 74.97  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001962    .1209 5.981 .0001664 4.995e-05 119.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   448.4       0          0                 1403 394.4 1478 3.764            1\n\n02:57:15 | running eval: valid\n02:57:15 | eval completed in 0.25s\n02:57:15 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1406       0          0 108.1   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6 1.155 4.995e-05    72 648.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1403  228 2055        .8333\n\u001b[0m\nEpoch 00007: reducing learning rate of group 0 to 2.4975e-05.\n02:57:15 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 22\u001b[0m\n02:57:15 | saving model checkpoint: /tmp/model2.checkpoint\n02:57:30 | time:516s total_exs:28840 total_steps:1442 epochs:144.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.68     0 273.6  1045       0          0  76.4  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001897    .1209 6.041 .0001608 2.498e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.6       0          0                 1442 394.5 1507 3.829            1\n\n02:57:35 | time:522s total_exs:29260 total_steps:1463 epochs:146.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.82     0 276.5  1051       0          0 76.01  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00186    .1209 5.948 .0001577 2.498e-05   119 452.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1463 395.4 1503 3.816            1\n\n02:57:35 | running eval: valid\n02:57:35 | eval completed in 0.19s\n02:57:35 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1776       0          0 136.6   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08116     6  1.19 2.498e-05    72 819.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1463  228 2596        .8333\n\u001b[0m\n02:57:35 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 23\u001b[0m\n02:57:35 | saving model checkpoint: /tmp/model2.checkpoint\n02:57:50 | time:536s total_exs:30020 total_steps:1501 epochs:150.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.95     0 278.9  1042       0          0 74.75  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001809    .1209 6.042 .0001533 2.498e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.6       0          0                 1501 399.8 1494 3.746            1\n\n02:57:55 | time:542s total_exs:30460 total_steps:1523 epochs:152.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.49     0 269.8  1048       0          0 77.69  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001784    .1209 5.932 .0001507 2.498e-05 118.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   460.9       0          0                 1523 388.4 1509  3.9            1\n\n02:57:55 | running eval: valid\n02:57:56 | eval completed in 0.22s\n02:57:56 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1565       0          0 120.4   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6  1.19 2.498e-05    72 722.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1523  228 2287        .8333\n\u001b[0m\n02:57:56 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 24\u001b[0m\n02:57:56 | saving model checkpoint: /tmp/model2.checkpoint\n02:58:10 | time:557s total_exs:31240 total_steps:1562 epochs:156.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.44     0 268.8  1029       0          0 76.58  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001733    .1209 5.974 .0001469 2.498e-05 119.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.5       0          0                 1562 388.3 1487 3.838            1\n\n02:58:16 | time:562s total_exs:31660 total_steps:1583 epochs:158.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.65     0 272.9  1064       0          0 77.95  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001687    .1209 6.029 .0001428 2.498e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   469.9       0          0                 1583 393.5 1534 3.914            1\n\n02:58:16 | running eval: valid\n02:58:16 | eval completed in 0.20s\n02:58:16 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1746       0          0 134.3   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 1.292 2.498e-05    72 805.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1583  228 2552        .8333\n\u001b[0m\n02:58:16 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 25\u001b[0m\n02:58:16 | saving model checkpoint: /tmp/model2.checkpoint\n02:58:31 | time:577s total_exs:32420 total_steps:1621 epochs:162.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.48     0 269.7  1025       0          0 76.04  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001647    .1210 6.005 .0001396 2.498e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   456.7       0          0                 1621 389.8 1482 3.811            1\n\n02:58:36 | time:582s total_exs:32820 total_steps:1641 epochs:164.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.62     0 272.4  1060       0          0 77.81  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001613    .1210  5.96 .0001367 2.498e-05 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.8       0          0                 1641 391.6 1524 3.908            1\n\n02:58:36 | running eval: valid\n02:58:36 | eval completed in 0.19s\n02:58:36 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1764       0          0 135.7   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 1.322 2.498e-05    72 814.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1641  228 2579        .8333\n\u001b[0m\nEpoch 00011: reducing learning rate of group 0 to 1.2488e-05.\n02:58:36 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 26\u001b[0m\n02:58:36 | saving model checkpoint: /tmp/model2.checkpoint\n02:58:51 | time:598s total_exs:33600 total_steps:1680 epochs:168.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.51     0 270.3  1028       0          0 76.08  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001581    .1210 6.054 .0001339 1.249e-05 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   460.6       0          0                 1680 391.4 1489 3.812            1\n\n02:58:56 | time:603s total_exs:33980 total_steps:1699 epochs:169.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.93     0 278.5  1044       0          0 74.96  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001565    .1210 6.016 .0001326 1.249e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     451       0          0                 1699 398.8 1495 3.765            1\n\n02:58:56 | running eval: valid\n02:58:56 | eval completed in 0.20s\n02:58:56 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1718       0          0 132.1   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 1.323 1.249e-05    72 792.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1699  228 2511        .8333\n\u001b[0m\n02:58:56 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 27\u001b[0m\n02:58:56 | saving model checkpoint: /tmp/model2.checkpoint\n02:59:11 | time:618s total_exs:34740 total_steps:1737 epochs:173.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.39     0 267.8  1006       0          0 75.15  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001551    .1210 5.963 .0001314 1.249e-05 119.3   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   448.1       0          0                 1737  387 1454 3.766            1\n\n02:59:17 | time:623s total_exs:35140 total_steps:1757 epochs:175.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.42     0 268.4  1019       0          0 75.95  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001538    .1210 5.925 .0001301 1.249e-05 118.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     450       0          0                 1757 386.9 1470 3.814            1\n\n02:59:17 | running eval: valid\n02:59:17 | eval completed in 0.20s\n02:59:17 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1732       0          0 133.2   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6  1.34 1.249e-05    72 799.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1757  228 2531        .8333\n\u001b[0m\n02:59:17 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 28\u001b[0m\n02:59:17 | saving model checkpoint: /tmp/model2.checkpoint\n02:59:32 | time:638s total_exs:35900 total_steps:1795 epochs:179.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.91     0 278.3  1041       0          0 74.85  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001513    .1210 5.992 .000128 1.249e-05 119.8 448.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1795 398.1 1490 3.751            1\n\n02:59:37 | time:643s total_exs:36280 total_steps:1814 epochs:181.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.62     0 272.3  1028       0          0 75.48  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001495    .1210 5.932 .0001266 1.249e-05 118.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   447.7       0          0                 1814 390.9 1475 3.791            1\n\n02:59:37 | running eval: valid\n02:59:37 | eval completed in 0.19s\n02:59:37 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1782       0          0   137   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08122     6  1.34 1.249e-05    72 822.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1814  228 2604        .8333\n\u001b[0m\n02:59:37 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 29\u001b[0m\n02:59:37 | saving model checkpoint: /tmp/model2.checkpoint\n02:59:52 | time:659s total_exs:37060 total_steps:1853 epochs:185.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.99     0 279.9  1069       0          0 76.37  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001466    .1210 6.069 .0001242 1.249e-05 121.4   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.5       0          0                 1853 401.3 1532 3.827            1\n\n02:59:57 | time:664s total_exs:37440 total_steps:1872 epochs:187.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.55     0 271.1  1012       0          0 74.64  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .001452    .1210 6.037 .000123 1.249e-05 120.7 450.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1872 391.8 1462 3.748            1\n\n02:59:57 | running eval: valid\n02:59:57 | eval completed in 0.21s\n02:59:57 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8333                 .8333   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8333              .8333   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333    11   156  1676       0          0 128.9   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08124     6 1.341 1.249e-05    72 773.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1872  228 2450        .8333\n\u001b[0m\nEpoch 00015: reducing learning rate of group 0 to 6.2438e-06.\n02:59:57 | \u001b[1mdid not beat best accuracy: 0.9167 impatience: 30\u001b[0m\n02:59:57 | saving model checkpoint: /tmp/model2.checkpoint\n03:00:02 | ran out of patience! stopping training.\n03:00:02 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n03:00:02 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n03:00:02 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run2/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n03:00:02 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n03:00:02 | Using CUDA\n03:00:02 | loading dictionary from /tmp/model2.dict\n03:00:02 | num words = 54944\n03:00:07 | Loading existing model parameters from /tmp/model2\n03:00:14 | Total parameters: 128,042,498 (128,042,498 trainable)\n03:00:15 | creating task(s): fromfile:parlaiformat\n03:00:15 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run2/data_valid.txt\n03:00:15 | running eval: valid\n03:00:16 | eval completed in 0.21s\n03:00:16 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167    11   156  1697       0          0 130.5   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298     6 .5346 5.404e-06    72 783.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    108  228 2481        .9167\n\u001b[0m\n03:00:16 | creating task(s): fromfile:parlaiformat\n03:00:16 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run2/data_test.txt\n03:00:16 | running eval: test\n03:00:21 | eval completed in 4.99s\n03:00:21 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8830 8.83e-10               .6164                 .4585   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9400            .9310              .9925   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8767 12.07 281.4  2835       0          0 201.5 1000 .8830   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298   5.2 .5198 5.404e-06   104  1048       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    108 385.4 3883        .8995\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type2/run2/data_test.txt -m transformer/classifier -mf /tmp/model2 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T03:00:22.799301Z","iopub.execute_input":"2022-12-04T03:00:22.799723Z","iopub.status.idle":"2022-12-04T03:00:53.282832Z","shell.execute_reply.started":"2022-12-04T03:00:22.799676Z","shell.execute_reply":"2022-12-04T03:00:53.281426Z"},"scrolled":true,"trusted":true},"execution_count":115,"outputs":[{"name":"stdout","text":"03:00:31 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr2type2/run2/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr2type2/run2/data)\u001b[0m\n03:00:31 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n03:00:31 | Using CUDA\n03:00:31 | loading dictionary from /tmp/model2.dict\n03:00:32 | num words = 54944\n03:00:36 | Loading existing model parameters from /tmp/model2\n03:00:42 | Total parameters: 128,042,498 (128,042,498 trainable)\n03:00:43 | Opt:\n03:00:43 |     activation: gelu\n03:00:43 |     adafactor_eps: '[1e-30, 0.001]'\n03:00:43 |     adam_eps: 1e-08\n03:00:43 |     add_p1_after_newln: False\n03:00:43 |     aggregate_micro: False\n03:00:43 |     allow_missing_init_opts: False\n03:00:43 |     area_under_curve_class: None\n03:00:43 |     area_under_curve_digits: -1\n03:00:43 |     attention_dropout: 0.1\n03:00:43 |     batchsize: 40\n03:00:43 |     betas: '[0.9, 0.999]'\n03:00:43 |     bpe_add_prefix_space: None\n03:00:43 |     bpe_debug: False\n03:00:43 |     bpe_dropout: None\n03:00:43 |     bpe_merge: None\n03:00:43 |     bpe_vocab: None\n03:00:43 |     candidates: inline\n03:00:43 |     cap_num_predictions: 100\n03:00:43 |     checkpoint_activations: False\n03:00:43 |     class_weights: None\n03:00:43 |     classes: \"['__notok__', '__ok__']\"\n03:00:43 |     classes_from_file: None\n03:00:43 |     data_parallel: True\n03:00:43 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n03:00:43 |     datatype: train\n03:00:43 |     delimiter: '\\n'\n03:00:43 |     dict_class: parlai.core.dict:DictionaryAgent\n03:00:43 |     dict_endtoken: __start__\n03:00:43 |     dict_file: /tmp/model2.dict\n03:00:43 |     dict_include_test: False\n03:00:43 |     dict_include_valid: False\n03:00:43 |     dict_initpath: None\n03:00:43 |     dict_language: english\n03:00:43 |     dict_loaded: True\n03:00:43 |     dict_lower: True\n03:00:43 |     dict_max_ngram_size: -1\n03:00:43 |     dict_maxexs: -1\n03:00:43 |     dict_maxtokens: -1\n03:00:43 |     dict_minfreq: 0\n03:00:43 |     dict_nulltoken: __null__\n03:00:43 |     dict_starttoken: __start__\n03:00:43 |     dict_textfields: text,labels\n03:00:43 |     dict_tokenizer: bpe\n03:00:43 |     dict_unktoken: __unk__\n03:00:43 |     display_examples: False\n03:00:43 |     download_path: None\n03:00:43 |     dropout: 0.1\n03:00:43 |     dynamic_batching: None\n03:00:43 |     embedding_projection: random\n03:00:43 |     embedding_size: 768\n03:00:43 |     embedding_type: random\n03:00:43 |     embeddings_scale: False\n03:00:43 |     encode_candidate_vecs: True\n03:00:43 |     encode_candidate_vecs_batchsize: 256\n03:00:43 |     eval_batchsize: None\n03:00:43 |     eval_candidates: inline\n03:00:43 |     eval_dynamic_batching: None\n03:00:43 |     evaltask: None\n03:00:43 |     ffn_size: 3072\n03:00:43 |     final_extra_opt: \n03:00:43 |     fixed_candidate_vecs: reuse\n03:00:43 |     fixed_candidates_path: None\n03:00:43 |     force_fp16_tokens: True\n03:00:43 |     fp16: True\n03:00:43 |     fp16_impl: safe\n03:00:43 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run2/data_test.txt\n03:00:43 |     fromfile_datatype_extension: True\n03:00:43 |     gpu: -1\n03:00:43 |     gradient_clip: 0.1\n03:00:43 |     hide_labels: False\n03:00:43 |     history_add_global_end_token: None\n03:00:43 |     history_reversed: False\n03:00:43 |     history_size: 20\n03:00:43 |     ignore_bad_candidates: False\n03:00:43 |     ignore_labels: None\n03:00:43 |     image_cropsize: 224\n03:00:43 |     image_mode: raw\n03:00:43 |     image_size: 256\n03:00:43 |     inference: max\n03:00:43 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n03:00:43 |     init_opt: None\n03:00:43 |     interactive_candidates: fixed\n03:00:43 |     interactive_mode: False\n03:00:43 |     invsqrt_lr_decay_gamma: -1\n03:00:43 |     is_debug: False\n03:00:43 |     label_truncate: 72\n03:00:43 |     learn_embeddings: True\n03:00:43 |     learn_positional_embeddings: True\n03:00:43 |     learningrate: 5e-05\n03:00:43 |     load_from_pretrained_ranker: True\n03:00:43 |     log_every_n_secs: 10.0\n03:00:43 |     log_every_n_steps: 50\n03:00:43 |     log_keep_fields: all\n03:00:43 |     loglevel: info\n03:00:43 |     lr_scheduler: reduceonplateau\n03:00:43 |     lr_scheduler_decay: 0.5\n03:00:43 |     lr_scheduler_patience: 3\n03:00:43 |     max_train_steps: -1\n03:00:43 |     max_train_time: 7200.0\n03:00:43 |     memory_attention: sqrt\n03:00:43 |     metrics: default\n03:00:43 |     model: transformer/classifier\n03:00:43 |     model_file: /tmp/model2\n03:00:43 |     model_parallel: False\n03:00:43 |     momentum: 0\n03:00:43 |     multitask_weights: [1]\n03:00:43 |     mutators: None\n03:00:43 |     n_decoder_layers: -1\n03:00:43 |     n_encoder_layers: -1\n03:00:43 |     n_heads: 12\n03:00:43 |     n_layers: 12\n03:00:43 |     n_positions: 1024\n03:00:43 |     n_segments: 2\n03:00:43 |     nesterov: True\n03:00:43 |     no_cuda: False\n03:00:43 |     normalize_sent_emb: False\n03:00:43 |     num_epochs: -1\n03:00:43 |     num_examples: -1\n03:00:43 |     num_workers: 0\n03:00:43 |     nus: [0.7]\n03:00:43 |     optimizer: adamax\n03:00:43 |     output_scaling: 0.06\n03:00:43 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type2/run2/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model2', 'batchsize': 40}\"\n03:00:43 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n03:00:43 |     person_tokens: False\n03:00:43 |     print_scores: False\n03:00:43 |     rank_candidates: False\n03:00:43 |     rank_top_k: -1\n03:00:43 |     reduction_type: mean\n03:00:43 |     ref_class: None\n03:00:43 |     relu_dropout: 0.0\n03:00:43 |     repeat_blocking_heuristic: True\n03:00:43 |     report_filename: \n03:00:43 |     return_cand_scores: False\n03:00:43 |     save_after_valid: True\n03:00:43 |     save_every_n_secs: -1\n03:00:43 |     save_format: conversations\n03:00:43 |     share_encoders: False\n03:00:43 |     share_word_embeddings: False\n03:00:43 |     short_final_eval: False\n03:00:43 |     special_tok_lst: None\n03:00:43 |     split_lines: False\n03:00:43 |     starttime: Dec04_02-48\n03:00:43 |     task: fromfile:parlaiformat\n03:00:43 |     tensorboard_log: False\n03:00:43 |     tensorboard_logdir: None\n03:00:43 |     text_truncate: 360\n03:00:43 |     threshold: 0.5\n03:00:43 |     topk: 5\n03:00:43 |     train_predict: False\n03:00:43 |     truncate: 1024\n03:00:43 |     update_classifier_head_only: False\n03:00:43 |     update_freq: 1\n03:00:43 |     use_memories: False\n03:00:43 |     use_reply: none\n03:00:43 |     validation_cutoff: 1.0\n03:00:43 |     validation_every_n_epochs: -1\n03:00:43 |     validation_every_n_secs: 20.0\n03:00:43 |     validation_every_n_steps: -1\n03:00:43 |     validation_max_exs: -1\n03:00:43 |     validation_metric: accuracy\n03:00:43 |     validation_metric_mode: max\n03:00:43 |     validation_patience: 30\n03:00:43 |     validation_share_agent: False\n03:00:43 |     variant: xlm\n03:00:43 |     verbose: False\n03:00:43 |     wandb_entity: None\n03:00:43 |     wandb_log: False\n03:00:43 |     wandb_name: None\n03:00:43 |     wandb_project: None\n03:00:43 |     warmup_rate: 0.0001\n03:00:43 |     warmup_updates: 1000\n03:00:43 |     weight_decay: None\n03:00:43 |     world_logs: \n03:00:43 |     wrap_memory_encoder: False\n03:00:43 | Evaluating task fromfile:parlaiformat using datatype valid.\n03:00:43 | creating task(s): fromfile:parlaiformat\n03:00:43 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n03:00:43 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run2/data_test.txt\n03:00:51 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8830 8.83e-10               .6164                 .4585   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9400            .9310              .9925   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8767 12.07 562.9  1938       0          0 137.8 1000 .8830   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5198 5.404e-06   208 716.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    108 770.9 2655        .8995\u001b[0m\n03:00:51 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8830 8.83e-10               .6164                 .4585   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9400            .9310              .9925   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8767 12.07 562.9  1938       0          0 137.8 1000 .8830   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5198 5.404e-06   208 716.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    108 770.9 2655        .8995\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model2*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T03:00:53.288050Z","iopub.execute_input":"2022-12-04T03:00:53.290627Z","iopub.status.idle":"2022-12-04T03:00:54.530061Z","shell.execute_reply.started":"2022-12-04T03:00:53.290581Z","shell.execute_reply":"2022-12-04T03:00:54.528360Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"markdown","source":"run 3","metadata":{}},{"cell_type":"code","source":"# run 3 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type2/run3/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model3","metadata":{"execution":{"iopub.status.busy":"2022-12-04T03:00:54.532005Z","iopub.execute_input":"2022-12-04T03:00:54.532799Z","iopub.status.idle":"2022-12-04T03:03:11.690204Z","shell.execute_reply.started":"2022-12-04T03:00:54.532757Z","shell.execute_reply":"2022-12-04T03:03:11.688973Z"},"scrolled":true,"trusted":true},"execution_count":117,"outputs":[{"name":"stdout","text":"03:01:01 | building dictionary first...\n03:01:01 | No model with opt yet at: /tmp/model3(.opt)\n03:01:01 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run3/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n03:01:01 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n03:01:01 | Using CUDA\n03:01:01 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n03:01:02 | num words = 54944\n03:01:06 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n03:01:16 | Total parameters: 128,042,498 (128,042,498 trainable)\n03:01:16 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n03:01:16 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n03:01:16 | Opt:\n03:01:16 |     activation: gelu\n03:01:16 |     adafactor_eps: '(1e-30, 0.001)'\n03:01:16 |     adam_eps: 1e-08\n03:01:16 |     add_p1_after_newln: False\n03:01:16 |     aggregate_micro: False\n03:01:16 |     allow_missing_init_opts: False\n03:01:16 |     attention_dropout: 0.1\n03:01:16 |     batchsize: 20\n03:01:16 |     betas: '(0.9, 0.999)'\n03:01:16 |     bpe_add_prefix_space: None\n03:01:16 |     bpe_debug: False\n03:01:16 |     bpe_dropout: None\n03:01:16 |     bpe_merge: None\n03:01:16 |     bpe_vocab: None\n03:01:16 |     candidates: inline\n03:01:16 |     cap_num_predictions: 100\n03:01:16 |     checkpoint_activations: False\n03:01:16 |     class_weights: None\n03:01:16 |     classes: \"['__notok__', '__ok__']\"\n03:01:16 |     classes_from_file: None\n03:01:16 |     data_parallel: True\n03:01:16 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n03:01:16 |     datatype: train\n03:01:16 |     delimiter: '\\n'\n03:01:16 |     dict_class: parlai.core.dict:DictionaryAgent\n03:01:16 |     dict_endtoken: __start__\n03:01:16 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n03:01:16 |     dict_include_test: False\n03:01:16 |     dict_include_valid: False\n03:01:16 |     dict_initpath: None\n03:01:16 |     dict_language: english\n03:01:16 |     dict_loaded: True\n03:01:16 |     dict_lower: True\n03:01:16 |     dict_max_ngram_size: -1\n03:01:16 |     dict_maxexs: -1\n03:01:16 |     dict_maxtokens: -1\n03:01:16 |     dict_minfreq: 0\n03:01:16 |     dict_nulltoken: __null__\n03:01:16 |     dict_starttoken: __start__\n03:01:16 |     dict_textfields: text,labels\n03:01:16 |     dict_tokenizer: bpe\n03:01:16 |     dict_unktoken: __unk__\n03:01:16 |     display_examples: False\n03:01:16 |     download_path: None\n03:01:16 |     dropout: 0.1\n03:01:16 |     dynamic_batching: None\n03:01:16 |     embedding_projection: random\n03:01:16 |     embedding_size: 768\n03:01:16 |     embedding_type: random\n03:01:16 |     embeddings_scale: False\n03:01:16 |     encode_candidate_vecs: True\n03:01:16 |     encode_candidate_vecs_batchsize: 256\n03:01:16 |     eval_batchsize: None\n03:01:16 |     eval_candidates: inline\n03:01:16 |     eval_dynamic_batching: None\n03:01:16 |     evaltask: None\n03:01:16 |     ffn_size: 3072\n03:01:16 |     final_extra_opt: \n03:01:16 |     fixed_candidate_vecs: reuse\n03:01:16 |     fixed_candidates_path: None\n03:01:16 |     force_fp16_tokens: False\n03:01:16 |     fp16: True\n03:01:16 |     fp16_impl: safe\n03:01:16 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run3/data\n03:01:16 |     fromfile_datatype_extension: True\n03:01:16 |     gpu: -1\n03:01:16 |     gradient_clip: 0.1\n03:01:16 |     hide_labels: False\n03:01:16 |     history_add_global_end_token: None\n03:01:16 |     history_reversed: False\n03:01:16 |     history_size: 20\n03:01:16 |     ignore_bad_candidates: False\n03:01:16 |     ignore_labels: None\n03:01:16 |     image_cropsize: 224\n03:01:16 |     image_mode: raw\n03:01:16 |     image_size: 256\n03:01:16 |     inference: max\n03:01:16 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n03:01:16 |     init_opt: None\n03:01:16 |     interactive_candidates: fixed\n03:01:16 |     interactive_mode: False\n03:01:16 |     invsqrt_lr_decay_gamma: -1\n03:01:16 |     is_debug: False\n03:01:16 |     label_truncate: 72\n03:01:16 |     learn_embeddings: True\n03:01:16 |     learn_positional_embeddings: True\n03:01:16 |     learningrate: 5e-05\n03:01:16 |     load_from_checkpoint: False\n03:01:16 |     load_from_pretrained_ranker: True\n03:01:16 |     log_every_n_secs: 10.0\n03:01:16 |     log_every_n_steps: 50\n03:01:16 |     log_keep_fields: all\n03:01:16 |     loglevel: info\n03:01:16 |     lr_scheduler: reduceonplateau\n03:01:16 |     lr_scheduler_decay: 0.5\n03:01:16 |     lr_scheduler_patience: 3\n03:01:16 |     max_train_steps: -1\n03:01:16 |     max_train_time: 7200.0\n03:01:16 |     memory_attention: sqrt\n03:01:16 |     metrics: default\n03:01:16 |     model: transformer/classifier\n03:01:16 |     model_file: /tmp/model3\n03:01:16 |     model_parallel: False\n03:01:16 |     momentum: 0\n03:01:16 |     multitask_weights: [1]\n03:01:16 |     mutators: None\n03:01:16 |     n_decoder_layers: -1\n03:01:16 |     n_encoder_layers: -1\n03:01:16 |     n_heads: 12\n03:01:16 |     n_layers: 12\n03:01:16 |     n_positions: 1024\n03:01:16 |     n_segments: 2\n03:01:16 |     nesterov: True\n03:01:16 |     no_cuda: False\n03:01:16 |     normalize_sent_emb: False\n03:01:16 |     num_epochs: -1\n03:01:16 |     num_workers: 0\n03:01:16 |     nus: (0.7,)\n03:01:16 |     optimizer: adamax\n03:01:16 |     output_scaling: 0.06\n03:01:16 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type2/run3/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model3'}\"\n03:01:16 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n03:01:16 |     person_tokens: False\n03:01:16 |     print_scores: False\n03:01:16 |     rank_candidates: False\n03:01:16 |     rank_top_k: -1\n03:01:16 |     reduction_type: mean\n03:01:16 |     ref_class: None\n03:01:16 |     relu_dropout: 0.0\n03:01:16 |     repeat_blocking_heuristic: True\n03:01:16 |     return_cand_scores: False\n03:01:16 |     save_after_valid: True\n03:01:16 |     save_every_n_secs: -1\n03:01:16 |     save_format: conversations\n03:01:16 |     share_encoders: False\n03:01:16 |     share_word_embeddings: False\n03:01:16 |     short_final_eval: False\n03:01:16 |     special_tok_lst: None\n03:01:16 |     split_lines: False\n03:01:16 |     starttime: Dec04_03-01\n03:01:16 |     task: fromfile:parlaiformat\n03:01:16 |     tensorboard_log: False\n03:01:16 |     tensorboard_logdir: None\n03:01:16 |     text_truncate: 360\n03:01:16 |     threshold: 0.5\n03:01:16 |     topk: 5\n03:01:16 |     train_predict: False\n03:01:16 |     truncate: 1024\n03:01:16 |     update_classifier_head_only: False\n03:01:16 |     update_freq: 1\n03:01:16 |     use_memories: False\n03:01:16 |     use_reply: none\n03:01:16 |     validation_cutoff: 1.0\n03:01:16 |     validation_every_n_epochs: -1\n03:01:16 |     validation_every_n_secs: 20.0\n03:01:16 |     validation_every_n_steps: -1\n03:01:16 |     validation_max_exs: -1\n03:01:16 |     validation_metric: accuracy\n03:01:16 |     validation_metric_mode: max\n03:01:16 |     validation_patience: 30\n03:01:16 |     validation_share_agent: False\n03:01:16 |     variant: xlm\n03:01:16 |     verbose: False\n03:01:16 |     wandb_entity: None\n03:01:16 |     wandb_log: False\n03:01:16 |     wandb_name: None\n03:01:16 |     wandb_project: None\n03:01:16 |     warmup_rate: 0.0001\n03:01:16 |     warmup_updates: 1000\n03:01:16 |     weight_decay: None\n03:01:16 |     world_logs: \n03:01:16 |     wrap_memory_encoder: False\n03:01:16 | creating task(s): fromfile:parlaiformat\n03:01:16 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run3/data_train.txt\n03:01:16 | training...\n03:01:27 | time:10s total_exs:420 total_steps:21 epochs:2.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5214 5.214e-10               .5086                 .5200   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .4976            .5336              .5227   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .5450 11.79     1 275.9 571.5       0          0 41.43  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5214             32768  2.399    .1206 5.995 .6910 1.055e-06 119.9 248.4   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   21 395.8 819.9 2.076        .5212\n\n03:01:36 | time:20s total_exs:1160 total_steps:58 epochs:5.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5959 5.959e-10               .5609                 .5932   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5320            .6258              .5981   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6562 11.49     1 269.9  1027       0          0 76.09  740   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5959             32768  2.444    .1207  5.97 .6760 2.905e-06 119.4 454.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   58 389.3 1481 3.813        .5943\n\n03:01:36 | creating task(s): fromfile:parlaiformat\n03:01:36 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run3/data_valid.txt\n03:01:37 | running eval: valid\n03:01:37 | eval completed in 0.23s\n03:01:37 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .6250 6.25e-10               .5714                 .6667   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5000            .6667              .6000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 11.71 164.5  1664       0          0 121.3   24 .6250   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6609 2.905e-06    72 728.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     58 236.5 2393        .6190\n\u001b[0m\n03:01:37 | \u001b[1;32mnew best accuracy: 0.625\u001b[0m\n03:01:37 | saving best valid model: /tmp/model3\n03:01:37 | Saving dictionary to /tmp/model3.dict\n03:01:40 | saving model checkpoint: /tmp/model3.checkpoint\n03:01:40 | Saving dictionary to /tmp/model3.checkpoint.dict\n03:01:57 | time:41s total_exs:1880 total_steps:94 epochs:9.40\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8125 8.125e-10               .7652                 .9053   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6627            .8439              .7652   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9407 11.57     1 271.4 953.7       0          0 70.29  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .8125             32768  2.449    .1207 5.922 .6184 4.705e-06 118.4 416.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   94 389.8 1370 3.522        .8076\n\n03:02:00 | time:44s total_exs:2120 total_steps:106 epochs:10.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9375 9.375e-10               .9309                 .9352   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9266            .9430              .9394   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9466  11.4     1 267.9 993.6       0          0 74.17  240   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9375             32768  2.915    .1207 5.908 .5563 5.304e-06 118.2 438.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  106 386.1 1432 3.734        .9375\n\n03:02:00 | running eval: valid\n03:02:01 | eval completed in 0.22s\n03:02:01 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.71 164.5  1720       0          0 125.4   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5368 5.304e-06    72 752.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    106 236.5 2473        .9167\n\u001b[0m\n03:02:01 | \u001b[1;32mnew best accuracy: 0.9167 (previous best was 0.625)\u001b[0m\n03:02:01 | saving best valid model: /tmp/model3\n03:02:06 | saving model checkpoint: /tmp/model3.checkpoint\n03:02:24 | time:68s total_exs:2900 total_steps:145 epochs:14.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9641 9.641e-10               .9644                 .9619   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9668            .9638              .9663   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9613 11.51     1 270.3  1041       0          0 77.06  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9641             32768  3.666    .1207 6.005 .4217 7.254e-06 120.1 462.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  145 390.4 1504 3.862        .9641\n\n03:02:26 | time:69s total_exs:3020 total_steps:151 epochs:15.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9417 9.417e-10               .9517                 .9324   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9718            .9263              .9565   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8980 11.39     1 267.8  1051       0          0 78.45  120   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9417             32768  4.179    .1207 6.183 .3035 7.554e-06 123.7 485.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  151 391.5 1536 3.981        .9413\n\n03:02:26 | running eval: valid\n03:02:26 | eval completed in 0.19s\n03:02:26 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 11.71 164.5  1921       0          0 140.1   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .2563 7.554e-06    72 840.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    151 236.5 2762        .9583\n\u001b[0m\n03:02:26 | \u001b[1;32mnew best accuracy: 0.9583 (previous best was 0.9167)\u001b[0m\n03:02:26 | saving best valid model: /tmp/model3\n03:02:31 | saving model checkpoint: /tmp/model3.checkpoint\n03:02:49 | time:93s total_exs:3800 total_steps:190 epochs:19.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9667 9.667e-10               .9674                 .9507   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9847            .9659              .9840   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9485 11.61     1 272.3  1045       0          0  76.8  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9667             32768  4.327    .1207 6.005 .1654 9.504e-06 120.1 461.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  190 392.4 1507 3.849        .9667\n\n03:02:51 | time:95s total_exs:3940 total_steps:197 epochs:19.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9643 9.643e-10               .9593                 .9219   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9682                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9383 11.06     1 261.3  1031       0          0  78.9  140   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9643             32768  7.237    .1207 5.843 .1281 9.854e-06 116.9   461   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  197 378.1 1492 3.995        .9644\n\n03:02:51 | running eval: valid\n03:02:51 | eval completed in 0.19s\n03:02:51 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 11.71 164.5  1903       0          0 138.8   24   1   \n    gpu_mem  llen   loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .04068 9.854e-06    72 832.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    197 236.5 2736            1\n\u001b[0m\n03:02:51 | \u001b[1;32mnew best accuracy: 1 (previous best was 0.9583)\u001b[0m\n03:02:51 | saving best valid model: /tmp/model3\n03:02:56 | task solved! stopping.\n03:02:56 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n03:02:56 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n03:02:56 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run3/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n03:02:56 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n03:02:56 | Using CUDA\n03:02:56 | loading dictionary from /tmp/model3.dict\n03:02:56 | num words = 54944\n03:03:01 | Loading existing model parameters from /tmp/model3\n03:03:02 | Total parameters: 128,042,498 (128,042,498 trainable)\n03:03:04 | creating task(s): fromfile:parlaiformat\n03:03:04 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run3/data_valid.txt\n03:03:04 | running eval: valid\n03:03:05 | eval completed in 0.53s\n03:03:05 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 11.71 164.5   686       0          0 50.03   24   1   \n    gpu_mem  llen   loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294     6 .04068 9.854e-06    72 300.2       0          0   \n    total_train_updates   tpb   tps  weighted_f1  \n                    197 236.5 986.2            1\n\u001b[0m\n03:03:05 | creating task(s): fromfile:parlaiformat\n03:03:05 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run3/data_test.txt\n03:03:05 | running eval: test\n03:03:10 | eval completed in 4.85s\n03:03:10 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9370 9.37e-10               .7510                 .6209   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9639              .9941   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9356 12.07 281.4  2917       0          0 207.3 1000 .9370   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294   5.2 .1790 9.854e-06   104  1078       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    197 385.4 3996        .9426\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type2/run3/data_test.txt -m transformer/classifier -mf /tmp/model3 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T03:03:11.692294Z","iopub.execute_input":"2022-12-04T03:03:11.692658Z","iopub.status.idle":"2022-12-04T03:03:42.102806Z","shell.execute_reply.started":"2022-12-04T03:03:11.692622Z","shell.execute_reply":"2022-12-04T03:03:42.101380Z"},"scrolled":true,"trusted":true},"execution_count":118,"outputs":[{"name":"stdout","text":"03:03:20 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr2type2/run3/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr2type2/run3/data)\u001b[0m\n03:03:20 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n03:03:20 | Using CUDA\n03:03:20 | loading dictionary from /tmp/model3.dict\n03:03:20 | num words = 54944\n03:03:24 | Loading existing model parameters from /tmp/model3\n03:03:30 | Total parameters: 128,042,498 (128,042,498 trainable)\n03:03:31 | Opt:\n03:03:31 |     activation: gelu\n03:03:31 |     adafactor_eps: '[1e-30, 0.001]'\n03:03:31 |     adam_eps: 1e-08\n03:03:31 |     add_p1_after_newln: False\n03:03:31 |     aggregate_micro: False\n03:03:31 |     allow_missing_init_opts: False\n03:03:31 |     area_under_curve_class: None\n03:03:31 |     area_under_curve_digits: -1\n03:03:31 |     attention_dropout: 0.1\n03:03:31 |     batchsize: 40\n03:03:31 |     betas: '[0.9, 0.999]'\n03:03:31 |     bpe_add_prefix_space: None\n03:03:31 |     bpe_debug: False\n03:03:31 |     bpe_dropout: None\n03:03:31 |     bpe_merge: None\n03:03:31 |     bpe_vocab: None\n03:03:31 |     candidates: inline\n03:03:31 |     cap_num_predictions: 100\n03:03:31 |     checkpoint_activations: False\n03:03:31 |     class_weights: None\n03:03:31 |     classes: \"['__notok__', '__ok__']\"\n03:03:31 |     classes_from_file: None\n03:03:31 |     data_parallel: True\n03:03:31 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n03:03:31 |     datatype: train\n03:03:31 |     delimiter: '\\n'\n03:03:31 |     dict_class: parlai.core.dict:DictionaryAgent\n03:03:31 |     dict_endtoken: __start__\n03:03:31 |     dict_file: /tmp/model3.dict\n03:03:31 |     dict_include_test: False\n03:03:31 |     dict_include_valid: False\n03:03:31 |     dict_initpath: None\n03:03:31 |     dict_language: english\n03:03:31 |     dict_loaded: True\n03:03:31 |     dict_lower: True\n03:03:31 |     dict_max_ngram_size: -1\n03:03:31 |     dict_maxexs: -1\n03:03:31 |     dict_maxtokens: -1\n03:03:31 |     dict_minfreq: 0\n03:03:31 |     dict_nulltoken: __null__\n03:03:31 |     dict_starttoken: __start__\n03:03:31 |     dict_textfields: text,labels\n03:03:31 |     dict_tokenizer: bpe\n03:03:31 |     dict_unktoken: __unk__\n03:03:31 |     display_examples: False\n03:03:31 |     download_path: None\n03:03:31 |     dropout: 0.1\n03:03:31 |     dynamic_batching: None\n03:03:31 |     embedding_projection: random\n03:03:31 |     embedding_size: 768\n03:03:31 |     embedding_type: random\n03:03:31 |     embeddings_scale: False\n03:03:31 |     encode_candidate_vecs: True\n03:03:31 |     encode_candidate_vecs_batchsize: 256\n03:03:31 |     eval_batchsize: None\n03:03:31 |     eval_candidates: inline\n03:03:31 |     eval_dynamic_batching: None\n03:03:31 |     evaltask: None\n03:03:31 |     ffn_size: 3072\n03:03:31 |     final_extra_opt: \n03:03:31 |     fixed_candidate_vecs: reuse\n03:03:31 |     fixed_candidates_path: None\n03:03:31 |     force_fp16_tokens: True\n03:03:31 |     fp16: True\n03:03:31 |     fp16_impl: safe\n03:03:31 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run3/data_test.txt\n03:03:31 |     fromfile_datatype_extension: True\n03:03:31 |     gpu: -1\n03:03:31 |     gradient_clip: 0.1\n03:03:31 |     hide_labels: False\n03:03:31 |     history_add_global_end_token: None\n03:03:31 |     history_reversed: False\n03:03:31 |     history_size: 20\n03:03:31 |     ignore_bad_candidates: False\n03:03:31 |     ignore_labels: None\n03:03:31 |     image_cropsize: 224\n03:03:31 |     image_mode: raw\n03:03:31 |     image_size: 256\n03:03:31 |     inference: max\n03:03:31 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n03:03:31 |     init_opt: None\n03:03:31 |     interactive_candidates: fixed\n03:03:31 |     interactive_mode: False\n03:03:31 |     invsqrt_lr_decay_gamma: -1\n03:03:31 |     is_debug: False\n03:03:31 |     label_truncate: 72\n03:03:31 |     learn_embeddings: True\n03:03:31 |     learn_positional_embeddings: True\n03:03:31 |     learningrate: 5e-05\n03:03:31 |     load_from_pretrained_ranker: True\n03:03:31 |     log_every_n_secs: 10.0\n03:03:31 |     log_every_n_steps: 50\n03:03:31 |     log_keep_fields: all\n03:03:31 |     loglevel: info\n03:03:31 |     lr_scheduler: reduceonplateau\n03:03:31 |     lr_scheduler_decay: 0.5\n03:03:31 |     lr_scheduler_patience: 3\n03:03:31 |     max_train_steps: -1\n03:03:31 |     max_train_time: 7200.0\n03:03:31 |     memory_attention: sqrt\n03:03:31 |     metrics: default\n03:03:31 |     model: transformer/classifier\n03:03:31 |     model_file: /tmp/model3\n03:03:31 |     model_parallel: False\n03:03:31 |     momentum: 0\n03:03:31 |     multitask_weights: [1]\n03:03:31 |     mutators: None\n03:03:31 |     n_decoder_layers: -1\n03:03:31 |     n_encoder_layers: -1\n03:03:31 |     n_heads: 12\n03:03:31 |     n_layers: 12\n03:03:31 |     n_positions: 1024\n03:03:31 |     n_segments: 2\n03:03:31 |     nesterov: True\n03:03:31 |     no_cuda: False\n03:03:31 |     normalize_sent_emb: False\n03:03:31 |     num_epochs: -1\n03:03:31 |     num_examples: -1\n03:03:31 |     num_workers: 0\n03:03:31 |     nus: [0.7]\n03:03:31 |     optimizer: adamax\n03:03:31 |     output_scaling: 0.06\n03:03:31 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type2/run3/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model3', 'batchsize': 40}\"\n03:03:31 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n03:03:31 |     person_tokens: False\n03:03:31 |     print_scores: False\n03:03:31 |     rank_candidates: False\n03:03:31 |     rank_top_k: -1\n03:03:31 |     reduction_type: mean\n03:03:31 |     ref_class: None\n03:03:31 |     relu_dropout: 0.0\n03:03:31 |     repeat_blocking_heuristic: True\n03:03:31 |     report_filename: \n03:03:31 |     return_cand_scores: False\n03:03:31 |     save_after_valid: True\n03:03:31 |     save_every_n_secs: -1\n03:03:31 |     save_format: conversations\n03:03:31 |     share_encoders: False\n03:03:31 |     share_word_embeddings: False\n03:03:31 |     short_final_eval: False\n03:03:31 |     special_tok_lst: None\n03:03:31 |     split_lines: False\n03:03:31 |     starttime: Dec04_03-01\n03:03:31 |     task: fromfile:parlaiformat\n03:03:31 |     tensorboard_log: False\n03:03:31 |     tensorboard_logdir: None\n03:03:31 |     text_truncate: 360\n03:03:31 |     threshold: 0.5\n03:03:31 |     topk: 5\n03:03:31 |     train_predict: False\n03:03:31 |     truncate: 1024\n03:03:31 |     update_classifier_head_only: False\n03:03:31 |     update_freq: 1\n03:03:31 |     use_memories: False\n03:03:31 |     use_reply: none\n03:03:31 |     validation_cutoff: 1.0\n03:03:31 |     validation_every_n_epochs: -1\n03:03:31 |     validation_every_n_secs: 20.0\n03:03:31 |     validation_every_n_steps: -1\n03:03:31 |     validation_max_exs: -1\n03:03:31 |     validation_metric: accuracy\n03:03:31 |     validation_metric_mode: max\n03:03:31 |     validation_patience: 30\n03:03:31 |     validation_share_agent: False\n03:03:31 |     variant: xlm\n03:03:31 |     verbose: False\n03:03:31 |     wandb_entity: None\n03:03:31 |     wandb_log: False\n03:03:31 |     wandb_name: None\n03:03:31 |     wandb_project: None\n03:03:31 |     warmup_rate: 0.0001\n03:03:31 |     warmup_updates: 1000\n03:03:31 |     weight_decay: None\n03:03:31 |     world_logs: \n03:03:31 |     wrap_memory_encoder: False\n03:03:32 | Evaluating task fromfile:parlaiformat using datatype valid.\n03:03:32 | creating task(s): fromfile:parlaiformat\n03:03:32 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n03:03:32 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run3/data_test.txt\n03:03:40 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9370 9.37e-10               .7510                 .6209   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9639              .9941   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9356 12.07 562.9  1778       0          0 126.3 1000 .9370   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .1790 9.854e-06   208 656.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    197 770.9 2435        .9426\u001b[0m\n03:03:40 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9370 9.37e-10               .7510                 .6209   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9639              .9941   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9356 12.07 562.9  1778       0          0 126.3 1000 .9370   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .1790 9.854e-06   208 656.9       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    197 770.9 2435        .9426\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model3*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T03:03:42.104613Z","iopub.execute_input":"2022-12-04T03:03:42.105174Z","iopub.status.idle":"2022-12-04T03:03:43.351054Z","shell.execute_reply.started":"2022-12-04T03:03:42.105136Z","shell.execute_reply":"2022-12-04T03:03:43.349759Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"markdown","source":"run 4","metadata":{}},{"cell_type":"code","source":"# run 4 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type2/run4/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model4","metadata":{"execution":{"iopub.status.busy":"2022-12-04T03:03:43.353321Z","iopub.execute_input":"2022-12-04T03:03:43.353832Z","iopub.status.idle":"2022-12-04T03:05:38.873372Z","shell.execute_reply.started":"2022-12-04T03:03:43.353778Z","shell.execute_reply":"2022-12-04T03:05:38.871973Z"},"scrolled":true,"trusted":true},"execution_count":120,"outputs":[{"name":"stdout","text":"03:03:50 | building dictionary first...\n03:03:50 | No model with opt yet at: /tmp/model4(.opt)\n03:03:50 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run4/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n03:03:50 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n03:03:50 | Using CUDA\n03:03:50 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n03:03:50 | num words = 54944\n03:03:54 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n03:04:04 | Total parameters: 128,042,498 (128,042,498 trainable)\n03:04:04 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n03:04:04 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n03:04:05 | Opt:\n03:04:05 |     activation: gelu\n03:04:05 |     adafactor_eps: '(1e-30, 0.001)'\n03:04:05 |     adam_eps: 1e-08\n03:04:05 |     add_p1_after_newln: False\n03:04:05 |     aggregate_micro: False\n03:04:05 |     allow_missing_init_opts: False\n03:04:05 |     attention_dropout: 0.1\n03:04:05 |     batchsize: 20\n03:04:05 |     betas: '(0.9, 0.999)'\n03:04:05 |     bpe_add_prefix_space: None\n03:04:05 |     bpe_debug: False\n03:04:05 |     bpe_dropout: None\n03:04:05 |     bpe_merge: None\n03:04:05 |     bpe_vocab: None\n03:04:05 |     candidates: inline\n03:04:05 |     cap_num_predictions: 100\n03:04:05 |     checkpoint_activations: False\n03:04:05 |     class_weights: None\n03:04:05 |     classes: \"['__notok__', '__ok__']\"\n03:04:05 |     classes_from_file: None\n03:04:05 |     data_parallel: True\n03:04:05 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n03:04:05 |     datatype: train\n03:04:05 |     delimiter: '\\n'\n03:04:05 |     dict_class: parlai.core.dict:DictionaryAgent\n03:04:05 |     dict_endtoken: __start__\n03:04:05 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n03:04:05 |     dict_include_test: False\n03:04:05 |     dict_include_valid: False\n03:04:05 |     dict_initpath: None\n03:04:05 |     dict_language: english\n03:04:05 |     dict_loaded: True\n03:04:05 |     dict_lower: True\n03:04:05 |     dict_max_ngram_size: -1\n03:04:05 |     dict_maxexs: -1\n03:04:05 |     dict_maxtokens: -1\n03:04:05 |     dict_minfreq: 0\n03:04:05 |     dict_nulltoken: __null__\n03:04:05 |     dict_starttoken: __start__\n03:04:05 |     dict_textfields: text,labels\n03:04:05 |     dict_tokenizer: bpe\n03:04:05 |     dict_unktoken: __unk__\n03:04:05 |     display_examples: False\n03:04:05 |     download_path: None\n03:04:05 |     dropout: 0.1\n03:04:05 |     dynamic_batching: None\n03:04:05 |     embedding_projection: random\n03:04:05 |     embedding_size: 768\n03:04:05 |     embedding_type: random\n03:04:05 |     embeddings_scale: False\n03:04:05 |     encode_candidate_vecs: True\n03:04:05 |     encode_candidate_vecs_batchsize: 256\n03:04:05 |     eval_batchsize: None\n03:04:05 |     eval_candidates: inline\n03:04:05 |     eval_dynamic_batching: None\n03:04:05 |     evaltask: None\n03:04:05 |     ffn_size: 3072\n03:04:05 |     final_extra_opt: \n03:04:05 |     fixed_candidate_vecs: reuse\n03:04:05 |     fixed_candidates_path: None\n03:04:05 |     force_fp16_tokens: False\n03:04:05 |     fp16: True\n03:04:05 |     fp16_impl: safe\n03:04:05 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run4/data\n03:04:05 |     fromfile_datatype_extension: True\n03:04:05 |     gpu: -1\n03:04:05 |     gradient_clip: 0.1\n03:04:05 |     hide_labels: False\n03:04:05 |     history_add_global_end_token: None\n03:04:05 |     history_reversed: False\n03:04:05 |     history_size: 20\n03:04:05 |     ignore_bad_candidates: False\n03:04:05 |     ignore_labels: None\n03:04:05 |     image_cropsize: 224\n03:04:05 |     image_mode: raw\n03:04:05 |     image_size: 256\n03:04:05 |     inference: max\n03:04:05 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n03:04:05 |     init_opt: None\n03:04:05 |     interactive_candidates: fixed\n03:04:05 |     interactive_mode: False\n03:04:05 |     invsqrt_lr_decay_gamma: -1\n03:04:05 |     is_debug: False\n03:04:05 |     label_truncate: 72\n03:04:05 |     learn_embeddings: True\n03:04:05 |     learn_positional_embeddings: True\n03:04:05 |     learningrate: 5e-05\n03:04:05 |     load_from_checkpoint: False\n03:04:05 |     load_from_pretrained_ranker: True\n03:04:05 |     log_every_n_secs: 10.0\n03:04:05 |     log_every_n_steps: 50\n03:04:05 |     log_keep_fields: all\n03:04:05 |     loglevel: info\n03:04:05 |     lr_scheduler: reduceonplateau\n03:04:05 |     lr_scheduler_decay: 0.5\n03:04:05 |     lr_scheduler_patience: 3\n03:04:05 |     max_train_steps: -1\n03:04:05 |     max_train_time: 7200.0\n03:04:05 |     memory_attention: sqrt\n03:04:05 |     metrics: default\n03:04:05 |     model: transformer/classifier\n03:04:05 |     model_file: /tmp/model4\n03:04:05 |     model_parallel: False\n03:04:05 |     momentum: 0\n03:04:05 |     multitask_weights: [1]\n03:04:05 |     mutators: None\n03:04:05 |     n_decoder_layers: -1\n03:04:05 |     n_encoder_layers: -1\n03:04:05 |     n_heads: 12\n03:04:05 |     n_layers: 12\n03:04:05 |     n_positions: 1024\n03:04:05 |     n_segments: 2\n03:04:05 |     nesterov: True\n03:04:05 |     no_cuda: False\n03:04:05 |     normalize_sent_emb: False\n03:04:05 |     num_epochs: -1\n03:04:05 |     num_workers: 0\n03:04:05 |     nus: (0.7,)\n03:04:05 |     optimizer: adamax\n03:04:05 |     output_scaling: 0.06\n03:04:05 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type2/run4/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model4'}\"\n03:04:05 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n03:04:05 |     person_tokens: False\n03:04:05 |     print_scores: False\n03:04:05 |     rank_candidates: False\n03:04:05 |     rank_top_k: -1\n03:04:05 |     reduction_type: mean\n03:04:05 |     ref_class: None\n03:04:05 |     relu_dropout: 0.0\n03:04:05 |     repeat_blocking_heuristic: True\n03:04:05 |     return_cand_scores: False\n03:04:05 |     save_after_valid: True\n03:04:05 |     save_every_n_secs: -1\n03:04:05 |     save_format: conversations\n03:04:05 |     share_encoders: False\n03:04:05 |     share_word_embeddings: False\n03:04:05 |     short_final_eval: False\n03:04:05 |     special_tok_lst: None\n03:04:05 |     split_lines: False\n03:04:05 |     starttime: Dec04_03-03\n03:04:05 |     task: fromfile:parlaiformat\n03:04:05 |     tensorboard_log: False\n03:04:05 |     tensorboard_logdir: None\n03:04:05 |     text_truncate: 360\n03:04:05 |     threshold: 0.5\n03:04:05 |     topk: 5\n03:04:05 |     train_predict: False\n03:04:05 |     truncate: 1024\n03:04:05 |     update_classifier_head_only: False\n03:04:05 |     update_freq: 1\n03:04:05 |     use_memories: False\n03:04:05 |     use_reply: none\n03:04:05 |     validation_cutoff: 1.0\n03:04:05 |     validation_every_n_epochs: -1\n03:04:05 |     validation_every_n_secs: 20.0\n03:04:05 |     validation_every_n_steps: -1\n03:04:05 |     validation_max_exs: -1\n03:04:05 |     validation_metric: accuracy\n03:04:05 |     validation_metric_mode: max\n03:04:05 |     validation_patience: 30\n03:04:05 |     validation_share_agent: False\n03:04:05 |     variant: xlm\n03:04:05 |     verbose: False\n03:04:05 |     wandb_entity: None\n03:04:05 |     wandb_log: False\n03:04:05 |     wandb_name: None\n03:04:05 |     wandb_project: None\n03:04:05 |     warmup_rate: 0.0001\n03:04:05 |     warmup_updates: 1000\n03:04:05 |     weight_decay: None\n03:04:05 |     world_logs: \n03:04:05 |     wrap_memory_encoder: False\n03:04:05 | creating task(s): fromfile:parlaiformat\n03:04:05 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run4/data_train.txt\n03:04:05 | training...\n03:04:15 | time:10s total_exs:380 total_steps:19 epochs:1.90\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .5184 5.184e-10               .4263                 .5271   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .3579            .5850              .5139   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6789 11.37     1 267.5 506.2       0          0 37.85  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5184             32768  2.936    .1245     6 .6911 9.549e-07   120 227.1   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps   ups  weighted_f1  \n         0          0                   19 387.5 733.3 1.897        .5057\n\n03:04:25 | time:20s total_exs:1140 total_steps:57 epochs:5.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6039 6.039e-10               .5790                 .6161   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5462            .6261              .5943   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .6614 11.24     1 264.9  1021       0          0 77.06  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6039             32768  2.837    .1245 5.997 .6739 2.855e-06 119.9 462.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   57 384.8 1483 3.862        .6026\n\n03:04:25 | creating task(s): fromfile:parlaiformat\n03:04:25 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run4/data_valid.txt\n03:04:25 | running eval: valid\n03:04:25 | eval completed in 0.20s\n03:04:25 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .7500 7.5e-10               .7500                 .7500   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .7500              .7500   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .7500 12.04 168.5  1894       0          0 134.9   24 .7500   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .6589 2.855e-06    72 809.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                     57 240.5 2704        .7500\n\u001b[0m\n03:04:25 | \u001b[1;32mnew best accuracy: 0.75\u001b[0m\n03:04:25 | saving best valid model: /tmp/model4\n03:04:25 | Saving dictionary to /tmp/model4.dict\n03:04:29 | saving model checkpoint: /tmp/model4.checkpoint\n03:04:29 | Saving dictionary to /tmp/model4.checkpoint.dict\n03:04:46 | time:41s total_exs:1840 total_steps:92 epochs:9.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7943 7.943e-10               .7700                 .8060   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7370            .8140              .7855   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8445 11.16     1 263.3 910.2       0          0 69.14  700   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7943             32768  2.778    .1245 5.934 .6170 4.605e-06 118.7 410.3   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                   92  382 1320 3.465        .7934\n\n03:04:49 | time:44s total_exs:2060 total_steps:103 epochs:10.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n       .9000   9e-10               .9091                 .9016   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8889              .8980   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8800 11.34     1 266.8  1042       0          0  78.1  220   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9000             32768  3.243    .1245 6.091 .5559 5.154e-06 121.8 475.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  103 388.6 1518 3.936        .8999\n\n03:04:49 | running eval: valid\n03:04:49 | eval completed in 0.19s\n03:04:49 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 12.04 168.5  1923       0          0 136.9   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5405 5.154e-06    72 821.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    103 240.5 2744        .9583\n\u001b[0m\n03:04:49 | \u001b[1;32mnew best accuracy: 0.9583 (previous best was 0.75)\u001b[0m\n03:04:49 | saving best valid model: /tmp/model4\n03:04:54 | saving model checkpoint: /tmp/model4.checkpoint\n03:05:13 | time:68s total_exs:2820 total_steps:141 epochs:14.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9342 9.342e-10               .9352                 .9352   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9352            .9332              .9332   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9332 11.47     1 269.4  1008       0          0 74.84  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9342             32768  3.499    .1245 6.016 .4259 7.054e-06 120.3 450.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  141 389.7 1458 3.75        .9342\n\n03:05:14 | time:69s total_exs:2900 total_steps:145 epochs:14.50\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9125 9.125e-10               .9091                 .9459   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8750            .9157              .8837   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9500 10.96     1 259.2  1012       0          0 78.03   80   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9125             32768  4.809    .1189     6 .3041 7.254e-06   120 468.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  145 379.2 1480 3.99        .9124\n\n03:05:14 | running eval: valid\n03:05:14 | eval completed in 0.19s\n03:05:14 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 12.04 168.5  1904       0          0 135.6   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .2691 7.254e-06    72 813.6       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    145 240.5 2718            1\n\u001b[0m\n03:05:14 | \u001b[1;32mnew best accuracy: 1 (previous best was 0.9583)\u001b[0m\n03:05:14 | saving best valid model: /tmp/model4\n03:05:24 | task solved! stopping.\n03:05:24 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n03:05:24 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n03:05:24 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run4/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n03:05:24 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n03:05:24 | Using CUDA\n03:05:24 | loading dictionary from /tmp/model4.dict\n03:05:24 | num words = 54944\n03:05:29 | Loading existing model parameters from /tmp/model4\n03:05:30 | Total parameters: 128,042,498 (128,042,498 trainable)\n03:05:32 | creating task(s): fromfile:parlaiformat\n03:05:32 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run4/data_valid.txt\n03:05:32 | running eval: valid\n03:05:32 | eval completed in 0.20s\n03:05:32 | \u001b[1mvalid:\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  f1  \\\n                      1 12.04 168.5  1843       0          0 131.2   24   1   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294     6 .2691 7.254e-06    72 787.5       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    145 240.5 2631            1\n\u001b[0m\n03:05:32 | creating task(s): fromfile:parlaiformat\n03:05:32 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run4/data_test.txt\n03:05:32 | running eval: test\n03:05:37 | eval completed in 4.81s\n03:05:37 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9240 9.24e-10               .7143                 .5723   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9562              .9940   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9211 12.07 281.4  2940       0          0 208.9 1000 .9240   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1294   5.2 .3016 7.254e-06   104  1086       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    145 385.4 4027        .9320\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type2/run4/data_test.txt -m transformer/classifier -mf /tmp/model4 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T03:05:38.875043Z","iopub.execute_input":"2022-12-04T03:05:38.875446Z","iopub.status.idle":"2022-12-04T03:06:09.024195Z","shell.execute_reply.started":"2022-12-04T03:05:38.875410Z","shell.execute_reply":"2022-12-04T03:06:09.022958Z"},"scrolled":true,"trusted":true},"execution_count":121,"outputs":[{"name":"stdout","text":"03:05:47 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr2type2/run4/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr2type2/run4/data)\u001b[0m\n03:05:47 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n03:05:47 | Using CUDA\n03:05:47 | loading dictionary from /tmp/model4.dict\n03:05:47 | num words = 54944\n03:05:52 | Loading existing model parameters from /tmp/model4\n03:05:57 | Total parameters: 128,042,498 (128,042,498 trainable)\n03:05:59 | Opt:\n03:05:59 |     activation: gelu\n03:05:59 |     adafactor_eps: '[1e-30, 0.001]'\n03:05:59 |     adam_eps: 1e-08\n03:05:59 |     add_p1_after_newln: False\n03:05:59 |     aggregate_micro: False\n03:05:59 |     allow_missing_init_opts: False\n03:05:59 |     area_under_curve_class: None\n03:05:59 |     area_under_curve_digits: -1\n03:05:59 |     attention_dropout: 0.1\n03:05:59 |     batchsize: 40\n03:05:59 |     betas: '[0.9, 0.999]'\n03:05:59 |     bpe_add_prefix_space: None\n03:05:59 |     bpe_debug: False\n03:05:59 |     bpe_dropout: None\n03:05:59 |     bpe_merge: None\n03:05:59 |     bpe_vocab: None\n03:05:59 |     candidates: inline\n03:05:59 |     cap_num_predictions: 100\n03:05:59 |     checkpoint_activations: False\n03:05:59 |     class_weights: None\n03:05:59 |     classes: \"['__notok__', '__ok__']\"\n03:05:59 |     classes_from_file: None\n03:05:59 |     data_parallel: True\n03:05:59 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n03:05:59 |     datatype: train\n03:05:59 |     delimiter: '\\n'\n03:05:59 |     dict_class: parlai.core.dict:DictionaryAgent\n03:05:59 |     dict_endtoken: __start__\n03:05:59 |     dict_file: /tmp/model4.dict\n03:05:59 |     dict_include_test: False\n03:05:59 |     dict_include_valid: False\n03:05:59 |     dict_initpath: None\n03:05:59 |     dict_language: english\n03:05:59 |     dict_loaded: True\n03:05:59 |     dict_lower: True\n03:05:59 |     dict_max_ngram_size: -1\n03:05:59 |     dict_maxexs: -1\n03:05:59 |     dict_maxtokens: -1\n03:05:59 |     dict_minfreq: 0\n03:05:59 |     dict_nulltoken: __null__\n03:05:59 |     dict_starttoken: __start__\n03:05:59 |     dict_textfields: text,labels\n03:05:59 |     dict_tokenizer: bpe\n03:05:59 |     dict_unktoken: __unk__\n03:05:59 |     display_examples: False\n03:05:59 |     download_path: None\n03:05:59 |     dropout: 0.1\n03:05:59 |     dynamic_batching: None\n03:05:59 |     embedding_projection: random\n03:05:59 |     embedding_size: 768\n03:05:59 |     embedding_type: random\n03:05:59 |     embeddings_scale: False\n03:05:59 |     encode_candidate_vecs: True\n03:05:59 |     encode_candidate_vecs_batchsize: 256\n03:05:59 |     eval_batchsize: None\n03:05:59 |     eval_candidates: inline\n03:05:59 |     eval_dynamic_batching: None\n03:05:59 |     evaltask: None\n03:05:59 |     ffn_size: 3072\n03:05:59 |     final_extra_opt: \n03:05:59 |     fixed_candidate_vecs: reuse\n03:05:59 |     fixed_candidates_path: None\n03:05:59 |     force_fp16_tokens: True\n03:05:59 |     fp16: True\n03:05:59 |     fp16_impl: safe\n03:05:59 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run4/data_test.txt\n03:05:59 |     fromfile_datatype_extension: True\n03:05:59 |     gpu: -1\n03:05:59 |     gradient_clip: 0.1\n03:05:59 |     hide_labels: False\n03:05:59 |     history_add_global_end_token: None\n03:05:59 |     history_reversed: False\n03:05:59 |     history_size: 20\n03:05:59 |     ignore_bad_candidates: False\n03:05:59 |     ignore_labels: None\n03:05:59 |     image_cropsize: 224\n03:05:59 |     image_mode: raw\n03:05:59 |     image_size: 256\n03:05:59 |     inference: max\n03:05:59 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n03:05:59 |     init_opt: None\n03:05:59 |     interactive_candidates: fixed\n03:05:59 |     interactive_mode: False\n03:05:59 |     invsqrt_lr_decay_gamma: -1\n03:05:59 |     is_debug: False\n03:05:59 |     label_truncate: 72\n03:05:59 |     learn_embeddings: True\n03:05:59 |     learn_positional_embeddings: True\n03:05:59 |     learningrate: 5e-05\n03:05:59 |     load_from_pretrained_ranker: True\n03:05:59 |     log_every_n_secs: 10.0\n03:05:59 |     log_every_n_steps: 50\n03:05:59 |     log_keep_fields: all\n03:05:59 |     loglevel: info\n03:05:59 |     lr_scheduler: reduceonplateau\n03:05:59 |     lr_scheduler_decay: 0.5\n03:05:59 |     lr_scheduler_patience: 3\n03:05:59 |     max_train_steps: -1\n03:05:59 |     max_train_time: 7200.0\n03:05:59 |     memory_attention: sqrt\n03:05:59 |     metrics: default\n03:05:59 |     model: transformer/classifier\n03:05:59 |     model_file: /tmp/model4\n03:05:59 |     model_parallel: False\n03:05:59 |     momentum: 0\n03:05:59 |     multitask_weights: [1]\n03:05:59 |     mutators: None\n03:05:59 |     n_decoder_layers: -1\n03:05:59 |     n_encoder_layers: -1\n03:05:59 |     n_heads: 12\n03:05:59 |     n_layers: 12\n03:05:59 |     n_positions: 1024\n03:05:59 |     n_segments: 2\n03:05:59 |     nesterov: True\n03:05:59 |     no_cuda: False\n03:05:59 |     normalize_sent_emb: False\n03:05:59 |     num_epochs: -1\n03:05:59 |     num_examples: -1\n03:05:59 |     num_workers: 0\n03:05:59 |     nus: [0.7]\n03:05:59 |     optimizer: adamax\n03:05:59 |     output_scaling: 0.06\n03:05:59 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type2/run4/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model4', 'batchsize': 40}\"\n03:05:59 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n03:05:59 |     person_tokens: False\n03:05:59 |     print_scores: False\n03:05:59 |     rank_candidates: False\n03:05:59 |     rank_top_k: -1\n03:05:59 |     reduction_type: mean\n03:05:59 |     ref_class: None\n03:05:59 |     relu_dropout: 0.0\n03:05:59 |     repeat_blocking_heuristic: True\n03:05:59 |     report_filename: \n03:05:59 |     return_cand_scores: False\n03:05:59 |     save_after_valid: True\n03:05:59 |     save_every_n_secs: -1\n03:05:59 |     save_format: conversations\n03:05:59 |     share_encoders: False\n03:05:59 |     share_word_embeddings: False\n03:05:59 |     short_final_eval: False\n03:05:59 |     special_tok_lst: None\n03:05:59 |     split_lines: False\n03:05:59 |     starttime: Dec04_03-03\n03:05:59 |     task: fromfile:parlaiformat\n03:05:59 |     tensorboard_log: False\n03:05:59 |     tensorboard_logdir: None\n03:05:59 |     text_truncate: 360\n03:05:59 |     threshold: 0.5\n03:05:59 |     topk: 5\n03:05:59 |     train_predict: False\n03:05:59 |     truncate: 1024\n03:05:59 |     update_classifier_head_only: False\n03:05:59 |     update_freq: 1\n03:05:59 |     use_memories: False\n03:05:59 |     use_reply: none\n03:05:59 |     validation_cutoff: 1.0\n03:05:59 |     validation_every_n_epochs: -1\n03:05:59 |     validation_every_n_secs: 20.0\n03:05:59 |     validation_every_n_steps: -1\n03:05:59 |     validation_max_exs: -1\n03:05:59 |     validation_metric: accuracy\n03:05:59 |     validation_metric_mode: max\n03:05:59 |     validation_patience: 30\n03:05:59 |     validation_share_agent: False\n03:05:59 |     variant: xlm\n03:05:59 |     verbose: False\n03:05:59 |     wandb_entity: None\n03:05:59 |     wandb_log: False\n03:05:59 |     wandb_name: None\n03:05:59 |     wandb_project: None\n03:05:59 |     warmup_rate: 0.0001\n03:05:59 |     warmup_updates: 1000\n03:05:59 |     weight_decay: None\n03:05:59 |     world_logs: \n03:05:59 |     wrap_memory_encoder: False\n03:05:59 | Evaluating task fromfile:parlaiformat using datatype valid.\n03:05:59 | creating task(s): fromfile:parlaiformat\n03:05:59 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n03:05:59 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run4/data_test.txt\n03:06:07 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9240 9.24e-10               .7143                 .5723   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9562              .9940   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9211 12.07 562.9  1880       0          0 133.6 1000 .9240   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .3016 7.254e-06   208 694.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    145 770.9 2575        .9320\u001b[0m\n03:06:07 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9240 9.24e-10               .7143                 .5723   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9500            .9562              .9940   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9211 12.07 562.9  1880       0          0 133.6 1000 .9240   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .3016 7.254e-06   208 694.8       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    145 770.9 2575        .9320\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model4*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T03:06:09.026120Z","iopub.execute_input":"2022-12-04T03:06:09.026533Z","iopub.status.idle":"2022-12-04T03:06:10.268133Z","shell.execute_reply.started":"2022-12-04T03:06:09.026492Z","shell.execute_reply":"2022-12-04T03:06:10.266827Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"markdown","source":"run 5","metadata":{}},{"cell_type":"code","source":"# run 5 training\n!parlai train_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type2/run5/data --fromfile-datatype-extension true --model transformer/classifier --init-model zoo:pretrained_transformers/bi_model_huge_reddit/model --dict-file zoo:pretrained_transformers/bi_model_huge_reddit/model.dict --dict-tokenizer bpe --dict-lower True --output-scaling 0.06 --variant xlm --n-layers 12 --n-heads 12 --learn-positional-embeddings True --ffn-size 3072 --n-positions 1024 --embedding-size 768 --activation gelu  --embeddings-scale False --n-segments 2 --dict-endtoken __start__  --classes __notok__ __ok__ --reduction-type mean --learn-embeddings True --share-word-embeddings False --load-from-pretrained-ranker True --optimizer adamax --max-train-time -1 --share-encoders False -lr 5e-05 --history-size 20 --label-truncate 72 --text-truncate 360 --dropout 0.1 --attention-dropout 0.1 --gradient-clip 0.1 --validation-metric accuracy --validation-metric-mode max --validation-patience 30 --validation-every-n-secs 20 --log-every-n-secs 10 -ttim 7200 --load-from-checkpoint False --lr_scheduler reduceonplateau --lr-scheduler-patience 3 --save-after-valid true --update-freq 1 --fp16 true --betas 0.9,0.999 --warmup-updates 1000 --data-parallel true -bs 20 --model-file /tmp/model5","metadata":{"execution":{"iopub.status.busy":"2022-12-04T03:06:10.269951Z","iopub.execute_input":"2022-12-04T03:06:10.270672Z","iopub.status.idle":"2022-12-04T03:18:03.349750Z","shell.execute_reply.started":"2022-12-04T03:06:10.270628Z","shell.execute_reply":"2022-12-04T03:18:03.348508Z"},"scrolled":true,"trusted":true},"execution_count":123,"outputs":[{"name":"stdout","text":"03:06:17 | building dictionary first...\n03:06:17 | No model with opt yet at: /tmp/model5(.opt)\n03:06:17 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /opt/conda/lib/python3.7/site-packages/data,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: False,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run5/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True\u001b[0m\n03:06:17 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n03:06:17 | Using CUDA\n03:06:17 | loading dictionary from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n03:06:17 | num words = 54944\n03:06:22 | Loading existing model parameters from /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n03:06:32 | Total parameters: 128,042,498 (128,042,498 trainable)\n03:06:32 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n03:06:32 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n03:06:32 | Opt:\n03:06:32 |     activation: gelu\n03:06:32 |     adafactor_eps: '(1e-30, 0.001)'\n03:06:32 |     adam_eps: 1e-08\n03:06:32 |     add_p1_after_newln: False\n03:06:32 |     aggregate_micro: False\n03:06:32 |     allow_missing_init_opts: False\n03:06:32 |     attention_dropout: 0.1\n03:06:32 |     batchsize: 20\n03:06:32 |     betas: '(0.9, 0.999)'\n03:06:32 |     bpe_add_prefix_space: None\n03:06:32 |     bpe_debug: False\n03:06:32 |     bpe_dropout: None\n03:06:32 |     bpe_merge: None\n03:06:32 |     bpe_vocab: None\n03:06:32 |     candidates: inline\n03:06:32 |     cap_num_predictions: 100\n03:06:32 |     checkpoint_activations: False\n03:06:32 |     class_weights: None\n03:06:32 |     classes: \"['__notok__', '__ok__']\"\n03:06:32 |     classes_from_file: None\n03:06:32 |     data_parallel: True\n03:06:32 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n03:06:32 |     datatype: train\n03:06:32 |     delimiter: '\\n'\n03:06:32 |     dict_class: parlai.core.dict:DictionaryAgent\n03:06:32 |     dict_endtoken: __start__\n03:06:32 |     dict_file: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict\n03:06:32 |     dict_include_test: False\n03:06:32 |     dict_include_valid: False\n03:06:32 |     dict_initpath: None\n03:06:32 |     dict_language: english\n03:06:32 |     dict_loaded: True\n03:06:32 |     dict_lower: True\n03:06:32 |     dict_max_ngram_size: -1\n03:06:32 |     dict_maxexs: -1\n03:06:32 |     dict_maxtokens: -1\n03:06:32 |     dict_minfreq: 0\n03:06:32 |     dict_nulltoken: __null__\n03:06:32 |     dict_starttoken: __start__\n03:06:32 |     dict_textfields: text,labels\n03:06:32 |     dict_tokenizer: bpe\n03:06:32 |     dict_unktoken: __unk__\n03:06:32 |     display_examples: False\n03:06:32 |     download_path: None\n03:06:32 |     dropout: 0.1\n03:06:32 |     dynamic_batching: None\n03:06:32 |     embedding_projection: random\n03:06:32 |     embedding_size: 768\n03:06:32 |     embedding_type: random\n03:06:32 |     embeddings_scale: False\n03:06:32 |     encode_candidate_vecs: True\n03:06:32 |     encode_candidate_vecs_batchsize: 256\n03:06:32 |     eval_batchsize: None\n03:06:32 |     eval_candidates: inline\n03:06:32 |     eval_dynamic_batching: None\n03:06:32 |     evaltask: None\n03:06:32 |     ffn_size: 3072\n03:06:32 |     final_extra_opt: \n03:06:32 |     fixed_candidate_vecs: reuse\n03:06:32 |     fixed_candidates_path: None\n03:06:32 |     force_fp16_tokens: False\n03:06:32 |     fp16: True\n03:06:32 |     fp16_impl: safe\n03:06:32 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run5/data\n03:06:32 |     fromfile_datatype_extension: True\n03:06:32 |     gpu: -1\n03:06:32 |     gradient_clip: 0.1\n03:06:32 |     hide_labels: False\n03:06:32 |     history_add_global_end_token: None\n03:06:32 |     history_reversed: False\n03:06:32 |     history_size: 20\n03:06:32 |     ignore_bad_candidates: False\n03:06:32 |     ignore_labels: None\n03:06:32 |     image_cropsize: 224\n03:06:32 |     image_mode: raw\n03:06:32 |     image_size: 256\n03:06:32 |     inference: max\n03:06:32 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n03:06:32 |     init_opt: None\n03:06:32 |     interactive_candidates: fixed\n03:06:32 |     interactive_mode: False\n03:06:32 |     invsqrt_lr_decay_gamma: -1\n03:06:32 |     is_debug: False\n03:06:32 |     label_truncate: 72\n03:06:32 |     learn_embeddings: True\n03:06:32 |     learn_positional_embeddings: True\n03:06:32 |     learningrate: 5e-05\n03:06:32 |     load_from_checkpoint: False\n03:06:32 |     load_from_pretrained_ranker: True\n03:06:32 |     log_every_n_secs: 10.0\n03:06:32 |     log_every_n_steps: 50\n03:06:32 |     log_keep_fields: all\n03:06:32 |     loglevel: info\n03:06:32 |     lr_scheduler: reduceonplateau\n03:06:32 |     lr_scheduler_decay: 0.5\n03:06:32 |     lr_scheduler_patience: 3\n03:06:32 |     max_train_steps: -1\n03:06:32 |     max_train_time: 7200.0\n03:06:32 |     memory_attention: sqrt\n03:06:32 |     metrics: default\n03:06:32 |     model: transformer/classifier\n03:06:32 |     model_file: /tmp/model5\n03:06:32 |     model_parallel: False\n03:06:32 |     momentum: 0\n03:06:32 |     multitask_weights: [1]\n03:06:32 |     mutators: None\n03:06:32 |     n_decoder_layers: -1\n03:06:32 |     n_encoder_layers: -1\n03:06:32 |     n_heads: 12\n03:06:32 |     n_layers: 12\n03:06:32 |     n_positions: 1024\n03:06:32 |     n_segments: 2\n03:06:32 |     nesterov: True\n03:06:32 |     no_cuda: False\n03:06:32 |     normalize_sent_emb: False\n03:06:32 |     num_epochs: -1\n03:06:32 |     num_workers: 0\n03:06:32 |     nus: (0.7,)\n03:06:32 |     optimizer: adamax\n03:06:32 |     output_scaling: 0.06\n03:06:32 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type2/run5/data', 'fromfile_datatype_extension': True, 'model': 'transformer/classifier', 'init_model': 'zoo:pretrained_transformers/bi_model_huge_reddit/model', 'dict_file': '/opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model.dict', 'dict_tokenizer': 'bpe', 'dict_lower': True, 'output_scaling': 0.06, 'variant': 'xlm', 'n_layers': 12, 'n_heads': 12, 'learn_positional_embeddings': True, 'ffn_size': 3072, 'n_positions': 1024, 'embedding_size': 768, 'activation': 'gelu', 'embeddings_scale': False, 'n_segments': 2, 'dict_endtoken': '__start__', 'classes': ['__notok__', '__ok__'], 'reduction_type': 'mean', 'learn_embeddings': True, 'share_word_embeddings': False, 'load_from_pretrained_ranker': True, 'optimizer': 'adamax', 'max_train_time': 7200.0, 'share_encoders': False, 'learningrate': 5e-05, 'history_size': 20, 'label_truncate': 72, 'text_truncate': 360, 'dropout': 0.1, 'attention_dropout': 0.1, 'gradient_clip': 0.1, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'validation_patience': 30, 'validation_every_n_secs': 20.0, 'log_every_n_secs': 10.0, 'load_from_checkpoint': False, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'save_after_valid': True, 'update_freq': 1, 'fp16': True, 'betas': (0.9, 0.999), 'warmup_updates': 1000, 'data_parallel': True, 'batchsize': 20, 'model_file': '/tmp/model5'}\"\n03:06:32 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n03:06:32 |     person_tokens: False\n03:06:32 |     print_scores: False\n03:06:32 |     rank_candidates: False\n03:06:32 |     rank_top_k: -1\n03:06:32 |     reduction_type: mean\n03:06:32 |     ref_class: None\n03:06:32 |     relu_dropout: 0.0\n03:06:32 |     repeat_blocking_heuristic: True\n03:06:32 |     return_cand_scores: False\n03:06:32 |     save_after_valid: True\n03:06:32 |     save_every_n_secs: -1\n03:06:32 |     save_format: conversations\n03:06:32 |     share_encoders: False\n03:06:32 |     share_word_embeddings: False\n03:06:32 |     short_final_eval: False\n03:06:32 |     special_tok_lst: None\n03:06:32 |     split_lines: False\n03:06:32 |     starttime: Dec04_03-06\n03:06:32 |     task: fromfile:parlaiformat\n03:06:32 |     tensorboard_log: False\n03:06:32 |     tensorboard_logdir: None\n03:06:32 |     text_truncate: 360\n03:06:32 |     threshold: 0.5\n03:06:32 |     topk: 5\n03:06:32 |     train_predict: False\n03:06:32 |     truncate: 1024\n03:06:32 |     update_classifier_head_only: False\n03:06:32 |     update_freq: 1\n03:06:32 |     use_memories: False\n03:06:32 |     use_reply: none\n03:06:32 |     validation_cutoff: 1.0\n03:06:32 |     validation_every_n_epochs: -1\n03:06:32 |     validation_every_n_secs: 20.0\n03:06:32 |     validation_every_n_steps: -1\n03:06:32 |     validation_max_exs: -1\n03:06:32 |     validation_metric: accuracy\n03:06:32 |     validation_metric_mode: max\n03:06:32 |     validation_patience: 30\n03:06:32 |     validation_share_agent: False\n03:06:32 |     variant: xlm\n03:06:32 |     verbose: False\n03:06:32 |     wandb_entity: None\n03:06:32 |     wandb_log: False\n03:06:32 |     wandb_name: None\n03:06:32 |     wandb_project: None\n03:06:32 |     warmup_rate: 0.0001\n03:06:32 |     warmup_updates: 1000\n03:06:32 |     weight_decay: None\n03:06:32 |     world_logs: \n03:06:32 |     wrap_memory_encoder: False\n03:06:32 | creating task(s): fromfile:parlaiformat\n03:06:32 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run5/data_train.txt\n03:06:32 | training...\n03:06:42 | time:10s total_exs:400 total_steps:20 epochs:2.00\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .5150 5.15e-10               .5291                 .5317   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .5266            .5000              .4974   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .5026 11.84     1 276.7 549.4       0          0 39.71  400   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .5150             32768  2.699    .1206 6.035 .6937 1.005e-06 120.7 239.7   \n    ltrunc  ltrunclen  total_train_updates   tpb   tps  ups  weighted_f1  \n         0          0                   20 397.4 789.1 1.99        .5151\n\n03:06:52 | time:20s total_exs:1120 total_steps:56 epochs:5.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .6639 6.639e-10               .7166                 .6538   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7927            .5870              .6825   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .5150 11.78     1 275.6  1021       0          0 74.06  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .6639             32768  2.615    .1206 6.072 .6641 2.805e-06 121.4 449.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   56 397.1 1470 3.712        .6565\n\n03:06:52 | creating task(s): fromfile:parlaiformat\n03:06:52 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run5/data_valid.txt\n03:06:52 | running eval: valid\n03:06:52 | eval completed in 0.20s\n03:06:52 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .6250 6.25e-10               .7273                 .5714   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .4000                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .2500 10.67   152  1656       0          0 130.7   24 .6250   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08088     6 .6593 2.805e-06    72 784.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                     56  224 2440        .5636\n\u001b[0m\n03:06:52 | \u001b[1;32mnew best accuracy: 0.625\u001b[0m\n03:06:52 | saving best valid model: /tmp/model5\n03:06:52 | Saving dictionary to /tmp/model5.dict\n03:06:57 | saving model checkpoint: /tmp/model5.checkpoint\n03:06:57 | Saving dictionary to /tmp/model5.checkpoint.dict\n03:07:14 | time:42s total_exs:1840 total_steps:92 epochs:9.20\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .7917 7.917e-10               .8280                 .7177   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9783            .7359              .9631   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .5954 12.11     1 282.2  1001       0          0 70.91  720   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .7917             32768   3.04    .1207 6.025 .6053 4.605e-06 120.5 427.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                   92 402.7 1428 3.553        .7831\n\n03:07:17 | time:45s total_exs:2040 total_steps:102 epochs:10.20\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9250 9.25e-10               .9239                 .8835   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9681            .9261              .9691   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .8868 11.86     1 277.2  1024       0          0 73.87  200   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9250             32768  3.183    .1207  5.94 .5246 5.104e-06 118.8 438.8   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                  102  396 1463 3.725        .9251\n\n03:07:17 | running eval: valid\n03:07:17 | eval completed in 0.25s\n03:07:17 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1352       0          0 106.7   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08089     6 .5226 5.104e-06    72 640.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    102  224 1992        .9583\n\u001b[0m\n03:07:17 | \u001b[1;32mnew best accuracy: 0.9583 (previous best was 0.625)\u001b[0m\n03:07:17 | saving best valid model: /tmp/model5\n03:07:27 | saving model checkpoint: /tmp/model5.checkpoint\n03:07:42 | time:70s total_exs:2820 total_steps:141 epochs:14.10\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9487 9.487e-10               .9479                 .9504   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9455            .9495              .9471   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9519 11.97     1 279.5  1078       0          0 77.12  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9487             32768  4.253    .1207 5.987 .3860 7.054e-06 119.7 461.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  141 399.2 1539 3.865        .9487\n\n03:07:47 | time:75s total_exs:3200 total_steps:160 epochs:16.00\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9711 9.711e-10               .9714                 .9740   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9689            .9707              .9681   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9733 11.89     1 277.8  1079       0          0 77.69  380   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9711             32768  5.859    .1207 6.016 .1956 8.004e-06 120.3 467.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  160 398.2 1547 3.902        .9711\n\n03:07:47 | running eval: valid\n03:07:47 | eval completed in 0.20s\n03:07:47 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8800                 .8462   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .8696              .9091   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .8333 10.67   152  1653       0          0 130.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0809     6 .2621 8.004e-06    72 782.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    160  224 2435        .8748\n\u001b[0m\n03:07:47 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 1\u001b[0m\n03:07:47 | saving model checkpoint: /tmp/model5.checkpoint\n03:08:07 | time:95s total_exs:3960 total_steps:198 epochs:19.80\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9829 9.829e-10               .9831                 .9793   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9869            .9827              .9866   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9788 12.14     1 282.9  1081       0          0 76.42  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9829             32768  3.965    .1207 6.008 .0939 9.904e-06 120.2 459.1   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps  ups  weighted_f1  \n         0          0                  198  403 1540 3.83        .9829\n\n03:08:07 | running eval: valid\n03:08:08 | eval completed in 0.20s\n03:08:08 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1665       0          0 131.4   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08091     6 .3146 9.904e-06    72 788.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    198  224 2453        .9167\n\u001b[0m\n03:08:08 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 2\u001b[0m\n03:08:08 | saving model checkpoint: /tmp/model5.checkpoint\n03:08:22 | time:110s total_exs:4720 total_steps:236 epochs:23.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9934 9.934e-10               .9938                 .9878   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9929                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9860 11.99 .9211 279.8  1037       0          0 74.13  760   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9934             32768  2.336    .1207 6.063 .03898 1.18e-05 121.3 449.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  236 401.1 1486 3.715        .9934\n\n03:08:28 | time:116s total_exs:5140 total_steps:257 epochs:25.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9976 9.976e-10               .9977                 .9954   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9976                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9951 11.89 .3810 277.8  1053       0          0 75.79  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n   .9976             32768  .2722    .1207 6.024 .0154 1.285e-05 120.5 456.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  257 398.2 1509 3.805        .9976\n\n03:08:28 | running eval: valid\n03:08:28 | eval completed in 0.20s\n03:08:28 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1667       0          0 131.6   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08092     6 .4434 1.285e-05    72 789.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    257  224 2457        .9167\n\u001b[0m\n03:08:28 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 3\u001b[0m\n03:08:28 | saving model checkpoint: /tmp/model5.checkpoint\n03:08:43 | time:130s total_exs:5920 total_steps:296 epochs:29.60\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9974 9.974e-10               .9974                 .9948   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9975                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9949 11.93 .1282 278.7  1066       0          0 76.49  780   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen   loss       lr  ltpb  ltps  \\\n   .9974             32768  .8331    .1207  5.99 .01599 1.48e-05 119.8 458.2   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  296 398.5 1524 3.833        .9974\n\n03:08:48 | time:136s total_exs:6340 total_steps:317 epochs:31.70\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9976 9.976e-10               .9975                 .9950   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9977                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                  .9954 11.79 .1905 275.9  1051       0          0 76.23  420   \n      f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  \\\n   .9976             32768  1.916    .1207 5.957 .004266 1.585e-05 119.1   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   454.1       0          0                  317  395 1505 3.827        .9976\n\n03:08:48 | running eval: valid\n03:08:48 | eval completed in 0.20s\n03:08:48 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8182                 .9000   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8462              .7857   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1688       0          0 133.2   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08093     6 .9218 1.585e-05    72 799.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    317  224 2487        .8322\n\u001b[0m\n03:08:48 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 4\u001b[0m\n03:08:48 | saving model checkpoint: /tmp/model5.checkpoint\n03:09:03 | time:150s total_exs:7100 total_steps:355 epochs:35.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.62     0 272.5  1033       0          0 75.83  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .02296    .1207 6.032 .001676 1.775e-05 120.6 457.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  355 393.1 1490  3.8            1\n\n03:09:08 | time:156s total_exs:7540 total_steps:377 epochs:37.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.76     0 275.3  1048       0          0 76.12  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01718    .1207 5.995 .001461 1.885e-05 119.9 456.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  377 395.2 1504 3.821            1\n\n03:09:08 | running eval: valid\n03:09:09 | eval completed in 0.21s\n03:09:09 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1586       0          0 125.2   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08094     6 .7852 1.885e-05    72 751.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    377  224 2338        .8748\n\u001b[0m\n03:09:09 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 5\u001b[0m\n03:09:09 | saving model checkpoint: /tmp/model5.checkpoint\n03:09:23 | time:171s total_exs:8320 total_steps:416 epochs:41.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.13     0 282.7  1079       0          0 76.31  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .01568    .1207 5.954 .001329 2.08e-05 119.1 454.3   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  416 401.8 1533 3.824            1\n\n03:09:29 | time:177s total_exs:8740 total_steps:437 epochs:43.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.18     0 283.6  1073       0          0 75.65  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01428    .1207 6.024 .001228 2.185e-05 120.5 455.7   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  437 404.1 1529 3.798            1\n\n03:09:29 | running eval: valid\n03:09:29 | eval completed in 0.23s\n03:09:29 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .8333 8.333e-10               .8000                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .6667            .8571              .7500   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1486       0          0 117.3   24 .8333   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08096     6 .6872 2.185e-05    72 704.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    437  224 2191        .8286\n\u001b[0m\n03:09:29 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 6\u001b[0m\n03:09:29 | saving model checkpoint: /tmp/model5.checkpoint\n03:09:44 | time:191s total_exs:9520 total_steps:476 epochs:47.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.87     0 277.5  1061       0          0 76.44  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss       lr  ltpb  ltps  \\\n     1             32768 .01334    .1207 6.072 .001143 2.38e-05 121.4 464.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  476 398.9 1525 3.83            1\n\n03:09:49 | time:197s total_exs:9940 total_steps:497 epochs:49.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.54     0 270.9  1039       0          0 76.68  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .01238    .1190     6 .001066 2.485e-05   120 460.1   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  497 390.9 1499 3.85            1\n\n03:09:49 | running eval: valid\n03:09:49 | eval completed in 0.20s\n03:09:49 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1650       0          0 130.2   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08097     6 .7031 2.485e-05    72 781.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    497  224 2432        .8748\n\u001b[0m\n03:09:49 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 7\u001b[0m\n03:09:49 | saving model checkpoint: /tmp/model5.checkpoint\n03:10:04 | time:212s total_exs:10700 total_steps:535 epochs:53.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.86     0 277.2  1040       0          0 75.03  760   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01171    .1207  6.05 .0009969 2.675e-05   121   454   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  535 398.2 1494 3.76            1\n\n03:10:09 | time:217s total_exs:11140 total_steps:557 epochs:55.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.47     0 269.4  1047       0          0 77.72  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .01087    .1207 5.968 .0009324 2.785e-05 119.4 463.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  557 388.7 1511 3.902            1\n\n03:10:09 | running eval: valid\n03:10:10 | eval completed in 0.20s\n03:10:10 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1638       0          0 129.3   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08098     6 .6959 2.785e-05    72 775.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    557  224 2414        .8730\n\u001b[0m\n03:10:10 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 8\u001b[0m\n03:10:10 | saving model checkpoint: /tmp/model5.checkpoint\n03:10:24 | time:232s total_exs:11920 total_steps:596 epochs:59.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.99     0 279.8  1072       0          0 76.63  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .01016    .1208 6.059 .0008715 2.98e-05 121.2 464.3   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps  ups  weighted_f1  \n         0          0                  596  401 1537 3.84            1\n\n03:10:30 | time:238s total_exs:12320 total_steps:616 epochs:61.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.36     0 267.2 990.2       0          0 74.12  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .009581    .1208  5.97 .0008179 3.08e-05 119.4 442.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  616 386.6 1433 3.721            1\n\n03:10:30 | running eval: valid\n03:10:30 | eval completed in 0.20s\n03:10:30 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1666       0          0 131.5   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08099     6 .6025 3.08e-05    72 788.9       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    616  224 2455        .9161\n\u001b[0m\n03:10:30 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 9\u001b[0m\n03:10:30 | saving model checkpoint: /tmp/model5.checkpoint\n03:10:44 | time:252s total_exs:13100 total_steps:655 epochs:65.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.64     0 272.7  1046       0          0  76.7  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .008938    .1208 6.038 .0007668 3.275e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.2       0          0                  655 393.5 1509 3.844            1\n\n03:10:50 | time:258s total_exs:13540 total_steps:677 epochs:67.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.59     0 271.8  1034       0          0 76.08  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .008388    .1208 5.959 .0007163 3.385e-05 119.2   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   453.4       0          0                  677  391 1487 3.819            1\n\n03:10:50 | running eval: valid\n03:10:50 | eval completed in 0.21s\n03:10:50 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1597       0          0   126   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0810     6 .6606 3.385e-05    72 756.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    677  224 2354        .8748\n\u001b[0m\n03:10:50 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 10\u001b[0m\n03:10:50 | saving model checkpoint: /tmp/model5.checkpoint\n03:11:05 | time:273s total_exs:14300 total_steps:715 epochs:71.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.67     0 273.4  1028       0          0 75.18  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .007866    .1208 6.003 .0006712 3.575e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.3       0          0                  715 393.5 1479 3.767            1\n\n03:11:11 | time:278s total_exs:14740 total_steps:737 epochs:73.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.93     0 278.7  1066       0          0 76.51  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .009537    .1208 6.027 .0006307 3.685e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   461.1       0          0                  737 399.2 1527 3.84            1\n\n03:11:11 | running eval: valid\n03:11:11 | eval completed in 0.20s\n03:11:11 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1684       0          0 132.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08101     6 .6414 3.685e-05    72 797.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    737  224 2482        .9167\n\u001b[0m\n03:11:11 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 11\u001b[0m\n03:11:11 | saving model checkpoint: /tmp/model5.checkpoint\n03:11:25 | time:293s total_exs:15500 total_steps:775 epochs:77.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.72     0 274.4  1040       0          0 75.82  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006869    .1208 6.039 .0005875 3.875e-05 120.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n   457.9       0          0                  775 395.2 1498  3.8            1\n\n03:11:31 | time:299s total_exs:15940 total_steps:797 epochs:79.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.7     0 273.9  1005       0          0 73.37  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .006403    .1208 6.095 .0005479 3.985e-05 121.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   447.2       0          0                  797 395.8 1452 3.671            1\n\n03:11:31 | running eval: valid\n03:11:31 | eval completed in 0.26s\n03:11:31 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8696                 .9091   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .8800              .8462   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1260       0          0 99.42   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08102     6 .8384 3.985e-05    72 596.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    797  224 1857        .8748\n\u001b[0m\n03:11:31 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 12\u001b[0m\n03:11:31 | saving model checkpoint: /tmp/model5.checkpoint\n03:11:46 | time:314s total_exs:16720 total_steps:836 epochs:83.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.82     0 276.3  1057       0          0  76.5  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .006009    .1208 5.967 .0005139 4.18e-05 119.3 456.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  836 395.7 1514 3.834            1\n\n03:11:52 | time:319s total_exs:17160 total_steps:858 epochs:85.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.79     0 275.8  1064       0          0 77.14  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .005615    .1208 6.041 .0004804 4.29e-05 120.8   466   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  858 396.6 1530 3.872            1\n\n03:11:52 | running eval: valid\n03:11:52 | eval completed in 0.20s\n03:11:52 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1674       0          0 132.2   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08103     6 .6432 4.29e-05    72 793.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    858  224 2468        .9161\n\u001b[0m\n03:11:52 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 13\u001b[0m\n03:11:52 | saving model checkpoint: /tmp/model5.checkpoint\n03:12:06 | time:334s total_exs:17920 total_steps:896 epochs:89.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.74     0 274.8  1037       0          0 75.44  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .005285    .1208 6.026 .0004501 4.48e-05 120.5 454.6   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                  896 395.4 1491 3.78            1\n\n03:12:12 | time:340s total_exs:18360 total_steps:918 epochs:91.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.57     0 271.4  1060       0          0 78.11  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss       lr  ltpb  ltps  \\\n     1             32768 .004926    .1208 6.068 .0004208 4.59e-05 121.4   474   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                  918 392.8 1534 3.921            1\n\n03:12:12 | running eval: valid\n03:12:12 | eval completed in 0.20s\n03:12:12 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1645       0          0 129.9   24 .9167   \n    gpu_mem  llen  loss       lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08104     6 .6484 4.59e-05    72 779.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    918  224 2425        .9161\n\u001b[0m\n03:12:12 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 14\u001b[0m\n03:12:12 | saving model checkpoint: /tmp/model5.checkpoint\n03:12:27 | time:354s total_exs:19140 total_steps:957 epochs:95.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.5     0   270  1038       0          0 76.85  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004618    .1208 6.046 .0003941 4.785e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   464.7       0          0                  957 390.9 1502 3.851            1\n\n03:12:32 | time:360s total_exs:19580 total_steps:979 epochs:97.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.65     0 273.1  1067       0          0 78.12  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .004326    .1208 6.027 .0003689 4.895e-05 120.5   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   470.8       0          0                  979 393.6 1537 3.921            1\n\n03:12:32 | running eval: valid\n03:12:32 | eval completed in 0.20s\n03:12:32 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1668       0          0 131.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08106     6 .6600 4.895e-05    72 790.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    979  224 2458        .9161\n\u001b[0m\n03:12:32 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 15\u001b[0m\n03:12:32 | saving model checkpoint: /tmp/model5.checkpoint\n03:12:47 | time:375s total_exs:20360 total_steps:1018 epochs:101.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.64     0 272.7  1055       0          0 77.34  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00405    .1208 6.013 .0003452 4.995e-05 120.3   465   \n    ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n         0          0                 1018  393 1520 3.876            1\n\n03:12:53 | time:380s total_exs:20760 total_steps:1038 epochs:103.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.62     0 272.5  1044       0          0 76.66  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .003799    .1208 6.045 .000324 4.995e-05 120.9 463.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1038 393.4 1508 3.85            1\n\n03:12:53 | running eval: valid\n03:12:53 | eval completed in 0.20s\n03:12:53 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1656       0          0 130.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08107     6 .6621 4.995e-05    72 784.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1038  224 2440        .9161\n\u001b[0m\n03:12:53 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 16\u001b[0m\n03:12:53 | saving model checkpoint: /tmp/model5.checkpoint\n03:13:07 | time:395s total_exs:21520 total_steps:1076 epochs:107.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.96     0 279.2  1053       0          0 75.47  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003577    .1208 6.063 .0003047 4.995e-05 121.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   457.6       0          0                 1076 400.4 1511 3.782            1\n\n03:13:13 | time:401s total_exs:21960 total_steps:1098 epochs:109.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.52     0 270.4  1036       0          0  76.6  440   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00338    .1208 5.973 .0002879 4.995e-05 119.5 457.5   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1098 389.9 1493 3.845            1\n\n03:13:13 | running eval: valid\n03:13:13 | eval completed in 0.21s\n03:13:13 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1591       0          0 125.6   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08108     6 .6757 4.995e-05    72 753.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1098  224 2345        .9161\n\u001b[0m\n03:13:13 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 17\u001b[0m\n03:13:13 | saving model checkpoint: /tmp/model5.checkpoint\n03:13:28 | time:416s total_exs:22720 total_steps:1136 epochs:113.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.69     0 273.8  1028       0          0 75.08  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003189    .1209 6.011 .0002713 4.995e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   451.3       0          0                 1136  394 1479 3.762            1\n\n03:13:33 | time:421s total_exs:23120 total_steps:1156 epochs:115.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.84     0 276.8  1051       0          0 75.98  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .003017    .1209  5.94 .0002569 4.995e-05 118.8   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   451.3       0          0                 1156 395.6 1503 3.815            1\n\n03:13:33 | running eval: valid\n03:13:33 | eval completed in 0.22s\n03:13:33 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1555       0          0 122.7   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08109     6 .7887 4.995e-05    72 736.5       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1156  224 2291        .8730\n\u001b[0m\n03:13:33 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 18\u001b[0m\n03:13:33 | saving model checkpoint: /tmp/model5.checkpoint\n03:13:48 | time:436s total_exs:23900 total_steps:1195 epochs:119.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.55     0 271.1  1033       0          0  76.2  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002858    .1209 6.028 .0002431 4.995e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.4       0          0                 1195 391.6 1492 3.819            1\n\n03:13:53 | time:441s total_exs:24300 total_steps:1215 epochs:121.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.85     0 276.9  1065       0          0 76.89  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002706    .1209  6.06 .0002302 4.995e-05 121.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n     466       0          0                 1215 398.1 1531 3.862            1\n\n03:13:53 | running eval: valid\n03:13:54 | eval completed in 0.23s\n03:13:54 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1491       0          0 117.7   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0811     6 .7355 4.995e-05    72 706.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1215  224 2198        .8730\n\u001b[0m\n03:13:54 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 19\u001b[0m\n03:13:54 | saving model checkpoint: /tmp/model5.checkpoint\n03:14:08 | time:456s total_exs:25080 total_steps:1254 epochs:125.40\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.82     0 276.3  1060       0          0 76.75  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002573    .1209 6.015 .0002187 4.995e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.7       0          0                 1254 396.6 1522 3.846            1\n\n03:14:14 | time:462s total_exs:25500 total_steps:1275 epochs:127.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.85     0 276.9  1043       0          0 75.34  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002439    .1209  6.01 .0002075 4.995e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   452.8       0          0                 1275 397.1 1496 3.783            1\n\n03:14:14 | running eval: valid\n03:14:14 | eval completed in 0.21s\n03:14:14 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1624       0          0 128.2   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08111     6 .9224 4.995e-05    72 769.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1275  224 2394        .8730\n\u001b[0m\nEpoch 00005: reducing learning rate of group 0 to 2.4975e-05.\n03:14:14 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 20\u001b[0m\n03:14:14 | saving model checkpoint: /tmp/model5.checkpoint\n03:14:29 | time:477s total_exs:26260 total_steps:1313 epochs:131.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1  11.7     0   274  1040       0          0  75.9  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002369    .1209 6.047 .0002007 2.498e-05 120.9   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n     459       0          0                 1313  395 1499 3.803            1\n\n03:14:34 | time:482s total_exs:26660 total_steps:1333 epochs:133.30\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.99     0 279.8  1083       0          0 77.38  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768 .002305    .1192 6.015 .000196 2.498e-05 120.3 465.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1333 400.1 1548 3.886            1\n\n03:14:34 | running eval: valid\n03:14:34 | eval completed in 0.20s\n03:14:34 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1684       0          0 132.9   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08112     6 .7092 2.498e-05    72 797.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1333  224 2481        .9161\n\u001b[0m\n03:14:34 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 21\u001b[0m\n03:14:34 | saving model checkpoint: /tmp/model5.checkpoint\n03:14:49 | time:497s total_exs:27420 total_steps:1371 epochs:137.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.09     0 281.8  1056       0          0 74.94  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002271    .1209 6.008 .0001911 2.498e-05 120.2   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   450.2       0          0                 1371 401.9 1506 3.755            1\n\n03:14:54 | time:502s total_exs:27840 total_steps:1392 epochs:139.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.69     0 273.7  1058       0          0 77.33  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00219    .1209 6.024 .0001862 2.498e-05 120.5 465.8   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1392 394.2 1524 3.883            1\n\n03:14:54 | running eval: valid\n03:14:55 | eval completed in 0.21s\n03:14:55 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1631       0          0 128.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08113     6 .6998 2.498e-05    72 772.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1392  224 2403        .9161\n\u001b[0m\n03:14:55 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 22\u001b[0m\n03:14:55 | saving model checkpoint: /tmp/model5.checkpoint\n03:15:09 | time:517s total_exs:28620 total_steps:1431 epochs:143.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.75     0 275.1  1055       0          0 76.71  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002137    .1209 6.051 .0001815 2.498e-05   121   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   464.2       0          0                 1431 396.1 1519 3.844            1\n\n03:15:15 | time:523s total_exs:29040 total_steps:1452 epochs:145.20\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.69     0 273.9  1023       0          0 74.68  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002085    .1209 6.005 .0001772 2.498e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   448.4       0          0                 1452  394 1471 3.749            1\n\n03:15:15 | running eval: valid\n03:15:15 | eval completed in 0.20s\n03:15:15 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1662       0          0 131.2   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08114     6 .7189 2.498e-05    72 787.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1452  224 2450        .9161\n\u001b[0m\n03:15:15 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 23\u001b[0m\n03:15:15 | saving model checkpoint: /tmp/model5.checkpoint\n03:15:30 | time:538s total_exs:29820 total_steps:1491 epochs:149.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.77     0 275.5  1053       0          0 76.48  780   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00203    .1209 5.974 .0001725 2.498e-05 119.5 456.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1491 394.9 1510 3.833            1\n\n03:15:35 | time:543s total_exs:30220 total_steps:1511 epochs:151.10\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.45     0 268.9  1023       0          0 76.11  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001977    .1192 6.055 .0001679 2.498e-05 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   460.8       0          0                 1511  390 1484 3.821            1\n\n03:15:35 | running eval: valid\n03:15:35 | eval completed in 0.20s\n03:15:35 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1685       0          0   133   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08115     6 .7461 2.498e-05    72 798.3       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1511  224 2484        .9161\n\u001b[0m\nEpoch 00009: reducing learning rate of group 0 to 1.2488e-05.\n03:15:35 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 24\u001b[0m\n03:15:35 | saving model checkpoint: /tmp/model5.checkpoint\n03:15:50 | time:558s total_exs:30980 total_steps:1549 epochs:154.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.49     0 269.9  1005       0          0 74.51  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001944    .1209 6.005 .0001652 1.249e-05 120.1   \n    ltps  ltrunc  ltrunclen  total_train_updates  tpb  tps   ups  weighted_f1  \n   447.4       0          0                 1549  390 1453 3.734            1\n\n03:15:56 | time:563s total_exs:31400 total_steps:1570 epochs:157.00\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.85     0 276.9  1051       0          0 75.89  420   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  ltps  \\\n     1             32768 .00192    .1209 5.981 .0001631 1.249e-05 119.6 453.9   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps  ups  weighted_f1  \n         0          0                 1570 396.5 1505 3.81            1\n\n03:15:56 | running eval: valid\n03:15:56 | eval completed in 0.21s\n03:15:56 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1615       0          0 127.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08117     6 .7659 1.249e-05    72 764.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1570  224 2380        .8730\n\u001b[0m\n03:15:56 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 25\u001b[0m\n03:15:56 | saving model checkpoint: /tmp/model5.checkpoint\n03:16:11 | time:578s total_exs:32180 total_steps:1609 epochs:160.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.84     0 276.9  1064       0          0 76.85  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001891    .1209 6.028 .0001606 1.249e-05 120.6   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.3       0          0                 1609 397.5 1527 3.851            1\n\n03:16:16 | time:584s total_exs:32580 total_steps:1629 epochs:162.90\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.81 .0500 276.2  1046       0          0 75.78  400   \n    f1  fp16_loss_scalar  gnorm  gpu_mem  llen    loss        lr  ltpb  ltps  \\\n     1             32768  7.855    .1209  5.97 .000592 1.249e-05 119.4 452.4   \n    ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n         0          0                 1629 395.6 1499 3.803            1\n\n03:16:16 | running eval: valid\n03:16:16 | eval completed in 0.23s\n03:16:16 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9167                 .9167   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9167            .9167              .9167   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152  1490       0          0 117.6   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08118     6 .7535 1.249e-05    72 705.8       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1629  224 2196        .9167\n\u001b[0m\n03:16:16 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 26\u001b[0m\n03:16:16 | saving model checkpoint: /tmp/model5.checkpoint\n03:16:31 | time:599s total_exs:33340 total_steps:1667 epochs:166.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen   clip  ctpb  ctps  ctrunc  ctrunclen  exps  \\\n                      1 11.64 .02632 272.8  1035       0          0 75.88   \n    exs  f1  fp16_loss_scalar  gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n    760   1             32768 .02176    .1209 6.053 .0001603 1.249e-05 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   459.3       0          0                 1667 393.8 1494 3.803            1\n\n03:16:36 | time:604s total_exs:33760 total_steps:1688 epochs:168.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.56     0 271.2  1054       0          0 77.71  420   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001819    .1210 6.143 .0001539 1.249e-05 122.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   477.4       0          0                 1688 394.1 1531 3.902            1\n\n03:16:36 | running eval: valid\n03:16:37 | eval completed in 0.20s\n03:16:37 | \u001b[1mvalid:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .8750 8.75e-10               .8571                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .7500            .8889              .8000   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1677       0          0 132.4   24 .8750   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08119     6 .8227 1.249e-05    72 794.4       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1688  224 2472        .8730\n\u001b[0m\n03:16:37 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 27\u001b[0m\n03:16:37 | saving model checkpoint: /tmp/model5.checkpoint\n03:16:51 | time:619s total_exs:34520 total_steps:1726 epochs:172.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.77     0 275.3  1040       0          0 75.51  760   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .002069    .1210 6.016 .0001524 1.249e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   454.3       0          0                 1726 395.7 1494 3.784            1\n\n03:16:57 | time:625s total_exs:34960 total_steps:1748 epochs:174.80\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.64     0 272.9  1065       0          0 78.03  440   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001767    .1210 6.014 .0001501 1.249e-05 120.3   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   469.3       0          0                 1748 393.1 1534 3.917            1\n\n03:16:57 | running eval: valid\n03:16:57 | eval completed in 0.20s\n03:16:57 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1644       0          0 129.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .0812     6 .7420 1.249e-05    72 778.6       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1748  224 2423        .9161\n\u001b[0m\nEpoch 00013: reducing learning rate of group 0 to 6.2438e-06.\n03:16:57 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 28\u001b[0m\n03:16:57 | saving model checkpoint: /tmp/model5.checkpoint\n03:17:12 | time:640s total_exs:35740 total_steps:1787 epochs:178.70\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.87     0 277.4  1071       0          0 77.19  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001749    .1210     6 .0001485 6.244e-06   120   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   463.1       0          0                 1787 397.4 1534 3.868            1\n\n03:17:17 | time:645s total_exs:36120 total_steps:1806 epochs:180.60\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.77     0 275.4  1075       0          0  78.1  380   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001739    .1210 5.947 .0001476 6.244e-06 118.9   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   464.5       0          0                 1806 394.3 1540 3.923            1\n\n03:17:17 | running eval: valid\n03:17:17 | eval completed in 0.20s\n03:17:17 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1682       0          0 132.7   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08121     6 .7414 6.244e-06    72 796.7       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1806  224 2479        .9161\n\u001b[0m\n03:17:17 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 29\u001b[0m\n03:17:17 | saving model checkpoint: /tmp/model5.checkpoint\n03:17:32 | time:660s total_exs:36900 total_steps:1845 epochs:184.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 12.04     0 280.9  1078       0          0 76.78  780   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001719    .1210   6.1 .0001459 6.244e-06   122   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   468.4       0          0                 1845 402.9 1547 3.848            1\n\n03:17:37 | time:665s total_exs:37300 total_steps:1865 epochs:186.50\n    accuracy  bleu-4  class___notok___f1  class___notok___prec  \\\n           1   1e-09                   1                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1                1                  1   \n    class___ok___recall  clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n                      1 11.98     0 279.6  1066       0          0 76.25  400   \n    f1  fp16_loss_scalar   gnorm  gpu_mem  llen     loss        lr  ltpb  \\\n     1             32768 .001707    .1210 6.055 .0001448 6.244e-06 121.1   \n    ltps  ltrunc  ltrunclen  total_train_updates   tpb  tps   ups  weighted_f1  \n   461.7       0          0                 1865 400.7 1528 3.829            1\n\n03:17:37 | running eval: valid\n03:17:38 | eval completed in 0.20s\n03:17:38 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9167 9.167e-10               .9091                     1   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .8333            .9231              .8571   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                      1 10.67   152  1645       0          0 129.8   24 .9167   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08122     6 .7418 6.244e-06    72 779.1       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                   1865  224 2424        .9161\n\u001b[0m\n03:17:38 | \u001b[1mdid not beat best accuracy: 0.9583 impatience: 30\u001b[0m\n03:17:38 | saving model checkpoint: /tmp/model5.checkpoint\n03:17:42 | ran out of patience! stopping training.\n03:17:42 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/bi_model_huge_reddit/model (previously: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model)\u001b[0m\n03:17:42 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n03:17:42 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: None,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 7200.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: 20.0,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: True,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 30,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: 10.0,mutators: None,fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run5/data,fromfile_datatype_extension: True,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,classes: __notok__,__ok__,class_weights: None,ref_class: None,threshold: 0.5,print_scores: False,classes_from_file: None,ignore_labels: None,update_classifier_head_only: False,load_from_pretrained_ranker: True,dict_loaded: True,load_from_checkpoint: False,download_path: None,verbose: False,datapath: /opt/conda/lib/python3.7/site-packages/data,interactive_mode: False\u001b[0m\n03:17:42 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n--show-advanced-args False --task convai2 --numthreads 1 --batchsize 512 --model transformer/biencoder --single-turn False --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 --warmup-updates 100 --rank-candidates True --use-reply label --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n03:17:42 | Using CUDA\n03:17:42 | loading dictionary from /tmp/model5.dict\n03:17:42 | num words = 54944\n03:17:47 | Loading existing model parameters from /tmp/model5\n03:17:54 | Total parameters: 128,042,498 (128,042,498 trainable)\n03:17:55 | creating task(s): fromfile:parlaiformat\n03:17:55 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run5/data_valid.txt\n03:17:56 | running eval: valid\n03:17:56 | eval completed in 0.40s\n03:17:56 | \u001b[1mvalid:\n    accuracy    bleu-4  class___notok___f1  class___notok___prec  \\\n       .9583 9.583e-10               .9600                 .9231   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                         1            .9565                  1   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9167 10.67   152 914.7       0          0 72.17   24 .9583   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1297     6 .5226 5.104e-06    72 433.2       0          0   \n    total_train_updates  tpb  tps  weighted_f1  \n                    102  224 1348        .9583\n\u001b[0m\n03:17:56 | creating task(s): fromfile:parlaiformat\n03:17:56 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run5/data_test.txt\n03:17:56 | running eval: test\n03:18:01 | eval completed in 5.02s\n03:18:01 | \u001b[1mtest:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9070 9.07e-10               .6760                 .5187   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9700            .9457              .9963   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9000 12.07 281.4  2817       0          0 200.2 1000 .9070   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n      .1298   5.2 .5177 5.104e-06   104  1041       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    102 385.4 3858        .9187\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate\n!parlai eval_model -t fromfile:parlaiformat --fromfile-datapath ../input/comp599projproposed/proposed/prev2corr2type2/run5/data_test.txt -m transformer/classifier -mf /tmp/model5 -bs 40","metadata":{"execution":{"iopub.status.busy":"2022-12-04T03:18:03.351782Z","iopub.execute_input":"2022-12-04T03:18:03.352185Z","iopub.status.idle":"2022-12-04T03:18:34.521167Z","shell.execute_reply.started":"2022-12-04T03:18:03.352145Z","shell.execute_reply":"2022-12-04T03:18:34.519947Z"},"scrolled":true,"trusted":true},"execution_count":124,"outputs":[{"name":"stdout","text":"03:18:12 | \u001b[33mOverriding opt[\"fromfile_datapath\"] to ../input/comp599projproposed/proposed/prev2corr2type2/run5/data_test.txt (previously: ../input/comp599projproposed/proposed/prev2corr2type2/run5/data)\u001b[0m\n03:18:12 | \u001b[33mOverriding opt[\"batchsize\"] to 40 (previously: 20)\u001b[0m\n03:18:12 | Using CUDA\n03:18:12 | loading dictionary from /tmp/model5.dict\n03:18:12 | num words = 54944\n03:18:17 | Loading existing model parameters from /tmp/model5\n03:18:23 | Total parameters: 128,042,498 (128,042,498 trainable)\n03:18:24 | Opt:\n03:18:24 |     activation: gelu\n03:18:24 |     adafactor_eps: '[1e-30, 0.001]'\n03:18:24 |     adam_eps: 1e-08\n03:18:24 |     add_p1_after_newln: False\n03:18:24 |     aggregate_micro: False\n03:18:24 |     allow_missing_init_opts: False\n03:18:24 |     area_under_curve_class: None\n03:18:24 |     area_under_curve_digits: -1\n03:18:24 |     attention_dropout: 0.1\n03:18:24 |     batchsize: 40\n03:18:24 |     betas: '[0.9, 0.999]'\n03:18:24 |     bpe_add_prefix_space: None\n03:18:24 |     bpe_debug: False\n03:18:24 |     bpe_dropout: None\n03:18:24 |     bpe_merge: None\n03:18:24 |     bpe_vocab: None\n03:18:24 |     candidates: inline\n03:18:24 |     cap_num_predictions: 100\n03:18:24 |     checkpoint_activations: False\n03:18:24 |     class_weights: None\n03:18:24 |     classes: \"['__notok__', '__ok__']\"\n03:18:24 |     classes_from_file: None\n03:18:24 |     data_parallel: True\n03:18:24 |     datapath: /opt/conda/lib/python3.7/site-packages/data\n03:18:24 |     datatype: train\n03:18:24 |     delimiter: '\\n'\n03:18:24 |     dict_class: parlai.core.dict:DictionaryAgent\n03:18:24 |     dict_endtoken: __start__\n03:18:24 |     dict_file: /tmp/model5.dict\n03:18:24 |     dict_include_test: False\n03:18:24 |     dict_include_valid: False\n03:18:24 |     dict_initpath: None\n03:18:24 |     dict_language: english\n03:18:24 |     dict_loaded: True\n03:18:24 |     dict_lower: True\n03:18:24 |     dict_max_ngram_size: -1\n03:18:24 |     dict_maxexs: -1\n03:18:24 |     dict_maxtokens: -1\n03:18:24 |     dict_minfreq: 0\n03:18:24 |     dict_nulltoken: __null__\n03:18:24 |     dict_starttoken: __start__\n03:18:24 |     dict_textfields: text,labels\n03:18:24 |     dict_tokenizer: bpe\n03:18:24 |     dict_unktoken: __unk__\n03:18:24 |     display_examples: False\n03:18:24 |     download_path: None\n03:18:24 |     dropout: 0.1\n03:18:24 |     dynamic_batching: None\n03:18:24 |     embedding_projection: random\n03:18:24 |     embedding_size: 768\n03:18:24 |     embedding_type: random\n03:18:24 |     embeddings_scale: False\n03:18:24 |     encode_candidate_vecs: True\n03:18:24 |     encode_candidate_vecs_batchsize: 256\n03:18:24 |     eval_batchsize: None\n03:18:24 |     eval_candidates: inline\n03:18:24 |     eval_dynamic_batching: None\n03:18:24 |     evaltask: None\n03:18:24 |     ffn_size: 3072\n03:18:24 |     final_extra_opt: \n03:18:24 |     fixed_candidate_vecs: reuse\n03:18:24 |     fixed_candidates_path: None\n03:18:24 |     force_fp16_tokens: True\n03:18:24 |     fp16: True\n03:18:24 |     fp16_impl: safe\n03:18:24 |     fromfile_datapath: ../input/comp599projproposed/proposed/prev2corr2type2/run5/data_test.txt\n03:18:24 |     fromfile_datatype_extension: True\n03:18:24 |     gpu: -1\n03:18:24 |     gradient_clip: 0.1\n03:18:24 |     hide_labels: False\n03:18:24 |     history_add_global_end_token: None\n03:18:24 |     history_reversed: False\n03:18:24 |     history_size: 20\n03:18:24 |     ignore_bad_candidates: False\n03:18:24 |     ignore_labels: None\n03:18:24 |     image_cropsize: 224\n03:18:24 |     image_mode: raw\n03:18:24 |     image_size: 256\n03:18:24 |     inference: max\n03:18:24 |     init_model: /opt/conda/lib/python3.7/site-packages/data/models/pretrained_transformers/bi_model_huge_reddit/model\n03:18:24 |     init_opt: None\n03:18:24 |     interactive_candidates: fixed\n03:18:24 |     interactive_mode: False\n03:18:24 |     invsqrt_lr_decay_gamma: -1\n03:18:24 |     is_debug: False\n03:18:24 |     label_truncate: 72\n03:18:24 |     learn_embeddings: True\n03:18:24 |     learn_positional_embeddings: True\n03:18:24 |     learningrate: 5e-05\n03:18:24 |     load_from_pretrained_ranker: True\n03:18:24 |     log_every_n_secs: 10.0\n03:18:24 |     log_every_n_steps: 50\n03:18:24 |     log_keep_fields: all\n03:18:24 |     loglevel: info\n03:18:24 |     lr_scheduler: reduceonplateau\n03:18:24 |     lr_scheduler_decay: 0.5\n03:18:24 |     lr_scheduler_patience: 3\n03:18:24 |     max_train_steps: -1\n03:18:24 |     max_train_time: 7200.0\n03:18:24 |     memory_attention: sqrt\n03:18:24 |     metrics: default\n03:18:24 |     model: transformer/classifier\n03:18:24 |     model_file: /tmp/model5\n03:18:24 |     model_parallel: False\n03:18:24 |     momentum: 0\n03:18:24 |     multitask_weights: [1]\n03:18:24 |     mutators: None\n03:18:24 |     n_decoder_layers: -1\n03:18:24 |     n_encoder_layers: -1\n03:18:24 |     n_heads: 12\n03:18:24 |     n_layers: 12\n03:18:24 |     n_positions: 1024\n03:18:24 |     n_segments: 2\n03:18:24 |     nesterov: True\n03:18:24 |     no_cuda: False\n03:18:24 |     normalize_sent_emb: False\n03:18:24 |     num_epochs: -1\n03:18:24 |     num_examples: -1\n03:18:24 |     num_workers: 0\n03:18:24 |     nus: [0.7]\n03:18:24 |     optimizer: adamax\n03:18:24 |     output_scaling: 0.06\n03:18:24 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': '../input/comp599projproposed/proposed/prev2corr2type2/run5/data_test.txt', 'model': 'transformer/classifier', 'model_file': '/tmp/model5', 'batchsize': 40}\"\n03:18:24 |     parlai_home: /opt/conda/lib/python3.7/site-packages\n03:18:24 |     person_tokens: False\n03:18:24 |     print_scores: False\n03:18:24 |     rank_candidates: False\n03:18:24 |     rank_top_k: -1\n03:18:24 |     reduction_type: mean\n03:18:24 |     ref_class: None\n03:18:24 |     relu_dropout: 0.0\n03:18:24 |     repeat_blocking_heuristic: True\n03:18:24 |     report_filename: \n03:18:24 |     return_cand_scores: False\n03:18:24 |     save_after_valid: True\n03:18:24 |     save_every_n_secs: -1\n03:18:24 |     save_format: conversations\n03:18:24 |     share_encoders: False\n03:18:24 |     share_word_embeddings: False\n03:18:24 |     short_final_eval: False\n03:18:24 |     special_tok_lst: None\n03:18:24 |     split_lines: False\n03:18:24 |     starttime: Dec04_03-06\n03:18:24 |     task: fromfile:parlaiformat\n03:18:24 |     tensorboard_log: False\n03:18:24 |     tensorboard_logdir: None\n03:18:24 |     text_truncate: 360\n03:18:24 |     threshold: 0.5\n03:18:24 |     topk: 5\n03:18:24 |     train_predict: False\n03:18:24 |     truncate: 1024\n03:18:24 |     update_classifier_head_only: False\n03:18:24 |     update_freq: 1\n03:18:24 |     use_memories: False\n03:18:24 |     use_reply: none\n03:18:24 |     validation_cutoff: 1.0\n03:18:24 |     validation_every_n_epochs: -1\n03:18:24 |     validation_every_n_secs: 20.0\n03:18:24 |     validation_every_n_steps: -1\n03:18:24 |     validation_max_exs: -1\n03:18:24 |     validation_metric: accuracy\n03:18:24 |     validation_metric_mode: max\n03:18:24 |     validation_patience: 30\n03:18:24 |     validation_share_agent: False\n03:18:24 |     variant: xlm\n03:18:24 |     verbose: False\n03:18:24 |     wandb_entity: None\n03:18:24 |     wandb_log: False\n03:18:24 |     wandb_name: None\n03:18:24 |     wandb_project: None\n03:18:24 |     warmup_rate: 0.0001\n03:18:24 |     warmup_updates: 1000\n03:18:24 |     weight_decay: None\n03:18:24 |     world_logs: \n03:18:24 |     wrap_memory_encoder: False\n03:18:24 | Evaluating task fromfile:parlaiformat using datatype valid.\n03:18:24 | creating task(s): fromfile:parlaiformat\n03:18:24 | \u001b[33mYou are using this fromfile data as a valid or test set without setting fromfile_datatype_extension to true. Please be aware this uses directly the file you indicated, make sure this is not the same as your training file.\u001b[0m\n03:18:24 | Loading ParlAI text data: ../input/comp599projproposed/proposed/prev2corr2type2/run5/data_test.txt\n03:18:32 | \u001b[1mReport for fromfile:parlaiformat:\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9070 9.07e-10               .6760                 .5187   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9700            .9457              .9963   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9000 12.07 562.9  1860       0          0 132.2 1000 .9070   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5177 5.104e-06   208 687.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    102 770.9 2547        .9187\u001b[0m\n03:18:32 | Finished evaluating tasks ['fromfile:parlaiformat'] using datatype valid\n    accuracy   bleu-4  class___notok___f1  class___notok___prec  \\\n       .9070 9.07e-10               .6760                 .5187   \n    class___notok___recall  class___ok___f1  class___ok___prec  \\\n                     .9700            .9457              .9963   \n    class___ok___recall  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  \\\n                  .9000 12.07 562.9  1860       0          0 132.2 1000 .9070   \n    gpu_mem  llen  loss        lr  ltpb  ltps  ltrunc  ltrunclen  \\\n     .08267   5.2 .5177 5.104e-06   208 687.3       0          0   \n    total_train_updates   tpb  tps  weighted_f1  \n                    102 770.9 2547        .9187\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean up to make sure to not affect later runs\n!rm /tmp/model5*","metadata":{"execution":{"iopub.status.busy":"2022-12-04T03:18:34.523143Z","iopub.execute_input":"2022-12-04T03:18:34.523518Z","iopub.status.idle":"2022-12-04T03:18:35.723988Z","shell.execute_reply.started":"2022-12-04T03:18:34.523485Z","shell.execute_reply":"2022-12-04T03:18:35.722581Z"},"trusted":true},"execution_count":125,"outputs":[]}]}